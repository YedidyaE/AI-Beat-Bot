{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Bidirectional, Dense, Dropout, LSTM, Activation, TimeDistributed, Embedding\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, History, Callback\n",
    "from keras.utils import np_utils\n",
    "import re \n",
    "import pandas as pd\n",
    "import music21\n",
    "import IPython\n",
    "from tqdm import tqdm\n",
    "\n",
    "from playsound import playsound\n",
    "from datetime import datetime\n",
    "from music21 import converter, instrument, note, chord, stream\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_directory = \"/Users/anant.a.sharma/Desktop/Darya/AI-Jukebox/Model3\"\n",
    "data_file = \"classical.txt\"\n",
    "charIndex_json = \"char_to_index.json\"\n",
    "model_weights_directory = '/Users/anant.a.sharma/Desktop/Darya/AI-Jukebox/Model3/Test3_Weights/'\n",
    "BATCH_SIZE = 16\n",
    "SEQ_LENGTH = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_batches(all_chars, unique_chars):\n",
    "    length = all_chars.shape[0]\n",
    "    batch_chars = int(length / BATCH_SIZE) #155222/16 = 9701\n",
    "    \n",
    "    for start in range(0, batch_chars - SEQ_LENGTH, 64):  #(0, 9637, 64)  #it denotes number of batches. It runs everytime when\n",
    "        #new batch is created. We have a total of 151 batches.\n",
    "        X = np.zeros((BATCH_SIZE, SEQ_LENGTH))    #(16, 64)\n",
    "        Y = np.zeros((BATCH_SIZE, SEQ_LENGTH, unique_chars))   #(16, 64, 87)\n",
    "        for batch_index in range(0, 16):  #it denotes each row in a batch.  \n",
    "            for i in range(0, 64):  #it denotes each column in a batch. Each column represents each character means \n",
    "                #each time-step character in a sequence.\n",
    "                X[batch_index, i] = all_chars[batch_index * batch_chars + start + i]\n",
    "                Y[batch_index, i, all_chars[batch_index * batch_chars + start + i + 1]] = 1 #here we have added '1' because the\n",
    "                #correct label will be the next character in the sequence. So, the next character will be denoted by\n",
    "                #all_chars[batch_index * batch_chars + start + i + 1]\n",
    "        yield X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def built_model(batch_size, seq_length, unique_chars):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim = unique_chars, output_dim = 512, batch_input_shape = (batch_size, seq_length), name = \"embd_1\")) \n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True, name = \"lstm_first\"))\n",
    "    model.add(Dropout(0.2, name = \"drp_1\"))\n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(TimeDistributed(Dense(unique_chars)))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(data, epochs = 90):\n",
    "    #mapping character to index\n",
    "    char_to_index = {ch: i for (i, ch) in enumerate(sorted(list(set(data))))}\n",
    "    print(\"Number of unique characters in our whole tunes database = {}\".format(len(char_to_index))) #87\n",
    "    \n",
    "    with open(os.path.join(data_directory, charIndex_json), mode = \"w\") as f:\n",
    "        json.dump(char_to_index, f)\n",
    "        \n",
    "    index_to_char = {i: ch for (ch, i) in char_to_index.items()}\n",
    "    unique_chars = len(char_to_index)\n",
    "    \n",
    "    model = built_model(BATCH_SIZE, SEQ_LENGTH, unique_chars)\n",
    "    model.summary()\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    all_characters = np.asarray([char_to_index[c] for c in data], dtype = np.int32)\n",
    "    print(\"Total number of characters = \"+str(all_characters.shape[0])) #155222\n",
    "    \n",
    "    epoch_number, loss, accuracy = [], [], []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(\"Epoch {}/{}\".format(epoch+1, epochs))\n",
    "        final_epoch_loss, final_epoch_accuracy = 0, 0\n",
    "        epoch_number.append(epoch+1)\n",
    "        \n",
    "        for i, (x, y) in enumerate(read_batches(all_characters, unique_chars)):\n",
    "            final_epoch_loss, final_epoch_accuracy = model.train_on_batch(x, y) #check documentation of train_on_batch here: https://keras.io/models/sequential/\n",
    "            print(\"Batch: {}, Loss: {}, Accuracy: {}\".format(i+1, final_epoch_loss, final_epoch_accuracy))\n",
    "            #here, above we are reading the batches one-by-one and train our model on each batch one-by-one.\n",
    "        loss.append(final_epoch_loss)\n",
    "        accuracy.append(final_epoch_accuracy)\n",
    "        \n",
    "        #saving weights after every 10 epochs\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            if not os.path.exists(model_weights_directory):\n",
    "                os.makedirs(model_weights_directory)\n",
    "            model.save_weights(os.path.join(model_weights_directory, \"Weights_{}.h5\".format(epoch+1)))\n",
    "            print('Saved Weights at epoch {} to file Weights_{}.h5'.format(epoch+1, epoch+1))\n",
    "    \n",
    "    #creating dataframe and record all the losses and accuracies at each epoch\n",
    "    log_frame = pd.DataFrame(columns = [\"Epoch\", \"Loss\", \"Accuracy\"])\n",
    "    log_frame[\"Epoch\"] = epoch_number\n",
    "    log_frame[\"Loss\"] = loss\n",
    "    log_frame[\"Accuracy\"] = accuracy\n",
    "    log_frame.to_csv(\"/Users/anant.a.sharma/Desktop/Darya/AI-Jukebox/Model3/log.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"X:1 \\nT:Chaconne from Partita 2 for Solo Violin (D Major section only)\\nR:Classical\\nC:J.S. Bach\\nN:(LOTRO) Best played on lute or harp\\nZ:Transcribed by Eleiniel, Brandywine server\\nM:3/4\\nL:1/4\\nQ:1/4=60 \\nK:D\\n\\n[D2F3/2] G/ | [CE] [A,2F3/2] G/4 A5/16 | [B,D] [G,2E3/2] F/4 G/4 | [A,F/] E/ [C2E3/2] A/ | [DF] [D3/2F/B/] A/ G/ [D/F/] | [EC/] B,/ [A,3/2F/4] G/4 A/4 G/4 F/ [A,/E/] |\\n[DB,/] A,/ [G,3/2E/] G/4 F/4 E/ [G,/D/] | [A,G/c/] [F/d/] [A,2E3/2] A/ | [DF/] E/ D/ E/ F/ +f+[D/^G/] | [CEA/] B/ [A,3/2E3/2c/] d/ B/ [A,/G/C/] | +ff+[B,Fd/] f/ [G,3/2G3/2B3/2e/] d/ c/ [G,/G/B/] |\\n[A,F/A/] [D/B/] [A,3/2E/c/] [F/d/] [G/e/] [A,/E/c/] | [dD/F/] E/ [d3/2f3/2D/] E/ F/ [G/d/f/] | [eA/c/] B/ [a3/2c/] A/ B/ [c/g/] | [d/f/] [c/e/] [B/g/] [A/f/] [G/d/b/] [F/B/a/] | [E/c/g/] [D/d/f/] [A2e2d] c |\\n[D/d/4]+mp+c/4B/4A/4 ^G/4B/4d/4f/4 e/ +f+[D/^G/B/e/] | [A/c/e/^C/4]+mp+D/4C/4B,/4 A,/4C/4E/4=G/4 F/ +f+[^A,/F/c/e/] | [F/d/B/4]+mp+C/4D/4B,/4 G,/4B,/4D/4F/4 E/ +f+[^G,/E/d/] | [A,/4E/4c/4]+mp+B/4A/4B/4 c/4e/4g/4b/4 a/4g/4f/4e/4 |\\n+p+f3/8a/4f/4d/4 A/4d/4A/4F/4 D/4F/4E/4D/4 | C3/8a/4e/4c/4 A/4c/4A/4E/4 C/4E/4D/4C/4 | B,3/8^g/4d/4B/4 ^G/4B/4^G/4E/4 B,/4D/4C/4B,/4 | A,/4B,/4C/4D/4 E/4C/4A,/4C/4 E/4=G/4F/4E/4 |\\nF3/8D/4A,/4D/4 +mp+F/4D/4+mf+A/4F/4 +f+d/4A/4+ff+f/4d/4 | a/4e/4c/4e/4 a/4e/4c/4a/4 e/4c/4f/4c/4 | d/4f/4d/4b/4 +f+f/4b/4d/4f/4 +mf+B/4d/4c/4B/4 | +mp+c/4e/4c/4A/4 +p+E/4A/4C/4E/4 A,/4C/4E/4G/4 |\\nF3/8D/4a/4a/4 a/4f/4d/4A/4 F/4D/4A,/4D/4 | E5/16C/4+mp+a/4+mf+a/4 a/4+mf+e/4c/4A/4 +mp+E/4C/4A,/4C/4 | +p+D5/16B,/4+mp+a/4+mf+a/4 +f+a/4+mf+f/4d/4B/4 +f+d/4^g/4b/4^g/4 | +ff+a3/8e/4a/4a/4 a/4+mf+c/4e/4e/4 e/4+mp+A/4c/4=G/4 |\\n+p+F3/8D/4 A/4A/4 A/4F/4D/4F/4 A/4d/4f/4B,/4 | C5/16E/4A/4A/4 A/4E/4C/4E/4 A/4c/4e/4A,/4 | B,5/16D/4A/4A/4 A/4D/4B,/4D/4 ^G/4B/4d/4E/4 |\\nA,5/16E/4A/4A/4 A/4E/4A/4c/4 e/4c/4A/4=G/4 | F/4A,/4A,/4A,/4 A,/4+f+a/4a/4[d/4f/4] [d/4f/4][A/4d/4][A/4d/4][d/4f/4] | [c/4e/4]+p+A,/4A,/4A,/4 A,/4+f+a/4a/4[c/4e/4] [c/4e/4][A/4c/4][A/4c/4][c/4e/4] |\\n[^G/4d/4]+p+A,/4A,/4A,/4 A,/4+f+b/4b/4[B/4^g/4] [B/4^g/4][d/4e/4][d/4e/4][d/4^g/4] | [c3/8a3/8]A,/4A,/4A,/4 A,/4[A/4a/4][A/4a/4][A/4a/4] [B/4a/4][B/4=g/4][c/4=g/4][c/4=g/4] | [d/4f/4]D/4D/4D/4 D/4A/4A/4A/4 [A/4B/4][G/4B/4][G/4c/4][G/4c/4] |\\n[F/4d/4]D/4D/4D/4 D/4[D5/16d5/16][D9/32d9/32][D9/32d9/32] [d5/16e5/16][e/4=c/4][f/4=c/4][f/4=c/4] | [g/4b/4]D/4D/4D/4 D/4+ff+[g/4b/4][g/4b/4][g/4b/4] [g/4^c/4][f/4d/4][f/4d/4][f/4d/4] | +fff+[f/4g/4][e/4g/4][e/4g/4][e/4g/4] [e/4f/4][F/4d/4f/4][F/4d/4f/4][F/4d/4f/4] [G/4d/4e/4][A5/16c5/16e5/16][A5/16c5/16e5/16][A3/8c3/8e3/8] |\\n\\n+fff+[D/8d/8][Ddf] [d3/2f3/2] [d/f/] | [df/]e/ [e3/2d/]c/ B/[^A/e/] | [Be/]d/ [=c3/2B/]A/ G/[F/=c/] | [G=c/]B/ ^c/[G/A/b/] [F/B/a/][E/c/g/] | [dfD/]F/ [d3/2f3/2B/]A/ G/[F/d/f/] |\\n[deG/]E/ [c3/2e3/2A/]G/ F/[E/c/e/] | [F/=c/a/][D/d/f/] [G,/8G/8][d/b/][=c/a/] [B/g/][A/f/] | [G/e/][F/d/] [A,/8E/8][E3/2^c3/2]d/ | [A,Fd] [D/8F/8][F3/2A3/2] [D/F/A/] | [=CFA] [=C/8F/8][F3/2A3/2][F/A/] |\\n[B,GB] [E/8G/8][E3/2G3/2B3/2] [G/B/] | [A,G/c/][F/d/] [dE/]D/ E/c/ | [Dd] [D3/16A3/16][d3/2f3/2][D/A/d/f/] | [=CDAf] [=C/8D/8][A3/2f3/2][=C/D/A/f/] | [B,Gdf] [^C/8G/8][A3/2e3/2][^C/G/A/e/] |\\n[DFA/e/]d/ [A,dE/]F/ G/c/ | [dF/]E/ [D3/2d3/2f3/2][D/d/f/] | [Edg] [F3/2d3/2a3/2][F/d/a/] | [Gdb] [^G3/2e3/2b3/2][^G/e/b/] | [Ae/c/][f/d/] [A2e2d] c | [Dfd] [D3/2f3/2d3/2][D/f/d/] |\\n[Aec] [D3/2f3/2=c3/2][D/f/=c/] | [Gbg/]d/ [^G3/2d3/2e3/2][^G/d/e/] | [Ade/]f/ [A,/9E/9][c4/8=g4/8]b10/16 a/[A,9/16E9/16c9/16=g9/16] |\\n\\n+f+[D3/8d3/8][d/4f/4][d/4f/4][D/4d/4] [D/4A/4][A/4f/4][A/4f/4][D/4A/4] [C5/16D5/16][A/4f/4][A/4f/4][C/4D/4] | [B,/4D/4][B/4f/4][B/4f/4][B,/4D/4] [B,/4D/4][B/4f/4][B/4f/4][B,/4D/4] [A,/4D/4][B/4f/4][B/4f/4][A,/4D/4] |\\n[G,/4D/4][B/4e/4][B/4e/4][G,/4D/4] [G,/4E/4][c/4a/4][c/4a/4][G,/4E/4] [G,/4E/4][E/4c/4][E/4c/4][G,/4E/4] | [^G,/4E/4][d/4b/4][d/4b/4][^G,/4E/4] [A,/4E/4][d/4e/4][A,/4E/4][d/4f/4] [A,/4E/4][c/4=g/4][c/4=g/4][A,/4E/4] |\\n[D/4d/4][d/4g/4][d/4g/4][D/4d/4] [D/4A/4][A/4f/4][D/4A/4][B/4f/4] [D/4=c/4][=c/4f/4][=c/4f/4][D/4=c/4] | [G,/4D/4][B/4f/4][B/4f/4][G,/4D/4] [G,/4E/4][B/4e/4][G,/4E/4][^c/4e/4] [^G,/4E/4][d/4e/4][d/4e/4][^G,/4E/4] |\\n[A,/4E/4][d/4e/4][d/4e/4][A,/4E/4] [A,/4E/4][c/4e/4][c/4e/4][A,/4F/4] [^A,/4=G/4][c/4e/4][c/4e/4][^A,/4=G/4] |\\n[B,11/16F11/16d11/16][G,13/16E13/16d13/16b13/16] [A,3/2E3/2c/4]d/12c/12d/12c/12d/12c/12d/12c/12d/12c/12d/12 c5/8[A,5/8E5/8d5/8] | [D3d3]\\n\\n\\nX:1\\nT:Fugue - Flute 1\\nC:Bach\\nZ:Giddily\\nM:4/4\\nL:1/8\\nQ:1/4=52\\nK:Bb\\n\\nG2 d2 B3A|GB AG _GA D2|=GD AD BA/2G/2 AD|GD/2G/2 AD/2A/2 BA/2G/2 A/2D/2d/2c/2|\\nB/2A/2G/2B/2 A/2G/2_G/2A/2 =G/2D/2G,/2A,/2 B,/2C/2D/2=E/2|F/2=E/2D/2F/2 =E/2D/2_D/2=E/2 =DA, D=E|F/2G/2F/2G/2 G/2G/2G/2F/2 A/2G/2A/2B/2 A/2G/2F/2=E/2|F/2A/2G/2A/2 _D/2A/2G/2A/2 =D/2A/2G/2A/2 _D/2A/2G/2A/2|\\nF/2=D/2_D/2=D/2 G/2D/2_D/2=D/2 A/2D/2_D/2=D/2 G/2D/2_D/2=D/2|A,F G,=E F,A, DF|_EA2E DG2D|C/2B,/2C/2D/2 C/2A/2G/2A/2 B,/2G/2_G/2=G/2 A,/2_G/2=E/2_G/2|\\n=G6 z2|z4 B/2d/2c/2d/2 _G/2d/2c/2d/2|=G/2d/2c/2d/2 _G/2d/2c/2d/2 B2 c2|d2 c2 zB2A|\\nzD =G/2A/2B/2G/2 Ad _d=e|A/2B/2A/2G/2 F/2=E/2D/2_D/2 =D2 B2|=E2 zA A/2A/2A/2A/2 A/2A/2A/2A/2|A/2A/2A/2A/2 A/2A/2A/2A/2 A/2A/2A/2A/2 A/2A/2A/2A/2|\\nA/2A/2A/2A/2 A/2A/2A/2A/2 A/2G/2A/2B/2 A/2G/2F/2=E/2|F4 zD GF|_E4- EC FE|D2- D/2G/2_G/2=G/2 C2- C/2B/2A/2B/2|\\nB/2A/2G/2B/2 A/2G/2_G/2A/2 =G/2D/2=E/2_G/2 =G/2D/2G/2A/2|B/2G/2B/2c/2 =d/2A/2d/2c/2 B3A|GB AG _GA D2|=GD AD BA/2G/2 AD|\\nGD/2G/2 AD/2A/2 BA/2G/2 A/2D/2d/2c/2|B/2A/2G/2B/2 A/2G/2_G/2A/2 =G/2B/2c/2d/2 _e/2B/2A/2G/2|_G/2A/2B/2c/2 d/2A/2=G/2F/2 _E/2G/2A/2B/2 c/2G/2F/2E/2|D/2F/2G/2A/2 B/2d/2c/2B/2 A/2C/2D/2E/2 F/2G/2F/2E/2|\\nD/2F/2E/2D/2 C/2B,/2A,/2C/2 B,/2F,/2G,/2A,/2 B,/2C/2B,/2C/2|D/2=E/2D/2=E/2 =E/2=E/2=E/2D/2 F/2_E/2F/2G/2 F/2E/2D/2C/2|D/2F/2E/2F/2 A,/2F/2E/2F/2 B,/2F/2E/2F/2 A,/2F/2E/2F/2|D/2B,/2A,/2B,/2 E/2B,/2A,/2B,/2 F/2B,/2A,/2B,/2 E/2B,/2A,/2B,/2|\\nB,/2C/2D/2B,/2 E/2D/2C/2E/2 D/2C/2D/2E/2 D/2C/2B,/2D/2|C/2B,/2C/2D/2 C/2B,/2A,/2C/2 B,/2A,/2B,/2C/2 B,/2A,/2G,/2B,/2|A,F2_A, G,F2G,|F,D2F E/2G/2c/2B/2 A/2G/2F/2E/2|\\nD/2E/2F/2G/2 A/2B/2c/2A/2 B/2F,/2G,/2=A,/2 B,/2C/2B,/2C/2|D/2=E/2D/2=E/2 =E/2=E/2=E/2D/2 F/2=E/2F/2G/2 FF|F/2F/2F/2F/2 F/2F/2F/2F/2 F/2F/2F/2F/2 F/2F/2F/2F/2|F/2F/2F/2F/2 F/2F/2F/2F/2 F/2F/2F/2F/2 F/2F/2F/2F/2|\\nF/2_E/2F/2G/2 C3/2A/2 B/2A/2B/2c/2 B/2A/2G/2F/2|E/2D/2E/2F/2 E/2D/2C/2B,/2 A/2G/2A/2B/2 A/2G/2F/2E/2|D/2C/2D/2E/2 D/2C/2B,/2A,/2 G/2F/2G/2_A/2 G/2F/2E/2D/2|C/2=B,/2C/2D/2 C/2D/2E/2C/2 F2- F/2_A/2G/2F/2|\\nE4- E/2C/2D/2E/2 F/2G/2_A/2F/2|=B,/2C/2D/2=B,/2 G,2 C2 G2|E3D CE DC|=B,D G,2 CG, DG,|\\nED/2C/2 DG, CG,/2C/2 DG,/2D/2|ED/2C/2 D/2G,/2G/2F/2 E/2D/2C/2E/2 D/2C/2=B,/2D/2|C/2G/2E/2G/2 C/2E/2G,/2_B,/2 A,/2C/2A,/2C/2 F,/2A,/2C,/2E,/2|D,/2F/2D/2F/2 B,/2D/2F,/2A,/2 G,/2B,/2G,/2B,/2 E,/2G,/2B,/2D,/2|\\nC,/2E/2C/2E/2 A,/2C/2=E,/2G,/2 _G,/2A,/2_G,/2A,/2 D,/2_G,/2A,/2C,/2|B,=G, A,_G, =G,4|G,/2B,/2A,/2G,/2 D/2A,/2D,/2A,/2 B,/2D/2C/2B,/2 F/2C/2F,/2E/2|D/2F/2E/2D/2 G/2D/2G,/2F/2 =E/2G/2F/2=E/2 =A/2=E/2A,/2G/2|\\n_G2 =GA B4-|B2 A4 G2-|G2 _G2 =G4|zD GA B/2A/2G/2A/2 _G/2=G/2_G/2=G/2|\\nA/2G/2_G/2=E/2 D/2C/2B,/2A,/2 B,/2D/2C/2D/2 _G,/2D/2C/2D/2|=G,/2D/2C/2D/2 _G,/2D/2C/2D/2 B,/2=G,/2_G,/2=G,/2 C/2G,/2_G,/2=G,/2|D/2G,/2_G,/2=G,/2 C/2G,/2_G,/2=G,/2 B,=G A,_G|=G8-|\\nG8|\\n\\nX:2\\nT:Fugue-Flute 2\\nC:Bach\\nZ:Giddily\\nM:4/4\\nL:1/8\\nQ:1/4=52\\nK:Bb\\n\\nz8|z8|z8|z8|\\nz8|z8|z8|z8|\\nz8|z8|z8|z4 G,2 D2|\\nB,3A, G,B, A,G,|_G,A, D,2 =G,D, A,D,|B,A,/2G,/2 A,D, G,D,/2G,/2 A,D,/2A,/2|B,A,/2G,/2 A,/2D,/2D/2C/2 B,/2A,/2G,/2B,/2 A,/2G,/2_G,/2A,/2|\\n=G,/2D,/2G,/2A,/2 B,/2C/2D/2=E/2 F/2=E/2D/2F/2 =E/2D/2_D/2=E/2|=DA, D=E F/2G/2F/2G/2 G/2G/2G/2F/2|A/2G/2A/2B/2 A/2G/2F/2=E/2 F/2A/2G/2A/2 _D/2A/2G/2A/2|=D/2A/2G/2A/2 _D/2A/2G/2A/2 F/2=D/2_D/2=D/2 G/2D/2_D/2=D/2|\\nA/2D/2_D/2=D/2 G/2D/2_D/2=D/2 F=E/2D/2 _D/2_D/2_D/2=D/2|D/2C/2D/2=E/2 D/2C/2B,/2A,/2 G,/2F,/2G,/2A,/2 G,/2F,/2E,/2D,/2|C/2B,/2C/2D/2 C/2B,/2A,/2G,/2 F,/2E,/2F,/2G,/2 F,/2E,/2D,/2C,/2|B,/2B,/2C/2D/2 _E2- E/2A,/2B,/2C/2 D2|\\nG,2 D2 B,3A,|G,/2B,/2A,/2G,/2 _G,/2=G,/2=E,/2_G,/2 =G,/2D,/2=E,/2_G,/2 =G,/2D,/2G,/2A,/2|B,/2C/2B,/2C/2 C/2C/2C/2B,/2 D/2C/2D/2E/2 D/2C/2B,/2A,/2|B,/2D/2C/2D/2 _G,/2D/2C/2D/2 =G,/2D/2C/2D/2 _G,/2D/2C/2D/2|\\nB,/2=G,/2_G,/2=G,/2 C/2G,/2_G,/2=G,/2 D/2G,/2_G,/2=G,/2 C/2G,/2_G,/2=G,/2|G,B, C/2B,/2A,/2C/2 B,2- B,/2D/2C/2B,/2|A,2- A,/2C/2B,/2A,/2 G,2- G,/2B,/2A,/2G,/2|F,3=E, F,_E, D,C,|\\nB,4 zC B,A,|G,4 F,2 F,2|B,F, CF, DC/2B,/2 CF,|B,F,/2B,/2 CF,/2C/2 DC/2B,/2 C/2F,/2F/2E/2|\\nD/2C/2B,/2D/2 C/2B,/2A,/2C/2 B,G2G,|A,F2F, G,F C=E|F/2_E/2F/2G/2 F/2E/2D/2F/2 E/2D/2E/2F/2 E/2D/2C/2E/2|D/2C/2D/2E/2 D/2C/2B,/2D/2 C/2B,/2C/2D/2 C/2B,/2A,/2C/2|\\nB,/2C/2D/2B,/2 C/2D/2E/2C/2 D/2C/2B,/2C/2 D/2E/2D/2E/2|F/2G/2F/2G/2 G/2G/2G/2F/2 A/2G/2A/2B/2 A/2G/2F/2E/2|D/2F/2E/2F/2 A,/2F/2E/2F/2 B,/2F/2E/2F/2 A,/2F/2E/2F/2|D/2B/2A/2B/2 E/2B/2A/2B/2 F/2B/2A/2B/2 E/2B/2A/2B/2|\\nB/2d/2c/2B/2 A/2G/2F/2E/2 D4-|DG, CB, A,4-|A,F, B,A, G,4-|G,E, _A,G, F,2 G,2-|\\nG,/2G,/2=A,/2=B,/2 C/2D/2E/2C/2 _A,4|G,=A, =B,2 C2 z2|z8|z8|\\nz8|z8|zG, E,C, F,4|zF, D,B, E,4|\\nzE, C,A, D,4|G,/2B,/2A,/2G,/2 D,/2A,/2D,/2C,/2 B,D, _G,D,|G,2 _G,2 =G,2 A,2|_B,2 =B,2 C2 _D2|\\n=D2 =E_G =G2 AB|c/2G/2F/2_E/2 c/2A/2F/2A/2 _B,/2F/2E/2D/2 B/2G/2E/2G/2|A,/2E/2D/2C/2 A/2_G/2D/2_G/2 G,/2B,/2D/2=G/2 _G/2=G/2=E/2_G/2|=G3_G =G2 AD|\\nD3_G, =G,2 C2|B,2 C2 B,2 A,2|G,2 A,2 G,B, CA,|=B,8-|\\n=B,8|\\n\\nX:3\\nT:Fugue-Clarinet\\nC:Bach\\nZ:Giddily\\nM:4/4\\nL:1/8\\nQ:1/4=52\\nK:Bb\\n\\nz8|z8|z8|z8|\\nz8|D2 A2 F3=E|DF =ED _D=E A,2|=DA, =EA, F=E/2D/2 =EA,|\\nDA,/2D/2 =EA,/2=E/2 F=E/2D/2 =E/2A,/2A/2G/2|F/2=E/2D/2F/2 =E/2D/2_D/2=E/2 =D/2A,/2D/2=E/2 F/2G/2A/2=B/2|c/2_B/2c/2d/2 c/2B/2A/2c/2 B/2A/2B/2c/2 B/2A/2G/2B/2|AG _GD =G4|\\nzD GA B/2c/2B/2c/2 c/2c/2c/2B/2|d/2c/2d/2e/2 d/2c/2B/2A/2 D2 C2|D2 C2- C/2G/2_G/2=GG/2_G/2=G/2-|G/2G/2_G/2=GG/2_G/2=G/2 D2 C2|\\nB,4 z4|z8|z8|z8|\\nz8|zA dc B4-|BG cB A4-|A2 G4 _G2|\\n=G2 z6|z8|z8|z8|\\nz8|z8|z8|z8|\\nB,2 F2 D3C|B,D CB, A,C2F|F/2F/2F/2F/2 F/2F/2F/2F/2 F/2F/2F/2F/2 F/2F/2F/2F/2|F/2F/2F/2F/2 F/2F/2F/2F/2 F/2F/2F/2F/2 F/2F/2F/2F/2|\\nG/2z6z3/2|z8|z8|z8|\\nz8|z8|z8|z8|\\nz4 zF BA|G4- GC AG|F4- FB, GF|_E4- E/2E/2D/2C/2 =B,2|\\nC4 zC _AF-|F2- F/2F/2E/2D/2 E/2D/2C/2E/2 D/2C/2=B,/2D/2|C/2G,/2C/2D/2 E/2F/2E/2F/2 G/2E/2C/2G/2 _A/2F/2G/2_A/2|D/2E/2D/2C/2 =B,D G,/2G,/2G,/2G,/2 G,/2G,/2G,/2G,/2|\\nG,/2G,/2G,/2G,/2 G,/2G,/2G,/2G,/2 G,/2G,/2G,/2G,/2 G,/2G,/2G,/2G,/2|G,/2G,/2G,/2G,/2 G,/2G,/2G,/2G,/2 G,G F/2E/2D/2F/2|E4 zC A,F,|_B,4- B,B, G,_E,|\\nA,4- A,A, _G,D,|=G,4 G,/2B,/2A,/2G,/2 D/2A,/2D,/2A,/2|B,D A,D2G CF-|FF DG2G =E=A-|\\nA/2_E/2D/2C/2 B,/2D/2A,/2D/2 G,/2_A/2G/2F/2 G/2F/2E/2D/2|E4 D4|C4 B/2d/2c/2B/2 =A/2B/2G/2A/2|B/2c/2B/2c/2 d/2e/2d/2c/2 Bd cB|\\nA3D D/2D/2D/2D/2 D/2D/2D/2D/2|D/2D/2D/2D/2 D/2D/2D/2D/2 D/2D/2D/2D/2 D/2D/2D/2D/2|D/2D/2D/2D/2 D/2D/2D/2D/2 DE2D|D8-|\\nD8|\\n\\nX:4\\nT:Fugue-Horn\\nC:Bach\\nZ:Giddily\\nM:4/4\\nL:1/8\\nQ:1/4=52\\nK:Bb\\n\\nz8|z8|z8|z8|\\nz8|z8|z8|z8|\\nz8|z8|z8|z8|\\nz8|z8|z8|z8|\\nz4 D,2 A,2|F,3=E, D,F, =E,D,|_D,=E, A,2 =D,A, =E,A,|F,=E,/2D,/2 =E,A, D,A,/2D,/2 =E,A,/2=E,/2|\\nF,=E,/2D,/2 =E,A, D,=G, A,2|D,4 z4|z8|z8|\\nz8|z4 zG, GF|_E2 _E,2 D,D D/2D/2D/2D/2|D,/2D,/2D,/2D,/2 D,/2D,/2D,/2D,/2 D,/2D,/2D,/2D,/2 D,/2D,/2D,/2D,/2|\\nD,/2D,/2D,/2D,/2 D,/2D,/2D,/2D,/2 D,/2D,/2D,/2D,/2 D,/2D,/2D,/2D,/2|D,/2D,/2D,/2D,/2 D,/2D,/2D,/2D,/2 D,/2D,/2D,/2D,/2 C,2-|C,2 B,4 A,2|B,A, G,2 F,4|\\nz8|z8|z8|z8|\\nz8|z8|z8|z8|\\nB,2 F,2 D,3C,|B,D, C,B, A,C, F,2|B,F, C,F, D,C,/2B,/2 C,F,|B,F,/2B,/2 C,F,/2C,/2 D,C,/2B,/2 C,F,|\\nD,E, F,F, B,4|C4 F,4|_B,4 E,4|_A,4 D,2 G,2|\\nC,4 F,4|G,8|C,G, C,D, E,2 F,2|G,2- G,/2G,/2F,/2G,/2 E,/2G,/2F,/2G,/2 =B,/2G,/2F,/2G,/2|\\nC,/2G,/2F,/2G,/2 =B,/2G,/2F,/2G,/2 E,/2C/2=B,/2C/2 F,/2C/2=B,/2C/2|G,/2C/2=B,/2C/2 G,/2=B,/2=A,/2=B,/2 C,E, F,G,|C,4 z4|z8|\\nz8|z8|z8|z8|\\nz8|z8|z4 G,2 D2|_B,3A, G,B, A,G,|\\n_G,A, D,2 =G,D, A,D,|B,A,/2G,/2 A,D, G,D,/2G,/2 A,D,/2A,/2|B,A,/2G,/2 A,D, G,E, C,D,|G,8-|\\nG,8|\\n\\n\\nX: 1\\nT: Prelude & Fugue\\nC: Bach\\nZ: by Tiamo/Skjald\\nL: 1/4\\nQ: 1/4=120\\nK: C\\n[^D13/4z3/8] [G13/4z/2] [^A9/8z3/8] [^d9/8z3/8] [g9/8z3/8]\\n[^A2z3/8] [^d2z3/8] [g2z/2] [^D25/8z3/8] [G11/4z3/8] [^A9/8z3/8]\\n[^d9/8z3/8] [g5/4z3/8] [^A13/8z/2] [^d9/8z3/8] [g15/8z3/8]\\n[^D25/8z3/8] [F25/8z3/8] [c5/4z3/8] [f5/4z/2] [^g9/8z3/8] [c15/8z3/8]\\n[f2z3/8] [^g2z3/8] [^D25/8z3/8] [F13/4z3/8] [c5/4z/2] [f9/8z3/8]\\n[^g9/8z3/8] [c3/2z3/8] [f2z3/8] [^g2z3/8] [=D13/4z/2] [F25/8z3/8]\\n[^A9/8z3/8] [f9/8z3/8] [^g9/8z3/8] [^A2z3/8] [f2z/2] [^g15/8z3/8]\\n[D25/8z3/8] [F11/4z3/8] [^A9/8z3/8] [f5/4z3/8] [^g5/4z/2]\\n[^A15/8z3/8] [f9/8z3/8] [^g3/4z3/8] [^D25/8z3/8] [G25/8z3/8]\\n[^A5/4z3/8] [^d5/4z/2] [=g9/8z3/8] [^A2z3/8] [^d2z3/8] [g2z3/8]\\n[^D13/4z3/8] [G13/4z/2] [^A9/8z3/8] [^d9/8z3/8] [g9/8z3/8]\\n[^A13/8z3/8] [^d2z3/8] [g13/8z/2] [^D25/8z3/8] [G25/8z3/8] [c9/8z3/8]\\n[g9/8z3/8] [c'5/4z3/8] [c2z/2] [g15/8z3/8] [c'15/8z3/8] [^D25/8z3/8]\\n[G11/4z3/8] [c5/4z3/8] [g5/4z3/8] [c'5/4z/2] [c15/8z3/8] [g9/8z3/8]\\n[c'9/8z3/8] [^D25/8z3/8] [F13/4z3/8] [=A5/4z/2] [c9/8z3/8] [f9/8z3/8]\\n[A2z3/8] [c2z3/8] [f2z3/8] [^D13/4z/2] [F25/8z3/8] [A9/8z3/8]\\n[c9/8z3/8] [f9/8z3/8] [A5/4z3/8] [c11/8z/2] [f3/2z3/8] [=D25/8z3/8]\\n[F25/8z3/8] [^A9/8z3/8] [f5/4z3/8] [^a5/4z3/8] [^A2z/2] [f15/8z3/8]\\n[^a2z3/8] [D25/8z3/8] [F11/4z3/8] [^A5/4z3/8] [f5/4z/2] [^a9/8z3/8]\\n[^A2z3/8] [f9/8z3/8] [^a3/4z3/8] [D25/8z3/8] [^D13/4z/2] [G9/8z3/8]\\n[^A9/8z3/8] [^d9/8z3/8] [G2z3/8] [^A2z3/8] [^d2z/2] [=D25/8z3/8]\\n[^D25/8z3/8] [G9/8z3/8] [^A9/8z3/8] [^d5/4z3/8] [G2z3/8] [^A2z/2]\\n[^d15/8z3/8] [C25/8z3/8] [^D25/8z3/8] [G5/4z3/8] [^A5/4z3/8]\\n[^d5/4z/2] [G15/8z3/8] [^A2z3/8] [^d2z3/8] [C25/8z3/8] [^D11/4z3/8]\\n[G5/4z/2] [^A9/8z3/8] [^d9/8z3/8] [G9/8z3/8] [^A5/4z3/8] [^d2z3/8]\\n[F,13/4z/2] [C25/8z3/8] [F9/8z3/8] [=A9/8z3/8] [^d9/8z3/8] [F2z3/8]\\n[A2z3/8] [^d2z/2] [F,25/8z3/8] [C11/4z3/8] [F9/8z3/8] [A5/4z3/8]\\n[^d5/4z3/8] [F2z/2] [A3/4z3/8] [^d3/4z3/8] [^A,25/8z3/8] [=D25/8z3/8]\\n[F5/4z3/8] [^A5/4z/2] [=d9/8z3/8] [F15/8z3/8] [^A2z3/8] [d2z3/8]\\n[^A,25/8z3/8] [D11/4z/2] [F9/8z3/8] [^A9/8z3/8] [d9/8z3/8]\\n[F13/8z3/8] [^A2z3/8] [d7/8z3/8] [^A,13/4z/2] [^C25/8z3/8] [G9/8z3/8]\\n[^A9/8z3/8] [e5/4z3/8] [G2z3/8] [^A2z/2] [e15/8z3/8] [^A,25/8z3/8]\\n[^C11/4z3/8] [G9/8z3/8] [^A5/4z3/8] [e5/4z/2] [G3/2z3/8] [^A9/8z3/8]\\n[e9/8z3/8] [^G,25/8z3/8] [=C25/8z3/8] [F5/4z/2] [c9/8z3/8] [f9/8z3/8]\\n[F2z3/8] [c2z3/8] [f2z3/8] [^G,13/4z3/8] [C23/8z/2] [F9/8z3/8]\\n[c9/8z3/8] [f9/8z3/8] [F2z3/8] [c5/4z3/8] [f2z/2] [^G,25/8z3/8]\\n[B,25/8z3/8] [F9/8z3/8] [^G9/8z3/8] [d5/4z3/8] [F2z/2] [^G15/8z3/8]\\n[d15/8z3/8] [^G,25/8z3/8] [B,11/4z3/8] [F5/4z3/8] [^G5/4z/2]\\n[d9/8z3/8] [F15/8z3/8] [^G9/8z3/8] [d9/8z3/8] [=G,25/8z3/8]\\n[^A,13/4z3/8] [^D5/4z/2] [^A9/8z3/8] [^d9/8z3/8] [^D2z3/8] [^A2z3/8]\\n[^d2z3/8] [G,13/4z/2] [^A,11/4z3/8] [^D9/8z3/8] [^A9/8z3/8]\\n[^d9/8z3/8] [^D19/8z3/8] [^A7/8z/2] ^d3/8 [G,25/8z3/8] [^G,25/8z3/8]\\n[C9/8z3/8] [^D5/4z3/8] [^G5/4z/2] [C15/8z3/8] [^D15/8z3/8] [^G2z3/8]\\n[=G,25/8z3/8] [^G,25/8z3/8] [C5/4z3/8] [^D5/4z/2] [^G9/8z3/8]\\n[C2z3/8] [^D2z3/8] [^G2z3/8] [F,13/4z3/8] [^G,13/4z/2] [C9/8z3/8]\\n[^D9/8z3/8] [^G9/8z3/8] [C2z3/8] [^D2z3/8] [^G2z/2] [F,7/2z3/8]\\n[^G,11/4z3/8] [C9/8z3/8] [^D9/8z3/8] [^G5/4z3/8] [C5/4z/2]\\n[^D9/8z3/8] [^G15/8z3/8] [^A,3/4z3/8] [F,25/8z3/8] [^A,5/4z3/8]\\n[=D5/4z3/8] [^G5/4z/2] [^A,9/8z3/8] [D2z3/8] [^G2z3/8] [^A,3/4z3/8]\\n[F,11/4z3/8] [^A,5/4z/2] [D9/8z3/8] [^G9/8z3/8] [^A,2z3/8] [D3/4z3/8]\\n[^G7/8z3/8] [^D,13/4z/2] [=G,25/8z3/8] [^A,9/8z3/8] [^D9/8z3/8]\\n[=G9/8z3/8] [^A,2z3/8] [^D2z/2] [G15/8z3/8] [^D,25/8z3/8]\\n[G,11/4z3/8] [^A,9/8z3/8] [^D5/4z3/8] [G5/4z3/8] [^A,13/8z/2]\\n[^D15/8z3/8] [G2z3/8] [^D,25/8z3/8] [^A,25/8z3/8] [^C5/4z3/8]\\n[^D5/4z/2] [G9/8z3/8] [^C2z3/8] [^D2z3/8] [G2z3/8] [^D,25/8z3/8]\\n[^A,11/4z/2] [^C9/8z3/8] [^D9/8z3/8] [G9/8z3/8] [^C5/4z3/8] [^D2z3/8]\\n[G2z/2] ^G,3/8 [^G,11/4z3/8] [=C9/8z3/8] [^D9/8z3/8] [G5/4z3/8]\\n[C2z3/8] [^D2z/2] [G15/8z3/8] ^G,3/8 [^G,11/4z3/8] [C5/4z3/8]\\n[^D5/4z3/8] [G5/4z/2] [C15/8z3/8] [^D2z3/8] G3/8 [=A,25/8z3/8]\\n[^D,25/8z3/8] [C5/4z/2] [^D9/8z3/8] [^F9/8z3/8] [C2z3/8] [^D2z3/8]\\n[^F2z3/8] [A,13/4z/2] [^D,11/4z3/8] [C9/8z3/8] [^D9/8z3/8]\\n[^F9/8z3/8] [C3/4z3/8] [^D2z3/8] ^F/2 [B,25/8z3/8] [^G,25/8z3/8]\\n[=D9/8z3/8] [^D3/4z3/8] [=F9/8z3/8] [=D2z/2] [^D3/4z3/8] [F15/8z3/8]\\n[B,25/8z3/8] [^G,25/8z3/8] [=D5/4z3/8] [^D7/8z/2] [F9/8z3/8]\\n[=D9/4z3/8] ^D3/8 [F7/8z3/8] [^A,7/8z3/8] [^G,13/4z/2] [^A,9/8z3/8]\\n[=D9/8z3/8] [F9/8z3/8] [^A,9/8z3/8] [D2z3/8] [F2z3/8] [^A,7/8z/2]\\n[^G,11/4z3/8] [^A,9/8z3/8] [D9/8z3/8] [F5/4z3/8] [^A,5/4z3/8] [D2z/2]\\n[F7/8z3/8] [^A,3/4z3/8] [=G,25/8z3/8] [^A,5/4z3/8] [^D5/4z3/8]\\n[G5/4z/2] [^A,9/8z3/8] [^D15/8z3/8] [G9/8z3/8] [^A,3/4z3/8]\\n[G,11/4z3/8] [^A,5/4z/2] [^D9/8z3/8] [G9/8z3/8] [^A,9/8z3/8]\\n[^D2z3/8] [G9/8z3/8] [^A,7/8z3/8] [F,13/4z/2] [^A,9/8z3/8]\\n[^D9/8z3/8] [^G9/8z3/8] [^A,5/4z3/8] [^D2z3/8] [^G5/4z/2]\\n[^A,3/4z3/8] [F,25/8z3/8] [^A,9/8z3/8] [^D9/8z3/8] [^G5/4z3/8]\\n[^A,5/4z/2] [^D15/8z3/8] [^G9/8z3/8] [^A,3/4z3/8] [F,25/8z3/8]\\n[^A,5/4z3/8] [=D5/4z/2] [^G9/8z3/8] [^A,9/8z3/8] [D2z3/8] [^G9/8z3/8]\\n[^A,3/4z3/8] [F,11/4z3/8] [^A,5/4z/2] [D9/8z3/8] [^G9/8z3/8]\\n[^A,9/8z3/8] [D13/8z3/8] [^G7/8z3/8] [^A,13/4z/2] [^F,25/8z3/8]\\n[C9/8z3/8] [^D9/8z3/8] [=A9/8z3/8] [C2z3/8] [^D2z/2] [A9/8z3/8]\\n[^A,25/8z3/8] [^F,11/4z3/8] [C9/8z3/8] [^D5/4z3/8] [A5/4z/2]\\n[C3/2z3/8] [^D15/8z3/8] [A3/4z3/8] [^A,3/4z3/8] [G,25/8z3/8]\\n[^A,5/4z3/8] [^D5/4z/2] [^A9/8z3/8] [^A,9/8z3/8] [^D2z3/8]\\n[^A9/8z3/8] [^A,7/8z3/8] [G,11/4z/2] [^A,9/8z3/8] [^D9/8z3/8]\\n[^A9/8z3/8] [^A,5/4z3/8] [^D2z3/8] [^A5/4z/2] [^A,3/4z3/8]\\n[=F,25/8z3/8] [^A,5/4z3/8] [^D5/4z3/8] [^G5/4z/2] [^A,9/8z3/8]\\n[^D2z3/8] [^G9/8z3/8] [^A,7/8z3/8] [F,13/4z/2] [^A,9/8z3/8]\\n[^D9/8z3/8] [^G9/8z3/8] [^A,5/4z3/8] [^D5/4z3/8] [^G5/4z/2]\\n[^A,3/4z3/8] [F,13/4z3/8] [^A,5/4z3/8] [=D5/4z/2] [^G9/8z3/8]\\n[^A,5/4z3/8] [D2z3/8] [^G5/4z/2] [^A,3/4z3/8] [F,23/8z3/8]\\n[^A,5/4z3/8] [D5/4z/2] [^G9/8z3/8] [^A,2z3/8] [D7/8z3/8] [^G5/4z/2]\\n^D,3/8 [^D,3z/2] [^A,5/4z3/8] [^C5/4z3/8] [=G5/4z/2] [^A,17/8z3/8]\\n[^C17/8z3/8] [G9/4z/2] ^D,3/8 [^D,25/8z/2] [^A,5/4z3/8] [^C11/8z/2]\\n[G5/4z3/8] [^A,11/8z/2] [^C7/8z/2] [G7/8z3/8] ^D,/2 [^D,57/8z/2]\\n[^G,15/4z3/8] [=C15/8z/2] [^D7/8z/2] [^G11/8z/2] [^D7/8z3/8] [Cz/2]\\n[^D11/8z/2] [C7/8z/2] [^G,7/8z3/8] [C3/2z/2] [^G,z/2] [F,z/2]\\n[^G,3/2z/2] [F,z/2] [^D,67/8z/2] [=D,17/2z/2] [^A33/8z/2] [=d17/8z/2]\\n[f9/8z5/8] [^g3/2z/2] [fz/2] [dz/2] [f3/2z/2] [dz/2] [^A13/8z/2]\\n[d23/8z/2] [F9/8z5/8] [^G9/4z/2] =G5/8 [F9/8z5/8] ^D,3/4\\n[^D,93/8z7/8] [G43/4z7/8] [^A79/8z7/8] ^d9 z ^D F7/8 z/8 G7/8 z/8\\n^G3/2 ^A/4 ^G/4 =G c7/8 z/8 F ^A/4 ^G/8 ^A5/4 c/2 ^A/2 ^G/2 =G/2 ^G/2\\n[=G/2^A7/8] F3/8 z/8 [^D3/8c5/8] z/8 F3/8 [^D/2=d3/4] =D/2 [C^d3/2]\\n[=Az/2] f/4 ^d/4 [^A25/8=d] =g3/4 z/4 c [=A/2f/4] ^d/4 [G/2f] [Az/2]\\ng/2 [Ff/2] ^d/2 [^A/2=d/2] ^A/2 [^A,^Gc/2] d/2 [C7/8=G^d/2] =d/2\\n[D7/8F^d/2] f/2 [^D3/2g/2] f/2 g/2 [F/4=a/2] ^D/4 [=D^a] [G3/4^A2=d]\\nz/4 [C^d] [F3/8^G/2cz/4] [^D3/8z/4] [F=G/2] [^G5/2f/2] [=G/2^d/2]\\n[F/2=d/2] [^D/2c/2] [=D^A3/2z/2] ^G/2 [^D,^D2=Gz/2] ^A/2 [F,F2^G/2]\\n=G/2 [=G,^C^G/2] ^A/2 [^G,3/2=C^Dc/2] ^A/2 [F^Gc/2] [^A,/4d/2] ^G,/4\\n[=G,^A,^d4z/2] ^A/2 [C7/8^D^G/2] =G/2 [F,7/8^Gz/2] C/2 [^A,3/2=D/2F]\\n^D/2 [F2z/8] [^A15/4z/4] [=d19/8z/8] C/2 ^A,/2 ^G,/2 [=G,/2^A,3]\\n^G,/2 [=G,/2^d] F,/2 [^D,/2f] F,/2 [^D,/2^A,g] =D,/2 [C,C^g3/2]\\n[F,=Dz/2] ^a/4 ^g/4 [C^D3/2=g] [=A,c'3/4z/2] F/4 ^D/4 [^A,/2=Df] C/2\\n[^C/2=G^a/4] ^g/4 [^A,/2^a] [E,=Cz/2] c'/2 [F,F11/8^a/2] ^g/2\\n[C15/8=g7/8z/2] G3/8 z/8 [F3/8c'/8] z/8 ^a/8 z/8 [^D3/8c'7/8] z/8\\n[G,15/8=D7/8z3/8] =d/2 [G3c'/2] ^a/2 [C/2^g4] D/2 [^D/2^A] F/2\\n[^D/2F2c] =D/2 [C/2d] ^A,/2 [^D/2^d3/2=g3/2] =D/2 ^D/2 [C/2f/4=a/2]\\n^d/4 [G/2=d^a4] F/2 [^D/2g7/8] =D/2 [^D/2c] C/2 [=D/2d/4] ^d/4\\n[^D/2f] [F/2=a2] [^D/2g/2] [=D/2f/2] [C/2^d/2] [^A,=d3/2^a/2] ^g/2\\n[^A,=g/2] f/2 [C,^d/2] f/2 [D,F^d/2] =d/2 [^D,3/2Gc/2] ^d/2 [=A=d/2]\\n[F,/4c/2] ^D,/4 [=D,^A3/2] [G,7/8z/2] c/4 ^A/4 [C,=Az/2] ^d/2\\n[F,/4=d/2] ^D,/4 [F,c/2] [GBz/2] G,/2 [F,/2c3/8gz/4] [B3/8z/4]\\n[^D,/2c] [=D,fz/2] d/2 [G,2c/2^d/2] [B/2=d/2] [=A,9/8A9/8c/2] z/8 B/2\\n[F,B,^Gc/2] d/2 [^D,C3/2=G^d/2] A/2 [^G,17/8F3/2B/2] [D/4c/2] C/4\\n[B,9/8=d9/8z5/8] G/2 [=G,2^DA/2c/2] [B/2d/2] [A,c/2^d] B/2\\n[F,17/8=D/4c/2^g] C/4 [D=d/2] [B/2=g9/8] [^D5/8A5/8] [G,=D/2B/2f3/2]\\n[C/2c/2] [^G,B,dz/4] ^d/4 f/2 [=G,/2C17/8^d/2] [F,/2=d/2]\\n[G,17/8^d/2] =d/4 [^d/4z/8] =d/4 [B,^d/4z/8] =d3/8 c/2 [C,19/8C2c2z]\\n^D F9/8 [^A,G] [C^G3/2] [=Dz/2] ^A/4 ^G/4 [^D13/8=G9/8] [c7/8z/2] F/4\\n^D/4 [=DF] [^A,G^A13/8] z/8 [C,Cz/2] c/2 [=D,F2^A/2] ^G/2 [^D,3/2=G]\\n[^A,G^Az/2] F,/4 ^D,/4 [=D,9/8F17/8=A9/8c9/8] [G,^A2d] [C,^D^d3/2]\\n[F,13/8C9/8=A9/8z/2] f/4 ^d/4 z/8 [GB=dz/2] G,/2 [F,/2Gc2^d] ^D,/2\\n[=D,Ff] [^C,^Ag] z/8 [=C,c^g3/2] [^A,=dz/2] ^a/4 ^g/4 [C,^d3/2=g]\\n[=A,9/8C9/8c'z/2] f/4 ^d3/8 [^A,=D=df] [G,Egz/4] [^g3/8z/4] [^az/2]\\n[F,17/8F3/2cz/2] c'/2 [f13/8^a/2] [G/4^g5/8] z/8 F/4 [G,^D=g/2] g/2\\n[^G,^Gf/2c'] ^d/2 [^A,3/2=D=df] [=G13/8^a9/8^c9/8z/2] C/4 z/8 ^A,/4\\n[^G,ec'z/2] ^G/2 [^C=G/2f^a/2] [F/2^g/2] [=G,E=g^a/2] ^g/2\\n[=C13/8e^a/2] =g/2 z/8 [f^g/2] [^C/2^a/2] [=C/2=gc'/4] ^a/4\\n[^A,/2^g/4] ^a/4 [^G,/2=cc'/2] [=G,/2e/2] [^G,/2Cf/2] [F,/2^a/2]\\n[^A,9/8D9/8=g3/8] f/4 [gz/2] [CEGz/2] f/2 [F,37/8F3/2=Af3/2] [^Az/2]\\nG/4 F/4 z/8 [^Dc3/2] [=Az/2] d/4 c/4 [=D^Az/2] =G,/2 [F,/2G13/8^d]\\n^D,/2 [=D,5/8=A5/8] [C,/2A/2] [^A,/2G/2=d3/2] [=A,/2F/2]\\n[G,^D29/8z/2] ^d/2 [G,9/8=d5/8] c/2 [A,^A/2] =A/2 [^A,17/8G/2^A9/8]\\nF5/8 [G2cz/2] F/2 [C/2^D/2d] [^A,/2=D/2] z/8 [=A,C/2F21/8^d3/2] ^A,/2\\n[F,C/2] [=A,/2f/4] ^d/4 [^A,17/8=d9/8z5/8] c/2 [D^A/2g] ^G/2\\n[^A,17/8^D9/8=G/2c9/8] ^A5/8 [F^G/2f3/2] c/2 [^A,17/4=G13/8^A17/8z/2]\\ng/2 f5/8 [^G/4^d/2] =G/4 [F^A/2=d/2] [c/2^d/2] [^A9/8^c9/8f/2] z/8\\ng/2 [C17/8^D^d17/8^g/2] ^a/2 [^G/4c'/2] =G/4 [^G9/8^a5/8] [=Df^g/2]\\n[^A/2=g/2] [^D^G/2^A5/4f/2] [=G/2^d5/8] [^G,5/8F17/8z3/8] [^A23/8z/4]\\n[C/2=d3/2] ^A,/2 ^G,/2 [=G,/2G9/8^d9/8] z/8 F,/2 [^D,/2F17/8^Gf]\\n=D,/2 [^D,/2^A9/8] F,5/8 [G,/2^A,=G^d2] ^G,/2 [^A,F17/8]\\n[^A,17/8=d/4] ^d/4 =d5/8 [^D,G^d17/8] [^D,13/4=c17/8z9/8] [F,=d] z/8\\n[=G,^A17/8^c] [^D,17/4^G,13/8=c9/8] [^Gf17/8z/2] ^A,/4 ^G,/4\\n[=G,9/8^A9/8] [Cc^d] [^D,17/4F,9/8^c13/8f9/8] [^A,13/8gz/2] ^d/4 ^c/4\\n[=c9/8^g11/4z5/8] C/2 [^A,/2f] ^G,/2 z/8 [^D,17/4=G,/2^A] [F,/2c'/2]\\n[G,5/8^d13/8^a5/8] [^G,/2^g/2] [^A,/2=g/2] [C5/8f5/8^g5/8]\\n[^C/2^d/2=g/2] [^A,/2^c/2f/2] [^D,9/2=C5/8=c5/8^d9/2] [=G,/2^c/2]\\n[^G,5/8=c5/8] [^A,/2^A/2] [C/2^G/2] z/8 [=D/2^A/2] [^D/2^G/2]\\n[C5/8=G5/8] [^D,16=D37/8F4z/2] ^A3/8 c/4 =d5/8 ^d/2 f5/8 g/2\\n[^g3/2z5/8] ^A5/8 [^D29/2c5/2z/4] ^d3/8 f/4 =g3/8 ^g5/8 ^a5/8\\n[c'9/4z3/4] ^g5/8 z/8 [f3/2z3/4] =d3/4 [^d9=g9^a9z47/8] ^D,25/8 \\n\\n\\nX:1 \\nT:Preludio from Partita 3 for Solo Violin\\nR:Classical\\nC:J.S. Bach\\nN:Transposed to A major (from the original E major) to fit into the LOTRO abc note range\\nZ:Transcribed by Eleiniel, Brandywine server\\nM:12/16\\nL:1/16\\nQ:1/16=420\\nK:A\\n\\nz2 ag a2 e2 c2 e2 | ABAG A2 E2 C2 E2 | A,EB,E C,ED,E C,EB,E | A,AGF EAGF EDCB, |\\n+pp+A,EB,E C,ED,E C,EB,E | A,AGF EAGF EDCB, | +f+A,B,CD EFGA BcdB |\\nceAB cdef gafg | aede cede ceBe | Aagf eAfA eAdA |\\n+pp+ceBe cede ceBe | Aagf eAfA eAdA | +f+cAAAGAAABAGA |\\nAAcABAcAdABA | +pp+cAAAGAAABAGA | AAcABAcAdABA |\\n\\n+f+cAcA cAcA cAcA | cAcG cAcG cAcG | cAc=G cAc=G cAc=G |\\ndAdF dAdF dAdF | dAdE dAdE dAdE | cAcE cAcE cAcE |\\n+mf+cAcD cAcD cAcD | BABD BABD BABD | +mp+BABC BABC BABC |\\n+p+AAAC AAAC AAAC | AAAB, AAAB, AAAB, | +pp+GAGB, GAGB, GAGB, |\\n\\n+f+A,4/3B,A,B, CEA,B, CEA,B, | CDCD EACD EACD | EFEF =GcEF =GcEF |\\n\\n%begin page 2\\n\\n=GecA =GECA, =G,F,=G,E, | F,^G,F,^G, ^A,CF,^G, ^A,CF,^G, | ^A,B,^A,B, CF^A,B, CF^A,B, |\\nCDCD E^ACD E^ACD | Ec^AF ecdB ^AcFE | DFDB, BG=AF ^EGCB, |\\nA,CA,F, A,CFC AFcF | ^EGEC c^Bc^B cGAF | ^EGEC =B^ABA BG=AF |\\n^EGEC DCDC DG,A,F, | ^E,B,F,B, G,B,F,B, ^E,B,G,B, | C,B,GB, ^EB,GB, ^EB,GB, |\\nC,A,FA, AA,FA, AA,FA, | +pp+C,B,GB, ^EB,GB, ^EB,GB, | C,A,FA, AA,FA, AA,FA, |\\n+f+C,^B,FB, AB,FB, AB,FB, | +pp+C,^B,FB, AB,FB, AB,FB, | +f+C,CFC GCFC GCFC |\\n+p+C,B,^EB, GB,^EB, GB,^EB, | +f+F,4/3F=ED CFCB, A,CA,G, | F,6/5FCB, A,CA,G, F,A,F,E, |\\n^D,B,FB, AB,FB, AB,FB, | ^D,B,AB, FB,AB, FB,AB, | E,4/3e^dc BeBA GBGF |\\nEeBA GBGF EGE=D | C=GAG cGeG cGAG | C=GAG CGB,G CGA,G |\\nFAdc dA=GA FAEA | DdcB ADBD AD=GD | +pp+FAEA FA=GA FAEA | DdcB ADBADA=GA |\\n+f+FDDDCDDDEDCD | DDFDEDFD=GDED | +pp+FDDDCDDDEDCD | DDFDEDFD=GDED |\\n\\n%begin page 3\\n\\n+f+FDFD FDFD FDFD | FDFC FDFC FDFC | FDF=C FDF=C FDF=C |\\n=GDGB, =GDGB, =GDGB, | =GDGA, =GDGA, =GDGA, | FDFA, FDFA, FDFA, |\\n+mf+FDF=G, FDF=G, FDF=G, | EDE=G, EDE=G, EDE=G, | +mp+EDEF, EDEF, EDEF, |\\n+p+DDDF, DDDF, DDDF, | DDDE, DDDE, DDDE, | +pp+CDCE, CDCE, CDCE, |\\n\\n+f+D,4/3E,D,E, F,A,D,E, F,A,D,E, | F,=G,F,=G, A,DF,=G, A,DF,=G, | A,B,A,B, =CFA,B, =CFA,B, |\\n=CAF=G AF^DE F^DB,A, | =G,F,E,F, =G,B,E,F, =G,B,E,F, | =G,A,G,A, B,E=G,A, B,E=G,A, |\\nB,CB,C D^GB,C D^GB,C | DBGA BG^EF G^ECB, | ^A,ecd ec^AB c^AF=E |\\nDfde fdBc dB=GF | E=gef =gecd ec^Ac | F4/3^GF^G ^AcFG ^AcFG |\\n^A6/5BAB ce^AB ce^AB | cdcd e=gcd e=gcd | e=gec ^Aec^A Fedc |\\nBcdB EdcB FcB^A | =G=ABG CBA=G ^DA=GF | EF=GE ^A,GFE B,FED |\\nCDED CEDE CEB,E | ^A,B,CD E^A,=GA, FA,EA, | B,DB,F, D,F,B,F, DF,B,F, |\\n\\n%begin page 4\\n\\n^A,CA,F, ^A,CFC ^AFcE | DFDB, DFBF dBfB | ^AcAF f^ef^e fcdB |\\n^AcAF =e^ded ec=dB | ^AcAF =GF=GF GCDB, | ^A,CFe ecdB ^AcFE |\\nDFBf fdec Bd=GF | E=G=CB, ^A,^CF,E, D,F,B,C | DB,EB, FB,=GB, F,B,C^A, |\\n\\n+mp+B,2DCD DDCD B,D=A,D | ^G,DA,D B,DCD DDB,D | CDCB, +mf+A,AGA FAEA | ^DAEA FAGA AAFA |\\n+f+GAGF EFGA BcdB | e+mp+EDE CEB,E A,E=G,E | +mf+F,A,B,C DEF=G +f+ABcA | d+mp+DCD B,DA,D ^G,DF,D |\\n+mf+E,G,A,B, CDEF +f+GABG | cA,=G,A, F,A,E,A, D,A,C,A, | D,4/3A,FE FAdc dBFA | E,4/3B,^GF GBdc dBGB |\\nE,4/3CED EAcB cAEA | E,4/3^DFE FA^dc dAFA | Ge^dc BeBA GBGF | Ee=dc BdBA GBGF |\\nEdcB AcAG FAFE | DcBA GBGF EGED | CAFE DFDC B,DB,A, | G,B,DF EGBc dcdB |\\ncAce aecA EBa6/5g7/5 | a13/6ecA =GAFA =GAEA | FAdA FAEA FADA |\\nEAcA EADA EACA | DABA GAAA BAcA | [E,B,][G6d6] e2 [A,E][E4c4] | D,dcd/B/ [Ec]B/c/B/c/B/c/B/c/B/c/ B7/2 A2 |\\nA7/4agf eada caBa | AAGF EADA CAB,A | A,CEG Aceg +ff+a2 |\\n\\n\\nX: 1\\nT: Fur Elise - Beethoven (Lute) [Piano]\\nZ: Jazriel the Naughty - Vilya\\n%  Transposed down a bit for LOTRO (yes THE high note was still out of range)\\nL: 1/4\\nQ: 120\\nK: C\\nz7/4 ^g3/8 =g3/8 z/8 ^g3/8 =g3/8 ^g/2 ^d3/8 ^f/2 e3/8\\n[^c7/8^C,21/8z/2] ^G,3/8 ^C3/8 E/2 ^G3/8 ^c/2 [^d3/4^G,3/8]\\n[^G,17/8z/2] =C3/8 ^G3/8 =c/2 ^d3/8 [e7/8^C,21/8z/2] ^G,3/8 ^C3/8 z/8\\n^G3/8 ^g3/8 =g/2 ^g3/8 =g/2 ^g3/8 ^d3/8 z/8 ^f3/8 e3/8\\n[^c7/8^C,21/8z/2] ^G,3/8 ^C/2 E3/8 ^G3/8 z/8 ^c3/8 [^d7/8^G,3/8]\\n[^G,17/8z/2] =C3/8 ^G/2 e3/8 ^d3/8 z/8 [^c13/8^C,5/2z3/8] ^G,3/8 ^C/2\\nz3/8 ^g/2 =g3/8 ^g3/8 z/8 =g3/8 ^g3/8 ^d/2 ^f3/8 e/2\\n[^c3/4^C,5/2z3/8] ^G,3/8 z/8 ^C3/8 E3/8 ^G/2 ^c3/8 [^d7/8^G,/2]\\n[^G,17/8z3/8] =C3/8 z/8 ^G3/8 =c3/8 ^d/2 [e7/8^C,5/2z3/8] ^G,/2 ^C3/8\\n^G3/8 z/8 ^g3/8 =g3/8 ^g/2 =g3/8 ^g/2 ^d3/8 ^f3/8 z/8 e3/8\\n[^c7/8^C,5/2z3/8] ^G,/2 ^C3/8 E/2 ^G3/8 ^c3/8 z/8 [^d3/4^G,3/8]\\n[^G,17/8z3/8] =C/2 ^G3/8 e/2 ^d3/8 [^c7/8^C,21/8z/2] ^G,3/8 ^C3/8\\n^d/2 e3/8 ^f/2 [^g5/4E,5/2z3/8] B,3/8 z/8 E3/8 B3/8 a/2 ^g3/8\\n[^f5/4B,/2] [B,17/8z3/8] ^D3/8 z/8 A3/8 ^g3/8 ^f/2 [e5/4^C,21/8z3/8]\\n^G,/2 ^C3/8 ^G/2 ^f3/8 e/2 [^d7/8^G,/2] [^G,9/4z3/8] ^G/2 ^G/2 ^g/2\\n^G3/8 z/8 ^g/2 ^g/2 ^g/2 =g/2 ^g5/8 =g/2 ^g/2 z/8 =g/2 ^g5/8 =g5/8\\n^g/2 =g5/8 ^g3/8 z/8 =g3/8 ^g3/8 z/8 ^d3/8 ^f3/8 e/2\\n[^c7/8^C,21/8z3/8] ^G,/2 ^C3/8 E/2 ^G3/8 ^c/2 [^d7/8^G,3/8]\\n[^G,9/4z/2] =C3/8 ^G/2 =c3/8 ^d/2 [e7/8^C,5/2z3/8] ^G,/2 ^C3/8 ^G/2\\n^g3/8 =g3/8 z/8 ^g3/8 =g3/8 z/8 ^g3/8 ^d3/8 ^f/2 e3/8\\n[^c7/8^C,21/8z/2] ^G,3/8 ^C/2 E3/8 ^G/2 ^c3/8 [^d7/8^G,/2]\\n[^G,17/8z3/8] =C3/8 z/8 ^G3/8 e3/8 ^d/2 [^c7/8^C,5/2z3/8] ^G,/2 ^C3/8\\n^d3/8 z/8 e3/8 ^f3/8 [^g11/8E,21/8z/2] B,3/8 E/2 B3/8 a3/8 z/8 ^g3/8\\n[^f5/4B,3/8] [B,17/8z/2] ^D3/8 A/2 ^g3/8 ^f3/8 z/8 [e3/4^C,5/2z3/8]\\n^G,3/8 z/8 ^C3/8 ^G3/8 ^f/2 e3/8 [^d/2^G,/2] [^G,19/8z/2] ^G/2 ^G/2\\n^g3/8 z/8 ^G3/8 ^g/2 z/8 ^g/2 ^g/2 =g/2 ^g/2 =g/2 z/8 ^g/2 =g5/8\\n^g5/8 =g/2 ^g5/8 =g5/8 ^g3/8 =g/2 ^g3/8 ^d/2 ^f3/8 e/2\\n[^c7/8^C,5/2z3/8] ^G,/2 ^C3/8 E/2 ^G3/8 ^c3/8 z/8 [^d3/4^G,3/8]\\n[^G,17/8z/2] =C3/8 ^G3/8 =c/2 ^d3/8 [e7/8^C,21/8z/2] ^G,3/8 ^C/2\\n^G3/8 ^g/2 =g3/8 ^g/2 =g3/8 ^g/2 ^d3/8 ^f/2 e3/8 [^c7/8^C,21/8z/2]\\n^G,3/8 ^C3/8 E/2 ^G3/8 ^c/2 [^d7/8^G,3/8] [^G,17/8z/2] =C3/8 ^G3/8\\ne/2 ^d3/8 [^c7/8^C,7/4z/2] ^G,3/8 ^C/2 [e3/8^G3/8=D3/8E3/8]\\n[A/8A,21/8] [e7/4] z/4 ^C/2 E3/8 ^C/2 [a5/8E3/8] [^C/2z/4] ^g/4\\n[^g3/4A,5/2z3/8] D3/8 [^f7/8^F/2] D3/8 [=d5/8^F/2] [D3/8z/8] ^c/4\\n[^c/2A,7/8] [b3/8^G3/8] [a3/8D7/8B,7/8A,7/8] [^g/2^G/2]\\n[^f3/8D7/8B,7/8A,7/8] [e/2^G/2] [d7/8A,3/8] ^C/2 [^c3/4E3/8] ^C3/8\\n[d/8E/2] [^c/4z/8] B/4 [^c/4^C3/8] d/8 [e7/4A,21/8z/2] ^C3/8 E/2\\n^C3/8 [^f3/8E3/8] [=g/2^C/2] [^g5/4^G,7/4z3/8] ^C/2 E3/8 [^g/2^C/2]\\n[a3/8^F,3/4^F3/4] [^c3/8A,3/8] [e11/8B,7/8z/2] ^G3/8 B,/2 [^f/8^G3/8]\\n[e/8^d/4] [e/4z/8] [^f5/8B,7/8z/2] [A3/8z/8] ^d/4 [e/4E21/8^G7/4] b/8\\nB/4 b/4 ^c/4 b/8 [^d/4A/2B/2] b/4 [e/8^G3/8B3/8] b/4 [^f/4B/2A/2^F/2]\\nb/4 [^g/8B5/2^G5/2E5/2] b/4 e/4 ^d/8 [^c/4^C7/8A,7/8] b/4 a/4 ^g/8\\n[^f/4^D7/8B,7/8] b/4 a/8 ^f/4 [e/4E21/8] b/4 B/8 b/4 ^c/4 b/8\\n[^d/4A/2B/2] b/4 [e/4^G3/8B3/8] b/8 [^f/4B/2A/2^F/2] b/4\\n[^g/8B5/2^G5/2E5/2] b/4 e/4 ^d/4 [^c/8^C3/4A,3/4] b/4 a/4 ^g/8\\n[^f/4^D7/8B,7/8] b/4 a/4 ^f/8 [^g/4^D21/8=C21/8] a/4 ^g/8 =g/4 ^g/4\\n^d/4 ^g/8 =g/4 ^g/4 ^d/8 ^g/4 =g/4 ^g5/4 ^d/2 ^g3/8 =g3/8 ^g11/8\\n^d3/8 ^g/2 z7/8 =g3/8 ^g/2 z9/8 =g/2 ^g/2 =g/2 ^g/2 ^d3/8 ^f/2 e3/8\\n[^c7/8^C,21/8z/2] ^G,3/8 ^C/2 E3/8 ^G/2 ^c3/8 [^d7/8^G,/2]\\n[^G,17/8z3/8] =C/2 ^G3/8 =c/2 ^d3/8 [e7/8^C,21/8z/2] ^G,3/8 ^C3/8\\n^G/2 ^g3/8 =g/2 ^g3/8 =g/2 ^g3/8 ^d3/8 ^f/2 e3/8 [^c7/8^C,21/8z/2]\\n^G,3/8 ^C/2 E3/8 ^G3/8 ^c/2 [^d7/8^G,3/8] [^G,17/8z/2] =C3/8 ^G/2\\ne3/8 ^d3/8 [^c7/8^C,21/8z/2] ^G,3/8 ^C/2 ^d3/8 e/2 ^f3/8\\n[^g5/4E,21/8z3/8] B,/2 E3/8 B/2 a3/8 ^g/2 [^f5/4B,3/8] [B,9/4z/2]\\n^D3/8 A/2 ^g3/8 ^f/2 [e5/4^C,5/2z3/8] ^G,/2 ^C3/8 ^G/2 ^f3/8 e3/8 z/8\\n[^d3/4^G,3/8] [^G,17/8z/2] ^G3/8 ^G3/8 ^g/2 ^G3/8 ^g/2 ^g3/8 ^g/2\\n=g/2 ^g/2 =g/2 ^g/2 =g/2 ^g/2 =g5/8 ^g/2 =g/2 z/8 ^g/2 =g/2 ^g/2\\n^d3/8 ^f/2 e3/8 [^c7/8^C,21/8z/2] ^G,3/8 ^C/2 E3/8 ^G/2 ^c3/8\\n[^d7/8^G,/2] [^G,17/8z3/8] =C/2 ^G3/8 =c/2 ^d3/8 [e7/8^C,21/8z/2]\\n^G,3/8 ^C3/8 z/8 ^G3/8 ^g3/8 z/8 =g3/8 ^g3/8 =g/2 ^g3/8 ^d/2 ^f3/8\\ne/2 [^c7/8^C,21/8z3/8] ^G,/2 ^C3/8 E/2 ^G3/8 ^c/2 [^d7/8^G,3/8]\\n[^G,9/4z/2] =C3/8 ^G/2 e3/8 ^d/2 [^c3/4^C,3/8] ^C,3/8 z/8 ^C,3/8\\n^C,3/8 z/8 ^C,3/8 ^C,3/8 [e21/8B21/8^G21/8^C,/2] ^C,3/8 ^C,/2 ^C,3/8\\n^C,/2 ^C,3/8 [^f7/4^c7/4A7/4^C,/2] ^C,3/8 ^C,3/8 ^C,/2\\n[^g3/8=f3/8^C,3/8] [a/2^f/2^C,/2] [a13/8^f13/8=c13/8^C,3/8] ^C,3/8\\nz/8 ^C,3/8 ^C,3/8 [a7/8^f7/8c7/8^C,/2] ^C,3/8\\n[^g21/8e21/8^c21/8^C,/2] ^C,3/8 ^C,3/8 z/8 ^C,3/8 ^C,3/8 ^C,/2\\n[^f13/8A13/8^C,3/8^F,3/8] [^C,/2^F,/2] [^C,3/8^F,3/8] [^C,3/8^F,3/8]\\nz/8 [e3/8^G3/8^C,3/8^F,3/8] [^d3/8^F3/8^C,3/8^F,3/8]\\n[^c7/4^A7/4E7/4^C,/2=G,/2] [^C,3/8G,3/8] [^C,/2G,/2] [^C,3/8G,3/8]\\n[^c7/8E7/8^C,3/8G,3/8] z/8 [^C,3/8G,3/8] [^c7/8E7/8^C,3/8^G,3/8]\\n[^C,/2^G,/2] [e7/8^G7/8^C,3/8^G,3/8] [^C,/2^G,/2]\\n[^d3/4^F3/4=C,3/8^G,3/8] [C,3/8^G,3/8] z/8 [^c5/2E5/2^C,3/8] ^C,3/8\\n^C,/2 ^C,3/8 ^C,/2 ^C,3/8 [=f21/8=d21/8B21/8^G21/8^C,/2] ^C,3/8\\n^C,3/8 ^C,/2 ^C,3/8 ^C,/2 [^f13/8^c13/8=A13/8^C,3/8] ^C,3/8 z/8\\n^C,3/8 ^C,3/8 [^g/2=f/2^C,/2] [a3/8^f3/8^C,3/8] [a7/4^f7/4^C,/2]\\n^C,3/8 ^C,3/8 z/8 ^C,3/8 [a7/8^f7/8^C,3/8] ^C,/2 [a5/2^f5/2D,3/8]\\nD,/2 D,3/8 D,3/8 z/8 D,3/8 D,3/8 [=g7/4B7/4D,/2] D,3/8 D,/2 D,3/8\\n[^f3/8A3/8D,/2] z/8 [e3/8=G3/8D,3/8] [d7/4A7/4^F7/4D,3/8] D,/2 D,3/8\\nD,/2 [^c3/4A3/4^F3/4D,3/8] D,3/8 z/8 [=c13/8A13/8^F13/8^D,3/8] ^D,3/8\\n^D,/2 ^D,3/8 [c7/8A7/8^F7/8^D,/2] ^D,3/8 [^c7/4^G7/4E7/4E,21/8] z7/8\\n[^d3/4^G3/4^F3/4C3/4^G,3/4] z7/4 [^C3/8^C,7/8] E/4 ^G/4 ^c/4 e3/8\\n^g/4 [^f/4^G7/8E7/8^C7/8] e3/8 ^d/4 [^c/4^G7/8E7/8^C7/8] e/4 ^g3/8\\n^c/4 e/4 ^g3/8 [^f/4^G3/4E3/4^C3/4] e/4 ^d/4 [^c3/8^G7/8E7/8^C7/8]\\ne/4 ^g/4 ^c3/8 e/4 ^g/4 [^f/4^G7/8E7/8^C7/8] e3/8 ^d/4\\n[=d/4^G7/8E7/8^C7/8] ^c3/8 c'/4 b/4 ^a/4 =a3/8 ^g/4 =g/4 ^f3/8 =f/4\\ne/4 ^d/4 =d3/8 ^c/4 c'/4 b3/8 ^a/4 =a/4 ^g/2 =g3/8 ^g/2 ^d3/8 ^f/2\\ne3/8 [^c7/8^C,21/8z/2] ^G,3/8 ^C/2 E3/8 ^G/2 ^c3/8 [^d7/8^G,/2]\\n[^G,17/8z3/8] =C3/8 z/8 ^G3/8 =c3/8 ^d/2 [e7/8^C,21/8z3/8] ^G,/2\\n^C3/8 ^G/2 ^g3/8 =g/2 ^g3/8 =g/2 ^g3/8 ^d/2 ^f3/8 e/2\\n[^c7/8^C,5/2z3/8] ^G,/2 ^C3/8 E3/8 ^G/2 ^c3/8 [^d7/8^G,/2]\\n[^G,17/8z3/8] =C/2 ^G3/8 e3/8 ^d/2 [^c7/8^C,5/2z3/8] ^G,/2 ^C3/8 ^d/2\\ne3/8 ^f3/8 [^g11/8E,21/8z/2] B,3/8 E/2 B3/8 a/2 ^g3/8 [^f5/4B,3/8]\\n[B,9/4z/2] ^D3/8 A/2 ^g3/8 ^f/2 [e5/4^C,5/2z3/8] ^G,3/8 ^C/2 ^G3/8\\n^f/2 e3/8 [^d7/8^G,/2] [^G,17/8z3/8] ^G3/8 ^G/2 ^g3/8 ^G/2 ^g3/8 ^g/2\\n^g3/8 =g3/8 ^g/2 =g3/8 ^g/2 =g3/8 ^g/2 =g3/8 ^g3/8 =g/2 ^g3/8 =g/2\\n^g3/8 ^d/2 ^f3/8 e3/8 [^c7/8^C,21/8z/2] ^G,3/8 ^C/2 E3/8 ^G/2 ^c3/8\\n[^d7/8^G,/2] [^G,17/8z3/8] =C/2 ^G3/8 =c/2 ^d3/8 [e7/8^C,21/8z/2]\\n^G,3/8 ^C3/8 z/8 ^G3/8 ^g3/8 z/8 =g3/8 ^g3/8 =g/2 ^g3/8 ^d/2 ^f3/8\\ne/2 [^c7/8^C,21/8z3/8] ^G,/2 ^C3/8 E/2 ^G3/8 ^c/2 [^d7/8^G,3/8]\\n[^G,21/8z/2] =C/2 ^G/2 z/8 e/2 ^d/2 [^c35/8E35/8^C,35/8] \\n\\n\\nX: 1\\nT: Moonlight Sonata 1st Movement - Beethoven (5:06)\\nZ: Jazriel the Naughty - Vilya\\nL: 1/4\\nQ: 110\\nK: C\\nz/8 [E5/8A,8] A3/4 c5/8 E5/8 A3/4 c5/8 E5/8 A3/4 c5/8 E5/8 A3/4 c5/8\\n[E5/8G,8] A3/4 c5/8 E5/8 A3/4 c5/8 E5/8 A3/4 c5/8 E5/8 A3/4 c5/8\\n[F5/8F,4] A3/4 c5/8 F5/8 A3/4 c5/8 [F5/8D,4] ^A3/4 d5/8 F5/8 ^A3/4\\nd5/8 [E5/8E,4] ^G3/4 d5/8 E5/8 =A3/4 c5/8 [E5/8E,4] A3/4 B5/8 D5/8\\n^G3/4 B5/8 [E,8C5/8A,8] E3/4 A5/8 E5/8 A3/4 c5/8 E5/8 A3/4 c5/8\\n[e3/2E5/8] A3/4 [c5/8z/8] e/2 [e6E5/8^G,8E,8] B3/4 d5/8 E5/8 B3/4\\nd5/8 E5/8 B3/4 d5/8 [e3/2E5/8] B3/4 [d5/8z/8] e/2 [e4E5/8A,4] A3/4\\nc5/8 E5/8 A3/4 c5/8 [f4F5/8D,4] A3/4 d5/8 F5/8 A3/4 d5/8 [e4E5/8=G,4]\\n=G3/4 c5/8 E5/8 G3/4 c5/8 [d2F5/8G,4] G3/4 B5/8 [g2F5/8] G3/4 B5/8\\n[c11/8E5/8C8C,8] G3/4 c5/8 E5/8 G3/4 c5/8 E5/8 G3/4 c5/8 E5/8 G3/4\\nc5/8 [^D5/8C8C,8] G3/4 c5/8 ^D5/8 G3/4 c5/8 ^D5/8 G3/4 c5/8\\n[^d3/2^D5/8] G3/4 [c5/8z/8] ^d/2 [^d6^D5/8^A,8] G3/4 ^c5/8 ^D5/8 G3/4\\n^c5/8 ^D5/8 G3/4 ^c5/8 [^d3/2^D5/8] G3/4 [^c5/8z/8] ^d/2\\n[^d6^D5/8^G,2] ^G3/4 =c5/8 [^D5/8=G,2] ^G3/4 c5/8 [^D5/8^F,4] A3/4\\nc5/8 [=d2=D5/8] A3/4 c5/8 [d4D5/8G,4] =G3/4 ^A5/8 D5/8 G3/4 ^A5/8\\n[^d2^D5/8C,2] G3/4 =A5/8 [c2C5/8^D,2] G3/4 A5/8 [=d4=D5/8=D,4] G3/4\\n^A5/8 D5/8 G3/4 ^A5/8 [D,4d4D5/8] ^F3/4 =A5/8 D5/8 ^F3/4 A5/8\\n[G2G,10z5/8] ^A3/4 d5/8 G5/8 ^A3/4 d5/8 G5/8 B3/4 d5/8 [g2G5/8] B3/4\\nd5/8 [^g6G5/8] c3/4 ^d5/8 [G5/8C2C,2] c3/4 ^d5/8 [G5/8^D2^D,2] c3/4\\n^d5/8 [^f2G5/8C2C,2] c3/4 ^d5/8 [=g6G5/8G,10] B3/4 =d5/8 G5/8 B3/4\\nd5/8 G5/8 B3/4 d5/8 [g2G5/8] B3/4 d5/8 [^g6G5/8] c3/4 ^d5/8\\n[C2G5/8C,2] c3/4 ^d5/8 [^D2^D,2G5/8] c3/4 ^d5/8 [^f2G5/8C2C,2] c3/4\\n^d5/8 [=g4G5/8G,4] B3/4 =d5/8 G5/8 B3/4 d5/8 [g4G5/8E,4] ^A3/4 ^c5/8\\nG5/8 ^A3/4 ^c5/8 [g4G5/8^C,4] =A3/4 e5/8 G5/8 A3/4 e5/8\\n[=f4=F5/8=D,4] A3/4 d5/8 F5/8 A3/4 d5/8 [^d4^D5/8G,4] G3/4 ^A5/8\\n^D5/8 G3/4 ^A5/8 [=d4=D5/8^G,4] F3/4 B5/8 D5/8 F3/4 B5/8\\n[=A4=A,2z5/8] D3/4 F5/8 [A,2z5/8] D3/4 F5/8 [A2A,2z5/8] D3/4 E5/8\\n[A2A,2z5/8] ^C3/4 E5/8 [A,8D5/8D,8] F3/4 A5/8 F5/8 A3/4 d5/8 A5/8\\nd3/4 f5/8 [a3/2A5/8] d3/4 [f5/8z/8] a/2 [a6A5/8^C8^C,8A,8] e3/4 g5/8\\nA5/8 e3/4 g5/8 A5/8 e3/4 g5/8 [a3/2A5/8] e3/4 [g5/8z/8] a/2\\n[a4A5/8D4D,4] d3/4 f5/8 A5/8 d3/4 f5/8 [^g2^G5/8B,2] d3/4 f5/8\\n[a2A5/8A,2] d3/4 f5/8 [E,6b6B5/8^G,6] d3/4 e5/8 B5/8 d3/4 e5/8 B5/8\\nd3/4 e5/8 [b2B5/8^G,2E,2] d3/4 e5/8 [c'4=c5/8A,4E,4] e3/4 a5/8 c5/8\\ne3/4 a5/8 [b2B5/8D,2] d3/4 f5/8 [a2A5/8^D,2] c3/4 ^f5/8 [^g5/8E,8]\\n^G3/4 B5/8 [e2z5/8] ^G3/4 B5/8 [=f2z5/8] ^G3/4 B5/8 [d2z5/8] ^G3/4\\nB5/8 [E,8z5/8] ^G3/4 [B5/4z5/8] [E2z5/8] ^G3/4 B5/8 [F2z5/8] ^G3/4\\nB5/8 [D2z5/8] ^G3/4 B5/8 [=C5/8E,8] c3/4 [e5/4z5/8] [a2z5/8] c3/4\\ne5/8 [c'2z5/8] c3/4 e5/8 [a2z5/8] c3/4 e5/8 [E,8z5/8] C3/4 E5/8\\n[A2z5/8] C3/4 E5/8 [c2z5/8] C3/4 E5/8 [A2z5/8] C3/4 E5/8 [B,5/8E,8]\\nF3/4 D5/8 ^G5/8 F3/4 B5/8 ^G5/8 d3/4 B5/8 f5/8 d3/4 ^g5/8 [C5/8E,8]\\nA3/4 E5/8 c5/8 A3/4 e5/8 c5/8 a3/4 e5/8 c'5/8 a3/4 e5/8 [A5/8E,8]\\n^d3/4 c5/8 ^f5/8 ^d3/4 a5/8 ^f5/8 c'3/4 a5/8 ^d5/8 c'3/4 ^f5/8\\n[=d5/8E,117/8] ^g3/4 =f5/8 b5/8 ^g3/4 d5/8 b5/8 f3/4 d5/8 ^g5/8 f3/4\\nb5/8 ^g5/8 d3/4 f5/8 b5/8 d3/4 ^g5/8 b5/8 f3/4 ^g5/8 d5/8\\n[E,75/8f3/4] B5/8 d5/8 ^G3/4 B5/8 F5/8 ^G3/4 D5/8 F5/8 [B,11/8z5/8]\\nD3/4 [A,2z5/8] D3/4 F5/8 [^G,4E,8z5/8] D3/4 E5/8 F5/8 E3/4 D5/8\\n[B,2z5/8] D3/4 F5/8 [A,2z5/8] D3/4 F5/8 [^G,4E,8z5/8] D3/4 E5/8 F5/8\\nE3/4 D5/8 [^A,2z5/8] D3/4 F5/8 [=A,2z5/8] D3/4 F5/8 [^G,4E,4z5/8]\\nD3/4 E5/8 F5/8 E3/4 D5/8 [A,5/8=F,4] C3/4 A5/8 A,5/8 C3/4 A5/8\\n[B,5/8=D,4] F3/4 A5/8 B,5/8 F3/4 A5/8 [B,5/8E,4] E3/4 ^G5/8 B,5/8\\nD3/4 ^G5/8 [E,8C5/8A,8] E3/4 A5/8 E5/8 A3/4 c5/8 E5/8 A3/4 c5/8\\n[e3/2E5/8] A3/4 [c5/8z/8] e/2 [e6E5/8^G,8E,8] B3/4 d5/8 E5/8 B3/4\\nd5/8 E5/8 B3/4 d5/8 [e3/2E5/8] B3/4 [d5/8z/8] e/2 [e4E5/8A,4] A3/4\\nc5/8 E5/8 A3/4 c5/8 [f4F5/8D,4] A3/4 d5/8 F5/8 A3/4 d5/8 [e4E5/8=G,4]\\n=G3/4 c5/8 E5/8 G3/4 c5/8 [d2F5/8G,4] G3/4 B5/8 [=g2F5/8] G3/4 B5/8\\n[c11/8E5/8C8=C,8] G3/4 c5/8 G5/8 c3/4 e5/8 G5/8 c3/4 e5/8 [g3/2G5/8]\\nc3/4 [e5/8z/8] g/2 [g6G5/8B,8] d3/4 f5/8 G5/8 d3/4 f5/8 G5/8 d3/4\\nf5/8 [g3/2G5/8] d3/4 [f5/8z/8] g/2 [g4G5/8C4C,4] c3/4 e5/8 G5/8 c3/4\\ne5/8 [^g2^G5/8B,2] d3/4 e5/8 [a2A5/8A,2] c3/4 e5/8 [E,4b4B5/8^G,4]\\nd3/4 e5/8 B5/8 d3/4 e5/8 [c'4c5/8A,4E,4] e3/4 a5/8 c5/8 e3/4 a5/8\\n[^a4^A5/8D,4] d3/4 f5/8 ^A5/8 d3/4 f5/8 [^g4^G5/8E,4] d3/4 e5/8 ^G5/8\\nd3/4 e5/8 [=a6=A5/8A,10] c3/4 e5/8 A5/8 c3/4 e5/8 A5/8 ^c3/4 e5/8\\n[a2A5/8] ^c3/4 e5/8 [^a6A5/8] d3/4 f5/8 [D,2D2A5/8] d3/4 f5/8\\n[A5/8F2F,2] d3/4 f5/8 [^g2A5/8D2D,2] d3/4 f5/8 [=a6A,10A5/8] ^c3/4\\ne5/8 A5/8 ^c3/4 e5/8 A5/8 ^c3/4 e5/8 [a2A5/8] ^c3/4 e5/8 [^a6A5/8]\\nd3/4 f5/8 [D2A5/8D,2] d3/4 f5/8 [F2A5/8F,2] d3/4 f5/8 [^g2A5/8D2D,2]\\nd3/4 f5/8 [=a4A5/8A,4] ^c3/4 e5/8 A5/8 ^c3/4 e5/8 [a4A5/8D,4] d3/4\\nf5/8 A5/8 d3/4 f5/8 [=g6=G5/8B,6] d3/4 f5/8 G5/8 d3/4 f5/8 G5/8 d3/4\\nf5/8 [g2G5/8C2C,2] =c3/4 e5/8 [f2F5/8A,2] c3/4 e5/8 [f2F5/8B,2] B3/4\\nd5/8 [e2E5/8^G,2] B3/4 d5/8 [e2E5/8A,2] A3/4 c5/8 [d4D5/8F,4] A3/4\\nB5/8 D5/8 A3/4 B5/8 [e2E5/8E,2] A3/4 B5/8 [f2F5/8D,2] A3/4 B5/8\\n[e4E5/8E,4] A3/4 c5/8 E5/8 A3/4 c5/8 [e4D5/8E,4] ^G3/4 B5/8 D5/8\\n^G3/4 B5/8 [A11/8E,6C5/8A,8] E3/4 A5/8 E5/8 A3/4 c5/8 E5/8 A3/4 c5/8\\n[E5/8E,3/2] A3/4 [c5/8z/8] E,/2 [E5/8E,6^G,8] B3/4 d5/8 E5/8 B3/4\\nd5/8 E5/8 B3/4 d5/8 [E5/8E,3/2] B3/4 [d5/8z/8] E,/2 [E5/8E,6A,8] c3/4\\nA5/8 e5/8 c3/4 a5/8 e5/8 c'3/4 a5/8 [E,3/2e5/8] c'3/4 [a5/8z/8] E,/2\\n[E,6^g5/8] b3/4 f5/8 ^g5/8 d3/4 f5/8 B5/8 d3/4 [F5/4z5/8]\\n[^G2E,3/2z5/8] E3/4 [D5/8z/8] E,/2 [C5/8E,6A5/8A,8] c3/4 A5/8 e5/8\\nc3/4 a5/8 e5/8 c'3/4 a5/8 [e5/8E,3/2] c'3/4 [a5/8z/8] E,/2 [^g5/8E,6]\\nb3/4 f5/8 ^g5/8 d3/4 f5/8 B5/8 d3/4 [F5/4z5/8] [^G2E,3/2z5/8] E3/4\\n[D5/8z/8] E,/2 [C5/8A5/8E,4A,4] E3/4 A5/8 c5/8 A3/4 E5/8 [A,37/8z5/8]\\nC3/4 E5/8 A5/8 E3/4 C5/8 [E,4z5/8] [A,11/4z3/4] C5/8 E5/8 C3/4 A,5/8\\nE,5/8 A,3/4 E,5/8 C,5/8 E,3/4 C,5/8 A,4 [A33/8E33/8C33/8E,33/8A,33/8]\\n[A117/8E117/8C117/8E,117/8A,117/8] [A,3E,3C3E3A3] \\n\\n\\nX: 1\\nT: Mysterious Barricades (2:29) \\nC: Francois Couperin\\nZ: Transcribed by LotRO MIDI Player: http://lotro.acasylum.com/midi\\nZ: contributed by Hyacinth of Landroval\\nL: 1/4\\nQ: 118\\nK: C\\n\\nz/2 [^c7/8z3/8] [f11/8^C15/8z/2] [^c7/4z3/8] [^G11/4z/2] ^d/2\\n[^g7/4^G,7/8z3/8] [=cz/2] [^C15/8z/2] [^c7/8z3/8] [f11/8^G7/4z/2]\\n[^c7/4z3/8] [^G,15/8z/2] [^d/2z3/8] [^g15/8^F15/8z/2] [=c7/8z/2]\\n[^A,15/8z3/8] [cz/2] [^c7/4=F7/4z3/8] [^Az/2] [F,7/4z/2] ^G3/8\\n[^c/2^G7/8F15/8] =c3/8 [^A11/8^F,15/8z/2] ^c/2 [^f5/4^D7/4z3/8] ^A3/8\\nz/8 [=c3/8^G,7/4] [^f/2z/4] =f/8 z/8 [^f/4^G7/4z/8] [=f3/8z/4] ^d/2\\n[f7/8^C15/8z/2] [^c7/8z3/8] [f11/8^G15/8z/2] [^c15/8z3/8]\\n[^G,15/8z/2] ^d/2 [^g7/4^G7/4z3/8] [=c7/8z/2] [^C15/8z/2] [^c7/8z3/8]\\n[f11/8^G7/4z/2] [^c7/4z3/8] [^G,7/4z/2] [^d/2z3/8] [^g15/8^F15/8z/2]\\n[=c7/8z3/8] [^A,2z/2] [cz/2] [^c7/4=F7/4z3/8] [^Az/2] [=F,7/4z/2]\\n[^G5/4z3/8] [^c/2F7/4] =c/4 z/8 [^A11/8^F,15/8z/2] [c/2z3/8]\\n[^c15/8^D15/8z/2] [^G7/8z/2] [^G,7/4z3/8] [^G7/4z/2]\\n[^c/2^D7/8^F7/8z3/8] [=c/2z/4] ^c/8 z/8 [=c/4=F7/8^C15/8] ^c/4\\n[^c7/8z3/8] [f11/8^G7/4z/2] [^c7/4z3/8] [^G,15/8z/2] [^d/2z3/8]\\n[^g15/8^G15/8z/2] =c3/8 z/8 [c/2^C15/8z3/8] [^cz/2] [f11/8^G7/4z/2]\\n[^c7/4z3/8] [^G,7/4z/2] [^d/2z3/8] [^g15/8^F15/8z/2] [=c7/8z3/8]\\n[^A,2z/2] [cz/2] [^c7/4=F7/4z3/8] [^Az/2] [=F,7/4z3/8] ^G/2\\n[^c/2^G7/8F7/4] =c/4 z/8 [^A11/8^F,15/8z/2] [^c/2z3/8]\\n[^f11/8^D15/8z/2] ^A3/8 [=c/2^G,15/8] [^f/2z/4] =f/8 z/8 [^f/8^G7/4]\\n=f/4 ^d/2 [f7/8^C15/8z/2] [^c7/8z3/8] [f11/8^G7/4z/2] [^c7/4z3/8]\\n[^G,15/8z/2] [^d/2z3/8] [^g15/8^G15/8z/2] [=c7/8z/2] [^C15/8z3/8]\\n[^c7/8z/2] [f11/8^G7/4z3/8] [^c15/8z/2] [^G,7/4z/2] [^d/2z3/8]\\n[^g15/8^F15/8z/2] [=c7/8z3/8] [^A,2z/2] [cz/2] [^c7/4=F7/4z3/8]\\n[^Az/2] [=F,7/4z3/8] [^G11/8z/2] [^c/2F7/4z3/8] =c3/8 z/8\\n[^A11/8^F,15/8z/2] [c/2z3/8] [^c15/8^D15/8z/2] [^G7/8z3/8]\\n[^G,15/8z/2] [^G11/8z/2] [^c/2^D7/8^F7/8z3/8] [=c/2z/4] ^c/8 z/8\\n[=c/4^G3/8=F7/8^C15/8z/8] ^c3/8 [f7/8z3/8] [^g7/4^c15/8z/2]\\n[f7/8z3/8] [^G15/8z/2] [^d7/8z3/8] [^g15/8=cz/2] [^d7/8z/2]\\n[^C15/8z3/8] [f7/8z/2] [^g7/4^c15/8z3/8] [fz/2] [^G7/4z/2]\\n[^d7/8z3/8] [^g15/8=c7/8z/2] [^d7/8z3/8] [^C15/8z/2] [f7/8z/2]\\n[^g7/4^c7/8z3/8] [fz/2] [=C7/4z3/8] [^d7/8z/2] [^g7/4^G7/8z3/8]\\n[^dz/2] [^A,15/8z/2] [^c7/8z3/8] [^g15/8^A7/4z/2] [^c7/8z3/8]\\n[^D15/8z/2] [^c7/8z3/8] [=g^Az/2] ^c/2 [^g7/8=c3/8^G,15/8] [c7/8z/2]\\n[^d7/4^G15/8z3/8] [cz/2] [^D7/4z/2] [^A7/8z3/8] [^d7/4=G7/8z/2]\\n[^A7/8z3/8] [^G,15/8z/2] [c7/8z3/8] [^d15/8^G15/8z/2] [cz/2]\\n[^D7/4z3/8] [^A7/8z/2] [^d7/4=G7/8z3/8] [^A7/8z/2] [^G,15/8z/2]\\n[c7/8z3/8] [^d7/4^G7/4z/2] [c7/8z3/8] [^D7/4z/2] [c7/8z3/8]\\n[^d15/8^G15/8z/2] [c7/8z3/8] [^C2z/2] [cz/2] [f7/8^G7/8z3/8] ^A/2\\n[^A/8=G15/8^D7/4] c/8 ^A/8 c/8 [^A/4z/8] c/4 [^A3/8^D,7/8] ^G/4 ^A/4\\n[^G3/8^G,7/4] z/8 [c7/8z3/8] [^d15/8^Gz/2] [c7/8z3/8] [^D15/8z/2]\\n[^A7/8z3/8] [^f15/8^D,z/2] [c7/8z/2] [^A,21/8z3/8] [^c7/8z/2]\\n[=f15/8^A7/8z3/8] [^cz/2] [F7/4z/2] [B7/8z3/8] [^g15/8=F,z/2]\\n[B7/8z3/8] [^F,15/8z/2] [^A7/8z/2] [^c7/4^F7/8z3/8] [^A7/8z/2]\\n[^D7/4z3/8] [^A7/8z/2] [^f7/4^D,7/8z3/8] [^A7/8z/2] [^G,7/4z/2]\\n[=c7/8z3/8] [^f15/8^Gz/2] [c7/8z3/8] [^C7/4z/2] [^c7/8z3/8]\\n[=f7/8^C,z/2] [^c/2z3/8] [f/4=c/2^G,] [^d/8^c/8] ^d/8 ^c/2\\n[f11/8^C7/8z3/8] [^c15/8z/2] [^G21/8z3/8] ^d/2 [^g7/4^G,7/8z/2]\\n[=c7/8z3/8] [^C15/8z/2] [^c7/8z/2] [f11/8^G7/4z3/8] [^c15/8z/2]\\n[^G,7/4z3/8] ^d/2 [^g7/4^F7/4z3/8] [=c7/8z/2] [^A,15/8z/2] [c7/8z3/8]\\n[^c7/4=F7/4z/2] [^A7/8z3/8] [=F,15/8z/2] [^G11/8z3/8] [^c/2F15/8]\\n=c3/8 z/8 [^A5/4^F,15/8z3/8] ^c/2 [^f11/8^D7/4z3/8] ^A/2\\n[=c3/8^G,7/4] z/8 [^f/4z/8] =f/8 [^f/4z/8] [=f/2^G15/8] [^d/2z3/8]\\n[f^C15/8z/2] [^c7/8z/2] [f11/8^G7/4z3/8] [^c15/8z/2] [^G,7/4z3/8]\\n^d/2 [^g7/4^G7/4z3/8] [=cz/2] [^C15/8z/2] [^c7/8z3/8] [f3/2^G15/8z/2]\\n[^c15/8z/2] [^G,7/4z3/8] ^d/2 [^g7/4^F7/4z3/8] [=c7/8z/2]\\n[^A,15/8z/2] [c7/8z3/8] [^c7/4=F7/4z/2] [^A7/8z3/8] [=F,7/4z/2]\\n[^G5/4z3/8] [^c/2F15/8] =c3/8 z/8 [^A11/8^F,15/8z3/8] c/2\\n[^c7/4^D7/4z3/8] [^Gz/2] [^G,7/4z/2] [^G5/4z3/8] [^c/2^D7/8^F7/8]\\n[=c3/8z/8] ^c/8 z/8 [=c/4^G=F^C15/8] ^c/4 ^c/2 [f15/8^G7/4z3/8]\\n[^c7/8z/2] [^G,7/4z3/8] [^cz/2] [^d7/4^F7/4z3/8] [=c7/8z/2]\\n[^A,15/8z/2] [c7/8z3/8] [^c15/8=F15/8z/2] [^A7/8z/2] [=F,7/4z3/8]\\n[^A7/8z/2] [=c7/8F7/8z3/8] =A/2 [^A7/8^F,15/8z3/8] ^f/2\\n[^a15/8^F7/8z/2] [^f7/8z3/8] [=D7/4z/2] [^f7/8z3/8] [^g15/8^A,7/8z/2]\\n[=f3/4z3/8] [^D15/8z/2] [fz/2] [^f15/8^G,7/8z3/8] [^d7/8z/2]\\n[^A,7/8z3/8] [^dz/2] [=f7/8^A,7/8z3/8] =d3/8 z/8 [^d7/8^D,15/8z/2]\\n[^A7/8z3/8] [^f7/4^D7/8z/2] [^A7/8z3/8] [=F,7/4z/2] [^G7/8z3/8]\\n[=f11/8=F7/8z/2] [^G7/8z/2] [^F,7/4z3/8] f/2 [^f/2^F7/8z3/8] =f/2\\n[^d/2=G,7/8z3/8] ^c/2 [=c/2^D,7/8] [^A/2^c/8] =c/8 ^c/8 [=c7/8^G,z/2]\\n[^c7/8z3/8] [f3/2^Cz/2] [^c15/8z/2] [^G21/8z3/8] ^d/2\\n[^g7/4^G,7/8z3/8] [=c7/8z/2] [^C7/4z/2] [^c7/8z3/8] [f11/8^G7/4z/2]\\n[^c15/8z3/8] [^G,15/8z/2] [^d/2z3/8] [^g15/8^F15/8z/2] [=c7/8z/2]\\n[^A,15/8z3/8] [cz/2] [^c7/4=F7/4z/2] [^A7/8z3/8] [=F,7/4z/2]\\n[^G5/4z3/8] [^c/2F15/8] =c3/8 [^A11/8^F,15/8z/2] ^c/2\\n[^f5/4^D7/4z3/8] ^A/2 [=c3/8^G,7/4] [^f3/8z/4] =f/8 ^f/8\\n[=f/2^G7/4z3/8] ^d/2 [f7/8^C15/8z/2] [^c7/8z3/8] [f11/8^G15/8z/2]\\n[^c15/8z3/8] [^G,15/8z/2] ^d/2 [^g7/4^G7/4z3/8] [=c7/8z/2]\\n[^C15/8z/2] [^c7/8z3/8] [f11/8^G7/4z/2] [^c7/4z3/8] [^G,15/8z/2]\\n[^d/2z3/8] [^g15/8^F15/8z/2] [=c7/8z/2] [^A,15/8z3/8] [cz/2]\\n[^c7/4=F7/4z3/8] [^Az/2] [=F,7/4z/2] [^G11/8z3/8] [^c/2F15/8] =c3/8\\n[^A11/8^F,15/8z/2] c/2 [^c7/4^D7/4z3/8] [^G7/8z/2] [^G,7/4z3/8]\\n[^G11/8z/2] [^c/2^D7/8^F7/8z3/8] [=c/2z/4] ^c/8 z/8\\n[=c/4^G7/8=F7/8^C15/8] ^c/8 z/8 [^c/2z3/8] [f15/8^G15/8z/2]\\n[^c7/8z3/8] [^G,15/8z/2] [^c7/8z/2] [^f7/4^A7/4z3/8] [^c7/8z/2]\\n[B,15/8z/2] [^c7/8z3/8] [^d11/8^F7/4z/2] [B7/8z3/8] [^G,7/4z/2]\\n[^d7/8z3/8] [^g15/8B15/8z/2] [^d7/8z/2] [^C15/8z3/8] [^dz/2]\\n[=f15/8^G7/4z3/8] [^cz/2] [^A,7/4z/2] [^c7/8z3/8] [^f7/4^A7/4z/2]\\n[^c7/8z3/8] [B,15/8z/2] [^d7/8z3/8] [^f15/8^G15/8z/2] [^dz/2]\\n[^C7/4z3/8] [B7/8z/2] [=f7/8^G7/8z3/8] [B7/8z/2] [^f11/8^F,15/8z/2]\\n[B/2z3/8] [^A11/8z/2] [^c/2z3/8] [^f/2^F7/4] [^f7/8z3/8]\\n[^a15/8^c15/8z/2] ^f3/8 [=G2z/2] [^d7/8z/2] [^a7/4^c7/4z3/8]\\n[^d7/8z/2] [^D7/4z3/8] [^d7/8z/2] [^a7/4^c7/4z3/8] [^d7/8z/2]\\n[^G15/8z/2] [^d7/8z3/8] [^a7/4B7/4z/2] [^d7/8z3/8] [^F15/8z/2]\\n[^d7/8z3/8] [^a15/8B15/8z/2] [^dz/2] [=F15/8z3/8] [=f7/8z/2]\\n[^g7/4B7/4z3/8] [f7/8z/2] [^C7/4z/2] [f7/8z3/8] [^g15/8B15/8z/2]\\n[f7/8z3/8] [^F15/8z/2] [^c7/8z/2] [^g7/4^A7/4z3/8] [^c7/8z/2]\\n[=F7/4z3/8] [^c7/8z/2] [^g7/4^A7/4z3/8] [^cz/2] [^D15/8z/2]\\n[^d7/8z3/8] [^f7/4^A7/4z/2] [^d3/4z3/8] [=C7/4z/2] [^d7/8z3/8]\\n[^f15/8^A15/8z/2] [^d7/8z3/8] [F2z/2] [=c7/8z/2] [^f7/4^G7/4z3/8]\\n[c7/8z/2] [^D7/4z3/8] [c7/8z/2] [^f7/4^G7/4z3/8] [cz/2] [^C15/8z/2]\\n[^c7/8z3/8] [=f15/8^G15/8z/2] [^c7/8z3/8] [^A,15/8z/2] [^c7/8z/2]\\n[f7/4^G7/4z3/8] [^cz/2] [^D15/8z3/8] [^A7/8z/2] [f7/4^F7/4z3/8]\\n[^A7/8z/2] [^C7/4z/2] [^A7/8z3/8] [f15/8^F15/8z/2] [^A7/8z3/8]\\n[=C15/8z/2] [=c7/8z/2] [^d7/4^F7/4z3/8] [c7/8z/2] [^G,15/8z3/8]\\n[c7/8z/2] [^d7/4^F7/4z3/8] [cz/2] [^C7/4z/2] [^G7/8z3/8]\\n[^d15/8=F15/8z/2] [^G7/8z3/8] [=F,15/8z/2] [^G7/8z/2] [^c7/4F7/4z3/8]\\n[^Gz/2] [^F,15/8z3/8] [^A7/8z/2] [^c7/4^D7/4z3/8] [^Az/2]\\n[^G,15/8z/2] [^G7/8z3/8] [^c15/8F15/8z/2] [^G7/8z3/8] [^A,15/8z/2]\\n[^F7/8z/2] [^c7/4^D7/8z3/8] [^Fz/2] [=F,7/4z3/8] [^G7/8z/2]\\n[^c7/4=F7/4z3/8] [^Gz/2] [^F,7/4z/2] [^A7/8z3/8] [^c15/8^D15/8z/2]\\n[^A7/8z3/8] [^A,15/8z/2] [^F7/8z/2] [^c7/4^D7/4z3/8] [^Fz/2]\\n[^G,7/4z3/8] [^Gz/2] [=c7/4^D7/8z/2] [^G3/4z3/8] [=F,7/4z/2]\\n[^G7/8z3/8] [^c15/8=F15/8z/2] [^G7/8z3/8] [^F,15/8z/2] [^A7/8z/2]\\n[^c7/4^D7/4z3/8] [^A7/8z/2] [^G,7/4z3/8] [^G7/8z/2] [^c7/4F7/4z3/8]\\n[^Gz/2] [^A,7/4z/2] [^F7/8z3/8] [^c15/8^D15/8z/2] [^F7/8z3/8]\\n[^F,15/8z/2] [^A7/8z/2] [^c7/4=F7/4z3/8] [^Az/2] [^G,3z/2]\\n[^G7/8z3/8] [^c17/8^D9/8z/2] [^Gz5/8] [^D17/8^F17/8z/2] ^G/2\\n[^c5/8^G13/8^G,9/8z/2] [=c5/8z3/8] ^c/8 z/8 [=c/4=F7/8^C15/8] ^c/8\\nz/8 [^c7/8z3/8] [f3/2^G15/8z/2] [^c15/8z/2] [^G,7/4z3/8] ^d/2\\n[^g7/4^G7/8z3/8] [=c7/8z/2] [^G7/8^C15/8z/2] [^c7/8z3/8]\\n[f11/8^G7/4z/2] [^c15/8z3/8] [^G,15/8z/2] [^d/2z3/8]\\n[^g15/8^F15/8z/2] [=c7/8z/2] [^A,15/8z3/8] [cz/2] [^c7/4=F7/4z/2]\\n[^A7/8z3/8] [=F,7/4z/2] ^G3/8 [^c/2^GF15/8] =c3/8 [^A11/8^F,15/8z/2]\\n^c/2 [^f5/4^D7/4z3/8] ^A3/8 z/8 [=c3/8^G,7/4] [^f/2z/4] =f/8 z/8\\n[^f/4^G7/4z/8] [=f3/8z/4] ^d/2 [f7/8^C15/8z/2] [^c7/8z3/8]\\n[f11/8^G15/8z/2] [^c15/8z3/8] [^G,15/8z/2] ^d/2 [^g7/4^G7/4z3/8]\\n[=c7/8z/2] [^C15/8z/2] [^c7/8z3/8] [f11/8^G7/4z/2] [^c7/4z3/8]\\n[^G,15/8z/2] [^d/2z3/8] [^g15/8^F15/8z/2] [=c7/8z/2] [^A,15/8z3/8]\\n[cz/2] [^c7/4=F7/4z3/8] [^Az/2] [=F,7/4z/2] [^G5/4z3/8] [^c/2F15/8]\\n=c3/8 [^A3/2^F,2z/2] c/2 [^c15/8^D15/8z3/8] [^Gz/2] [^G,17/8z/2]\\n[^G13/8z/2] [^c5/8^D9/8^F9/8z/2] =c/2 z/8\\n[^c37/8=F37/8^G37/8^C37/8^C,37/8]\\n\\n\\nX:1\\nT:Harmonious Blacksmith (Air and variations in E major) \\nC:George Frideric Handel\\nZ:Rhysling of Landroval\\nM:2/4\\nL:1/16\\nQ:1/4=115\\nK:G\\n[G4D4-B,4] [B4D4G,4]| \\\\\\n[A4D4-F,4] [d4D4D,4]| \\\\\\n[c2D2-G,2-] [B2D2-G,2] [A2D2-B,2-] [G2D2B,2]|\\n[A4D4-F,4] [d4D4D,4]| \\\\\\n[B4G4] [e2G,2-] [G2G,2]| \\\\\\n[F4A,4] [d2B,2-] [F2B,2]| \\\\\\n[E4G,4] [^c4G4A,4]|\\n[d4-F4-D4] [d4F4D,4]| \\\\\\n[G4D4-B,4] [B4D4G,4]| \\\\\\n[A4D4-F,4] [d4D4D,4]| \\\\\\n[=c2D2-G,2-] [B2D2-G,2] [A2D2-B,2-] [G2D2B,2]|\\n[A4D4-F,4] [d4D4D,4]| \\\\\\n[B4G4] [e2G,2-] [G2G,2]| \\\\\\n[F4A,4] [d2B,2-] [F2B,2]| \\\\\\n[E4G,4] [^c4G4A,4]|\\n[d4-F4-D4] [d4F4D,4]| \\\\\\n[d4G4-B,4] [g2G2-G,2-] [d2G2G,2]| \\\\\\n[e4G4-=C4] [d4G4B,4]| \\\\\\nB2 d2 [g2B2-G,2-] [d2B2G,2]|\\n[e4G4-C4] [d4G4B,4]| \\\\\\nB2 d2 [g2B2-G,2-] [f2B2G,2]| \\\\\\n[f2G2-C2-] [e2G2C2] [e2G2-B,2-] [d2G2B,2]| \\\\\\n[d2F2-A,2-] [c2F2A,2] [B2G2-G,2-] [cG-G,-][dGG,]|\\n[A4-F4-D4] [A4F4C4]| \\\\\\n[d4B,4] [G4D4]| \\\\\\n[B2E2-C2-] [A2E2C2] [G4D4B,4]| \\\\\\n[d2G,2-] [B2G,2] [A2B,2-] [G2B,2]|\\n[A2_E2-C2-] [F2_E2C2] [G4D4B,4]| \\\\\\n[d2G,2-] [B2G,2] [A2B,2-] [G2B,2]| \\\\\\n[F2A,2-] [c2A,2] [B2D,2-] [A2D,2]| \\\\\\n[B4G4G,4] [A3F3-C3-D,3-][GFCD,]|\\n[G8B,8G,8]| \\\\\\n[d4G4-B,4] [g2G2-G,2-] [d2G2G,2]| \\\\\\n[=e4G4-C4] [d4G4B,4]| \\\\\\nB2 d2 [g2B2-G,2-] [d2B2G,2]|\\n[e4G4-C4] [d4G4B,4]| \\\\\\nB2 d2 [g2B2-G,2-] [f2B2G,2]| \\\\\\n[f2G2-C2-] [e2G2C2] [e2G2-B,2-] [d2G2B,2]| \\\\\\n[d2F2-A,2-] [c2F2A,2] [B2G2-G,2-] [cG-G,-][dGG,]|\\n[A4-F4-D4] [A4F4C4]| \\\\\\n[d4B,4] [G4D4]| \\\\\\n[B2E2-C2-] [A2E2C2] [G4D4B,4]| \\\\\\n[d2G,2-] [B2G,2] [A2B,2-] [G2B,2]|\\n[A2_E2-C2-] [F2_E2C2] [G4D4B,4]| \\\\\\n[d2G,2-] [B2G,2] [A2B,2-] [G2B,2]| \\\\\\n[F2A,2-] [c2A,2] [B2D,2-] [A2D,2]| \\\\\\n[B4G4G,4] [A3F3-C3-D,3-][GFCD,]|\\n[G8B,8G,8]| \\\\\\n[G2-B,2] [G2D2] [B2-G,2] [B2D2]| \\\\\\n[A2-F,2] [A2D2] [d2-D,2] [d2D2]| \\\\\\n[c2G,2] [B2D2] [A2B,2] [G2D2]|\\n[A2-F,2] [A2D2] [d2-D,2] [d2D2]| \\\\\\n[B2G,2-] [G2G,2] [=e2G,2-] [G2G,2]| \\\\\\n[F2A,2-] [e2A,2] [d2B,2-] [F2B,2]| \\\\\\n[E2G,2-] [G2G,2] [d2A,2-] [^c2A,2]|\\n[d2D,2-] [A2D,2] F2 D2| \\\\\\n[G2-B,2] [G2D2] [B2-G,2] [B2D2]| \\\\\\n[A2-F,2] [A2D2] [d2-D,2] [d2D2]| \\\\\\n[=c2G,2] [B2D2] [A2B,2] [G2D2]|\\n[A2-F,2] [A2D2] [d2-D,2] [d2D2]| \\\\\\n[B2G,2-] [G2G,2] [e2G,2-] [G2G,2]| \\\\\\n[F2A,2-] [e2A,2] [d2B,2-] [F2B,2]| \\\\\\n[E2G,2-] [G2G,2] [d2A,2-] [^c2A,2]|\\n[d2D,2-] [A2D,2] F2 D2| \\\\\\n[d2-B,2] [d2G2] [g2G,2-] [d2G,2]| \\\\\\n[e2-=C2] [e2G2] [^c2-_B,2] [^c2G2]| \\\\\\n[d2-=B,2] [d2G2] [g2G,2-] [f2G,2]|\\n[e2-=C2] [e2G2] [^c2-_B,2] [^c2G2]| \\\\\\n[d2-=B,2] [d2G2] [B2G,2-] [g2G,2]| \\\\\\n[f2G2-=C2-] [e2G2C2] [e2F2-B,2-] [d2F2B,2]| \\\\\\n[d2F2-A,2-] [c2F2A,2] [B2G2-G,2-] [d2G2G,2]|\\n[A2-F2-D2] [A2-F2-C2] [A2-F2-B,2] [A2F2A,2]| \\\\\\n[d2G,2-] [D2G,2] G2 B2| \\\\\\n[A2C2-] [F2C2] [G2-B,2] [G2D2]| \\\\\\n[d2G,2-] [B2G,2] [A2A,2] [G2B,2]|\\n[A2_E2-C2-] [F2_E2C2] [G2-B,2] [G2D2]| \\\\\\n[d2G,2-] [B2G,2] [B/2A/2-B,/2-][A3/2B,3/2-] [G2B,2]| \\\\\\n[F2A,2-] [c2A,2] [B2D,2-] [A2D,2]| \\\\\\n[B2G2-G,2-] [G2D2G,2] [B2F2-C2-D,2-] [A2F2C2D,2]|\\n[G2-G,2] [G2-B,2] [G4G,4]| \\\\\\n[d2-B,2] [d2G2] [g2G,2-] [d2G,2]| \\\\\\n[=e2-C2] [e2G2] [^c2-_B,2] [^c2G2]| \\\\\\n[d2-=B,2] [d2G2] [g2G,2-] [f2G,2]|\\n[e2-=C2] [e2G2] [^c2-_B,2] [^c2G2]| \\\\\\n[d2-=B,2] [d2G2] [B2G,2-] [g2G,2]| \\\\\\n[f2G2-=C2-] [e2G2C2] [e2F2-B,2-] [d2F2B,2]| \\\\\\n[d2F2-A,2-] [c2F2A,2] [B2G2-G,2-] [d2G2G,2]|\\n[A2-F2-D2] [A2-F2-C2] [A2-F2-B,2] [A2F2A,2]| \\\\\\n[d2G,2-] [D2G,2] G2 B2| \\\\\\n[A2C2-] [F2C2] [G2-B,2] [G2D2]| \\\\\\n[d2G,2-] [B2G,2] [A2A,2] [G2B,2]|\\n[A2_E2-C2-] [F2_E2C2] [G2-B,2] [G2D2]| \\\\\\n[d2G,2-] [B2G,2] [B/2A/2-B,/2-][A3/2B,3/2-] [G2B,2]| \\\\\\n[F2A,2-] [c2A,2] [B2D,2-] [A2D,2]| \\\\\\n[B2G2-G,2-] [G2D2G,2] [B2F2-C2-D,2-] [A2F2C2D,2]|\\n[G2-G,2] [G2-B,2] [G4G,4]| \\\\\\n[DG,-]G,/2-[=EG,-][FG,-]G,/2 [GB,-]B,/2-[GB,-][GB,-]B,/2| \\\\\\n[GC-A,-][C/2-A,/2-][FC-A,-][GC-A,-][C/2A,/2] (3^G2A2B2| \\\\\\n[c=G-E,-][G/2-E,/2-][BG-E,-][cG-E,-][G/2E,/2] [eA-F,-][A/2-F,/2-][dA-F,-][cA-F,-][A/2F,/2]|\\n[BG-G,-][G/2-G,/2-][dG-G,-][cG-G,-][G/2G,/2] (3B2A2G2| \\\\\\n[DG,-]G,/2-[EG,-][FG,-]G,/2 [GB,]z/2[AA,][BG,]z/2| \\\\\\n[AF,-]F,/2-[BF,-][^cF,-]F,/2 [dF,]z/2[eE,][fD,]z/2| \\\\\\n[B-BG-G,-][B/2-G/2-G,/2-][fB-G-G,-][eB-G-G,-][B/2G/2G,/2] [G-GE-A,-][G/2-E/2-A,/2-][dG-E-A,-][^cG-E-A,-][G/2E/2A,/2]|\\n[dD,-]D,/2-[AD,-][FD,-]D,/2 [D-D]D/2-[D-=C][D-A,]D/2| \\\\\\n[DG,-]G,/2-[EG,-][FG,-]G,/2 [GB,-]B,/2-[GB,-][GB,-]B,/2| \\\\\\n[GC-A,-][C/2-A,/2-][FC-A,-][GC-A,-][C/2A,/2] (3^G2A2B2| \\\\\\n[c=G-E,-][G/2-E,/2-][BG-E,-][cG-E,-][G/2E,/2] [eA-F,-][A/2-F,/2-][dA-F,-][cA-F,-][A/2F,/2]|\\n[BG-G,-][G/2-G,/2-][dG-G,-][cG-G,-][G/2G,/2] (3B2A2G2| \\\\\\n[DG,-]G,/2-[EG,-][FG,-]G,/2 [GB,]z/2[AA,][BG,]z/2| \\\\\\n[AF,-]F,/2-[BF,-][^cF,-]F,/2 [dF,]z/2[eE,][fD,]z/2| \\\\\\n[B-BG-G,-][B/2-G/2-G,/2-][fB-G-G,-][eB-G-G,-][B/2G/2G,/2] [G-GE-A,-][G/2-E/2-A,/2-][dG-E-A,-][^cG-E-A,-][G/2E/2A,/2]|\\n[dD,-]D,/2-[AD,-][FD,-]D,/2 [D-D]D/2-[D-=C][D-A,]D/2| \\\\\\n[GG,-]G,/2-[GG,-][BG,-]G,/2 [dB,-]B,/2-[gB,-][fB,-]B,/2| \\\\\\n[e-c-C][e/2-c/2-][e-c-E][e-c-F][e/2c/2] [d-B-G][d/2-B/2-][d-B-D][d-B-B,][d/2B/2]| \\\\\\n[GG,-]G,/2-[GG,-][BG,-]G,/2 [dB,-]B,/2-[gB,-][fB,-]B,/2|\\n[e-c-C][e/2-c/2-][e-c-E][e-c-F][e/2c/2] [d-B-G][d/2-B/2-][d-B-D][d-B-B,][d/2B/2]| \\\\\\n[GG,-]G,/2-[GG,-][BG,-]G,/2 [dB,-]B,/2-[gB,-][fB,-]B,/2| \\\\\\n[fG-C-][G/2-C/2-][fG-C-][eG-C-][G/2C/2] [eG-B,-][G/2-B,/2-][eG-B,-][dG-B,-][G/2B,/2]| \\\\\\n[dF-A,-][F/2-A,/2-][dF-A,-][cF-A,-][F/2A,/2] [cG-G,-][G/2-G,/2-][cG-G,-][BG-G,-][G/2G,/2]|\\n[^GD,-]D,/2-[AD,-][=GD,-]D,/2 (3F2E2D2| \\\\\\n[e/2d/2-B,/2-][d/2B,/2-]B,/2-[^cB,-][dB,-]B,/2 [gG,-]G,/2-[dG,-][BG,-]G,/2| \\\\\\n[dA,-]A,/2-[=cA,-][AA,-]A,/2 [FC-]C/2-[AC-][DC-]C/2| \\\\\\n[e/2d/2-B,/2-][d/2B,/2-]B,/2-[^cB,-][dB,-]B,/2 [gG,-]G,/2-[dG,-][BG,-]G,/2|\\n[dA,-]A,/2-[=cA,-][AA,-]A,/2 [FC-]C/2-[AC-][DC-]C/2| \\\\\\n[dB,-]B,/2-[eB,-][fB,-]B,/2 [gG,-]G,/2-[aG,-][bG,-]G,/2| \\\\\\n[cA,-]A,/2-[dA,-][eA,-]A,/2 [fD,-]D,/2-[gD,-][aD,-]D,/2| \\\\\\n[BG,-]G,/2-[fG,-][gG,-]G,/2 [AD,-]D,/2-[gD,-][fD,-]D,/2|\\n[gG,-]G,/2-[dG,-][BG,-]G,/2 [G-G]G/2-[G-D][G-B,]G/2| \\\\\\n[GG,-]G,/2-[GG,-][BG,-]G,/2 [dB,-]B,/2-[gB,-][fB,-]B,/2| \\\\\\n[e-c-C][e/2-c/2-][e-c-E][e-c-F][e/2c/2] [d-B-G][d/2-B/2-][d-B-D][d-B-B,][d/2B/2]| \\\\\\n[GG,-]G,/2-[GG,-][BG,-]G,/2 [dB,-]B,/2-[gB,-][fB,-]B,/2|\\n[e-c-C][e/2-c/2-][e-c-E][e-c-F][e/2c/2] [d-B-G][d/2-B/2-][d-B-D][d-B-B,][d/2B/2]| \\\\\\n[GG,-]G,/2-[GG,-][BG,-]G,/2 [dB,-]B,/2-[gB,-][fB,-]B,/2| \\\\\\n[fG-C-][G/2-C/2-][fG-C-][eG-C-][G/2C/2] [eG-B,-][G/2-B,/2-][eG-B,-][dG-B,-][G/2B,/2]| \\\\\\n[dF-A,-][F/2-A,/2-][dF-A,-][cF-A,-][F/2A,/2] [cG-G,-][G/2-G,/2-][cG-G,-][BG-G,-][G/2G,/2]|\\n[^GD,-]D,/2-[AD,-][=GD,-]D,/2 (3F2E2D2| \\\\\\n[e/2d/2-B,/2-][d/2B,/2-]B,/2-[^cB,-][dB,-]B,/2 [gG,-]G,/2-[dG,-][BG,-]G,/2| \\\\\\n[dA,-]A,/2-[=cA,-][AA,-]A,/2 [FC-]C/2-[AC-][DC-]C/2| \\\\\\n[e/2d/2-B,/2-][d/2B,/2-]B,/2-[^cB,-][dB,-]B,/2 [gG,-]G,/2-[dG,-][BG,-]G,/2|\\n[dA,-]A,/2-[=cA,-][AA,-]A,/2 [FC-]C/2-[AC-][DC-]C/2| \\\\\\n[dB,-]B,/2-[eB,-][fB,-]B,/2 [gG,-]G,/2-[aG,-][bG,-]G,/2| \\\\\\n[cA,-]A,/2-[dA,-][eA,-]A,/2 [fD,-]D,/2-[gD,-][aD,-]D,/2| \\\\\\n[BG,-]G,/2-[fG,-][gG,-]G,/2 [AD,-]D,/2-[gD,-][fD,-]D,/2|\\n[gG,-]G,/2-[dG,-][BG,-]G,/2 G4| \\\\\\nG,2- [AG,-][GG,] [FD,-][GD,-] [AD,-][BD,]| \\\\\\n[A2F,2-] [^c2-F,2] [^c2D,2-] [d2D,2]| \\\\\\nG,2- [=cG,-][BG,] [AD,-][GD,-] [FD,-][GD,]|\\n[A2F,2-] [e2-F,2] [e2D,2-] [d2D,2]| \\\\\\n[d2B,2-] [eB,-][fB,] [g2G,2-] [^cG,-][BG,]| \\\\\\n[_B2F,2-] [fF,-][eF,] [d2=B,2-] [B2B,2]| \\\\\\nE,2- [B2G2E,2] F,2- [_B2F2F,2]|\\n[=B2B,2-] [_B=B,-][BB,] d=c AF| \\\\\\nG,2- [AG,-][GG,] [FD,-][GD,-] [AD,-][BD,]| \\\\\\n[A2F,2-] [^c2-F,2] [^c2D,2-] [d2D,2]| \\\\\\nG,2- [=cG,-][BG,] [AD,-][GD,-] [FD,-][GD,]|\\n[A2F,2-] [e2-F,2] [e2D,2-] [d2D,2]| \\\\\\n[d2B,2-] [eB,-][fB,] [g2G,2-] [^cG,-][BG,]| \\\\\\n[_B2F,2-] [fF,-][eF,] [d2=B,2-] [B2B,2]| \\\\\\nE,2- [B2G2E,2] F,2- [_B2F2F,2]|\\n=B,2- [B2B,2] B,4| \\\\\\nG,2- [FG,-][GG,] [AB,-][GB,-] [gB,-][fB,]| \\\\\\n[e2=C2-] [fC-][gC] [d2-B,2] [d-C][dD]| \\\\\\nG,2- [cG,-][BG,] [AB,-][GB,-] [gB,-][fB,]|\\n[_eC-][=eC-] [fC-][gC] [d-_B,][d-=B,] [d-C][dD]| \\\\\\nG,-[dG,-] [cG,-][BG,] [AB,-][GB,-] [gB,-][fB,]| \\\\\\n[fC-][eC-] [_eC-][=eC] [eB,-][dB,-] [^cB,-][dB,]| \\\\\\n[dF,-][^cF,-] [^GF,-][AF,] [=c=G,-][BG,-] [FG,-][GG,]|\\n[BD,-][AD,-] [^GD,-][AD,] =GF ED| \\\\\\nd-[d-D,] [d-G,][dB,] D-[GD-] [cD-][BD]| \\\\\\n[AG,-][CG,-] [FG,-][AG,] G-[G-D] [G-B,][GD]| \\\\\\nG,-[dG,-] [eG,-][fG,] gG Be|\\n[dF,-][DF,-] [AF,-][cF,] [B-G,][B-G] [B-D][BB,]| \\\\\\nG,-[GG,-] [BG,-][dG,] gb fg| \\\\\\n[_eC-][=eC-] [^GC-][AC] ^C-[_B^C-] [A^C-][=G^C]| \\\\\\nD-[GD-] [=BD-][eD] [dD,-][=cD,-] [AD,-][FD,]|\\nG,-[GG,-] [BG,-][DG,] G-[G-B,] [G-D][GD,]| \\\\\\nG,2- [FG,-][GG,] [AB,-][GB,-] [gB,-][fB,]| \\\\\\n[e2C2-] [fC-][gC] [d2-B,2] [d-C][dD]| \\\\\\nG,2- [cG,-][BG,] [AB,-][GB,-] [gB,-][fB,]|\\n[_eC-][=eC-] [fC-][gC] [d-_B,][d-=B,] [d-C][dD]| \\\\\\nG,-[dG,-] [cG,-][BG,] [AB,-][GB,-] [gB,-][fB,]| \\\\\\n[fC-][eC-] [_eC-][=eC] [eB,-][dB,-] [^cB,-][dB,]| \\\\\\n[dF,-][^cF,-] [^GF,-][AF,] [=c=G,-][BG,-] [FG,-][GG,]|\\n[BD,-][AD,-] [^GD,-][AD,] =GF ED| \\\\\\nd-[d-D,] [d-G,][dB,] D-[GD-] [cD-][BD]| \\\\\\n[AG,-][CG,-] [FG,-][AG,] G-[G-D] [G-B,][GD]| \\\\\\nG,-[dG,-] [eG,-][fG,] gG Be|\\n[dF,-][DF,-] [AF,-][cF,] [B-G,][B-G] [B-D][BB,]| \\\\\\nG,-[GG,-] [BG,-][dG,] gb fg| \\\\\\n[_eC-][=eC-] [^GC-][AC] ^C-[_B^C-] [A^C-][=G^C]| \\\\\\nD-[GD-] [=BD-][eD] [dD,-][=cD,-] [AD,-][FD,]|\\nG,-[GG,-] [BG,-][DG,] G,4| \\\\\\nB,[GD] [GD]B, G,[BG] [BG]G,| \\\\\\nF,[AD] [AD]F, D,[dF] [dF]D,| \\\\\\nG,[BG] [BG]G, B,[GD] [GD]B,|\\nF,[AD] [AD]F, D,[dF] [dF]D,| \\\\\\nG,[B=F] [B=F]G, ^G,[dE] [dE]=G,| \\\\\\nA,[^cG] [^cG]_B, =B,[d^F] [dF]B,| \\\\\\nG,[dE] [dE]G, A,[^cE] [^cE]A,|\\nD,[dF] [dF]D =C[dF] [dF]A,| \\\\\\nB,[GD] [GD]B, G,[BG] [BG]G,| \\\\\\nF,[AD] [AD]F, D,[dF] [dF]D,| \\\\\\nG,[BG] [BG]G, B,[GD] [GD]B,|\\nF,[AD] [AD]F, D,[dF] [dF]D,| \\\\\\nG,[B=F] [B=F]G, ^G,[dE] [dE]=G,| \\\\\\nA,[^cG] [^cG]_B, =B,[d^F] [dF]B,| \\\\\\nG,[dE] [dE]G, A,[^cE] [^cE]A,|\\nD,[dF] [dF]D D,4| \\\\\\nG,G, [dB][dB] G,g ab| \\\\\\nG,G, [e=c]g G,G, [dB]g| \\\\\\nG,G, [dB][dB] G,b ag|\\nG,G, [ec]g G,G, [dB]g| \\\\\\nG,G, [dB][dB] G,g ab| \\\\\\nCC [eG][eG] B,B, [d^G][d^G]| \\\\\\nA,-[^cAA,] F,-[=cAF,] =G,-[BGG,] ^C-[_BG^C]|\\nD[AF] [AF]D =C[dF] [dF]A,| \\\\\\n=B,[dG] [dG]_B, =B,[dG] [dG]G,| \\\\\\nC[eG] [eG]C _B,[^cG] [^cG]A,| \\\\\\n=B,[dG] [dG]_B, =B,[dG] [dG]G,|\\n=C[eG] [eG]C _B,[^cG] [^cG]A,| \\\\\\n=B,[dG] [dG]A, ^G,[eB] [eB]E,| \\\\\\nA,[^cA] [^cA]=G, F,[dA] [dA]D,| \\\\\\nG,-[B-G-G,] [BG=C-][c-A-C] [cAD-][B-G-D] [BGD,-][AFD,]|\\n[GG,-][dG,-] [BG,-][GG,] D-[GD] DB,| \\\\\\nG,G, [dB][dB] G,g ab| \\\\\\nG,G, [ec]g G,G, [dB]g| \\\\\\nG,G, [dB][dB] G,b ag|\\nG,G, [ec]g G,G, [dB]g| \\\\\\nG,G, [dB][dB] G,g ab| \\\\\\nCC [eG][eG] B,B, [d^G][d^G]| \\\\\\nA,-[^cAA,] F,-[=cAF,] =G,-[BGG,] ^C-[_BG^C]|\\nD[AF] [AF]D =C[dF] [dF]A,| \\\\\\n=B,[dG] [dG]_B, =B,[dG] [dG]G,| \\\\\\nC[eG] [eG]C _B,[^cG] [^cG]A,| \\\\\\n=B,[dG] [dG]_B, =B,[dG] [dG]G,|\\n=C[eG] [eG]C _B,[^cG] [^cG]A,| \\\\\\n=B,[dG] [dG]A, ^G,[eB] [eB]E,| \\\\\\nA,[^cA] [^cA]=G, F,[dA] [dA]D,| \\\\\\nG,-[B-G-G,] [BG=C-][c-A-C] [cAD-][B-G-D] [BGD,-][AFD,]|\\nG,[dB] [BG]D, G,4| \\\\\\nK:Bb\\nG,-[DG,-] [GG,-][DG,] D,-[DD,-] [BD,-][DD,]| \\\\\\n^F,-[D^F,-] [A^F,-][D^F,] D,-[DD,-] [dD,-][DD,]| \\\\\\n[cG,-][DG,-] [BG,-][DG,] [AB,-][DB,-] [GB,-][DB,]|\\n^F,-[D^F,-] [A^F,-][D^F,] D,-[DD,-] [dD,-][DD,]| \\\\\\nG,-[GG,-] [BG,-][eG,] G,-[BG,-] [eG,-][dG,]| \\\\\\n^c-[^c-A,] [^cG-][^cG] d-[d-B,] [d=F-][dF]| \\\\\\nG,-[GG,-] [BG,-][=eG,] A,-[=EA,-] [GA,-][^cA,]|\\nD,-[DD,-] [FD,-][AD,] d-[dD] =CA,| \\\\\\nG,-[DG,-] [GG,-][DG,] D,-[DD,-] [BD,-][DD,]| \\\\\\n^F,-[D^F,-] [A^F,-][D^F,] D,-[DD,-] [dD,-][DD,]| \\\\\\n[cG,-][DG,-] [BG,-][DG,] [AB,-][DB,-] [GB,-][DB,]|\\n^F,-[D^F,-] [A^F,-][D^F,] D,-[DD,-] [dD,-][DD,]| \\\\\\nG,-[GG,-] [BG,-][_eG,] G,-[BG,-] [eG,-][dG,]| \\\\\\n^c-[^c-A,] [^cG-][^cG] d-[d-B,] [d=F-][dF]| \\\\\\nG,-[GG,-] [BG,-][=eG,] A,-[=EA,-] [GA,-][^cA,]|\\nD,-[DD,-] [FD,-][AD,] dd dd| \\\\\\nB,-[dBB,] =C-[dBC] D-[dBD] _E-[dBE]| \\\\\\n=E-[dB=E] [dB][dB] F-[cAF] G,-[d=BG,]| \\\\\\nC-[_ecC] D-[ecD] E-[ecE] F-[ecF]|\\n^F-[ec^F] [ec][ec] G-[d=BG] A,-[=e^cA,]| \\\\\\nD,-[=fdD,] =E,-[fd=E,] F,-[fdF,] G,-[fdG,]| \\\\\\nA,-[fdA,] _B,-[fdB,] A,-[fdA,] ^G,-[fd^G,]| \\\\\\nA,-[fAA,-] [=e=GA,-][dFA,] A,-[=eGA,-] [dFA,-][^c=EA,]|\\nD,-[dD,-] [AD,-][FD,] D2 z2| \\\\\\nG,-[dG,-] [g-BG,-][gdG,] [a-B][ad] [g-B][gd]| \\\\\\n[g-G,-][g-_eG,-] [g-=cG,-][geG,] [^f-c][^fe] ce| \\\\\\nG,-[dG,-] [b-BG,-][bdG,] [a-B][ad] [g-B][gd]|\\n[g-G,-][g-eG,-] [g-cG,-][geG,] [^f-c][^fe] ce| \\\\\\nG,-[dG,-] [b-BG,-][bdG,] [a-B][ad] [g-B][gd]| \\\\\\n[^g-C-][^geC-] [c'-cC-][c'eC] [b-c][be] [^g-c][^ge]| \\\\\\nD,-[dD,-] [=g-BD,-][g-dD,] [g-D,-][gdD,-] [^f-cD,-][^fdD,]|\\n[gG,-][DG,-] [=EG,-][^FG,] GA Bc| \\\\\\nB,-[dBB,] C-[dBC] D-[dBD] _E-[dBE]| \\\\\\n=E-[dB=E] [dB][dB] =F-[cAF] G,-[d=BG,]| \\\\\\nC-[_ecC] D-[ecD] E-[ecE] F-[ecF]|\\n^F-[ec^F] [ec][ec] G-[d=BG] A,-[=e^cA,]| \\\\\\nD,-[=fdD,] =E,-[fd=E,] F,-[fdF,] G,-[fdG,]| \\\\\\nA,-[fdA,] _B,-[fdB,] A,-[fdA,] ^G,-[fd^G,]| \\\\\\nA,-[fAA,-] [=e=GA,-][dFA,] A,-[=eGA,-] [dFA,-][^c=EA,]|\\nD,-[dD,-] [AD,-][FD,] D2 z2| \\\\\\nG,-[dG,-] [g-BG,-][gdG,] [a-B][ad] [g-B][gd]| \\\\\\n[g-G,-][g-_eG,-] [g-=cG,-][geG,] [^f-c][^fe] ce| \\\\\\nG,-[dG,-] [b-BG,-][bdG,] [a-B][ad] [g-B][gd]|\\n[g-G,-][g-eG,-] [g-cG,-][geG,] [^f-c][^fe] ce| \\\\\\nG,-[dG,-] [b-BG,-][bdG,] [a-B][ad] [g-B][gd]| \\\\\\n[^g-C-][^geC-] [c'-cC-][c'eC] [b-c][be] [^g-c][^ge]| \\\\\\nD,-[dD,-] [=g-BD,-][g-dD,] [g-D,-][gdD,-] [^f-cD,-][^fdD,]|\\nG,-[gG,-] [^fG,-][=fG,] =e_e d^c| \\\\\\ndd [GB,-][dB,] [A=C-][dC] [^FA,-][dA,]| \\\\\\nG,-[GG,-] [^FG,-][=FG,] =E_E D^C| \\\\\\nDD, [BG-][GD,] [=cA-][AD,] [A^F-][^FD,]|\\nG,-[BG,-] [AG,-][GG,] G,-[A^FG,-] [eG,-][dG,]| \\\\\\nG,-[BG,-] [AG,-][GG,] G,-[A^FG,-] [eG,-][dG,]| \\\\\\nG,-[BDG,-] [ACG,-][GB,G,] G,-[BDG,-] [ACG,-][GB,G,]| \\\\\\n[G8B,8G,8]|\\nK:G\\nB,-[DB,-] [GB,-][DB,] G,-[DG,-] [BG,-][DG,]| \\\\\\nF,-[DF,-] [AF,-][DF,] D,-[DD,-] [dD,-][DD,]| \\\\\\n[cG,-][DG,-] [BG,-][DG,] [AB,-][DB,-] [GB,-][DB,]| \\\\\\nF,-[DF,-] [AF,-][DF,] D,-[DD,-] [dD,-][DD,]|\\nG,-[GG,-] [BG,-][GG,] G,-[BG,-] [eG,-][dG,]| \\\\\\n_B,-[G_B,-] [^c_B,-][G_B,] =B,-[FB,-] [dB,-][FB,]| \\\\\\nG,-[EG,-] [BG,-][eG,] A,-[EA,-] [AA,-][^cA,]| \\\\\\nD,-[DD,-] [FD,-][AD,] d-[d-D] [d-=C][dA,]|\\nB,-[DB,-] [GB,-][DB,] G,-[DG,-] [BG,-][DG,]| \\\\\\nF,-[DF,-] [AF,-][DF,] D,-[DD,-] [dD,-][DD,]| \\\\\\n[cG,-][DG,-] [BG,-][DG,] [AB,-][DB,-] [GB,-][DB,]| \\\\\\nF,-[DF,-] [AF,-][DF,] D,-[DD,-] [dD,-][DD,]|\\nG,-[GG,-] [BG,-][GG,] G,-[BG,-] [eG,-][dG,]| \\\\\\n_B,-[G_B,-] [^c_B,-][G_B,] =B,-[FB,-] [dB,-][FB,]| \\\\\\nG,-[EG,-] [BG,-][eG,] A,-[EA,-] [AA,-][^cA,]| \\\\\\nD,-[DD,-] [FD,-][AD,] dA FD|\\nB,-[GB,-] [dB,-][GB,] G,-[GG,-] [gG,-][GG,]| \\\\\\n=C-[GC-] [eC-][GC] _B,-[G_B,-] [^c_B,-][G_B,]| \\\\\\n=B,-[GB,-] [dB,-][GB,] [gG,-][GG,-] [fG,-][GG,]| \\\\\\n=C-[GC-] [eC-][GC] _B,-[G_B,-] [^c_B,-][G_B,]|\\n=B,-[GB,-] [dB,-][GB,] G,-[GG,-] [gG,-][GG,]| \\\\\\n[f=C-][GC-] [eC-][GC] B,-[GB,-] [dB,-][GB,]| \\\\\\n[dA,-][FA,-] [cA,-][FA,] G,-[GG,-] [BG,-][GG,]| \\\\\\n[BD,-][AD,-] [^GD,-][AD,] =GF ED|\\nG,-[B,G,-] [DG,-][GG,] Bd gd| \\\\\\nC-[FC-] [AC-][dC] B,-[GB,-] [BB,-][dB,]| \\\\\\n[gG,-][fG,-] [eG,-][dG,] cB AG| \\\\\\nD,-[FD,-] [cD,-][dD,] G,-[GG,-] [BG,-][dG,]|\\nG,-[B,G,-] [DG,-][GG,] Bd gd| \\\\\\n[_eC-][=eC-] [fC-][eC] dc BA| \\\\\\n[eD,-][dD,-] [BD,-][GD,] [dD,-][cD,-] [AD,-][FD,]| \\\\\\nG,-[GG,-] [DG,-][B,G,] G,4|\\nB,-[GB,-] [dB,-][GB,] G,-[GG,-] [gG,-][GG,]| \\\\\\nC-[GC-] [eC-][GC] _B,-[G_B,-] [^c_B,-][G_B,]| \\\\\\n=B,-[GB,-] [dB,-][GB,] [gG,-][GG,-] [fG,-][GG,]| \\\\\\n=C-[GC-] [eC-][GC] _B,-[G_B,-] [^c_B,-][G_B,]|\\n=B,-[GB,-] [dB,-][GB,] G,-[GG,-] [gG,-][GG,]| \\\\\\n[f=C-][GC-] [eC-][GC] B,-[GB,-] [dB,-][GB,]| \\\\\\n[dA,-][FA,-] [cA,-][FA,] G,-[GG,-] [BG,-][GG,]| \\\\\\n[BD,-][AD,-] [^GD,-][AD,] =GF ED|\\nG,-[B,G,-] [DG,-][GG,] Bd gd| \\\\\\nC-[FC-] [AC-][dC] B,-[GB,-] [BB,-][dB,]| \\\\\\n[gG,-][fG,-] [eG,-][dG,] cB AG| \\\\\\nD,-[FD,-] [cD,-][dD,] G,-[GG,-] [BG,-][dG,]|\\nG,-[B,G,-] [DG,-][GG,] Bd gd| \\\\\\n[_eC-][=eC-] [fC-][eC] dc BA| \\\\\\n[eD,-][dD,-] [BD,-][GD,] [dD,-][cD,-] [AD,-][FD,]| \\\\\\nG,-[GG,-] [BG,-][dG,] ^cd [f/2e/2-]e/2d|\\n[=cD,-][dD,] [AF,-][dF,] [cD,-][dD,] [AF,-][dF,]| \\\\\\n[BG,-][dG,-] [^cG,-][dG,] gf ed| \\\\\\n[=cD,-][dD,] [AF,-][dF,] [cD,-][dD,] [AF,-][dF,]| \\\\\\nG,-[BG,-] [gG,-][BG,] E-[BE-] [gE-][BE]|\\nC-[AC-] [gC-][AC] D,-[AD,-] [fD,-][AD,]| \\\\\\n[gG,-][dG,-] [BG,-][dG,] [fD,-][dD,-] [cD,-][dD,]| \\\\\\n[gG,-][dG,-] [BG,-][dG,] [fD,-][dD,-] [cD,-][dD,]| \\\\\\nG,-[gG,-] [fG,-][eG,] dc BA|\\n[G2G,2] z2 [B2G2G,2] z2| \\\\\\n[G8D8B,8G,8]|\\n\\n\\nX:1\\nT:Rhapsody in Blue\\nC:George Gershwin\\nZ:celestial\\nI:string\\nQ:1/4=100\\nM:4/4\\nL:1/8\\nK:C\\n\\nC,8 C,2 C,/4 D,/4 _E,/4 F,/4 G,/4 A,/4 _B,/4 C/4 D/4 _E/4 F/4 G/4 A/4 _B/4 c/4 |_B4 _A/4 c/4 _A2/3_G2/3_A2/3 _G2/3_A2/3_G2/3 |F _E D _D2 _E =E F2 |D _B,/4 C/4 _B,/4 A,/4 _A,2 _G, F, F, |_B, =B,2 C D =B,2 C |z F, G, F, G, F, G, F, |_B, =E,2 F, G, =E,2 F, |G, _B, C _B, C _B, C _B, |_E A,2 _B, C A,2 _B, |C8 _E F _E _e4-_e2/3c2/3F2/3 ^F2/3G2/3_B2/3 |z _E _E _E _E _D _D _D |_D _E _E _E _E ^F ^F ^F |^F G _E C _D C _B, ^F, |G, _B, G, _E,3 _B,2/3=B,2/3C2/3 |_D8 _E,4 _E,/4 F,/4 G,/4 _A,/4 _B,/4 C/4 _D/4 _E/4 F/4 G/4 |\\n_A4 _G/4 _A/4 _G2/3_F2/3_G2/3 _F2/3_G2/3_F2/3 |_E _D C _C2 _D =D _E2 |C _A, _G,2 _F, _E, _E, |_E/2 _A/2 _B/2 _A/2 _c _c _G/2 _A/2 _B/2 _A/2 _c _d _c _B |_E/2 _A/2 _B/2 _A/2 _c _c _c2 _d2/3_e2/3f2/3 |_g4 _d2 _f2/3=d2/3_f2/3 =d2/3_f2/3=d2/3 |_d _c _B _A2 _c =c _d2 |_B _G =E2 =D _D2 |D/2 ^F/2 ^G ^F/2 ^c ^c E/2 ^F/2 ^G/2 ^F/2 A/2 B/2 A/2 ^G/2 |D/2 ^F/2 ^G ^F/2 ^c ^c ^D ^C B, A, |G,/2 B,/2 ^C/2 B,/2 D D A,/2 B,/2 ^C/2 B,/2 D/2 E/2 D/2 ^C/2 |G,/2 B,/2 ^C/2 B,/2 D D ^G,/2 ^F,/2 E,/2 D,/2 |C,/2 E,/2 ^F,/2 E,/2 G, G,/2 A,/2 _B,/2 A,/2 G, C, C,/2 ^C,/2 |D,/2 E,/2 ^F,/2 E,/2 ^G, ^G,/2 A,/2 B,/2 A,/2 ^G, ^G,2 |\\nE, B,/3^F,/3E,/3 D/2 B,/2 ^G,/2 E/2 ^C/2 B/2 ^G,/2 E,/2 ^D,/2 =D,/2 E |E, C/3G,/3F,/3 _E/2 _B,/2 A,/2 ^F,/2 D,/2 C,/2 A,/2 =F,/2 =E,/2 _E,/2 =F |E D/3A,/3^G,/3 F/2 C/2 B,/2 ^G/2 E/2 D/2 B/2 =G/2 ^F/2 =F/2 =G |z E/3E/3E/3 E/3E/3E/3 E/3E/3E/3 E/2 F D E/2 C |z B,/3B,/3B,/3 B,/2 C A, B,/2 G, |z F,/3F,/3F,/3 F,/2 G, E, F,/2 D |D,/2 ^D, C, ^C, _B,/2 =B, ^G,/2 A, ^G,2 |D/2 ^D C/2 ^C _B,/2 =B, ^G,/2 A, ^G,8 E,/4 ^F,/4 ^G,/4 A,/4 =B,/4 ^C/4 =D/4 E/4 ^F/4 =G/4 A/4 =B/4 |^C E  ^D2 G/4 A/4 G2/3F2/3G2/3 F2/3G2/3F2/3 |E D ^C =C2 D ^D E2 |^C A, G,2 F, E, E,-E/2 |A,/2 E,/2 ^E,/2 ^F/2 A,/2 =E/2 ^E/2 ^F/2 A/2 =e/2 ^e/2 ^F/2 A/2 =e/2 ^e/2 |f/2 A/2 E/2 ^E/2 f/2 A/2 =E/2 ^E/2 ^F/2 A,/2 =E,/2 ^E,/2 ^F,/2 D,/2 =E,/3^F,/3^G,/3 |\\nz2 C, D, E, F3 |z2 C, D, F, A,3 |z C, C, D, F, G, A, C9 |C4 _B,2/3_A,2/3_B,2/3 _A,2/3_B,2/3_A,2/3 |E/4F/4^F/4 G =F E _E2 F ^F G2 |_E C _B,4 _B, _A, G, G,8 |z/2 G,/2 A,/2 G,/2 _B, _B, z/2 A,/2 =B,/2 A,/2 ^C/2 ^D/2 =B,/2 A/2 |z/2 _B,/2 C/2 _B,/2 _D _D z/2 C/2 =D/2 C/2 E/2 ^F/2 =D/2 C/2 |^G,/3^E/3=g/3 ^C ^E =g ^C, ^E =g ^C ^E =g ^C, ^E =g z |\\nz/2 ^C,/2 ^D,/2 ^C,/2 E, E, z/2 _E,/2 F,/2 _E,/2 G,/2 A,/2 F,/2 _E,/2 |z/2 E,/2 ^F,/2 E,/2 G, G, z/2 _G,/2 _A,/2 _G,/2 _B,/2 C/2 _A,/2 _G,/2 |z/2 G,/2 A,/2 G,/2 _B, _B, z/2 A,/2 =B,/2 A,/2 ^C/2 ^D/2 =B,/2 A,/2 |F,/3D/3e/3 _D,/2 =D/2 e/2 _B,/2 =D/2 e/2 _B,/2 =D/2 e/2 _B,/2 =D/2 e/2 _D |_A,/3C/3d/3 _A,/2 C/2 d/2 _A,/2 C/2 d/2 _A,/2 C/2 d/2 _A,/2 C/2 d/2 _A, |^F,/3^A,/3C/3 =F,/2 ^A,/2 C/2 =F,/2 =A,/2 C/2 ^F,/2 =A,/2 C/2 ^F,/2 =A,/2 C/2 ^F |F,/3A,/3B/3 F,/2 A,/2 B/2 F,/2 A,/2 B/2 F,/2 A,/2 B/2 F,/2 A,/2 B/2 F |z B,/3^F,/3E,/3 D/2 A,/2 ^G,/2 E/2 ^C/2 B,/2 ^G/2 E/2 ^D/2 =D/2 e |z C/3G,/3F,/3 _E/2 _B,/2 A,/2 F/2 D/2 C/2 A/2 F/2 =E/2 _E/2 f |z D/3A,/3^G,/3 F/2 C/2 B,/2 ^G/2 E/2 D/2 B/2 =G/2 ^F/2 =F/2 =g |\\nz e/2 e/2 e/2 e/2 e/2 e/2 e/2 f d e/2 c |z B/2 B/2 B/2 B/2 B/2 B/2 B/2 c A B/2 G |z F/2 F/2 F/2 F/2 F/2 F/2 F/2 G E F/2 D |z/2 ^G,/2 ^F,/4 =F,/4 E,/2 B,/2 ^A,/4 =A,/4 ^G,/2 D/2 ^C/4 =C/4 B,/2 ^F/2 E/4 ^D/4 =D/2 ^G/2 ^F/4 =F/4 E/2 |A4 G2/3F2/3G2/3 F,2/3G2/3F2/3 |E D ^C =C2 D ^D E2 |^C A, G,2 F, E, E,-E,/2 |E/2 ^F/2 E/2 G G z/2 E/2 ^F/2 E/2 G/2 A/2 G/2 ^F/2 |z/2 E/2 ^F,/2 E/2 G G z/2 E/2 ^F/2 E/2 ^G/2 A/2 ^G/3^F/3=F/3 |E/4 A4 G2/3F2/3G2/3 F,2/3G2/3F2/3 |E D ^C =C2 D ^D E2 |^C A, G,2 F, E, A3 |E,2 E,2 E,2 |\\nz A c d e f3 |z A c d F A3 |z A c d F G A c |c C D _E F G _A _B |G2 C2 _B2/3_A2/3_B2/3 _A2/3_B2/3_A2/3 |G F E _E2 F ^F G2 |_E C _B G _E c2 |G _E _e2 c _A g |G,2 E/2 ^D,/2 E/2 ^D,/2 E/2 ^D,/2 E/2 ^D,/2 E/2 ^D,/2 E/2 ^D,/2 |E/2 D,/2 E/2 D,/2 E/2 D,/2 E/2 D,/2 E/2 D,/2 E/2 D,/2 E/2 D,/2 E/2 D,/2 |B,/4 C E G2 G2 G2 |G2 ^G/4 A =G F E D2 |C4 z E A, G, |_e _A _G _e _A _G _e2/3_A2/3_G2/3 |B,/4 C E G2 G2 G2 |\\nG2 ^G/4 A =G F E D2 |_B4 z C F, E, |c F E c F E c2/3F2/3E2/3 |z C C C C C F2 |z C C C A, A, F, F, |A,5 C F A |A8 |C E G2 G2 G2 |G4/3A4/3G4/3 F4/3E4/3D4/3 |c2 ^D,/4 E,/4 F,/4 C/4 E/4 ^F,/4 G,/4 C/4 E/4 G/4 B,/4 C/4 E/4 G/4 c/4 |^D,/4 E,/4 G,/4 C/4 E/4 ^F,/4 G,/4 C/4 E/4 G/4 B,/4 C/4 E/4 G/4 c/4 ^D/4 E/4 G/4 c/4 e/4 |z _B _B _B _B/2 A/2 _A _A _A |_A/2 _A/2 _B _B _B _B/2 c/2 ^c ^c ^c |\\n^c2 =C,/4 ^C,/4 E,/4 A,/4 ^C/4 ^D,/4 E,/4 A,/4 =C/4 E/4 ^G,/4 A,/4 ^C/4 E/4 A/4 |C,/4 ^C,/4 E,/4 A,/4 ^C/4 ^D,/4 E,/4 A,/4 =C/4 E/4 ^G,/4 A,/4 =C/4 E/4 A/4 =C/4 ^C/4 E/4 A/4 ^c/4 |z G G G G/2 ^F/2 =F =F =F |F/2 ^F/2 G G G G/2 A/2 ^A ^A ^A |^A B G E G/4 F E D ^A, |B, D B, G,3 G,/2 F,/2 E,/2 D,/2 |C, c c c c _B _B _B |_B c c c c ^d ^d ^d |^d e ^d A _B A G ^D |D G D C _B,2/3_A,2/3_B,2/3 _A,2/3_B,2/3_A,2/3 |z c c c c _B _B _B |_B c c c c ^d ^d ^d |^d e ^d A _B A G ^D |E G E C2 c c c |\\n^c/4 d =c f2 ^c/4 d =c F2 |_E, D,2 _E, D,2 C,2 |^c/4 d =c f2 ^c/4 d =c F2 |_E, D,2 _E, D,2 C,2 |z c c c c _B _B _B |_B A A A2 A A A |A G G G2 G G G |G ^A B G ^A B D E |F2/3E2/3D2/3 ^F/4 G ^F/4 G ^F/4 G _E C G, |z ^A, B, G, ^A, B, D, E, |E,2/3D,2/3C,2/3 ^F,/4 G, ^F,/4 G, ^F,/4 G, E, C, A, |A13 ^E ^F ^D |E ^C D B, =C2 d z |z d z d d z3 |\\nD,/2 ^D,/2 E,2 E,/2 ^E,/2 ^F, ^F, ^F,/2 G,/2 ^G,2 |^G,/2 A,/2 ^A, ^A, ^A,/2 B,/2 C,2 C,/2 ^C,/2 |D, D, D,/2 ^D,/2 E,2 E,/2 ^E,/2 ^F, ^F, |^F,/2 G,/2 ^G,2 ^G,/2 A,/2 ^A,/2 B,/2 C/2 ^C/2 D/2 ^D/2 E/3^E/3^F/3 |z ^F/4 G G G A/4 G/2 ^F/2 =F =F =F |F/2 ^F,/2 G G G G/3^G/3A/3 ^A ^A ^A |^A B G E G/4 F E D ^A, |B, D B, G,5 |z ^F/4 G G G A/4 G/2 ^F/2 =F =F =F |F/2 ^F/2 G G G G/3^G/3A/3 ^A ^A ^A |^A B G E G/4 F E D ^A, |B, D B, G,-G,/2 E/2 D/2 D,/2 B, G |^G/4 A =G c2 ^G/4 A =G C2 |\\nC,-C,/2 D,/2 _E,/2 _E, D,/2 _E,/2 _E, D,/2 _E,/2 D,/2 C, |^G/4 A =G c2 ^G/4 A =G C2 |C,-C,/2 D,/2 _E,/2 _E, D,/2 _E,/2 _E, D,/2 _E,/2 D,/2 C, |z ^F/4 G G G A/4 G/2 ^F/2 =F =F =F |F/2 ^F/2 G G G G/3^G/3A/3 ^A ^A ^A |^A B G E G/4 F E D ^A,4 |B, D B, G, z D B, ^F, |z E _E D =E/2 _E/2 D3 |A, E ^C A, z E =C G, |z ^F =F E ^F/2 =F/2 E3 |z A A A B/4 A/2 ^G/2 =G =G =G |G/2 ^G/2 A A A A/3^A/3B/3 ^B ^B ^B |^B ^c A ^F A/4 G ^F E ^B, |^C E ^C A,2 z3 |z ^G/4 A A A ^c/4 A/2 ^G/2 =G =G =G |G/2 ^G/2 A A A A/3^A/3B/3 ^B ^B ^B |\\n^B ^c A ^F A/4 G ^F E ^B, |^C E ^C A,3 A2 |B A d2 B A D2 |D,-D,/2 E,/2 F,/2 F, E,/2 F,/2 F, E,/2 F,/2 E,/2 D, |B A d2 B A D2 |D,-D,/2 E,/2 F,/2 F, E,/2 F,/2 F, E,/2 F,/2 E,/2 D, |z A A A B/4 A/2 ^G/2 =G =G =G |G/2 ^G/2 A A A A/3^A/3B/3 ^B ^B ^B |^B ^c A ^F A/4 G ^F E ^B, |^C E ^C A,2 ^E4 |^F D B, D/4 C B, A, ^E, |^F, A, ^F, E, D, ^B,4 |^C A, ^F, A/4 G ^F E ^B, |^C E ^C A,2 ^E12 |^F D B, D/4 C B, A, ^E, |^F, A, ^F, D,5 |\\ng4 f2/3_e2/3f2/3 _e2/3f2/3_e2/3 |d c B _B2 c c d2 |B G F2 _E D2 |D B, G, F,2 _E, D,2 |D2/3B,2/3G,2/3 F, _E, D, D B, G, |F,2/3_E,2/3D,2/3 D B, G, F, _E, D, |d2/3B2/3G2/3 F _E D d B G |F2/3_E2/3D2/3 d B G F =E D |d2/3B2/3G2/3 F _E D d B G |F2/3_E2/3D2/3 d B G F =E D |d2/3B2/3G2/3 F _E D d B G |F2/3_E2/3D2/3 d B G F =E D |f4 F,2 _e/4 c/4 _A/4 F/4 _E/4 C/4 _A,/4 F,/4 _E/4 C/4 _A,/4 F,/4 _E,/4 C,/4 D,6 |d E G G2 D E D |D/4 E/4 F4 E D3 |A,4/3B,4/3A,4/3 C4 |_E2-_E/2 _D/2 _B,/2 G,/2 _E,/2 =D,8 |\\nD E G G2 D E D |D/4 E/4 F4 E/4 F/4 E D3 |A,4/3B,4/3A,4/3 C4 |_e2-_e/2 _d/2 _B/2 G/2 _E/2 =D z =E, z |D E G G2 D E D |D/4 E/4 F4 E/4 F/4 E D3 |C/4 D/4 C4/3B,4/3C4/3 A,5 |B, C D E ^F G A |_B3 ^F/4 G2 _B2 G |_B3 ^F/4 G2 _B2 G |F z F z F D2 |F6 ^F G2/3^G2/3A2/3 |_B3 ^F/4 G2 _B2 G |c3 G2 _B2 G |F z F z F D3 |\\n^C, D, ^D, E,2 F, A,4 |z/2 B,/2 G/2 B,/2 G/2 B,/2 G/2 B,/2 G/2 B,/2 G/2 B,/2 G/2 B,/2 G/2 B,/2 |z/2 B,/2 ^G/2 B,/2 ^G,/2 B,/2 ^G,/2 B,/2 z/2 B,/2 A/2 B,/2 A/2 B,/2 A/2 B,/2 |z/2 D,/2 _B,/2 D,/2 _B,/2 D,/2 _B,/2 D,/2 _B,/2 D,/2 _B,/2 D,/2 _B,/2 D,/2 _B,/2 D,/2 |z/2 D,/2 B,/2 D,/2 B,/2 D,/2 B,/2 D,/2 z/2 D,/2 C/2 D,/2 C/2 D,/2 C/2 D,/2 |_A _B _d _d2 _A _B _A |_c4 _B _A3 |_E4/3F4/3_E4/3 _G4 |_A/2 c/2 _e _e _e _e _g/2 f/2 _e/2 _d/2 c |_A _B _d _d2 _A _B _A |_c4 _B _A3 |_G4/3F4/3_G4/3 _E4 |_A/2 c/2 _e _e _e _e _g/2 f/2 _e/2 _d/2 c |z F,/2 _D/2 F,/2 _D/2 F,/2 _D/2 F,/2 _D/2 F,/2 _D/2 F,/2 _D/2 F,/2 _D/2 F,/2 |\\nz/2 F,/2 D/2 F,/2 D/2 F,/2 D/2 F,/2 z/2 F,/2 _E/2 F,/2 _E/2 F,/2 _E/2 F,/2 |z/2 ^G,/2 E/2 ^G,/2 E/2 ^G,/2 E/2 ^G,/2 E/2 ^G,/2 E/2 ^G,/2 E/2 ^G,/2 E/2 ^G,/2 |z/2 ^G,/2 F/2 ^G,/2 F/2 ^G,/2 F/2 ^G,/2 z/2 ^G,/2 ^F/2 ^G/2 ^F/2 ^G/2 ^F/2 ^G/2 |D E G G2 D E D |F4 E D3 |D E G G2 D E D |F4 E D3 |c4/3B4/3c4/3 A4 |D,2 ^F2 ^C,/4 D,/4 E,/4 ^E,/4 ^F,/2 A,/4 ^C/4 D/4 =E/4 ^E/4 ^F,/2 A/4 ^c/4 d/4 =e/4 ^e/4 ^f/2 A/4 ^c/4 d/4 =e/4 ^e/4 ^f/2 ^e/4 =e/4 d/4 ^c/4 A/4 ^F/2 A/4 ^c/4 d/4 =e/4 ^e/4 ^f/2 ^e/4 =e/4 d/4 ^c/4 A/4 ^F/2 A/4 ^c/4 d/4 =e/4 ^e/4 ^f/2 ^e/4 =e/4 d/4 ^c/4 A/4 ^F/2 A/4 ^c/4 d/4 =e/4 ^e/4 ^f/2 |c2/3B2/3A2/3 F2/3E2/3D2/3 c2/3B2/3A2/3 F2/3E2/3D2/3 C2/3B,2/3A,2/3 F,2/3E,2/3D,2/3 D,8 |\\n^A, B, C ^C2 D ^F2 |E F ^F G2 ^G c2 |^A, B, C ^C2 D ^F6 B4 |^G,2 A,2 B,2 B,4 ^C2 ^D2 E2 |^D, =D, ^C,2 ^D,2 =D,2 |C, ^D, =D,2 ^C,2 ^D,2 |D, ^C, ^D,2 =D,2 ^C,2 |^D, =D, ^C,2 ^D,2 =D,2 |^C, ^D, =D,2 ^C,2 ^D,2 |D, ^C, ^D,2 =D,2 ^C,2 |^G,2 A,2 B,2 B,4 ^C2 ^D2 E2 |^F, =F, E,2 ^F,2 =F,2 |E, ^F, =F,2 E,2 ^F,2 |F, E, ^F,2 =F,2 E,2 |^F, =F, E,2 ^F,2 =F,2 |^C2 ^D2 E2 E,2/3^D,2/3^C,2/3 |E,2 ^F,2 ^G,2 A,2 |B,2 ^C2 ^D2 ^D,2/3^C,2/3=C,2/3 |^D,2 E,2 ^F,2 ^G,2 |z ^G, ^C2 ^D2 E2 |\\n^F4/3^C4/3^D4/3 ^F4 |z G, C2 D2 _E2 |F4/3C4/3D4/3 F2 ^F2 |^G2 A2 B2 B,4 |^C2 ^D2 E2 |^D =D ^C2 ^D2 =D2 |^C ^D =D2 ^C2 ^D2 |D ^C ^D2 =D2 ^C2 |^D =D ^C2 ^D2 =D2 |^C ^D =D2 ^C2 ^D2 |D ^C ^D2 =D2 ^C2 |^G2 A2 B2 B,4 |^C2 ^D2 E2 |^F =F E2 ^F2 =F2 |E ^F =F2 E2 ^F2 |F E ^F2 =F2 E2 |^F =F E2 ^F2 =F2 |^c2 ^d2 e2 E2/3^D2/3^C2/3 |E2 ^F2 ^G2 A2 |B2 ^c2 ^d2 ^D2/3^C2/3=C2/3 |^D2 E2 ^F2 ^G2|\\n^G2 ^A2 c2 C4 |D2 E2 ^F2 |^G2 A2 B2 B,4 |^C2 ^D2 z ^G, |^D, =D, ^C,2 ^D,2 =D,2 |^C, ^D, =D,2 ^C, ^D, E, ^E, |^F, =F, E,2 ^F,2 =F,2 |E, ^F, =F,2 E, ^F, ^G, A, |B, _B, A,2 =B,2 _B,2 |A, B, _B,2 A, =B, ^C D |E _E D2 =E2 _E2 |D E _E2 D2 =E2 |_E D =E2 _E2 D2 |^G =G ^F2 ^G2 ^F2 |^G E A ^F B ^G B, ^G, |B, ^G, ^C ^G, ^D B, E B, |^F5 ^F, ^F ^F |^f ^F ^f ^F ^f ^F, ^F2 |G5 G, G G |g G g G g G, G2 |\\n^G5 ^G, ^G ^G |^g ^G ^g ^G ^g ^G, ^G,2 |^G E A ^F B ^G B, ^G, |B, ^G, ^C ^G, ^D B, E B, |A5 A, A A |A A a A a A, A2 |B5 B, B B |B B b B b B, B2 |^c2 ^d2 e2 E2/3^D2/3^C2/3 |E2 ^F2 ^G2 A2 |B2 ^c2 ^d2 ^D2/3^C2/3=C2/3 |^D2 E2 ^F2 ^G2 |^G2 ^A2 c2 C4 |D2 E2 ^F2 |^G2 A2 B2 B,4 |^C2 ^D3 E/2 ^E/2 |^F2 ^G2 ^A2 ^A,4 |C2 D2 E2 |^F2 G2 A2 A,4 |B,2 C8 |\\n^c/2 ^c/2 d/2 ^c/2 ^c/2 e/2 ^c/2 ^c/2 |^c z5 |^C/2 ^C/2 D/2 ^C/2 ^C/2 E/2 ^C/2 ^C/2 |^C z3 |^C,/2 ^C,/2 D,/2 ^C,/2 ^C,/2 E,/2 ^C,/2 ^C,/2 |^C,/2 ^C,/2 D,/2 ^C,/2 ^C,/2 E,/2 ^C,/2 ^C,/2 |^C,/2 ^C,/2 D,/2 ^C,/2 ^C,/2 E,/2 ^C,/2 ^C,/2 |^C,/2 ^C,/2 D,/2 ^C,/2 ^C,/2 E,/2 ^C,/2 ^C,/2 |^F,/2 ^F,/2 G,/2 ^F,/2 ^F,/2 A,/2 ^F,/2 ^F,/2 |^F,/2 ^F,/2 G,/2 ^F,/2 ^F,/2 A,/2 ^F,/2 ^F,/2 |^F,/2 ^F,/2 G,/2 ^F,/2 ^F,/2 A,/2 ^F,/2 ^F,/2 |^F,/2 ^F,/2 G,/2 ^F,/2 ^F,/2 A,/2 ^F,/2 ^F,/2 |^c/2 ^c/2 d/2 ^C,/2 ^c/2 e/2 ^G,/2 ^c/2 |^C/2 ^c/2 d/2 G/2 ^c/2 e/2 ^c/2 ^c/2 |^c/2 ^c/2 d/2 ^C,/2 ^c/2 e/2 ^F,/2 ^c/2 |^C/2 ^c/2 d/2 ^F/2 ^c/2 e/2 ^c/2 ^c/2 |\\n^C,/2 ^C,/2 D,/2 ^C,/2 ^C,/2 E,/2 ^G/2 ^C,/2 |^F/2 ^C,/2 D,/2 ^C,/2 ^C,/2 E,/2 ^C,/2 ^C,/2 |^C,/2 ^C,/2 D,/2 ^C,/2 ^C,/2 E,/2 A/2 ^C,/2 |^G/2 ^C,/2 D,/2 ^C,/2 ^C,/2 E,/2 ^C,/2 ^C,/2 |^C,/2 ^C,/2 D,/2 ^C,/2 ^C,/2 E,/2 B/2 ^C,/2 |A/2 ^C,/2 D,/2 ^C,/2 ^C,/2 E,/2 ^C,/2 ^C,/2 |^C,/2 ^C,/2 D,/2 ^C,/2 ^C,/2 E,/2 ^c/2 ^C,/2 |B/2 ^C,/2 D,/2 ^C,/2 ^C,/2 E,/2 B/2 ^C,/2 |A/2 ^C,/2 D,/2 ^C,/2 ^C,/2 E,/2 A/2 ^C,/2 |^G,/2 ^G,/2 A,/2 ^G,/2 ^G,/2 B,/2 E/2 ^G,/2 |^C/2 ^G,/2 A,/2 ^G,/2 ^G,/2 B,/2 ^G,/2 ^G,/2 |^G,/2 ^G,/2 A,/2 ^G,/2 ^G,/2 B,/2 E3 |^C,/2 ^G,/2 ^A,/2 ^G,/2 B, B, |E,/2 ^G,/2 ^A,/2 ^G,/2 B,/2 ^C/2 B,/2 ^A,/2 |^E,/2 ^G,/2 ^A,/2 ^G,/2 B B2 |^G,2 ^G, |^c/2 ^c/2 ^d/2 g/2 ^c/2 ^e/2 ^G/2 ^G/2 |^G/2 ^G/2 ^A/2 ^d/2 ^G/2 ^B/2 ^C/2 ^C/2 |^C/2 ^C/2 ^D/2 ^G/2 ^C/2 ^E/2 ^G,/2 ^G,/2 |^G,/2 ^G,/2 ^A,/2 ^D/2 ^G,/2 ^B,/2 ^C,/2 ^C,/2 |\\n^G,/2 ^C/2 ^D/2 ^G/2 ^C/2 ^E/2 A,/2 ^C/2 |^G,/2 ^C/2 ^D/2 ^G/2 ^C/2 ^E/2 A,/2 ^C/2 |G,/2 ^C/2 ^D/2 G/2 ^C/2 ^E/2 A,/2 ^C/2 |G,/2 ^C/2 ^D/2 G/2 ^C/2 ^E/2 A,/2 ^C/2 |^C,4 |C,/4 D,/4 E,/4 F,/4 G,/4 A,/4 B,/4 C/4 D/4 E/4 F/4 G/4 A/4 B/4 C,/4 D,/4 E,/4 F,/4 G,/4 A,/4 B,/4 C/4 D/4 E/4 F/4 G/4 A/4 B/4 c/4 |^C/2 ^C,/2 D/2 ^C/2 ^c/2 ^C/2 ^C/2 ^C,/2 |^C/2 ^C,/2 D/2 ^C/2 ^c/2 ^C/2 ^C/2 ^C,/2 |^c/2 ^C/2 d/2 ^g/2 ^c/2 e/2 ^G/2 ^c/2 |^G/2 ^c/2 d/2 ^C/2 ^c/2 e/2 ^G/2 ^c/2 |^C/2 ^C,/2 D/2 ^C/2 ^c/2 ^C/2 ^C/2 ^C,/2 |^C/2 ^C,/2 D/2 ^C/2 ^c/2 ^C/2 ^C/2 ^C,/2 |^c/2 ^C/2 d/2 ^g/2 ^c/2 e/2 ^G/2 ^c/2 |^G/2 ^c/2 d/2 ^C/2 ^c/2 e/2 ^G/2 ^c/2 |^A/2 B,/2 B/2 ^C,/2 ^C/2 ^C/2 ^c/2 ^C/2 |^c/2 ^C/2 ^C/2 ^D,/2 ^E ^F |^G,/2 ^G/2 ^A/2 ^d/2 ^G/2 ^B/2 ^D/2 ^G/2 |^D/2 ^G/2 ^A/2 ^d/2 ^G/2 ^B/2 ^D/2 ^G/2 |\\nA,/2 A/2 B/2 ^e/2 A/2 ^c/2 ^C/2 A/2 |^C/2 A/2 B/2 ^e/2 A/2 ^c/2 B,/2 A/2 |^A,/2 ^A/2 B/2 ^f/2 ^A/2 ^c/2 ^C/2 ^A/2 |^C/2 ^A,/2 B,/2 ^C,/2 ^A,2/3B,2/3^B,2/3 |^C/2 D,/2 D/2 E,/2 E/2 E/2 e/2 E/2 |e/2 E/2 E/2 ^F,/2 ^G, A, |B,/2 B/2 ^c/2 ^f/2 B/2 ^d/2 B,/2 B/2 |B,/2 B/2 ^c/2 ^f/2 B/2 ^d/2 A,/2 B/2 |^B,/2 ^B/2 d/2 ^g/2 ^B/2 e/2 E/2 ^B/2 |E/2 ^B/2 d/2 ^g/2 ^B/2 e/2 D/2 ^B/2 |^C/2 ^c/2 d/2 a/2 ^c/2 e/2 E/2 ^c/2 |E/2 ^C/2 D/2 E,/2 ^C2/3D2/3^D2/3 |E F G G,2 |A, B,2/3C2/3D2/3 |E F G G,2 |A, B,2/3C2/3D2/3 |\\nE F G G, |A, B, C D |E2/3F2/3G2/3 G,2/3A,2/3B,2/3 |C2/3D2/3E2/3 F2/3G2/3G,2/3 |A,2/3B,2/3C2/3 D2/3E2/3F2/3 |G2/3G,2/3A,2/3 B,2/3C2/3D2/3 |A4 |A4 |E/2 G/2 A/2 G/2 _B _B |^D/2 A/2 B/2 A/2 ^c/2 ^d/2 B/2 A/2 |G/2 _B/2 c/2 _B/2 _d _d |^F/2 c/2 d/2 c/2 e/2 ^f/2 d/2 c/2 |E,/3^E/3g/3 ^C/2 =E,/2 G/2 c/2 =E,/2 G/2 |^C,/2 ^E,/2 G/2 ^C/2 ^E,/2 G/2 =c |^F,/2 ^C,/2 ^D,/2 ^C,/2 E E |F,/2 _E,/2 F,/2 _E,/2 G,/2 A,/2 F,/2 _E,/2 |^C,/2 E,/2 ^F,/2 E,/2 G, G, |C,/2 _G,/2 _A,/2 _G,/2 _B,/2 C/2 _A,/2 _G,/2 |\\nE,/2 G,/2 A,/2 G,/2 _B, _B, |^D,/2 A,/2 B,/2 A,/2 ^C/2 ^D/2 B,/2 A,/2 |F,/3D,/3E/3 _B/2 D,/2 E/2 _B,/2 D,/2 E/2 |_B,/2 D,/2 E/2 _B,/2 D,/2 E/2 _B |_E,/3C,/3D/3 _A/2 C,/2 D/2 _A,/2 C,/2 D/2 |_A,/2 C,/2 D/2 _A,/2 C,/2 D/2 _A |^C,/3^A,/3=C/3 ^F/2 ^A,/2 =C/2 ^F,/2 ^A,/2 =C/2 |^F,/2 ^A,/2 C/2 ^F,/2 ^A,/2 C/2 ^F |_E, F, ^F, G, |^G, A, ^A, B, |C ^C D _E |E F ^F G |^G A ^A B |c ^c d _G/4 _F/4 E/4 D/4 |z/2 _e/2 _e/2 _e/2 _e/2 _d/2 _d/2 _d/2 |_d/2 _e/2 _e/2 _e/2 _e/2 ^f/2 ^f/2 ^f/2 |^f/2 g/2 _e/2 c/2 _d/2 c/2 _B/2 =F/2 |\\nG/2 _B/2 G/2 _E _B,/2 D/4 C/2 _B/2 |z/2 _e/2 _e/2 _e/2 _e/2 _d/2 _d/2 _d/2 |_d/2 _e/2 _e/2 _e/2 _e/2 ^f/2 ^f/2 ^f/2 |^f/2 g/2 _e/2 c/2 _d/2 c/2 _B/2 =F/2 |G/2 _B/2 G/2 _E _e/2 _e/2 _e/2 |f/2 _e/2 _a f/2 _e/2 _A |_A C/4 _E/4 F/4 _A/4 c/4 _e/4 f/4 _a/4 c/4 _e/4 f/4 _a/4 |f/2 _e/2 _a f/2 _e/2 _A |_A _C/4 _E/4 _G/4 _A/4 _c/4 _e/4 _g/4 _a/4 _c/4 _e/4 _g/4 _a/4 |z/2 _e/2 _e/2 _e/2 _e/2 _d/2 _d/2 _d/2 |\\n_d/2 _e/2 _e/2 _e/2 _e/2 ^f/2 ^f/2 ^f/2 |^f/2 g/2 _e/2 c/2 _d/2 c/2 _B/2 ^F/2 |G _B G _E2 z F2/3G2/3A2/3 |_B2 F,/4 _B,/4 D/4 F/4 A/4 _B/4 d/4 f/4 _b/4 _b z _A2/3_G2/3_A2/3 _G2/3_A2/3_G2/3 |F _E D _D2 _E E F2 |D _B _A _A/2 =A,/2 _G F2 |F F G F _A2 _A2 z F G F =A _B =A G |f2 D,2 D2 f2 |_B z7 |\\n\\n\\nX: 1\\nT: The Godfather Theme (Clarinet/Flute) [Wind]\\nZ: Jazriel the Naughty - Vilya\\n%  Alternative to the more complex 'Waltz' version I did for Lute\\nL: 1/4\\nQ: 96\\nK: C\\nz3 B,3/4 E3/4 G3/4 [^Fz3/4] [Ez3/4] [Gz3/4] [Ez3/4] [^Fz3/4] [Ez3/4]\\n[Cz3/4] [Dz3/4] B,15/4 B,3/4 E3/4 G3/4 ^F3/4 E3/4 G3/4 E3/4 ^F3/4\\nE3/4 B,3/4 ^A,3/4 =A,15/4 A,3/4 C3/4 ^D3/4 ^F15/4 A,3/4 C3/4 ^D3/4\\nE15/4 E,3/4 G,3/4 =D3/4 C3/4 B,3/4 D3/4 C3/4 C3/4 B,3/4 B,3/4 z3/4\\nE,15/4 E3/4 E3/4 ^D3/4 =D3 ^F3/2 E3/4 C3/4 B,15/4 B,3/4 D3/4 B,3/4\\nA,15/4 A,3/4 C3/4 ^A,3/4 B,15/4 B,3/4 E3/4 G3/4 ^F3/4 E3/4 G3/4 E3/4\\n^F3/4 E3/4 C3/4 D3/4 B,15/4 B,3/4 E3/4 G3/4 ^F3/4 E3/4 G3/4 E3/4\\n^F3/4 E3/4 B,3/4 ^A,3/4 =A,15/4 A,3/4 C3/4 ^D3/4 ^F15/4 A,3/4 C3/4\\n^D3/4 E15/4 E,3/4 G,3/4 =D3/4 C3/4 B,3/4 D3/4 C3/4 C3/4 B,3/4 B,3/4\\n^D3/4 [E,6G,6B,6E6] \\n\\n\\nX: 1\\nT: Hallelujah Chorus\\nC: Handel\\nZ: by Tiamo/Skjald\\nL: 1/4\\nQ: 1/4=100\\nK: C\\n[^C,3/8^c11/8^GF3/8] z/8 [^D,3/8^F3/8] z/8 [F,3/8^G3/8] z/8\\n[^C,3/8^g3/8f3/8^C3/8] z/8 [^F,3/8^a3/8^f3/8^c3/8] z/8\\n[^C,3/8^g3/8=f3/8^C3/8] z/8 =F,3/8 z/8 ^G,3/8 z/8\\n[^C,3/8^c11/8f3/4^G] z/8 ^D,3/8 z/8 [F,3/8^G3/8] z/8\\n[^C,3/8f3/8^c3/8^G3/8] z/8 [^D,3/8^f3/8=c3/8^F3/8] z/8\\n[^C,3/8=f3/8^c3/8^G3/8] z5/8 F,/8 [F,/4^g/4^G/4^C/4] z/8\\n[^D,3/8^f3/8=c3/8^F3/8] z/8 [^C,3/8=f3/8^c7/8^G3/8] z/8\\n[^G,3/8f/8^G3/8] [f/8] z/8 [f/8] z/8 [f/8] z/8 [^G,3/8f/8=c3/8^D3/8]\\nz/8 [f/8] z/8 [^c/8] z/8 ^d/8 [^C,3/4^c3/8=F/2] z/8 [^G3/8F3/8] z/8\\n[^A3/8^F3/8] z/8 [=c3/8^D3/8] z/8 [^c11/8^C,/2^G11/8=F11/8]\\n[^C,7/8z/2] ^D,3/8 z/8 [^G3/8F,3/8^C3/8] z/8\\n[^A3/8^F,3/8^F3/8^C/2^c11/8] z/8 [^G3/8^C,3/8=F3/8^C7/8] z5/8\\n[^G3/8F3/8^C3/8] z/8 [^c11/8^C,/2^G11/8F11/8^C3/8^G,3/8] z/8\\n[^C,7/8^C3/8^G,3/8=F,3/8] z/8 ^D,3/8 z/8 [^G3/8F,3/8F3/8] z/8\\n[^A3/8^F,3/8^F3/8^C/2^c11/8] z/8 [^G3/8^C,3/8=F3/8^C7/8] z5/8\\n[^c/4=F,/4^G/4^C/4^g3/8] [^c/4F,/4^G/4^C/4]\\n[^c3/8^F,3/8^A3/8^F3/8^C3/8] z/8 [^c3/8^C,3/8^G/4=F3/8f/4^C/4]\\n[f/4^G/4^C/4] [^f3/8^A3/8^C3/8] z/8 [^c/4=F,/4^G/4^C/4=f3/8]\\n[^c/4F,/4^G/4^C/4] [^c3/8^F,3/8^A3/8^F3/8] z/8\\n[^c3/8^C,3/8^G3/8=F3/8^g/4f/4] [^g/4f/4^C/4] [^a3/8^f3/8^C3/8] z/8\\n[^c3/8=F,3/8^G3/8^C3/8^g3/8] z/8 [=c3/8^D,3/8^F3/8^D3/8] z/8\\n[^c7/8^C,3/8=F3/8^G,/2] z/8 [^G,3/8^D3/8] z/8\\n[=c3/8^G,3/8^D3/8^d3/8z/8] ^G/4 z/8 [^c/2^C,3/4F3/4^G,3/4=f3/8^G3/8]\\nz/8 [F,3/8^g3/8^c3/8^G3/8] z/8 [^D,3/8^f3/8=c3/8^D3/8] z/8\\n[^C,3/8=f3/8^c3/8^G3/8] z/8 [^d11/8^G,11/8^G11/8=C11/8=c3/4] z3/4\\n[^G3/8C3/8^D3/8=C,3/8] z/8 [f3/8^C3/8^G/2^g11/8^C,3/8] z/8\\n[^d3/8^G,3/8^G7/8=C3/8] z5/8 [^d3/8c3/8^G3/8] z/8\\n[^d11/8^G,11/8^G11/8C11/8c3/4^D3/4] z3/4 [^G3/8C3/8^D3/8=C,3/8] z/8\\n[f3/8^C3/8^G3/8^C,3/8] z/8 [^d/4^G,3/8^G/4=C3/8c/4] [^d/4c/4^G/4]\\n[f3/8^c3/8^G3/8] z/8 [^d/4C/4^G/4^D/4=c3/8=C,/4]\\n[^d/4C/4^G/4^D/4C,/4] [f3/8^C3/8^G3/8^C,3/8] z/8\\n[^d/4^G,3/8^G/4=C3/8c'/4] [c'/4^d/4^G/4] [^c3/8f3/8^G3/8] z/8\\n[^d/4C/4^G/4^D/4c'3/8=C,/4] [^d/4C/4^G/4^D/4C,/4]\\n[f3/8^C3/8^G3/8^C,3/8] z/8 [^d/4^G,3/8^G/4=C3/8c'/4] [c'/4^d/4^G/4]\\n[^c3/8f3/8^G3/8] z/8 [^d3/8C3/8^G3/8^D3/8c'3/8=C,3/8] z/8\\n[f3/8^C3/8^G/2^c3/8^C,3/8] z/8 [^d3/8=C3/8^D3/8^g7/8^G7/8=C,3/8] z/8\\n[^c3/4^A,3/4F3/8^A3/4] z/8 [=G3/8^C3/8=g3/8] z/8\\n[=c/2^G,3/4^G/2^D3/4^g3/8] z/8 [^d/4c/4^G/4] [^d/4c/4^G/4]\\n[f3/8^c3/8^G3/8] z/8 [^d3/8=c3/8^G3/8] z/8 [^G15/8^G,15/8] z/8\\n[^A7/8^A,7/8] z/8 [c7/8=C7/8C,7/8] z/8 [^c3/8^C3/8^C,3/8] z/8\\n[^C3/8^C,3/8] z/8 [^c3/2^C3/2^C,15/8] [^c3/8^C3/8] z/8\\n[=c7/8=C7/8=C,7/8] z/8 [^A15/8^A,15/8] z/8 [^G3/4^G,3/4] z3/4\\n[^d/4C/4^G/4^G,/4^g/4C,/4] [^d/4C/4^G/4^G,/4^g/4C,/4]\\n[^c3/8^C3/8^G3/8f3/8^C,/2F3/8] z/8 [=c3/8^G,/2^G3/8^d3/8^D3/8c'3/8]\\nz5/8 [^d/4=C/4^G/4^G,/4^D/4^g/4] [^d/4C/4^G/4^G,/4^D/4^g/4]\\n[^c3/8^C3/8^G3/8f3/8^C,/2F3/8] z/8 [=c3/8^G,/2^G3/8^d3/8^D3/8c'3/8]\\nz5/8 [^d/4=C/4^g/4^G,/4^G/4^D/4] [^d/4C/4^g/4^G,/4^G/4^D/4]\\n[f3/8^C3/8^g3/8^C,/2^G3/8^c3/8] z/8 [^d/4^G,/4^g/4^G/4=C3/8c'/4]\\n[^g/4^d/4^G,/4c'/4^G/4] [^d3/8^g3/8^G,/2c'3/8^G3/8] z/8\\n[^d/4C/4^G/4^G,/4^D/4^g/4] [^d/4C/4^G/4^G,/4^D/4^g/4]\\n[f3/8^C3/8^G3/8^C,/2^c3/8] z/8 [^d3/8^G,/2^G3/8=C3/8c'3/8] z9/8\\n[^C,15/8^C15/8] z/8 [^D,7/8^D7/8] z/8 [F,7/8F7/8] z/8 [^F,3/8^F3/8]\\nz/8 ^F,3/8 z/8 [^F,3/2^F3/2] [^F3/8^F,3/8] z/8 [=F,7/8=F7/8] z/8\\n[^D,15/8^D15/8] z/8 [^C,3/4^C3/4] z3/4 [^c/4F,/4^g/4^C,/4^G/4^C/4]\\n[^c/4F,/4^g/4^C,/4^G/4^C/4] [^c3/8^F,3/8^a3/8^f3/8^C,/2^A3/8] z/8\\n[^c3/8^C,/2^g3/8=f3/8^G3/8F3/8] z5/8 [^c/4=F,/4^g/4^C,/4^G/4^C/4]\\n[^c/4F,/4^g/4^C,/4^G/4^C/4] [^c3/8^F,3/8^a3/8^f3/8^C,/2^A3/8] z/8\\n[^c3/8^C,/2^g3/8=f3/8^G3/8F3/8] z5/8 [^c/4=F,/4F/4^C,/4^G/4^C/4]\\n[^c/4F,/4F/4^C,/4^G/4^C/4] [^c3/8^F,3/8^f3/8^C3/8^C,/2^A3/8] z/8\\n[^c/4^C,/4=f/4^C/4^G/4F3/8] [f/4^C/4^C,/4^c/4^G/4]\\n[f3/8^G3/8^C,/2^c3/8^C3/8] z/8 [^c/4=F,/4F/4^C,/4^G/4^C/4]\\n[^c/4F,/4F/4^C,/4^G/4^C/4] [^c3/8^F,3/8^C3/8^C,/2^A3/8^F3/8] z/8\\n[^c3/8^C,/4^G/4=F/4^g3/8f3/8] [^G/4F/4^C,/4] [^G3/8F3/8^C,/2] z/8\\n[^G/4F/4^C,/4] [^G/4F/4^C,/4] [^c15/8F3/4^C3/4^C,] z3/4 ^C/4 ^C/4\\n[^d7/8=C3/8] z/8 [^G,3/8^G/4] ^G/4 [f7/8F3/8] z/8 ^C/4 ^C/4\\n[^f3/8^A,3/8] z/8 [^F3/8^A,3/8^C/4] ^C/4 [^f3/2^A3/8] z/8 [^D/4^A3/8]\\n^D/4 [=C3/8^D3/8] z/8 [^f3/8^G,/4^G3/8] ^G,/4 [=f7/8^C7/4z/2] ^G/4\\n^G/4 [^d15/8^F3/8] z/8 ^D/4 ^D/4 [^G3/8=C3/4] z/8 [^G,/4^G3/8] ^G,/4\\n[^c3/4=F,3/8^G3/8^C3/8] z/8 [^C,3/8^G/4=F/4^g/4] [^G/4F/4^g/4]\\n[^C3/8F3/8^G3/8f3/8^C,3/8] z/8 [^c/4F,3/8^C3/8F3/8] ^c/4\\n[=c3/8^G,/2c'3/8] z/8 [^G/4^d/4^G,/4^D/4^g3/8c/4]\\n[^d/4^G/4^G,/4^D/4c/4] [^d3/8^G3/8^G,/2=C3/8c3/8] z/8\\n[c/4f/4^G/4^G,/2c'/4] [c/4^d/4c'/4^G/4] [^c3/8^A,7/8F3/8^C,/2] z/8\\n[^c/4^f/4^C/4^C,/4^F/4] [^c/4=f/4^C/4^C,/4=F/4]\\n[^d3/8=C7/8^G3/8^G,/2^D3/8=c3/8] z/8 [^d/4^g/4^G/4^G,/4c/4]\\n[^f/4^G/4^G,/4^F/4^d/4c/4] [^G3/4^C3/8=f3/4^C,/2=F/2] z/8\\n[^C,3/8^G,/2^g/4F/4] [^f/4^D/4] [^C3/2^C,3/2=f3/8] [f3/8^G3/8z/8]\\n[^c/4^A/4^a/4F3/8] [=c/4^G/4c'/4^g/4] [^A3/8=g/2^d/2=G3/8^a3/8] z/8\\n[^A3/8^C,/2^D/4^C3/8g/4^d/2] [^D/4f/4] [=C7/8^g3/2^G,^G3/2^d3/8c3/8]\\nz/8 [^d/4f/4c3/8] ^d/4 [^c3/8^A,15/8F3/8] z/8\\n[=c3/8^g3/8^G3/8^C,/2F3/8] z/8 [^c3/8=g3/4^C,3/4=G3/4^C3/8] z/8\\n[^d/4^C3/8] [^c/4^C,/4] [=c3/8^G,^g3/4^d/2^G/2^D3/8] z/8\\n[c/4^D/4^d/4^G/4] [c/4^D/4^d/4^G/4] [^d3/8=C3/8^g3/8c3/8] z/8\\n[c3/8^G,/4^d/4^g/4^D/4^G3/8] [^G,/4^d/4^g/4^D/4]\\n[F,3/8^g3/8^c3/8^C,/2^G3/8] z/8 [^G/4^C,/2f/4F3/8^C/4^g/4]\\n[^G/4^C/4^g/4f/4] [^c3/8F3/8^g3/8] z/8 [^G3/8^C/4f/4F/4^C,/4^g3/8]\\n[^C/4f/4F/4^C,/4] [=C3/8^d3/8^G3/8^G,/2^D3/8=C,3/8] z/8\\n[=c/4^G,/2^d3/8^G3/8C3/8^D/4] [c/4^D/4^g/4] [^d3/8C3/8^g3/8] z/8\\n[c3/8^G,3/8^d3/8] z/8 [^c^C/2] [^G/4F/4^C/4] [^G/4F/4^C3/4]\\n[f3/8^G3/8^c/2] z/8 [^c3/8^C/4f/4^G/4^C,/4] [^C/4f/4^G/4^C,/4]\\n[=C3/8^d/2^D7/8^g3/8=C,3/8] z/8 [=c/4^G,3/8c'/4^d/4^G/4]\\n[c/4c'/4^d/4^G/4] [^c3/8f7/8F/2^G3/8] z/8\\n[^G3/8^C/4^g3/8^c/4F/4^C,/4] [^C/4^c/4F/4^C,/4]\\n[^A,3/8^f7/8^F3/8^c3/8^C3/8] z/8 [^A/4^F,3/8^c/4^C/4] [^A/4^c/4^C/4]\\n[^d3/8^f15/8^F/2^A3/8] z/8 [^d3/8^D,/4^F/4] [^D,/4^F5/8]\\n[^G,3/8^D3/8=C3/8] z/8 [=c/4^G,3/8^F3/8c'/4^d/4^G/4]\\n[c/4c'/4^d/4^G/4] [^c/2=f7/8=F/2] [^c/4^A,/4F3/8] [^A,/4^c/4^C/4]\\n[^c/2^F,3/8^d^D15/8^a3/8] z/8 [^D,/4^c3/8^f3/8^A3/8] ^D,/4\\n[=c3/4^G,5/8c'5/8^d3/4=C3/8] z/8 [^G3/8z/4] [^F,/4c'/4^d/4]\\n[^c/2=F,3/4^C^g3/8^G3/8] z/8 [^G/4^g/4^c/4F/4] [^G/4^g/4^c/4F/4]\\n[^c/2F3/8=f3/8^G3/8^C3/8] z/8 [^C/4F3/8^c/2f/4^G/4^C,/4]\\n[^C/4f/4^G/4^C,/4] [^c^A,3/8^F11/8^f3/8^C3/8] z/8\\n[^F,/4^A3/8^a3/8^f3/8^C/4] [^F,/4^C/4]\\n[^c3/4^A,3/8^A3/8^a3/8^f3/8^C3/8] z/8\\n[=C3/8^A3/8^F3/8^a3/8^f3/8^D3/8] z/8 [^c^C7/4^G/2=F/2^g3/8=f3/8] z/8\\n[^C,/4f/4^G/4^g/4F/4] [^C,/4f/4^G/4^g/4F3/4] [^C,/2f3/8^G/2^c/2] z/8\\n[^C,/2f3/8^G3/8^c3/8F3/8] z/8 [^A,3/8^c3/8^f3/8^C,/2^F3/8] z/8\\n[^A,/4^c/4^C/4^C,/4^f/4^F/4] [^A,/4^c/4^C/4^C,/4^f/4^F/4]\\n[^F,3/8^c3/8^C3/8^C,/2^a3/8^f3/8] z/8\\n[^F,3/8^c3/8^C3/8^C,/2^a3/8^f3/8] z/8 [^C,^G3/4=F3/4^g3/4=f3/4^C3/4]\\nz/4 [^G^C,F^C] [^G=C,^D^G,] [^F^A,^C^C,] [=F^G,3/2^C] [^D3/4^F,=Cz/2]\\n[^G,3/8z/4] [^C/4=F,/4] [^C3F,15/4^G,15/4] [^C,^G7/8F7/8^C7/8] z/8\\n[=C,^G7/8^D7/8^G,7/8] z/8 [^A,^C2^F7/8^C,7/8] z/8 [=F^G,3/2]\\n[^D3/4=C^F,3/4z/2] [^G,/2z/4] [^C/4=F,/4]\\n[^C11/4^C,11/4F,11/4^G,11/4] z/4 [f^C^g^C,^G7/8^c7/8] z/8\\n[^d=C^g^G,^G7/8^D] z/8 [^c^A,^f^C,^C^F] [^c^G,3/2=f=F7/8^G7/8] z/8\\n[=c^F,7/8^d3/4^G^D7/8z/2] [^G,/2z/4] [^c/4^C/4=F,/4]\\n[^c5/4F,5/4F5/4^C,3/2^C5/4^G,5/4] z/4 [=c/2^D,/2^d/2^G/2^G,/2^D/2]\\n[^c^C,f^GF^G,] [^c^A,=g^C,=G7/8^C] z/8\\n[=c5/4^G,3/2^g5/4^d5/4^G5/4^D5/4] z/4 [^G/2F,/2^g/2f/2^C,/2^C/2]\\n[^A^F,^c^C,^F^C] [=c^D,^f^d^G,^F7/8] z/8 [^c5/4^C,2=f5/4^G5/4=F5/4]\\nz/4 ^G,3/8 z/8 [^C7/8^C,7/8] z/8 =F,7/8 z/8 ^A,7/8 z/8 ^C,7/8 z/8\\n^F,7/8 z/8 =F,3/8 z/8 ^D,3/8 z/8 [^D,/8F,/8] [^D,/8F,/8] [^D,/8F,/8]\\n[^D,/8F,/8] [^D,/8F,/8] [^D,/8F,/8] [^D,/8F,/8] [^D,/8F,/8]\\n[^D,/8F,/8] [^D,/8F,/8] [^D,/8F,/8] [^D,/8F,/8] [^D,/8F,/8]\\n[^D,/8F,/8] [^D,/8^C,/8] ^D,/8 ^C,3/4 z/4 ^C7/8 z/8 ^G7/8 z/8\\n[=C7/8z/2] ^G,/8 ^G,/4 z/8 [^C3/8F7/8^C,3/8] z/8 ^C,3/8 z/8\\n[^G,7/8z/2] F,/8 F,/4 z/8 [^A,3/8^C7/8] z/8 =G,3/8 z/8 [^G,3/4=C3/8]\\nz/8 ^A,3/8 z/8 [C7/8z/2] ^D,/8 ^D,/4 z/8 [^C,3/8^A,5/8] z/8\\n[^D,3/8z/4] ^G,/4 [=C,3/8^G,/2] z/8 ^G,3/8 z/8 [^F,3/8^G7/8] z/8\\n^G,3/8 z/8 [=F,3/4^C7/8^c7/8z/2] ^G,3/8 z/8 [F7/8^C3/8] z/8\\n[F,3/8^C3/8] z/8 [^F,3/8^A7/8^C3/4] z/8 ^C,3/8 z/8 [^C7/8z/2] ^A,3/8\\nz/8 [^F7/8^D3/8] z/8 =C3/8 z/8 [=F3/8^C/2] z/8 [^F,3/8^D3/8^C3/8] z/8\\n[^G,3/8F7/8^C3/4] z/8 ^G,3/8 z/8 [^D5/8=C3/4z/2] [^G,3/8z/4] ^C/4\\n[=F,3/8^C3/4] z/8 [^C,3/8^G3/8] z/8 [^c7/8F3/8] [^C,3/8^C/8]\\n[^C3/8z/8] F/4 z/8 [^g7/8=C3/8^D3/8=C,3/8] z/8 [^G,3/8^D3/8C3/8] z/8\\n[=c7/8^G3/8] [C,3/8C/8] [C3/8^D3/8z/8] ^G/4 z/8\\n[f7/8^C3/8^G3/8^C,3/8] z/8 [^C,3/8^C3/8] z/8 [^G5/8=C3/8] z/8\\n[C3/8^G,3/8F,/8] [F,/4^G/4] z/8 [^c7/8^A,3/8^C3/8F3/8] z/8\\n[=G,3/8^A3/8^D/2] z/8 [=c3/8^G,3/8^G7/4^D3/8] z/8 [^A3/8^C,3/8F3/8]\\nz/8 [c7/8^D,3/8^D/2] z/8 [^D,3/8^D3/8] z/8 [^A5/8=G3/4^D/2]\\n[^D3/8^D,/8] [^D,/4z/8] ^G/4 [^G7/4=C,3/4^D3/4] z/4\\n[^G,3/4^D3/4=C3/4] z/4 ^G7/8 z/8 ^G7/8 z/8 ^G3/2\\n[C3/8^d/8^G/8^G,/2^D3/8C,3/8] [^g/4^d/4^G3/8] z/8\\n[^C3/8f3/8^G/2^C,/2F3/8^c3/8] z/8 [^G,/2^d3/8^G^D3/8c'3/8] z5/8\\n[^d/8^G/8^G,/2^D3/8=C/8=C,3/8] [C/4^g/4^d/4^G3/8] z/8\\n[^C3/8f3/8^G/2^C,/2F3/8^c3/8] z/8 [^G,/2^d3/8^G^D3/8c'3/8] z5/8\\n[=C/4^d/4^G/4^G,/4^D/4^g/4] [C/4^d/4^G/4^G,/4^D/4^g/4]\\n[^C3/8f3/8^G/2^C,/2F3/8^c3/8] z/8 [^G,/2^d3/8^G^D3/8c'3/8] z5/8\\n[=C/4^d/4^G/4^G,/4^D/4^g/4] [C/4^d/4^G/4^G,/4^D/4^g/4]\\n[^C3/8f3/8^G3/8^C,/2F3/8^c3/8] z/8 [^G,/2^d3/8^G3/8^D3/8c'3/8] z/8\\n^G7/8 z/8 ^G7/8 z/8 ^G7/8 z/8 [^G13/8z] [^g5/8z/2]\\n[=C3/8^d/8^G,/2^D3/8=C,3/8] [^g/4^d/4^G3/8] z/8\\n[^C3/8^g13/8f3/8^C,/2F3/8^c3/8] z/8 [^G,/2^d3/8^D3/8c'3/8^G9/8] z5/8\\n[=C3/8^d/8^G,/2^D3/8=C,3/8] [^g15/8^d/4^G3/8] z/8\\n[^C3/8f3/8^C,/2F3/8^c3/8^G/2] z/8 [^G,/2^d3/8^D3/8c'3/8^G] z5/8\\n[=C/4^d/4^G,/4^D/4^g/4^G/4] [C/4^d/4^G,/4^D/4^g7/4^G/4]\\n[^C3/8f3/8^C,/2F3/8^c3/8^G/2] z/8 [^G,/2^d3/8^D3/8c'3/8^G] z5/8\\n[=C/4^d/4^G,/4^D/4^g/4^G/4] [C/4^d/4^G,/4^D/4^g3/2^G/4]\\n[^C3/8f3/8^C,/2F3/8^c3/8^G/2] z/8 [^G,/2^d3/8^D3/8c'3/8^G3/8] z3/8\\n^f/4 =f/4 ^d/4 ^c7/8 z/8 ^c7/8 z/8 [^c13/8z3/2] [F,3/8^G3/8^C/8]\\n[^g/4^c11/8^C/4] z/8 [^F,3/8^A3/8^F3/8^a3/8^f3/8^C3/8] z/8\\n[^C,3/8^G3/8=F3/8^g3/8=f3/8^C3/8] z/8 [^c^g3/8F3/8] z/8\\n[=F,3/8^G3/8^C3/8^g3/8f3/8] z/8 [^F,3/8^A3/8^F3/8^a3/8^c3/2^C3/8] z/8\\n[^C,3/8^G3/8=F3/8^g3/8f3/8^C3/8] z5/8 [=F,/4^G/4^C/4^g/4^c/4]\\n[F,/4^G/4^C/4^g/4^c7/4] [^F,3/8^A3/8^F3/8^a3/8^f3/8^C3/8] z/8\\n[^C,3/8^G3/8=F3/8^g3/8=f3/8^C3/8] z5/8 [=F,/4^G/4^C/4^g/4^c/4]\\n[F,/4^G/4^C/4^g/4^c] [^F,3/8^A3/8^F3/8^a3/8^f3/8^C3/8] z/8\\n[^C,3/8^G3/8=F3/8^g3/8=f3/8^C3/8] z/8 ^c7/8 z/8 ^d7/8 z/8 ^d7/8 z/8\\n[^d13/8z3/2] [=G,3/8^D/8^A,3/8] [^a/4^d11/8^D/4] z/8\\n[^G,3/8^G3/8=C3/8c'3/8^g3/8^D3/8] z/8\\n[^D,3/8=G3/8^A,3/8^a3/8=g3/8^D3/8] z/8 [^d2^A3/8G3/8] z/8\\n[=G,3/8^D3/8^A,3/8^a3/8g3/8] z/8 [^G,3/8^G3/8C3/8c'3/8^g3/8^D3/8] z/8\\n[^D,3/8=G3/8^A,3/8^a3/8=g3/8^D3/8] z/8 [^d15/4G3/8] z/8\\n[=G,/4^D/4^A,/4^a/4g/4] [G,/4^D/4^A,/4^a/4g/4]\\n[^G,3/8^G3/8C3/8c'3/8^g3/8^D3/8] z/8\\n[^D,3/8=G3/8^A,3/8^a3/8=g/2^D3/8] z5/8 [=G,/4^D/4^A,/4^a/4g/4]\\n[G,/4^D/4^A,/4^a/4g/4] [^G,3/8^G3/8C3/8c'3/8^g3/8^D3/8] z/8\\n[^D,3/8=G3/8^A,3/8^a3/8=g3/8^D3/8] z9/8 f7/8 z/8 f7/8 z/8 [f13/8z3/2]\\n[=A,3/8F/8C3/8] [c'/4f11/8F/4] z/8 [^A,3/8^A3/8^C3/8^c3/8^a3/8F3/8]\\nz/8 [=F,3/8=A3/8=C3/8c'3/8=a3/8F3/8] z/8 [f/2=c3/8A3/8] z/8\\n[=A,3/8F3/8C3/8c'3/8f3/2] z/8 [^A,3/8^A3/8^C3/8^c3/8^a3/8F3/8] z/8\\n[F,3/8=A3/8=C3/8c'3/8=a3/8F3/8] z/8 [f/2=c3/8A3/8] z/8\\n[=A,/4F/4C/4c'/4f/4] [A,/4F/4C/4c'/4f7/4]\\n[^A,3/8^A3/8^C3/8^c3/8^a3/8F3/8] z/8 [F,3/8=A3/8=C3/8c'3/8=a3/8F3/8]\\nz5/8 [=A,/4F/4C/4c'/4f/4] [A,/4F/4C/4c'/4f5/4]\\n[^A,3/4^A3/4^C3/4^c3/4^a3/4F3/4] z/4 [^A,3/4F3/4^C3/4^c3/4f/2] f3/8\\nz/8 ^f7/8 z/8 ^f7/8 z/8 [^f43/8z2] [^A,7/8^c7/8^C,^A7/8^C7/8^F7/8]\\nz/8 [^A,7/8^c7/8^C,^A7/8^C7/8^F7/8] z/8\\n[=C11/8^d/2^G,3/2^G/2^D11/8^g3/8] z/8 [^d/2^G/2] [^d3/8^G3/8] z/8\\n[^f3/8C3/8^d3/8^G,/2^G3/8^D3/8] z/8 [=f3/8^C7/8^c3/8^C,/2^G/2] z/8\\n[^d3/8^G3/8^C,/2=C3/8=c3/8] z/8 [f3/8^C,/2^G/2^C3/8^c3/8] z/8\\n[^f3/8^G3/8^C,/2^D3/8^d3/8] z/8 [^d11/8^G,3/2^G11/8=C11/8=c11/8] z/8\\n^G,/2 [^G,7/8z/2] c/8 c/4 z/8 [^c3/8=C,7/8] z/8 ^d3/8 z/8\\n[^G5/8F,7/8z/2] [^G,3/8z/8] ^G/4 z/8 [^G,7/8^A,3/8^A3/8] z/8\\n[C3/8=c3/8] z/8 [^C,7/8F,3/8=F3/8] z/8 [F3/8^G,3/8^G3/8z/8] =f/4 z/8\\n[=C,/2=G3/8^G,15/8=g3/8^D3/8] z/8 [^G3/8C,3/8^g3/8] z/8\\n[^A,15/8^C3/8^c3/8^G7/8] z/8 [=C3/8=c3/8] z/8 [^C3/8=G,7/8^c3/8=G7/8]\\nz/8 [^D/4^d/4] [^C/4^c/4] [^G,3/4=C3/8=c3/8^G3/4] z/8 ^D3/8 z/8\\n[^G7/8^g7/8z/2] ^F3/8 z/8 [^c7/8=Fz/2] ^G,/8 ^G,/4 z/8\\n[F7/8^C3/8f7/8] z/8 [^D3/8=C3/8] z/8 [^A7/8^C^A,11/8^a7/8z/2] ^C,/8\\n^C,/4 z/8 [^C/2^F,3/8^c/2] z/8 [=F,3/8^C3/8^G,3/8^c3/8^G3/8] z/8\\n[^F7/8^D,7/8^C3/8^F,7/8^f7/8^c3/8] z/8 [=C3/8=c3/8] z/8\\n[=F3/8=F,3/8^C3/8^G,3/8=f3/8^c3/8] z/8\\n[^D3/8^F,3/8^C3/8^A,3/8^d3/8^c3/8] z/8\\n[F7/8^G,3/2^C7/8f7/8^c7/8^G15/8] z/8 [^D5/8^F,3/8=C7/8^d5/8=c7/8] z/8\\n[^G,3/8z/4] [^C/4^c/4] [^C7/4=F,3/4^G,7/4^c7/4^G7/4] z/4 ^C,3/4 z/4\\n^C7/8 z/8 ^C7/8 z/8 ^C3/2 [^c3/8F,3/8^C,/2^G3/8^g3/8^C2] z/8\\n[^f3/8^F,3/8^C,/2^A3/8^a3/8^c3/8] z/8 [=f3/8^C,/2^G3/8^g3/8^c3/8]\\nz5/8 [^c3/8=F,3/8^C,/2^G3/8^g3/8^C7/4] z/8\\n[^f3/8^F,3/8^C,/2^A3/8^a3/8^c3/8] z/8 [=f3/8^C,/2^G3/8^g3/8^c3/8]\\nz5/8 ^C3/8 z/8 ^C7/8 z/8 ^C7/8 z/8 ^C3/2 [^c/4=F,/4^C,/4^G/4^g/4^C/4]\\n[^c/4F,/4^C,/4^G/4^g/4^C/4] [^f3/8^F,3/8^C,/2^A3/8^a3/8^C/2] z/8\\n[=f3/8^C,/2^G3/8^g3/8^C] z5/8 [^c/4=F,/4^C,/4^G/4^g/4^C/4]\\n[^c/4F,/4^C,/4^G/4^g/4^C/4] [^f3/8^F,3/8^C,/2^A3/8^a3/8^C/2] z/8\\n[=f3/8^C,/4^C/4^G3/8^g3/8] [^C/4^C,/4] [F3/8^C3/8^C,/2] z/8\\n[^G3/8^C,/2^C3/8F3/8^g3/8] z/8 [^G7/8^C7/8^c7/8F7/8^C,/2f/4] ^d/4\\n[^C,/2f/4] ^f/4 [^c7/8=F,7/8^g7/8^C,/2^G7/8^C7/8] ^f/4 [^C,/2=f/4]\\n^d/4 [f7/8^A,7/8^c/2^C,^C7/8F7/8] =c/4 [^c3/8z/4] ^d/4\\n[^c7/8^C,3/4f7/8F7/8^C7/8z/4] =c/4 ^A/4 [^C,/4^G/4]\\n[^c7/8^F,7/8^a7/8^C,/2^A/2^A,7/8] ^G/4 [^C,/4^A3/8] [^C,/4^F/4]\\n[^G3/8=F,3/8^c7/8^C,/2^C7/8^G,3/8] z/8 [^G3/8F,3/8^C,/2^G,3/8^g3/8]\\nz/8 [=c7/8^D,7/8^f7/8^d7/8^G,^F7/8] z/8\\n[^c3/8^C,/2=f3/8=F3/8^G,3/8^G/2] z/8\\n[^c3/8^C,/2^d3/8^G3/8^D3/8^G,3/8] z/8 [^c7/8^G,3/2^d/8^G/2^D15/8f/8]\\n[^d/8f/8] [^d/8f/8] [^d/8f/8] [^d/8^G/4f/8] [^d/8f/8] [^d/8^G/4f/8]\\n[^d/8f/8] [^d/8=c7/8^G/2^c/8c'7/8] [^d/8^c/8] [^d/8^c/8] ^d/8\\n[^c3/8^G3/8^G,/2^g3/8] z/8 [^c/2^C,F3/4^G,3/4f/4^G3/4] ^d/4 [f/4^c/4]\\n[^f/4^d/4] [^g/4=f/4] [^f/4^d/4] [=f/4^c/4] [^d/4=c/4]\\n[^G/2^C,f7/8^c/2F/2^C7/8] [^c/4^G/4F/4] [^c/4^G/4F/4]\\n[^G/2^C,3/4f/2^c/2F5/8^C5/8] [f/4^c/4^G/4]\\n[^f/4^d/4^C,/4^F/4^D/4^G/4] [^c/2^C7/8^g7/8=f/2^C,^G7/8]\\n[f3/8^c3/8z/4] [^f/4^d/4] [^g3/8=f3/8] z/8\\n[^G3/8^C,/2^g3/8f3/8=F3/8^C3/8] [c'/4^d/4] [^G/2^C,f/2^c/2F7/8^C7/8]\\n[^c3/8f3/8^G/4] [^d/4^f/4^G/4] [^G/2^C,3/4=f/2^c/2F5/8^C5/8]\\n[f/4^c/4^G/4] [^f/4^d/4^C,/4^F/4^D/4^G/4]\\n[^c/2^C7/8^g7/8=f/2^C,^G7/8] [f3/8^c3/8z/4] [^f/4^d/4] [^g3/8=f3/8]\\nz/8 [^a/4^f/4] [c'/4^d/4] [^G/2^C,=f/2^c/2=F7/8^C7/8] [^c3/8f3/8^G/4]\\n[^d/4^f/4^G/4] [^G/2^C,=f/2^c/2F7/8^C7/8] [f/4^c/4^G/4]\\n[^f/4^d/4^G/4] [^c/2^C7/8^g7/8=f/2^C,^G7/8] [f3/8^c3/8z/4] [^f/4^d/4]\\n[^g3/8=f3/8] z/8 [^G3/8^C,/2^g3/8f3/8F3/8^C3/8] [c'/4^d/4]\\n[^G/2^C,f/2^c/2F7/8^C7/8] [^c3/8f3/8^G/4] [^d/4^f/4^G/4]\\n[^G/2^C,3/4=f/2^c/2F5/8^C5/8] [f/4^c/4^G/4]\\n[^f/4^d/4^C,/4^F/4^D/4^G/4] [^c/2^C7/8^g7/8=f/2^C,^G7/8]\\n[f3/8^c3/8z/4] [^f/4^d/4] [^g3/8=f3/8] z/8 [^C,3/8^a/4^f/4^G3/8]\\n[c'/4^d/4] [^C7/8^c7/8=f3/8^G7/8^C,7/8] z/8 f/4 ^f/4\\n[^G7/8F,7/8=F7/8^C,^C7/8^g7/8] ^f/4 =f/4 ^d/4\\n[^c/2^A,7/8F7/8^C,^C/2z/4] =c/4 [^C3/8^c3/8z/4] ^d/4\\n[f7/8^C,^G3/8F/2^G,7/8^c/4] =c/4 [F3/8^A/4] ^G/4\\n[^A/2^F,7/8^a7/8^c7/8^C,^C7/8] ^G/4 [^A3/8z/4] ^F/4\\n[^c7/8=F,3/8^G7/8^C,^G,7/8] z/8 [F,3/8^g3/8] z/8\\n[^f7/8^D,7/8^d7/8^G,^D7/8=C7/8] z/8 [=f3/8^C,/2^c7/8^G3/8^C3/8] z/8\\n[^d3/8^C,/2^G3/8^C3/8] z/8 [^d/8^G,3/2^G/2^C7/8f/8^c7/8] [^d/8f/8]\\n[^d/8f/8] [^d/8f/8] [^d/8^G/4f/8] [^d/8f/8] [^d/8^G/4f/8] [^d/8f/8]\\n[^d/8^G/2=C7/8f/8=c7/8^D7/8] [^d/8f/8] [^d/8^c/8] [^d/2z/8]\\n[^c3/8^G3/8^G,/2] z/8 [^c3/4^C,=F3/4^G3/4z/2] ^C/4 ^C/4 F3/8 z/8\\n[F,3/8^G/4F3/8^C,/2^C3/8^g3/8] ^G/4 [^c7/8^F,3/8^C3/8^C,/2^A3/8^F3/8]\\nz/8 [^C,/2^C3/8^G3/8=F3/8^g3/8f3/8] z/8 [^c/2z3/8] ^G/8\\n[=F,3/8^C,/2^G3/8^C3/8^g3/8^c3/8] z/8\\n[^c/2^F,3/8^C3/8^C,/2^A3/8^F3/8] z/8 [^C,/2f3/8^c3/8^G3/8=F3/8^g3/8]\\nz/8 [^g3/8f3/8] z/8 [^c3/8=F,3/8f3/8^C,/2^G3/8^C3/8] z/8\\n[^c7/8^F,3/8^C/2^C,/2^A3/8^F3/8] z/8 [^C,/2^G3/8=F3/8^g3/8f3/8^C3/8]\\nz/8 [^c/2^C/2] [=F,3/8^C,/2^G3/8^C3/8^g3/8^c3/8] z/8\\n[^c/2^F,3/8^C3/8^C,/2^A3/8^F3/8] z/8 [^C,/2f/4^c/2^G3/8=F3/8^g/4]\\n[^g/4f/4^C/4] [^g3/8f3/8^c3/8^G3/8] z/8 [^c/4=F,/4f3/8^C,/4^G/4^C/4]\\n[^c/4F,/4^C,/4^G/4^C/4^g/4] [^c/2^F,3/8^C/2^C,/2^A3/8^F3/8] z/8\\n[^c3/8^C,/2^G3/8=F3/8^g/4f/4] [^g/4f/4^C/4] [^c/2^C/2f3/8^G3/8] z/8\\n[^c/4=F,/4^C,/4^G/4^C/4^g/4] [^c/4F,/4^C,/4^G/4^C/4^g/4]\\n[^c3/8^F,3/8^C3/8^C,/2^A3/8^F3/8] z/8 [^c3/8^C,/2f/4^G3/8=F3/8^g/4]\\n[^f/4^d/4^g/4=f/4^C/4] [^g3/8f3/8^c3/8^G3/8] z/8\\n[^c/4=F,/4f3/8^C,/4^G/4^C/4] [^c/4F,/4^C,/4^G/4^C/4^g/4]\\n[^c3/8^F,3/8^C3/8^C,/2^A3/8^F3/8] z/8 [^c3/8^C,/4f/4^G3/8=F3/8^g/4]\\n[^f/4^d/4^C,/4^g/4=f/4^C/4] [^g3/8f3/8^C,/2^c3/8^G3/8] z/8\\n[^c/4=F,/4f/4^C,/4^G/4^C/4] [^c/4F,/4f/4^C,/4^G/4^C/4]\\n[^c3/8^F,3/8^C3/8^C,/2^A3/8^F3/8] z/8 [^c3/8^C,/2=F3/8^G3/8^g3/8f3/8]\\nz17/8 [^c5/4^C,11/8f5/4^G5/4F5/4^G,5/4] z/8\\n[^c17/4^F,17/4^C17/4^C,35/8^F17/4^A,17/4] z/8\\n[^c3/2^F,3/2^C3/2^C,13/8^F3/2^A,3/2] z/8\\n[^c49/8^C,49/8^C49/8=F49/8^G,49/8^g49/8] \\n\\n\\nX: 1\\nT: Xerxes Largo\\nC: Handel\\nZ: by Tiamo/Skjald\\nL: 1/4\\nQ: 1/4=120\\nK: C\\n[c51/8E13/8G,13/8C,13/8] [E3/2G,3/2C,3/2] z/8 [E3/2G,3/2C,3/2]\\n[F13/8G,13/8D,13/8] [F13/8B13/8G,13/8D,13/8] [F13/8A9/8B,13/8D,13/8]\\nz/8 G3/8 [G19/4C3/2E,3/2] z/8 [C3/2E,3/2] [C13/8E,13/8]\\n[A13/8F13/8C13/8F,13/8] [B13/8F13/8G,13/8D,13/8] [c/2E3/2G,3/2C,3/2]\\nd/2 e/2 z/8 [d19/4B3/2G3/2G,19/4] [B13/8G13/8D13/8] [B13/8G13/8D13/8]\\n[a25/8c25/8A25/8F13/8C13/8F,19/4] [F3/2C3/2] z/8\\n[a9/8A3/2c3/2F3/2C3/2] g3/8 [g39/8c39/8G39/8E13/8C13/8E,39/8]\\n[E13/8C13/8] [E13/8C13/8] [f25/8B25/8G25/8D3/2G,3/2D,19/4] z/8\\n[D3/2G,3/2] [f5/4G13/8B13/8D13/8G,13/8] e3/8\\n[e19/4c19/4G19/4C13/8G,13/8C,19/4] [C13/8G,13/8] [C3/2G,3/2] z/8\\n[c'3/2e3/2c3/2C51/8C,3/2] [c'13/8f13/8c13/8D,13/8]\\n[b13/8g13/8c13/8E,13/8] [b13/8f13/8c13/8F,13/8]\\n[a9/8f3/2c3/2F3/2F,3/2] g3/8 z/8 [g3/2e3/2c3/2E3/2G,3/2]\\n[g5/4c13/4d13/4D13/4A,13/4] ^f3/8 ^f13/8\\n[^f13/8d13/8c13/8D13/8A,13/8] [g19/8B3/2d3/2D3/2G,3/2] z/8\\n[B3/2d3/2D3/2F,3/2z3/4] a3/4 [g13/8c13/8G13/8E13/8E,13/8]\\n[=f3/4A13/8c13/8F13/8F,13/8] z/8 e3/4 [d19/8c13/8D3/4G,13/8] E7/8\\n[F3/2B3/2G,3/2z3/4] d3/4 z/8 [c3/2E3/2G,3/2C,3/2] [g77/8z13/4]\\n[e13/8c13/8G13/8C19/4] [e3/2c3/2G3/2] z/8 [e3/2c3/2G3/2]\\n[e13/8B13/8G13/8G,39/8] [e13/8B13/8G13/8] [d9/8F13/8B13/8] z/8 c3/8\\n[c13/8A3/2E3/2A,19/4] z/8 [c3/2A3/2E3/2] [c13/8A13/8E13/8]\\n[c13/8G13/8C13/8E,13/4] [B13/8G13/8C13/8] [A9/8F3/2C3/2F,3/2] G3/8\\nz/8 [G19/4E19/4C3/2C,3/2] [C13/8E,13/8] [C13/8C,13/8]\\n[A13/8F13/8C13/8F,13/8] [B3/2F3/2G,25/8D,3/2] z/8 [c/2E3/2C,3/2] d/2\\ne/2 [d19/8D13/8G13/8B,13/4G,13/4] [D13/8G13/8z7/8] c3/4\\n[d13/8G13/8B,13/8G,13/8] [a3/2f3/2c3/2F3/2F,3/2] z/8\\n[a3/2f3/2c3/2A3/2F3/2] [b13/8g13/8d13/8G13/8F13/8]\\n[c'19/8c13/8g13/8G13/8E13/8] [c13/8G13/8E13/8z3/4] g7/8\\n[g3/2c3/2E3/2E,3/2] z/8 [c3/2A3/2F3/2F,3/2z3/4] a3/4\\n[f19/8A13/8c13/8D13/8D,13/8] [G13/8B13/8D13/8G,13/8z7/8] e3/4\\n[e25/8c25/8G25/8C13/8G,13/8C,25/8] [C3/2G,3/2] z/8\\n[c3/2E3/2G,3/2C,3/2] [c13/8F13/8G,13/8D,13/8]\\n[B13/8F13/8G,13/8D,13/8] [A9/8F13/8B,13/8D,13/8] z/8 G3/8\\n[G25/8C3/2E,3/2] z/8 [C3/2E,3/2] [c13/8G13/8C13/8E,13/8]\\n[f13/8F13/8C13/8A,13/8] [f13/8G25/8D13/8B,13/8] [e3/2E3/2C3/2] z/8\\n[d25/8c3/2G3/2G,25/8] [B13/8F13/8z7/8] c3/4 [c13/8A13/8E13/8A,13/8]\\n[b13/8f13/8B13/8D13/8D,13/8] [b3/2f3/2B3/2D3/2D,3/2] z/8\\n[a3/2d3/2A3/2F3/2F,3/2] [^g5/4B13/8e13/8E13/8E,13/8] ^f3/8\\n[^g3/4B13/8e13/8D13/8D,13/8] z/8 a3/4 [a13/8e13/8A13/8C13/8C,13/8]\\n[A3/2F3/2D3/2D,3/2z3/4] d3/4 z/8 [B19/8A3/2E3/2D3/2E,3/2]\\n[^G13/8E13/8D13/8E,13/8z7/8] A3/4 [A13/8E13/8C13/8A,13/8] =f13/8\\n[f25/8c25/8F3/2C3/2A,3/2] z/8 [=G3/2B,3/2] [e7/8G13/8c13/8C13/4] d3/4\\n[e13/8c13/8G13/8C,13/8] [d13/8B13/8G13/8D13/8G,13/8z5/4] c3/8\\n[d3/2B3/2G3/2D3/2G,3/2] z/8 [a3/2c3/2A3/2F3/2F,3/2]\\n[a13/8c13/8A13/8F13/8F,13/8] [=g13/8c13/8G13/8E13/8E,13/8]\\n[f9/8G13/8B13/8D13/8D,13/8] z/8 e3/8 [e13/8c3/2G3/2C3/2C,3/2] z/8\\n[e3/2c3/2G3/2E3/2C3/2] [g13/8f13/8B13/8G13/8D13/8]\\n[c'13/8g13/8c13/8G13/8E13/8] [c'13/8g13/8c13/8G13/8E13/8]\\n[b3/2g3/2B3/2E3/2E,3/2] z/8 [b3/2f3/2c3/2F3/2F,3/2]\\n[a5/4c13/8f13/8F13/8F,13/8] g3/8 [g13/8e13/8c13/8E13/8G,13/8]\\n[g13/8d13/8c13/8D13/8A,13/8z5/4] ^f3/8 [^f3/2d3/2c3/2D3/2A,3/2] z/8\\n[^f3/2d3/2c3/2D3/2A,3/2] [g19/8B13/8d13/8D13/8G,13/8]\\n[B13/8d13/8D13/8F,13/8z7/8] a3/4 [g13/8c13/8G13/8E13/8E,13/8]\\n[=f3/4A3/2c3/2F3/2F,3/2] e3/4 z/8 [d25/8c3/2G3/2G,3/2]\\n[B13/8F13/8G,13/8z7/8] b3/4 [c'8c13/8A13/8E13/8C13/8A,13/8] z51/8\\nc13/8 [d13/8A13/8F13/8F,13/8z/2] e/2 z/8 f/2 [e3/2c3/2E3/2G,13/8] z/8\\n[d9/8F3/2B3/2G,3/2] c3/8 [c13/8G13/8E13/8G,13/8C,13/8]\\n[g13/8e13/8c13/8G13/8C13/8G,13/8] [b13/8g13/8f13/8d13/8B13/8D13/8]\\n[c'13/8c13/8G25/8E3/2g3/2E,3/2] z/8 [E,3/2c'3/2g3/2c3/2]\\n[b13/8c13/8G13/8E13/8g13/8E,13/8] [b13/8c13/8F13/4f13/8C13/8F,13/8]\\n[a13/8F,13/8c13/8f13/8z5/4] g3/8 [g3/2c3/2E3/2G,3/2e3/2C3/2] z/8\\n[g9/8c9/8D9/8A,3/2d3/2C3/2] [^f3/8c3/8D3/8]\\n[^f13/8c13/8D13/8A,13/8d13/8] [^f13/8c13/8D13/8A,13/8d13/8C13/8]\\n[g19/8B13/8D13/8G,13/8d13/8B,13/8] [F,3/2B3/2d3/2D3/2z3/4] a3/4 z/8\\n[g3/2c3/2E3/2E,3/2G3/2] [=f7/8c7/8A7/8F,7/8] [e3/4c3/4A3/4F,3/4]\\n[d19/8B13/8D3/4G,13/8c13/8] z/8 E3/4 [G13/8F13/8G,13/8B13/8z3/4] c7/8\\n[c19/2G19/2E19/2C19/2C,19/2] \\n\\n\\nX:1\\nT:Carol of the Bells\\nC:Trans-Siberian Orchestra\\nZ:Celestial\\nI:Harp\\nQ:1/4=180\\nL:1/8\\nM:3/4\\nK:Bb\\n\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B6 |\\n\\nz6 |z6 |z6 |z6 |z6 |z6 |z6 |z6 |\\n\\nz6 |z6 |z6 |z6 |z6 |z6 |z6 |z6 |\\n\\nz6 |z6 |z6 |z6 |z6 |z6 |z6 |z6 |\\n\\nz6 |z6 |z6 |z6 |B2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\ng2 g g f e |d2 d d c B |c2 c c d c |B2 A B G2 |D =E ^F G A B |c d c2 B2 |D =E ^F G A B |c d c2 B2 |\\nD =E ^F G A B |D =E ^F G A B |D =E ^F G A B |D =E ^F G A B |\\n\\nz6 |z6 |z6 |z6 |g2 g g f e |d2 d d c B |c2 c c d c |B2 A B G2 |\\nz6 |z6 |z6 |z6 |g2 g g f e |d2 d d c B |c2 c c d c |B2 A B G2 |\\n\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\n\\nz6 |z6 |z6 |z6 |z6 |z6 |z6 |z6 |\\nG,6 |F,6 |E,6 |D,6 |[E,6G,6]|[D,6F,6]|[C,6E,6]|[G,6D6]|\\n\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\n\\ng2 g g f e |d2 d d c B |c2 c c d c |B2 A B G2 |D =E ^F G A B |c d c2 B2 |D =E ^F G A B |c d c2 B2 |\\n\\nz6 |B2 A B G2 |z6 |B2 A B G2 |\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\ng2 g g f e |d2 d d c B |c2 c c d c |B2 A B G2 |D =E ^F G A B |c d c2 B2 |D =E ^F G A B |c d c2 B2 |\\nD =E ^F G A B |D =E ^F G A B |D =E ^F G A B |D =E ^F G A B |\\n\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\n\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\nB2 B B B2 |B2 B B B2 |B2 B B B2 |B2 B B B2 |\\n[=f6g6]|[e6g6]|[d6g6]|[c6g6]|[G6g6]|\\n\\nX:2\\nT:Carol of the Bells\\nC:Trans-Siberian Orchestra\\nZ:Celestial\\nI:Lute\\nQ:1/4=180\\nL:1/8\\nM:3/4\\nK:Bb\\n\\nz6 |z6 |z6 |z6 |\\n=E2 =E2 =B2 |=B2 A2 G2 |^F2 =E2 D2 |=E2 ^F2 G2 |\\nA2 =B4 |z6 |z4 =E2 |=E2 =B2 =B2 |\\nA2 G2 ^F2 |=E2 D2 =E2 |^F2 G2 A2 |=E2 =E2 =B2 |\\n=B2 A2 G2 |^F2 =E2 D2 |G6 |G6 |\\n\\nz6 |z6 |z6 |z6 |z6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |z6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |z6 |z6 |z6 |z6 |\\n\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\n\\ng2 g g f e |d2 d d c B |c2 c c d c |B2 A B G2 |D =E ^F G A B |c d c2 B2 |D =E ^F G A B |c d c2 B2 |\\nD =E ^F G A B |D =E ^F G A B |D =E ^F G A B |D =E ^F G A B |\\nz6 |z6 |z6 |z6 |\\ng2 g g f e |d2 d d c B |c2 c c d c |B2 A B G2 |\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\n\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\n\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\nG,6 |F,6 |E,6 |D,6 |\\n[E,6G,6]|[D,6F,6]|[C,6E,6]|[G,6D6]|\\n[E,6C6]|[G,6D6]|[E,6C6]|[G,6D6]|\\n[G,6D6]|[G,6=E6]|[G,6F6]|[G,2=E2][G,2_E2][G,2D2]|\\ng2 g g f e |d2 d d c B |c2 c c d c |B2 A B G2 |D =E ^F G A B |c d c2 B2 |D =E ^F G A B |c d c2 B2 |\\n\\nz6 |B2 A B G2 |z6 |B2 A B G2 |\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\n\\ng2 g g f e |d2 d d c B |c2 c c d c |B2 A B G2 |D =E ^F G A B |c d c2 B2 |D =E ^F G A B |c d c2 B2 |\\nD =E ^F G A B |D =E ^F G A B |D =E ^F G A B |D =E ^F G A B |\\n\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\n\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\nB2 B B B2 |B2 B B B2 |B2 B B B2 |B2 B B B2 |\\n[=f6g6]|[e6g6]|[d6g6]|[c6g6]|[G6g6]|\\n\\nX:3\\nT:Carol of the Bells\\nC:Trans-Siberian Orchestra\\nZ:Celestial\\nI:Flute\\nQ:1/4=180\\nL:1/8\\nM:3/4\\nK:Bb\\n\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\nz6 |=E2 =E2 =B2 |=B2 A2 G2 |^F2 =E2 D2 |\\nz6 |=E2 =E2 =B2 |=B2 A2 G2 |G6 |\\n\\nz6 |z6 |z6 |z6 |z6 |z6 |z6 |z6 |\\n\\n=E2 =E4 |=B2 =B4 |A2 G4 |^F2 =E4 |\\nz6 |z6 |z6 |z6 |\\n=E2 =E4 |=B2 =B4 |A2 G4 |^F2 =E4 |\\nz6 |z6 |z6 |z6 |\\n\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\n\\ng2 g g f e |d2 d d c B |c2 c c d c |B2 A B G2 |D =E ^F G A B |c d c2 B2 |D =E ^F G A B |c d c2 B2 |\\nD =E ^F G A B |D =E ^F G A B |D =E ^F G A B |D =E ^F G A B |\\nz6 |z6 |z6 |z6 |\\ng2 g g f e |d2 d d c B |c2 c c d c |B2 A B G2 |\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\n\\nz6 |z6 |z6 |z6 |\\n=E2 z =E2 z |=B2 z =B2 z |A2 z G2 z |^F2 z =E2 z |\\n=E2 z =E2 z |=B2 z =B2 z |A2 z G2 z |^F2 z =E2 z |\\n=E2 z =E2 z |=B2 z =B2 z |A2 z G2 z |^F2 z =E2 z |\\n=E2 z =E2 z |=B2 z =B2 z |A2 z G2 z |^F2 z =E2 z |\\n=E2 z =E2 z |=B2 z =B2 z |A2 z G2 z |^F2 z =E2 z |\\n=E2 z =E2 z |=B2 z =B2 z |A2 z G2 z |^F2 z =E2 z |\\n\\nG6 |F6 |E6 |D6 |G6 |F6 |E6 |D6 |\\nC6 |D6 |C6 |D6 |D6 |=E6 |F6 |=E2 _E2 D2 |\\n\\nz6 |z6 |z6 |z6 |\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\ng2 g g f e |d2 d d c B |c2 c c d c |B2 A B G2 |D =E ^F G A B |c d c2 B2 |D =E ^F G A B |c d c2 B2 |\\n\\nz6 |z6 |z6 |z6 |\\ng6 |f6 |e6 |d6 |\\ng2 g g f e |d2 d d c B |c2 c c d c |B2 A B G2 |D =E ^F G A B |c d c2 B2 |D =E ^F G A B |c d c2 B2 |\\nD =E ^F G A B |D =E ^F G A B |D =E ^F G A B |D =E ^F G A B |\\n\\nG,6 |F,6 |E,6 |D,6 |G,6 |F,6 |E,6 |D6 |\\n\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\nB2 B B B2 |B2 B B B2 |B2 B B B2 |B2 B B B2 |\\nG6 |G6 |G6 |G6 |G6 |\\n\\nX:4\\nT:Carol of the Bells\\nC:Trans-Siberian Orchestra\\nZ:Celestial\\nI:Guitar (clarinet)\\nQ:1/4=180\\nL:1/8\\nM:3/4\\nK:Bb\\n\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\n\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\n\\nz6 |z6 |z6 |z6 |\\nG,6 |F,6 |E,6 |D,6 |\\nz6 |z6 |z6 |z6 |\\nG,6 |F,6 |E,6 |D,6 |\\n\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\n\\ng2 g g f e |d2 d d c B |c2 c c d c |B2 A B G2 |D =E ^F G A B |c d c2 B2 |D =E ^F G A B |c d c2 B2 |\\nD =E ^F G A B |D =E ^F G A B |D =E ^F G A B |D =E ^F G A B |\\nz6 |z6 |z6 |z6 |\\ng2 g g f e |d2 d d c B |c2 c c d c |B2 A B G2 |\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\n\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\n\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\n\\nG,6 |F,6 |E,6 |D,6 |G,6 |F,6 |E,6 |D6 |\\nC6 |D6 |C6 |D6 |D6 |=E6 |F6 |=E2 _E2 D2 |\\ng2 g g f e |d2 d d c B |c2 c c d c |B2 A B G2 |D =E ^F G A B |c d c2 B2 |D =E ^F G A B |c d c2 B2 |\\n\\nB2 A B G2 |z6 |B2 A B G2 |z6 |\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\n\\ng2 g g f e |d2 d d c B |c2 c c d c |B2 A B G2 |D =E ^F G A B |c d c2 B2 |D =E ^F G A B |c d c2 B2 |\\nD =E ^F G A B |D =E ^F G A B |D =E ^F G A B |D =E ^F G A B |\\n\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\n\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\nB2 B B B2 |B2 B B B2 |B2 B B B2 |B2 B B B2 |\\nG6 |G6 |G6 |G6 |G6 |\\n\\nX:5\\nT:Carol of the Bells\\nC:Trans-Siberian Orchestra\\nZ:Celestial\\nI:Bass (theorbo)\\nQ:1/4=180\\nL:1/8\\nM:3/4\\nK:Bb\\n\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\n\\nG,6 |F,6 |E,6 |D,6 |\\n[E,6G,6]|[D,6F,6]|[C,6E,6]|[G,6D6]|\\nG,6 |F,6 |E,6 |D,6 |\\n[E,6G,6]|[D,6F,6]|[C,6E,6]|[G,6D6]|\\nG,6 |F,6 |E,6 |D,6 |\\n[E,6G,6]|[D,6F,6]|[C,6E,6]|[G,6D6]|\\n\\n[E,6C6]|[G,6D6]|[E,6C6]|[G,6D6]|\\n[G,6D6]|[G,6=E6]|[G,6F6]|[G,2=E2][G,2_E2][G,2D2]|\\n\\n[B,6D6G6B6d6]|[B,6D6G6B6]|[G,6E6G6]|[G,6D6G6]|\\n[D,6^F,6]|[D,4A,4][D,2F,2]|[D,6^F,6]|[D,4A,4][D,2G,2]|\\n[D,6^F,6]|[D,6^F,6]|[D,6^F,6]|[D,6^F,6]|\\n[G,2B,2D2G2][G,G][G,G][F,F][E,E]|[D,2G,2B,2D2] D D C B, |[E,2G,2C2] C C D C |[D,2G,2B,2] A, B, G,2 |\\n[B,6D6G6B6d6]|[B,6D6G6B6]|[G,6E6G6]|[G,6D6G6]|\\n[G,2B,2D2G2][G,G][G,G][F,F][E,E]|[D,2G,2B,2D2] D D C B, |[E,2G,2C2] C C D C |[D,2G,2B,2] A, B, G,2 |\\n[B,6D6G6B6d6]|[B,6D6G6B6]|[G,6E6G6]|[G,6D6G6]|\\n\\n[B,6D6G6B6]|F6 |E6 |D6 |\\n[E6G6]|[D6F6]|[C6E6]|[G,6D6]|\\n[E,6C6]|[G,6D6]|[E,6C6]|[G,6D6]|\\n[E6G6]|[D6F6]|[C6E6]|[G,6D6]|\\n[E,6C6]|[G,6D6]|[E,6C6]|[G,6D6]|\\n[E6G6]|[D6F6]|[C6E6]|[G,6D6]|\\n[E,6C6]|[G,6D6]|[E,6C6]|[G,6D6]|\\n\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\nB2 A B G2 |B2 A B G2 |B2 A B G2 |B2 A B G2 |\\n\\n[E,6C6]|[G,6D6]|[E,6C6]|[G,6D6]|\\n[G,6D6]|[G,6=E6]|[G,6F6]|[G,2=E2][G,2_E2][G,2D2]|\\n[B,6D6G6B6d6]|[B,6D6G6B6]|[G,6E6G6]|[G,6D6G6]|\\n[D,6^F,6]|[D,4A,4][D,2F,2]|[D,6^F,6]|[D,4A,4][D,2G,2]|\\n\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\n\\n[B,6D6G6B6d6]|[B,6D6G6B6]|[G,6E6G6]|[G,6D6G6]|\\n[D,6^F,6]|[D,4A,4][D,2F,2]|[D,6^F,6]|[D,4A,4][D,2G,2]|\\n[D,6^F,6]|[D,6^F,6]|[D,6^F,6]|[D,6^F,6]|\\n\\nz6 |z6 |z6 |z6 |\\nz6 |z6 |z6 |z6 |\\n\\nG,6 |F,6 |E,6 |D,6 |\\nG,6 |G,6 |G,6 |G,6 |\\n[^F,6G,6]|[E,6G,6]|[D,6G,6]|[C,6G,6]|[G,6G6]|\\n\\n\\nX:1\\nT:Toccata and Fugue in D min \\nC:Bach\\nZ:celestial\\nI:flute but any wind would do\\nQ:1/4=115\\nM:4/4\\nL:1/8\\nK:F\\n\\nA/2G/2A6 z G/2 F/2 E/2 D/2 ^C3/2 D4 z z2 A,/2G,/2A,6 z E,3/2 F,3/2 ^C,3/2 D,4 z z2 |A,/2G,/2A,6 z G,/2 F,/2 E,/2 D,/2 ^C,3/2 D,4 z z2 D,4 ^C,4 E,4 G,4 B,4 ^C,4 D,4 |E,4 D,4 z3 z/2 ^C,/2 |D,/2 E,/2 ^C,/2 D,/2 E,/2 ^C,/2 D,/2 E,/2 ^C,/2 D,/2 E,/2 F,/2 G,/2 E,/2 F,/2 G,/2 E,/2 F,/2 G,/2 E,/2 F,/2 G,/2 |A,/2 B,/2 G,/2 A,/2 B,/2 G,/2 A,/2 B,/2 G,/2 A,/2 z5 ^C/2 |D/2 E/2 ^C/2 D/2 E/2 ^C/2 D/2 E/2 ^C/2 D/2 E/2 F/2 G/2 E/2 F/2 G/2 E/2 F/2 G/2 E/2 F/2 G/2 |A/2 B/2 G/2 A/2 B/2 G/2 A/2 B/2 G/2 A/2 z5 A/2 |G/2 B/2 E/2 G/2 B/2 E/2 F/2 A/2 D/2 F/2 A/2 D/2 E/2 G/2 C/2 E/2 G/2 C/2 D/2 F/2 B,/2 D/2 F/2 B,/2 |C/2 E/2 A,/2 C/2 E/2 A,/2 B,/2 D/2 G,/2 B,/2 D/2 B,/2 A,/2 C/2 F,/2 A,/2 C/2 F,/2 G,/2 B,/2 E,/2 G,/2 B,/2 E,/2 |F,/2 A,/2 D,/2 F,/2 A,/2 D,/2 E,/2 G,/2 ^C,/2 E,/2 G,/2 ^C,/2 z2 B,4-B,/3 |A,/3 G,/3 F,/3 E,/3 D,/3 ^C,/3 =B,/3 ^C,/2 A,/2 ^C,/2 E,/3 G,/3 F,G,/2F,/2 E,/2 |\\n\\nF,6 z z/2 A,/2 D/2 E/2 F/2 D/2 E/2 F/2 G/2 E/2 |F/2 G/2 A/2 F/2 G/2 A/2 B/2 G/2 A/2 F/2 G/2 E/2 F/2 D/2 E/2 ^C/2 |D/2 A,/2 B,/2 G,/2 A,/2 F,/2 G,/2 E,/2 F,/2 D,/2 G,/2 E,/2 F,/2 D,/2 E,/2 ^C,/2 |C/2 A,/2 B,/2 G,/2 A,/2 F,/2 G,/2 E,/2 F,/2 D,/2 G,/2 E,/2 F,/2 D,/2 E,/2 ^C,/2 |D, D/3 F/3 B/3 F/3 C/3 E/3 A/3 E/3 B,/3 D/3 G/3 D/3 A,/3 ^C/3 E/3 A/3 D/2 B/2 A,/2 A/2 B,/2 G/2 |A D/3 F/3 B/3 F/3 C/3 E/3 A/3 E/3 B,/3 D/3 G/3 D/3 A,/3 ^C/3 E/3 A/3 D/2 B/2 A,/2 A/2 B,/2 G/2 |A2-A/3 G/3 F/3 E/3 D/3 ^C/3 =B,/3 ^C/3 A,/3 =B,/3 ^C/3 D/3 E/3 F/3 G/3 A/3 G/3 F/3 E/3 F/3 D/3 F/3 A/3 ^c/3 |d/3 A/3 =B/3 ^c/3 d/3 e/3 f/4 g/4 a/3 b d/2 b/2 A/2 a/2 B/2 g/2 a/2 d/3 f/3 b/3 f/3 |c/3 e/3 a/3 e/3 B/3 d/3 g/3 d/3 A/3 ^c/3 e/3 a/3 d/2 b/2 A/2 a/2 B/2 g/2 a =B |^c-^c/2 =B/2 A/2 ^c/2 e/3 g/3 b/2 a/3 g/3 f/3 e/3 f/3 e/3 d/3 ^c/3 d/3 ^c/3 B/3 A/3 G/3 F/3 E/3 D/3 |E4 ^C/2 E/2 ^C/2 B,/2 ^C/2 B,/2 ^C/2 E/2 ^C/2 B,/2 ^C/2 B,/2 |\\n\\n^C/2 E/2 ^C/2 B,/2 ^C/2 B,/2 ^C/2 E/2 ^C/2 B,/2 ^C/2 B,/2 G,/2 B,/2 B,/2 E,/2 G,/2 E,/2 G,/2 B,/2 G,/2 E,/2 G,/2 E,/2 |G,/2 B,/2 G,/2 E,/2 G,/2 E,/2 G,/2 B,/2 G,/2 E,/2 G,/2 E,/2 ^C,/2 E,/2 ^C,/2 ^C,/2 E,/2 ^C,/2 ^C,/2 E,/2 ^C,/2 ^C,/2 E,/2 ^C,/2 |^C,/2 E,/2 ^C,/2 ^C,/2 E,/2 ^C,/2 ^C,/2 E,/2 ^C,/2 ^C,/2 E,/2 ^C,/2 ^C,/2 E,/2 ^C,/2 E,/2 G,/2 E,/2 ^C,/2 E,/2 ^C,/2 E,/2 G,/2 E,/2 |^C,/2 E,/2 ^C,/2 E,/2 G,/2 E,/2 ^C,/2 E,/2 ^C,/2 E,/2 G,/2 E,/2 G,/2 B,/2 G,/2 B,/2 G,/2 B,/2 G,/2 B,/2 G,/2 B,/2 G,/2 B,/2 |^C/2 B,/2 ^C/2 E/2 ^C/2 E/2 ^C/2 E/2 ^C/2 E/2 ^C/2 E/2 A2 A2 |B3 A/2 G/2 A-A/2 E/2 F/2 D/2 E/2 ^C/2 |D/2 =B,/2 ^C/2 A,/2 _B,/2 ^G,/2 A,/2 G/2 F D A2 |G F/2 E/2 F2 z/2 A/2 G/2 A/2 F/2 A/2 E/2 A/2 |D/2 A/2 ^C/2 A/2 D/2 A/2 E/2 A/2 F/2 A/2 A,/2 A/2 =B,/2 A/2 ^C/2 A/2 |D,/2 A,/2 ^C,/2 A,/2 D,/2 A,/2 E,/2 A,/2 z/2 D/2 ^C/2 D/2 B,/2 D/2 A,/2 D/2 |G,/2 D/2 ^F,/2 D/2 G,/2 D/2 A,/2 D/2 B,/2 D/2 D,/2 D/2 E,/2 D/2 ^F,/2 D/2 |G,/2 D/2 ^F,/2 D/2 G,/2 D/2 A,/2 D/2 B, D B, D |_E G, _E G, C A, C A, |D F, D F, B, G, B, G, |^C E, ^C E, A, F, A, F, |\\n\\nG, ^C, G, ^C, F, D, F, D, |D, B, D, B, z/2 A/2 G/2 A/2 F/2 A/2 E/2 A/2 |D/2 A/2 ^C/2 A/2 D/2 A/2 E/2 A/2 F/2 A/2 A,/2 A/2 =B,/2 A/2 ^C/2 A/2 |D/2 A/2 ^C/2 A/2 D/2 A/2 E/2 A/2 F/2 A/2 E/2 A/2 D/2 A/2 C/2 A/2 |B,/2 A/2 C/2 A/2 E/2 G/2 B,/2 G/2 E/2 G/2 D/2 G/2 C/2 G/2 B,/2 G/2 |A,/2 G/2 B,/2 G/2 C/2 F/2 A,/2 F/2 D/2 F/2 C/2 F/2 B,/2 F/2 A,/2 F/2 |G,/2 F/2 A,/2 F/2 B,/2 E/2 G,/2 E/2 ^C/2 E/2 B,/2 E/2 A,/2 E/2 G,/2 E/2 |F,/2 E/2 G,/2 E/2 A,/2 D/2 F,/2 D/2 E,/2 E/2 E,/2 E/2 F,/2 D/2 F,/2 D/2 |B,/2 ^C/2 B,/2 ^C/2 A,/2 D/2 F,/2 D/2 E,/2 E/2 E,/2 E/2 F,/2 D/2 F,/2 D/2 |z/2 D/2 ^C/2 D/2 =B,/2 D/2 ^C/2 =B,/2 z/2 A,/2 G,/2 A,/2 E,/2 G,/2 F,/2 E,/2 |F,/2 D/2 ^C/2 D/2 F/2 D/2 ^C/2 =B,/2 ^C/2 A,/2 G,/2 A,/2 E/2 G,/2 F,/2 E,/2 |z/2 d/2 ^c/2 d/2 A/2 A/2 G/2 A/2 ^F/2 d/2 ^c/2 d/2 G/2 f/2 _e/2 d/2 |^c/2 e/2 A/2 ^c/2 D/2 _e/2 d/2 =c/2 c/2 d/2 G/2 B/2 C/2 d/2 c/2 _B/2 |A/2 c/2 ^F/2 A/2 D/2 c/2 B/2 A/2 B,/2 A/2 G/2 ^F/2 G/2 B,/2 A,/2 G,/2 |D,2 D C B, A, B, ^F, |G, ^F, G, A, B, A, B, ^F, |D/2 G/2 F/2 G/2 E/2 F/2 D/2 E/2 C/2 A/2 G/2 A/2 F/2 G/2 E/2 F/2 |D/2 B/2 A/2 B/2 G/2 A/2 F/2 G/2 E/2 c/2 B/2 c/2 A/2 B/2 G/2 A/2 |\\n\\nF/2 _E/2 D/2 C/2 D/2 C/2 B,/2 A,/2 B,/2 D/2 B,/2 A,/2 G,/2 B,/2 G,/2 F,/2 |E,/2 F,/2 G,/2 A,/2 B,/2 D/2 C/2 B,/2 A,2 C B, |A, G, A, B, C E, F, G, |A, G, A, B, C/2 B,/2 A,/2 G,/2 F,/2 _E,/2 D,/2 C,/2 |D/2 C/2 B,/2 A,/2 G,/2 F,/2 E,/2 D,/2 C,/2 |F/2 E/2 D/2 C/2 B,/2 A,/2 G,/2 F,/2 G/2 F/2 E/2 D/2 C/2 B,/2 A,/2 G,/2 |A/2 F/2 E/2 F/2 C/2 F/2 E/2 F/2 A/2 F/2 E/2 F/2 C/2 F/2 E/2 F/2 |G/2 E/2 D/2 E/2 C/2 E/2 D/2 E/2 G/2 E/2 D/2 E/2 C/2 E/2 D/2 E/2 |A/2 F/2 E/2 F/2 C/2 F/2 E/2 F/2 A/2 F/2 E/2 F/2 C/2 F/2 E/2 F/2 |G/2 E/2 D/2 E/2 C/2 E/2 D/2 E/2 G/2 E/2 D/2 E/2 C/2 E/2 D/2 E/2 |F/2 G/2 F/2 E/2 D/2 C/2 =B,/2 A,/2 =B,/2 G,/2 =B,/2 D/2 F/2 A/2 F/2 D/2 |=B,/2 G,/2 =B,/2 D/2 F/2 A/2 F/2 D/2 _B,/2 G,/2 _B,/2 C/2 E/2 G/2 E/2 C/2 |B,/2 G,/2 B,/2 C/2 E/2 G/2 E/2 C/2 A,/2 F,/2 A,/2 C/2 D/2 F/2 D/2 B,/2 |A,/2 F,/2 A,/2 C/2 D/2 F/2 D/2 B,/2 G,/2 E,/2 G,/2 B,/2 ^C/2 E/2 ^C/2 B,/2 |G,/2 E,/2 G,/2 B,/2 ^C/2 E/2 ^C/2 B,/2 z/2 A/2 G/2 A/2 F/2 A/2 E/2 A/2 |D/2 A/2 ^C/2 A/2 D/2 A/2 E/2 A/2 F/2 A/2 A,/2 A/2 =B,/2 A/2 ^C/2 A/2 |D/2 A/2 ^C/2 A/2 D E D =C B, A, |B/2 A/2 G/2 F/2 E/2 D/2 ^C/2 =B,/2 ^C/2 A,/2 ^C/2 E/2 G/2 _B/2 G/2 E/2 |^C/2 A,/2 ^C/2 E/2 G/2 B/2 G/2 E/2 D/2 A,/2 D/2 F/2 A/2 d/2 A/2 F/2 |\\n\\nD/2 A,/2 D/2 F/2 A/2 d/2 A/2 F/2 ^C/2 A,/2 ^C/2 E/2 G/2 B/2 G/2 E/2 |^C/2 A,/2 ^C/2 E/2 G/2 B/2 G/2 E/2 D/2 A,/2 D/2 F/2 A/2 d/2 A/2 F/2 |D/2 A,/2 D/2 F/2 A/2 d/2 A/2 F/2 E/2 ^C/2 E/2 G/2 B/2 ^c/2 B/2 G/2 |E/2 ^C/2 E/2 G/2 B/2 ^c/2 B/2 G/2 F/2 D/2 F/2 A/2 d/2 f/2 d/2 A/2 |F/2 D/2 F/2 A/2 d/2 f/2 d/2 A/2 E/2 ^C/2 E/2 G/2 B/2 ^c/2 B/2 G/2 |E/2 ^C/2 E/2 G/2 B/2 ^c/2 B/2 G/2 F/2 D/2 F/2 A/2 d/2 f/2 d/2 A/2 |F/2 D/2 F/2 A/2 d/2 f/2 d/2 A/2 G/2 E/2 G/2 B/2 ^c/2 e/2 ^c/2 B/2 |G/2 E/2 G/2 B/2 ^c/2 e/2 ^c/2 B/2 A/2 F/2 A/2 ^c/2 d/2 f/2 d/2 A/2 |B/2 d/2 B/2 G/2 F/2 A/2 F/2 D/2 A,/2 D/2 A,/2 F,/2 D,/2 D/2 ^C/2 =B,/2 |^C/2 B/2 A/2 G/2 F/2 G/2 F/2 E/2 D/2 B/2 A/2 G/2 F/2 G/2 F/2 E/2 |D/2 E/3 F/3 G/3 A/3 =B/3 ^c/3 d/2 f/2 e/2 d/2 A,/2 =B,/3 ^C/3 D/3 E/3 F/3 G/3 z/2 E/2 D/2 ^C/2 |D/2 _E/3 D/3 C/3 B,/3 A,/3 G,/3 ^F, A,2 G, C =B, |_E D _E =B, C =B, C D |_E D _E F G,/2 G,/2 F,/2 G,/2 _E,/2 G,/2 D,/2 G,/2 |C/2 G/2 =B,/2 G,/2 C/2 G/2 D/2 G/2 _E/2 G/2 G,/2 G/2 A,/2 G/2 =B,/2 G/2 |C/2 G/2 =B,/2 G/2 C/2 G/2 D/2 G/2 G/2 G/2 F/2 G/2 _E/2 F/2 D/2 _E/2 |C/2 F/2 _E/2 F/2 D/2 _E/2 C/2 D/2 B,/2 _E/2 D/2 _E/2 C/2 D/2 B,/2 C/2 |\\n\\nA,/2 D/2 C/2 D/2 B,/2 C/2 A,/2 B,/2 G,/2 B,/2 A,/2 B,/2 C/2 B,/2 A,/2 G,/2 |^F, A, D/2 G,/2 C/2 ^F,/2 B,/2 G,/2 D/2 A,/2 B,/2 G,/2 A,/2 ^F,/2 |G,/2 D/2 ^F,/2 D/2 G,/2 D/2 A,/2 D/2 B,/2 G,/2 D/2 A,/2 B,/2 G,/2 A/2 A,/2 |D/2 C/2 B,/2 A,/2 B,/2 A,/2 B,/2 G,/2 A,/2 B,/2 C/2 D/2 _E/2 D/2 C/2 D/2 |B,/2 C/2 A,/2 B,/2 G, =B, C/2 _E/2 F/2 G/2 _A/2 G/2 F/2 G/2 |_E/2 F/2 D/2 _E/2 C B, A, B,2 A,2 |G,2 ^F, F, _E,2 D,/2 B,/2 |A,/2 B,/2 A,/2 G,/2 ^F,/2 _E/2 D/2 C/2 B,/2 A/2 G/2 ^F/2 G-G/2 =F/2 |_E/2 F/2 D/2 _E/2 ^C/2 B,/2 A,/2 G,/2 D/2 _E/2 D/2 =C/2 D/2 C/2 B/2 A/2 |G,/2 F,/2 _E,/2 D/2 A, ^C D =E A,/2 G,/2 A,/2 F,/2 |G,/2 A,/2 G,/2 A,/2 B,/2 A,/2 G,/2 A,/2 A,/2 B,/2 G,/2 A,/2 F, A, |G D ^C D E D ^C D |E D ^C D E G F D |B, E D D E,/2 A,/2 G,/2 A,/2 F,/2 A,/2 E,/2 A,/2 |D,/2 A,/2 ^C,/2 A,/2 D,/2 A,/2 E,/2 A,/2 F,/2 A,/2 A,/2 A,/2 =B,/2 A,/2 ^C,/2 A,/2 |D,/2 A,/2 ^C,/2 A,/2 D,/2 A,/2 E,/2 A,/2 A/2 B/2 G/2 A/2 F/2 G/2 E/2 F/2 |D/2 A,/2 ^C/2 A,/2 D/2 A,/2 E/2 A,/2 F/2 A,/2 E/2 A,/2 F/2 A,/2 G/2 A,/2 |A/2 A,/2 E/2 A,/2 F/2 A,/2 G/2 A,/2 z/2 A/2 G/2 A/2 F/2 A/2 E/2 A/2 |\\n\\nD/2 A/2 ^C/2 A/2 D/2 A/2 E/2 A/2 F/2 A/2 A,/2 A/2 =B,/2 A/2 ^C/2 A/2 |D/2 A/2 ^C/2 A/2 D/2 A/2 E/2 A/2 z/2 E/2 D/2 ^C/2 D z/2 F/2 |E/2 F/2 G/2 A/2 B/2 A/2 G/2 A/2 F E D/2 E/2 F/2 _E/2 |D/2 C/2 B,/2 A,/2 G,/2 A,/2 B,/2 C/2 E/2 C/2 A,/2 F,/2 A,/2 C/2 _E/2 C/2 |D/2 B,/2 G,/2 D,/2 G,/2 B,/2 D/2 G/2 C/2 D/2 B,/2 C/2 A,/2 G,/2 ^F,/2 E,/2 |^F,/2 D,/2 ^F,/2 G,/2 A,/2 D/2 A,/2 G,/2 ^F,/2 D/2 ^F,/2 G,/2 A,/2 D/2 A,/2 ^F,/2 |G,/2 D,/2 G,/2 A,/2 B,/2 D/2 B,/2 A,/2 G,/2 D,/2 G,/2 A,/2 B,/2 D/2 C/2 B,/2 |A,/2 F,/2 A,/2 B,/2 C/2 _E/2 C/2 B,/2 A,/2 F,/2 A,/2 B,/2 C/2 _E/2 C/2 B,/2 |A,/2 B,/2 D/2 F/2 G/2 B/2 G/2 D/2 B,/2 G,/2 B,/2 D/2 G/2 B/2 G/2 D/2 |C/2 A,/2 C/2 _E/2 ^F/2 A/2 ^F/2 _E/2 C/2 A,/2 C/2 _E/2 ^F/2 A/2 ^F/2 =E/2 |D, z D C B,2 C D |_E2 F G A2 F _E |D/2 _E/2 D/2 C/2 B,/2 C/2 B,/2 A,/2 G,/2 A,/2 B,/2 A,/2 G,/2 A,/2 G,/2 ^F,/2 |G,/2 F,/2 E,/2 D,/2 ^C, E, F,/2 G,/2 A,/2 =B,/2 ^C/2 D/2 E/2 F/2 |G F/2 E/2 D ^C D E F G |A ^C D E F E F D |E D D ^C D G E C |D8 z/3 f/3 g/3 a/3 b/3 A/3 B/3 c/3 d/3 c/3 d/3 _e/3 f/3 F/3 G/3 A/3 |\\n\\nB/3 A/3 B/3 c/3 d/3 A/3 G/3 F/3 _E/3 G/3 A/3 B/3 c/3 G/3 F/3 _E/3 D/3 F/3 G/3 A/3 B/3 A,/3 B,/3 C/3 D/3 C/3 D/3 _E/3 F/3 F,/3 G,/3 A,/3 |B,/3 A,/3 B,/3 C/3 D/3 C/3 B,/3 A,/3 G,/3 B,/3 C/3 D/3 _E/3 D/3 C/3 B,/3 A,/3 C/3 D/3 =E/3 ^F/3 _E/3 D/3 C/3 B,/3 ^F/3 G/3 A/3 B/3 c/3 d/3 G/3 |e6 d6 |z/2 ^G/2 =B/2 F/2 G/2 D/2 F/2 =B,/2 |D/2 ^G,/2 A, z D A,3 =G,/2 F,/2 |C8 z/3 G,/3 F,/3 G,/3 E,/3 E,/3 D,/3 E,/3 C,/3 A,/3 G,/3 A,/3 F,/3 F,/3 E,/3 F,/3 |D,/3 =B,/3 A,/3 =B,/3 G,/3 G,/3 F,/3 G,/3 E,/3 C/3 =B,/3 C/3 A,/3 D/3 C/3 D/3 =B,/3 E/3 D/3 E/3 C/3 F/3 E/3 F/3 D/3 G/3 F/3 G/3 E/3 C/3 =B/3 C/3 |A,/3 D/3 C/3 D/3 =B,/3 ^G,/3 ^F,/3 ^G,/3 E,/3 C/3 =B,/3 C/3 A,/3 =F,/3 E,/3 F,/3 D,/3 =B,/3 A,/3 =B,/3 C,/3 A,/3 =G,/3 A,/3 =B,/3 ^G,/3 ^F,/3 ^G,/3 E,/3 C/3 =B,/3 A,/3 |^G,/3 D/3 C/3 =B,/3 A,/2 D/3 C/3 =B,/3 =B,/3 F/3 E/3 D/3 C/3 =G/3 F/3 E/3 D/3 A/3 G/3 F/3 E/3 G/3 A/3 =B/3 c G |^c A,/3 ^C/3 E/3 A/3 ^c ^c d A,/3 D/3 F/3 A/3 d d |=B G,/3 =B,/3 D/3 G/3 =B, =B, c G,/3 C/3 E/3 G/3 c c |A F,/3 A,/3 C/3 F/3 A A B F,/3 B,/3 D/3 F/3 B B |B E,/3 G,/3 B,/3 ^C/3 B B A D,/3 A,/3 D/3 ^F/3 A A3 |G2 E2 F2 |E2 C2 D2 B,2 |D12 |\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(os.path.join(data_directory, data_file), mode = 'r')\n",
    "data = file.read()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique characters in our whole tunes database = 79\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embd_1 (Embedding)           (16, 64, 512)             40448     \n",
      "_________________________________________________________________\n",
      "lstm_first (LSTM)            (16, 64, 256)             787456    \n",
      "_________________________________________________________________\n",
      "drp_1 (Dropout)              (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "lstm_21 (LSTM)               (16, 64, 256)             525312    \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "lstm_22 (LSTM)               (16, 64, 256)             525312    \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (16, 64, 256)             0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (16, 64, 79)              20303     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (16, 64, 79)              0         \n",
      "=================================================================\n",
      "Total params: 1,898,831\n",
      "Trainable params: 1,898,831\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Total number of characters = 114842\n",
      "Epoch 1/90\n",
      "Batch: 1, Loss: 4.369387626647949, Accuracy: 0.01171875\n",
      "Batch: 2, Loss: 4.354128360748291, Accuracy: 0.138671875\n",
      "Batch: 3, Loss: 4.3174729347229, Accuracy: 0.1396484375\n",
      "Batch: 4, Loss: 4.192574501037598, Accuracy: 0.1435546875\n",
      "Batch: 5, Loss: 3.8795197010040283, Accuracy: 0.1376953125\n",
      "Batch: 6, Loss: 3.712522506713867, Accuracy: 0.134765625\n",
      "Batch: 7, Loss: 3.585503578186035, Accuracy: 0.12890625\n",
      "Batch: 8, Loss: 3.4550936222076416, Accuracy: 0.12890625\n",
      "Batch: 9, Loss: 3.4023776054382324, Accuracy: 0.130859375\n",
      "Batch: 10, Loss: 3.4135332107543945, Accuracy: 0.115234375\n",
      "Batch: 11, Loss: 3.3757896423339844, Accuracy: 0.103515625\n",
      "Batch: 12, Loss: 3.3531336784362793, Accuracy: 0.1494140625\n",
      "Batch: 13, Loss: 3.2711968421936035, Accuracy: 0.1435546875\n",
      "Batch: 14, Loss: 3.3080406188964844, Accuracy: 0.1376953125\n",
      "Batch: 15, Loss: 3.2854561805725098, Accuracy: 0.1298828125\n",
      "Batch: 16, Loss: 3.2898709774017334, Accuracy: 0.1357421875\n",
      "Batch: 17, Loss: 3.3047308921813965, Accuracy: 0.126953125\n",
      "Batch: 18, Loss: 3.203995943069458, Accuracy: 0.1259765625\n",
      "Batch: 19, Loss: 3.2005209922790527, Accuracy: 0.1220703125\n",
      "Batch: 20, Loss: 3.253262996673584, Accuracy: 0.1103515625\n",
      "Batch: 21, Loss: 3.2188620567321777, Accuracy: 0.1318359375\n",
      "Batch: 22, Loss: 3.192925453186035, Accuracy: 0.1162109375\n",
      "Batch: 23, Loss: 3.2766647338867188, Accuracy: 0.1259765625\n",
      "Batch: 24, Loss: 3.2952747344970703, Accuracy: 0.130859375\n",
      "Batch: 25, Loss: 3.4497666358947754, Accuracy: 0.12109375\n",
      "Batch: 26, Loss: 3.5496106147766113, Accuracy: 0.123046875\n",
      "Batch: 27, Loss: 3.3789327144622803, Accuracy: 0.12890625\n",
      "Batch: 28, Loss: 3.238070487976074, Accuracy: 0.1396484375\n",
      "Batch: 29, Loss: 3.2089972496032715, Accuracy: 0.126953125\n",
      "Batch: 30, Loss: 3.438784122467041, Accuracy: 0.11328125\n",
      "Batch: 31, Loss: 3.2962002754211426, Accuracy: 0.1171875\n",
      "Batch: 32, Loss: 3.223841667175293, Accuracy: 0.1318359375\n",
      "Batch: 33, Loss: 3.2401413917541504, Accuracy: 0.1396484375\n",
      "Batch: 34, Loss: 3.1833791732788086, Accuracy: 0.142578125\n",
      "Batch: 35, Loss: 3.2162623405456543, Accuracy: 0.1298828125\n",
      "Batch: 36, Loss: 3.2575199604034424, Accuracy: 0.140625\n",
      "Batch: 37, Loss: 3.244722843170166, Accuracy: 0.1279296875\n",
      "Batch: 38, Loss: 3.231250286102295, Accuracy: 0.138671875\n",
      "Batch: 39, Loss: 3.2198123931884766, Accuracy: 0.154296875\n",
      "Batch: 40, Loss: 3.234220027923584, Accuracy: 0.140625\n",
      "Batch: 41, Loss: 3.1821212768554688, Accuracy: 0.1328125\n",
      "Batch: 42, Loss: 3.1723854541778564, Accuracy: 0.1552734375\n",
      "Batch: 43, Loss: 3.1748416423797607, Accuracy: 0.154296875\n",
      "Batch: 44, Loss: 3.268545150756836, Accuracy: 0.1328125\n",
      "Batch: 45, Loss: 3.268436908721924, Accuracy: 0.1494140625\n",
      "Batch: 46, Loss: 3.2380571365356445, Accuracy: 0.1318359375\n",
      "Batch: 47, Loss: 3.1842942237854004, Accuracy: 0.169921875\n",
      "Batch: 48, Loss: 3.381999969482422, Accuracy: 0.146484375\n",
      "Batch: 49, Loss: 3.401488780975342, Accuracy: 0.130859375\n",
      "Batch: 50, Loss: 3.231693744659424, Accuracy: 0.1630859375\n",
      "Batch: 51, Loss: 3.3349947929382324, Accuracy: 0.1494140625\n",
      "Batch: 52, Loss: 3.2607104778289795, Accuracy: 0.1474609375\n",
      "Batch: 53, Loss: 3.3179783821105957, Accuracy: 0.134765625\n",
      "Batch: 54, Loss: 3.306643486022949, Accuracy: 0.1240234375\n",
      "Batch: 55, Loss: 3.2105088233947754, Accuracy: 0.1416015625\n",
      "Batch: 56, Loss: 3.243645668029785, Accuracy: 0.1552734375\n",
      "Batch: 57, Loss: 3.4372763633728027, Accuracy: 0.1416015625\n",
      "Batch: 58, Loss: 3.305342674255371, Accuracy: 0.142578125\n",
      "Batch: 59, Loss: 3.252270221710205, Accuracy: 0.1328125\n",
      "Batch: 60, Loss: 3.29089617729187, Accuracy: 0.146484375\n",
      "Batch: 61, Loss: 3.33756685256958, Accuracy: 0.1201171875\n",
      "Batch: 62, Loss: 3.2877955436706543, Accuracy: 0.107421875\n",
      "Batch: 63, Loss: 3.1625890731811523, Accuracy: 0.123046875\n",
      "Batch: 64, Loss: 3.1389000415802, Accuracy: 0.130859375\n",
      "Batch: 65, Loss: 3.178813934326172, Accuracy: 0.1455078125\n",
      "Batch: 66, Loss: 3.144752264022827, Accuracy: 0.1591796875\n",
      "Batch: 67, Loss: 3.1202893257141113, Accuracy: 0.1806640625\n",
      "Batch: 68, Loss: 3.2886924743652344, Accuracy: 0.162109375\n",
      "Batch: 69, Loss: 3.139885902404785, Accuracy: 0.140625\n",
      "Batch: 70, Loss: 3.078352928161621, Accuracy: 0.15234375\n",
      "Batch: 71, Loss: 3.030418872833252, Accuracy: 0.1572265625\n",
      "Batch: 72, Loss: 3.037768840789795, Accuracy: 0.1689453125\n",
      "Batch: 73, Loss: 3.1348488330841064, Accuracy: 0.146484375\n",
      "Batch: 74, Loss: 3.1040687561035156, Accuracy: 0.16796875\n",
      "Batch: 75, Loss: 2.988009214401245, Accuracy: 0.1689453125\n",
      "Batch: 76, Loss: 3.0718541145324707, Accuracy: 0.171875\n",
      "Batch: 77, Loss: 3.09810209274292, Accuracy: 0.1630859375\n",
      "Batch: 78, Loss: 2.9737679958343506, Accuracy: 0.1708984375\n",
      "Batch: 79, Loss: 2.97576904296875, Accuracy: 0.1845703125\n",
      "Batch: 80, Loss: 3.002178907394409, Accuracy: 0.1875\n",
      "Batch: 81, Loss: 2.960205078125, Accuracy: 0.1796875\n",
      "Batch: 82, Loss: 2.9622979164123535, Accuracy: 0.162109375\n",
      "Batch: 83, Loss: 2.9541335105895996, Accuracy: 0.17578125\n",
      "Batch: 84, Loss: 2.9205994606018066, Accuracy: 0.1650390625\n",
      "Batch: 85, Loss: 2.924725294113159, Accuracy: 0.169921875\n",
      "Batch: 86, Loss: 2.894317150115967, Accuracy: 0.17578125\n",
      "Batch: 87, Loss: 2.9049606323242188, Accuracy: 0.169921875\n",
      "Batch: 88, Loss: 3.012613534927368, Accuracy: 0.1640625\n",
      "Batch: 89, Loss: 2.9468135833740234, Accuracy: 0.1630859375\n",
      "Batch: 90, Loss: 2.9804749488830566, Accuracy: 0.1669921875\n",
      "Batch: 91, Loss: 2.9565541744232178, Accuracy: 0.1591796875\n",
      "Batch: 92, Loss: 2.8522863388061523, Accuracy: 0.1787109375\n",
      "Batch: 93, Loss: 2.9504106044769287, Accuracy: 0.171875\n",
      "Batch: 94, Loss: 2.936511993408203, Accuracy: 0.181640625\n",
      "Batch: 95, Loss: 2.8883352279663086, Accuracy: 0.1845703125\n",
      "Batch: 96, Loss: 2.9224722385406494, Accuracy: 0.1767578125\n",
      "Batch: 97, Loss: 2.9189910888671875, Accuracy: 0.17578125\n",
      "Batch: 98, Loss: 2.9617984294891357, Accuracy: 0.171875\n",
      "Batch: 99, Loss: 2.967550277709961, Accuracy: 0.169921875\n",
      "Batch: 100, Loss: 3.0448315143585205, Accuracy: 0.1669921875\n",
      "Batch: 101, Loss: 3.0097217559814453, Accuracy: 0.1640625\n",
      "Batch: 102, Loss: 3.0012807846069336, Accuracy: 0.173828125\n",
      "Batch: 103, Loss: 3.0203070640563965, Accuracy: 0.1708984375\n",
      "Batch: 104, Loss: 2.9748101234436035, Accuracy: 0.1640625\n",
      "Batch: 105, Loss: 2.91530704498291, Accuracy: 0.1650390625\n",
      "Batch: 106, Loss: 2.90643310546875, Accuracy: 0.1650390625\n",
      "Batch: 107, Loss: 2.9593775272369385, Accuracy: 0.1708984375\n",
      "Batch: 108, Loss: 2.901289463043213, Accuracy: 0.181640625\n",
      "Batch: 109, Loss: 3.0142040252685547, Accuracy: 0.1630859375\n",
      "Batch: 110, Loss: 2.9774651527404785, Accuracy: 0.1640625\n",
      "Batch: 111, Loss: 3.089967966079712, Accuracy: 0.1455078125\n",
      "Batch: 112, Loss: 2.968783140182495, Accuracy: 0.1484375\n",
      "Epoch 2/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1, Loss: 3.231658458709717, Accuracy: 0.1396484375\n",
      "Batch: 2, Loss: 3.138866901397705, Accuracy: 0.138671875\n",
      "Batch: 3, Loss: 3.1237752437591553, Accuracy: 0.16015625\n",
      "Batch: 4, Loss: 3.0910093784332275, Accuracy: 0.1552734375\n",
      "Batch: 5, Loss: 3.0367937088012695, Accuracy: 0.17578125\n",
      "Batch: 6, Loss: 3.0433738231658936, Accuracy: 0.1669921875\n",
      "Batch: 7, Loss: 3.0100245475769043, Accuracy: 0.1611328125\n",
      "Batch: 8, Loss: 3.0030529499053955, Accuracy: 0.1826171875\n",
      "Batch: 9, Loss: 2.992349624633789, Accuracy: 0.1689453125\n",
      "Batch: 10, Loss: 3.014517068862915, Accuracy: 0.171875\n",
      "Batch: 11, Loss: 3.0125155448913574, Accuracy: 0.1708984375\n",
      "Batch: 12, Loss: 2.9979372024536133, Accuracy: 0.1884765625\n",
      "Batch: 13, Loss: 2.9453413486480713, Accuracy: 0.1787109375\n",
      "Batch: 14, Loss: 2.9813432693481445, Accuracy: 0.1826171875\n",
      "Batch: 15, Loss: 2.952054500579834, Accuracy: 0.1982421875\n",
      "Batch: 16, Loss: 2.989229679107666, Accuracy: 0.185546875\n",
      "Batch: 17, Loss: 2.9946327209472656, Accuracy: 0.18359375\n",
      "Batch: 18, Loss: 2.93500018119812, Accuracy: 0.2001953125\n",
      "Batch: 19, Loss: 2.910698175430298, Accuracy: 0.201171875\n",
      "Batch: 20, Loss: 2.8984434604644775, Accuracy: 0.2099609375\n",
      "Batch: 21, Loss: 2.8971951007843018, Accuracy: 0.2216796875\n",
      "Batch: 22, Loss: 2.8599276542663574, Accuracy: 0.2353515625\n",
      "Batch: 23, Loss: 2.9600467681884766, Accuracy: 0.2138671875\n",
      "Batch: 24, Loss: 2.9863803386688232, Accuracy: 0.2119140625\n",
      "Batch: 25, Loss: 2.9681410789489746, Accuracy: 0.232421875\n",
      "Batch: 26, Loss: 2.927250385284424, Accuracy: 0.2119140625\n",
      "Batch: 27, Loss: 2.9397497177124023, Accuracy: 0.224609375\n",
      "Batch: 28, Loss: 2.8273181915283203, Accuracy: 0.2236328125\n",
      "Batch: 29, Loss: 2.8716726303100586, Accuracy: 0.20703125\n",
      "Batch: 30, Loss: 2.949829339981079, Accuracy: 0.2373046875\n",
      "Batch: 31, Loss: 2.8959085941314697, Accuracy: 0.23046875\n",
      "Batch: 32, Loss: 2.722005844116211, Accuracy: 0.2607421875\n",
      "Batch: 33, Loss: 2.731522560119629, Accuracy: 0.2744140625\n",
      "Batch: 34, Loss: 2.7358436584472656, Accuracy: 0.275390625\n",
      "Batch: 35, Loss: 2.7632811069488525, Accuracy: 0.275390625\n",
      "Batch: 36, Loss: 2.764071464538574, Accuracy: 0.2734375\n",
      "Batch: 37, Loss: 2.752922534942627, Accuracy: 0.279296875\n",
      "Batch: 38, Loss: 2.6953864097595215, Accuracy: 0.27734375\n",
      "Batch: 39, Loss: 2.6302428245544434, Accuracy: 0.3134765625\n",
      "Batch: 40, Loss: 2.714592933654785, Accuracy: 0.30078125\n",
      "Batch: 41, Loss: 2.5654454231262207, Accuracy: 0.3193359375\n",
      "Batch: 42, Loss: 2.524320602416992, Accuracy: 0.3310546875\n",
      "Batch: 43, Loss: 2.569314956665039, Accuracy: 0.318359375\n",
      "Batch: 44, Loss: 2.5708742141723633, Accuracy: 0.3212890625\n",
      "Batch: 45, Loss: 2.5716776847839355, Accuracy: 0.294921875\n",
      "Batch: 46, Loss: 2.6236400604248047, Accuracy: 0.2890625\n",
      "Batch: 47, Loss: 2.5773019790649414, Accuracy: 0.29296875\n",
      "Batch: 48, Loss: 2.6933345794677734, Accuracy: 0.2822265625\n",
      "Batch: 49, Loss: 2.726609706878662, Accuracy: 0.26171875\n",
      "Batch: 50, Loss: 2.655670166015625, Accuracy: 0.2939453125\n",
      "Batch: 51, Loss: 2.685967445373535, Accuracy: 0.291015625\n",
      "Batch: 52, Loss: 2.6452760696411133, Accuracy: 0.291015625\n",
      "Batch: 53, Loss: 2.776484966278076, Accuracy: 0.265625\n",
      "Batch: 54, Loss: 2.66933274269104, Accuracy: 0.287109375\n",
      "Batch: 55, Loss: 2.5893003940582275, Accuracy: 0.2880859375\n",
      "Batch: 56, Loss: 2.577974319458008, Accuracy: 0.3203125\n",
      "Batch: 57, Loss: 2.678295612335205, Accuracy: 0.259765625\n",
      "Batch: 58, Loss: 2.5405378341674805, Accuracy: 0.294921875\n",
      "Batch: 59, Loss: 2.5964362621307373, Accuracy: 0.2822265625\n",
      "Batch: 60, Loss: 2.5231404304504395, Accuracy: 0.3076171875\n",
      "Batch: 61, Loss: 2.4982361793518066, Accuracy: 0.296875\n",
      "Batch: 62, Loss: 2.4401042461395264, Accuracy: 0.3125\n",
      "Batch: 63, Loss: 2.331040620803833, Accuracy: 0.34375\n",
      "Batch: 64, Loss: 2.4830574989318848, Accuracy: 0.2958984375\n",
      "Batch: 65, Loss: 2.4757351875305176, Accuracy: 0.2890625\n",
      "Batch: 66, Loss: 2.4942855834960938, Accuracy: 0.2978515625\n",
      "Batch: 67, Loss: 2.4480161666870117, Accuracy: 0.326171875\n",
      "Batch: 68, Loss: 2.5382862091064453, Accuracy: 0.2978515625\n",
      "Batch: 69, Loss: 2.4608139991760254, Accuracy: 0.3076171875\n",
      "Batch: 70, Loss: 2.3217110633850098, Accuracy: 0.330078125\n",
      "Batch: 71, Loss: 2.2123045921325684, Accuracy: 0.375\n",
      "Batch: 72, Loss: 2.3625993728637695, Accuracy: 0.328125\n",
      "Batch: 73, Loss: 2.352635383605957, Accuracy: 0.3125\n",
      "Batch: 74, Loss: 2.3201489448547363, Accuracy: 0.33984375\n",
      "Batch: 75, Loss: 2.1401755809783936, Accuracy: 0.3720703125\n",
      "Batch: 76, Loss: 2.231381416320801, Accuracy: 0.3701171875\n",
      "Batch: 77, Loss: 2.2988901138305664, Accuracy: 0.3583984375\n",
      "Batch: 78, Loss: 2.2649765014648438, Accuracy: 0.369140625\n",
      "Batch: 79, Loss: 2.231386184692383, Accuracy: 0.3798828125\n",
      "Batch: 80, Loss: 2.2362422943115234, Accuracy: 0.373046875\n",
      "Batch: 81, Loss: 2.1068882942199707, Accuracy: 0.40625\n",
      "Batch: 82, Loss: 2.072330951690674, Accuracy: 0.3896484375\n",
      "Batch: 83, Loss: 2.1683363914489746, Accuracy: 0.3837890625\n",
      "Batch: 84, Loss: 2.020073413848877, Accuracy: 0.4052734375\n",
      "Batch: 85, Loss: 1.9870519638061523, Accuracy: 0.4404296875\n",
      "Batch: 86, Loss: 2.0251755714416504, Accuracy: 0.4052734375\n",
      "Batch: 87, Loss: 2.0760622024536133, Accuracy: 0.375\n",
      "Batch: 88, Loss: 2.1241936683654785, Accuracy: 0.3837890625\n",
      "Batch: 89, Loss: 1.9962997436523438, Accuracy: 0.4111328125\n",
      "Batch: 90, Loss: 2.0805888175964355, Accuracy: 0.4033203125\n",
      "Batch: 91, Loss: 2.1344857215881348, Accuracy: 0.3916015625\n",
      "Batch: 92, Loss: 1.9288783073425293, Accuracy: 0.421875\n",
      "Batch: 93, Loss: 1.9377174377441406, Accuracy: 0.4306640625\n",
      "Batch: 94, Loss: 1.9709256887435913, Accuracy: 0.41796875\n",
      "Batch: 95, Loss: 1.998196005821228, Accuracy: 0.4150390625\n",
      "Batch: 96, Loss: 2.078321933746338, Accuracy: 0.4150390625\n",
      "Batch: 97, Loss: 2.0382654666900635, Accuracy: 0.4287109375\n",
      "Batch: 98, Loss: 2.0636446475982666, Accuracy: 0.423828125\n",
      "Batch: 99, Loss: 2.088338613510132, Accuracy: 0.40625\n",
      "Batch: 100, Loss: 2.139946937561035, Accuracy: 0.3740234375\n",
      "Batch: 101, Loss: 2.036513328552246, Accuracy: 0.4140625\n",
      "Batch: 102, Loss: 2.030752182006836, Accuracy: 0.412109375\n",
      "Batch: 103, Loss: 2.1066346168518066, Accuracy: 0.4052734375\n",
      "Batch: 104, Loss: 2.019956588745117, Accuracy: 0.4130859375\n",
      "Batch: 105, Loss: 1.9253230094909668, Accuracy: 0.4228515625\n",
      "Batch: 106, Loss: 1.8934024572372437, Accuracy: 0.4169921875\n",
      "Batch: 107, Loss: 1.9926331043243408, Accuracy: 0.369140625\n",
      "Batch: 108, Loss: 1.8771798610687256, Accuracy: 0.42578125\n",
      "Batch: 109, Loss: 2.0176005363464355, Accuracy: 0.4130859375\n",
      "Batch: 110, Loss: 2.017378330230713, Accuracy: 0.419921875\n",
      "Batch: 111, Loss: 2.058799982070923, Accuracy: 0.4072265625\n",
      "Batch: 112, Loss: 2.044076919555664, Accuracy: 0.4140625\n",
      "Epoch 3/90\n",
      "Batch: 1, Loss: 2.3457489013671875, Accuracy: 0.3720703125\n",
      "Batch: 2, Loss: 2.038215160369873, Accuracy: 0.4453125\n",
      "Batch: 3, Loss: 2.09873366355896, Accuracy: 0.404296875\n",
      "Batch: 4, Loss: 2.0826363563537598, Accuracy: 0.4091796875\n",
      "Batch: 5, Loss: 2.071215867996216, Accuracy: 0.4189453125\n",
      "Batch: 6, Loss: 2.0998053550720215, Accuracy: 0.4052734375\n",
      "Batch: 7, Loss: 2.0164272785186768, Accuracy: 0.4267578125\n",
      "Batch: 8, Loss: 2.002552032470703, Accuracy: 0.4287109375\n",
      "Batch: 9, Loss: 2.1369948387145996, Accuracy: 0.40625\n",
      "Batch: 10, Loss: 2.1200757026672363, Accuracy: 0.4013671875\n",
      "Batch: 11, Loss: 2.0040316581726074, Accuracy: 0.435546875\n",
      "Batch: 12, Loss: 2.0171148777008057, Accuracy: 0.4296875\n",
      "Batch: 13, Loss: 1.9218670129776, Accuracy: 0.447265625\n",
      "Batch: 14, Loss: 2.0031988620758057, Accuracy: 0.4248046875\n",
      "Batch: 15, Loss: 1.977366328239441, Accuracy: 0.4189453125\n",
      "Batch: 16, Loss: 1.9747047424316406, Accuracy: 0.4140625\n",
      "Batch: 17, Loss: 1.9576671123504639, Accuracy: 0.423828125\n",
      "Batch: 18, Loss: 1.8639025688171387, Accuracy: 0.4697265625\n",
      "Batch: 19, Loss: 1.9001291990280151, Accuracy: 0.4609375\n",
      "Batch: 20, Loss: 1.9206006526947021, Accuracy: 0.44140625\n",
      "Batch: 21, Loss: 1.896553635597229, Accuracy: 0.474609375\n",
      "Batch: 22, Loss: 1.827345371246338, Accuracy: 0.47265625\n",
      "Batch: 23, Loss: 1.972693920135498, Accuracy: 0.4521484375\n",
      "Batch: 24, Loss: 2.0789124965667725, Accuracy: 0.40625\n",
      "Batch: 25, Loss: 1.997342824935913, Accuracy: 0.421875\n",
      "Batch: 26, Loss: 1.9524435997009277, Accuracy: 0.4404296875\n",
      "Batch: 27, Loss: 1.9747306108474731, Accuracy: 0.4580078125\n",
      "Batch: 28, Loss: 1.8212096691131592, Accuracy: 0.45703125\n",
      "Batch: 29, Loss: 1.9481135606765747, Accuracy: 0.447265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 30, Loss: 1.996878743171692, Accuracy: 0.435546875\n",
      "Batch: 31, Loss: 1.9539663791656494, Accuracy: 0.451171875\n",
      "Batch: 32, Loss: 1.771515965461731, Accuracy: 0.478515625\n",
      "Batch: 33, Loss: 1.8379199504852295, Accuracy: 0.4677734375\n",
      "Batch: 34, Loss: 1.8574097156524658, Accuracy: 0.44921875\n",
      "Batch: 35, Loss: 1.9747141599655151, Accuracy: 0.447265625\n",
      "Batch: 36, Loss: 1.913233995437622, Accuracy: 0.4423828125\n",
      "Batch: 37, Loss: 1.8755102157592773, Accuracy: 0.4697265625\n",
      "Batch: 38, Loss: 1.8878517150878906, Accuracy: 0.4521484375\n",
      "Batch: 39, Loss: 1.8302184343338013, Accuracy: 0.4697265625\n",
      "Batch: 40, Loss: 1.9028561115264893, Accuracy: 0.462890625\n",
      "Batch: 41, Loss: 1.7906272411346436, Accuracy: 0.4755859375\n",
      "Batch: 42, Loss: 1.7743490934371948, Accuracy: 0.498046875\n",
      "Batch: 43, Loss: 1.8654711246490479, Accuracy: 0.44921875\n",
      "Batch: 44, Loss: 1.8998234272003174, Accuracy: 0.4453125\n",
      "Batch: 45, Loss: 1.9526304006576538, Accuracy: 0.43359375\n",
      "Batch: 46, Loss: 1.95521879196167, Accuracy: 0.4404296875\n",
      "Batch: 47, Loss: 1.9315263032913208, Accuracy: 0.419921875\n",
      "Batch: 48, Loss: 2.1011972427368164, Accuracy: 0.40625\n",
      "Batch: 49, Loss: 2.1127889156341553, Accuracy: 0.4091796875\n",
      "Batch: 50, Loss: 1.9638670682907104, Accuracy: 0.4501953125\n",
      "Batch: 51, Loss: 2.0507450103759766, Accuracy: 0.43359375\n",
      "Batch: 52, Loss: 2.006762742996216, Accuracy: 0.43359375\n",
      "Batch: 53, Loss: 2.2293965816497803, Accuracy: 0.388671875\n",
      "Batch: 54, Loss: 2.0735116004943848, Accuracy: 0.4130859375\n",
      "Batch: 55, Loss: 2.0030899047851562, Accuracy: 0.4384765625\n",
      "Batch: 56, Loss: 1.9456064701080322, Accuracy: 0.451171875\n",
      "Batch: 57, Loss: 2.0580191612243652, Accuracy: 0.4130859375\n",
      "Batch: 58, Loss: 1.9851511716842651, Accuracy: 0.4150390625\n",
      "Batch: 59, Loss: 1.9812307357788086, Accuracy: 0.4375\n",
      "Batch: 60, Loss: 1.9521247148513794, Accuracy: 0.439453125\n",
      "Batch: 61, Loss: 1.9310760498046875, Accuracy: 0.4375\n",
      "Batch: 62, Loss: 1.873570203781128, Accuracy: 0.4443359375\n",
      "Batch: 63, Loss: 1.724402904510498, Accuracy: 0.4814453125\n",
      "Batch: 64, Loss: 1.86720871925354, Accuracy: 0.4345703125\n",
      "Batch: 65, Loss: 1.9027001857757568, Accuracy: 0.3984375\n",
      "Batch: 66, Loss: 1.832822561264038, Accuracy: 0.4169921875\n",
      "Batch: 67, Loss: 1.9075688123703003, Accuracy: 0.4482421875\n",
      "Batch: 68, Loss: 2.0393786430358887, Accuracy: 0.4287109375\n",
      "Batch: 69, Loss: 1.8727028369903564, Accuracy: 0.443359375\n",
      "Batch: 70, Loss: 1.7536700963974, Accuracy: 0.470703125\n",
      "Batch: 71, Loss: 1.690967082977295, Accuracy: 0.486328125\n",
      "Batch: 72, Loss: 1.7723557949066162, Accuracy: 0.4638671875\n",
      "Batch: 73, Loss: 1.807190179824829, Accuracy: 0.4453125\n",
      "Batch: 74, Loss: 1.7576627731323242, Accuracy: 0.4609375\n",
      "Batch: 75, Loss: 1.5712871551513672, Accuracy: 0.4970703125\n",
      "Batch: 76, Loss: 1.6901665925979614, Accuracy: 0.478515625\n",
      "Batch: 77, Loss: 1.807289719581604, Accuracy: 0.4697265625\n",
      "Batch: 78, Loss: 1.7201249599456787, Accuracy: 0.4658203125\n",
      "Batch: 79, Loss: 1.6456332206726074, Accuracy: 0.4931640625\n",
      "Batch: 80, Loss: 1.7239151000976562, Accuracy: 0.5126953125\n",
      "Batch: 81, Loss: 1.6122078895568848, Accuracy: 0.5048828125\n",
      "Batch: 82, Loss: 1.5487332344055176, Accuracy: 0.5224609375\n",
      "Batch: 83, Loss: 1.6254065036773682, Accuracy: 0.509765625\n",
      "Batch: 84, Loss: 1.529232144355774, Accuracy: 0.533203125\n",
      "Batch: 85, Loss: 1.5064287185668945, Accuracy: 0.5517578125\n",
      "Batch: 86, Loss: 1.4928410053253174, Accuracy: 0.5390625\n",
      "Batch: 87, Loss: 1.5066518783569336, Accuracy: 0.529296875\n",
      "Batch: 88, Loss: 1.604154109954834, Accuracy: 0.4990234375\n",
      "Batch: 89, Loss: 1.5077433586120605, Accuracy: 0.53515625\n",
      "Batch: 90, Loss: 1.537077784538269, Accuracy: 0.521484375\n",
      "Batch: 91, Loss: 1.583101511001587, Accuracy: 0.5078125\n",
      "Batch: 92, Loss: 1.394779086112976, Accuracy: 0.57421875\n",
      "Batch: 93, Loss: 1.3546841144561768, Accuracy: 0.5771484375\n",
      "Batch: 94, Loss: 1.4293454885482788, Accuracy: 0.5556640625\n",
      "Batch: 95, Loss: 1.45845365524292, Accuracy: 0.5419921875\n",
      "Batch: 96, Loss: 1.5037438869476318, Accuracy: 0.53125\n",
      "Batch: 97, Loss: 1.4604411125183105, Accuracy: 0.537109375\n",
      "Batch: 98, Loss: 1.5594723224639893, Accuracy: 0.5078125\n",
      "Batch: 99, Loss: 1.5217251777648926, Accuracy: 0.5166015625\n",
      "Batch: 100, Loss: 1.6226578950881958, Accuracy: 0.4990234375\n",
      "Batch: 101, Loss: 1.5267066955566406, Accuracy: 0.5302734375\n",
      "Batch: 102, Loss: 1.5358564853668213, Accuracy: 0.5361328125\n",
      "Batch: 103, Loss: 1.6502037048339844, Accuracy: 0.5029296875\n",
      "Batch: 104, Loss: 1.579024314880371, Accuracy: 0.5234375\n",
      "Batch: 105, Loss: 1.4589636325836182, Accuracy: 0.529296875\n",
      "Batch: 106, Loss: 1.477001428604126, Accuracy: 0.54296875\n",
      "Batch: 107, Loss: 1.536024570465088, Accuracy: 0.5107421875\n",
      "Batch: 108, Loss: 1.4128081798553467, Accuracy: 0.55859375\n",
      "Batch: 109, Loss: 1.5901296138763428, Accuracy: 0.53515625\n",
      "Batch: 110, Loss: 1.5436079502105713, Accuracy: 0.5439453125\n",
      "Batch: 111, Loss: 1.5923594236373901, Accuracy: 0.5302734375\n",
      "Batch: 112, Loss: 1.513892650604248, Accuracy: 0.5244140625\n",
      "Epoch 4/90\n",
      "Batch: 1, Loss: 1.9885141849517822, Accuracy: 0.458984375\n",
      "Batch: 2, Loss: 1.6817810535430908, Accuracy: 0.5185546875\n",
      "Batch: 3, Loss: 1.6887037754058838, Accuracy: 0.49609375\n",
      "Batch: 4, Loss: 1.6354953050613403, Accuracy: 0.5185546875\n",
      "Batch: 5, Loss: 1.6619596481323242, Accuracy: 0.5126953125\n",
      "Batch: 6, Loss: 1.7022426128387451, Accuracy: 0.4931640625\n",
      "Batch: 7, Loss: 1.60329008102417, Accuracy: 0.5283203125\n",
      "Batch: 8, Loss: 1.640973448753357, Accuracy: 0.5283203125\n",
      "Batch: 9, Loss: 1.7696841955184937, Accuracy: 0.4931640625\n",
      "Batch: 10, Loss: 1.7118971347808838, Accuracy: 0.50390625\n",
      "Batch: 11, Loss: 1.6345924139022827, Accuracy: 0.5322265625\n",
      "Batch: 12, Loss: 1.678562879562378, Accuracy: 0.5146484375\n",
      "Batch: 13, Loss: 1.5998914241790771, Accuracy: 0.5419921875\n",
      "Batch: 14, Loss: 1.6645078659057617, Accuracy: 0.5234375\n",
      "Batch: 15, Loss: 1.6022377014160156, Accuracy: 0.544921875\n",
      "Batch: 16, Loss: 1.596773624420166, Accuracy: 0.5380859375\n",
      "Batch: 17, Loss: 1.5926859378814697, Accuracy: 0.5439453125\n",
      "Batch: 18, Loss: 1.4636772871017456, Accuracy: 0.556640625\n",
      "Batch: 19, Loss: 1.4882721900939941, Accuracy: 0.5537109375\n",
      "Batch: 20, Loss: 1.5143415927886963, Accuracy: 0.5693359375\n",
      "Batch: 21, Loss: 1.4778952598571777, Accuracy: 0.5703125\n",
      "Batch: 22, Loss: 1.4625260829925537, Accuracy: 0.568359375\n",
      "Batch: 23, Loss: 1.6230823993682861, Accuracy: 0.5439453125\n",
      "Batch: 24, Loss: 1.695478916168213, Accuracy: 0.5087890625\n",
      "Batch: 25, Loss: 1.66367506980896, Accuracy: 0.52734375\n",
      "Batch: 26, Loss: 1.6490939855575562, Accuracy: 0.5126953125\n",
      "Batch: 27, Loss: 1.630312204360962, Accuracy: 0.5341796875\n",
      "Batch: 28, Loss: 1.3678017854690552, Accuracy: 0.5830078125\n",
      "Batch: 29, Loss: 1.5866103172302246, Accuracy: 0.548828125\n",
      "Batch: 30, Loss: 1.6101257801055908, Accuracy: 0.55078125\n",
      "Batch: 31, Loss: 1.539494514465332, Accuracy: 0.5546875\n",
      "Batch: 32, Loss: 1.4256563186645508, Accuracy: 0.5830078125\n",
      "Batch: 33, Loss: 1.4635175466537476, Accuracy: 0.560546875\n",
      "Batch: 34, Loss: 1.4327526092529297, Accuracy: 0.552734375\n",
      "Batch: 35, Loss: 1.613791823387146, Accuracy: 0.5244140625\n",
      "Batch: 36, Loss: 1.4762550592422485, Accuracy: 0.5537109375\n",
      "Batch: 37, Loss: 1.4250128269195557, Accuracy: 0.5810546875\n",
      "Batch: 38, Loss: 1.483581304550171, Accuracy: 0.5595703125\n",
      "Batch: 39, Loss: 1.4694921970367432, Accuracy: 0.56640625\n",
      "Batch: 40, Loss: 1.5935288667678833, Accuracy: 0.5478515625\n",
      "Batch: 41, Loss: 1.4932677745819092, Accuracy: 0.5595703125\n",
      "Batch: 42, Loss: 1.4514834880828857, Accuracy: 0.5810546875\n",
      "Batch: 43, Loss: 1.4946484565734863, Accuracy: 0.5400390625\n",
      "Batch: 44, Loss: 1.5754930973052979, Accuracy: 0.533203125\n",
      "Batch: 45, Loss: 1.6611950397491455, Accuracy: 0.4912109375\n",
      "Batch: 46, Loss: 1.5918501615524292, Accuracy: 0.5185546875\n",
      "Batch: 47, Loss: 1.5690897703170776, Accuracy: 0.5078125\n",
      "Batch: 48, Loss: 1.7505922317504883, Accuracy: 0.490234375\n",
      "Batch: 49, Loss: 1.8030521869659424, Accuracy: 0.48828125\n",
      "Batch: 50, Loss: 1.583338975906372, Accuracy: 0.5498046875\n",
      "Batch: 51, Loss: 1.6542521715164185, Accuracy: 0.5302734375\n",
      "Batch: 52, Loss: 1.5967484712600708, Accuracy: 0.5361328125\n",
      "Batch: 53, Loss: 1.8951979875564575, Accuracy: 0.470703125\n",
      "Batch: 54, Loss: 1.7387852668762207, Accuracy: 0.4873046875\n",
      "Batch: 55, Loss: 1.6814801692962646, Accuracy: 0.49609375\n",
      "Batch: 56, Loss: 1.5768624544143677, Accuracy: 0.52734375\n",
      "Batch: 57, Loss: 1.7548470497131348, Accuracy: 0.4765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 58, Loss: 1.6565771102905273, Accuracy: 0.4912109375\n",
      "Batch: 59, Loss: 1.6065266132354736, Accuracy: 0.5029296875\n",
      "Batch: 60, Loss: 1.6649943590164185, Accuracy: 0.494140625\n",
      "Batch: 61, Loss: 1.660707950592041, Accuracy: 0.494140625\n",
      "Batch: 62, Loss: 1.540785312652588, Accuracy: 0.5263671875\n",
      "Batch: 63, Loss: 1.368179202079773, Accuracy: 0.576171875\n",
      "Batch: 64, Loss: 1.5636473894119263, Accuracy: 0.513671875\n",
      "Batch: 65, Loss: 1.484649658203125, Accuracy: 0.5478515625\n",
      "Batch: 66, Loss: 1.4721002578735352, Accuracy: 0.548828125\n",
      "Batch: 67, Loss: 1.656160593032837, Accuracy: 0.5126953125\n",
      "Batch: 68, Loss: 1.7916224002838135, Accuracy: 0.48046875\n",
      "Batch: 69, Loss: 1.6078803539276123, Accuracy: 0.5185546875\n",
      "Batch: 70, Loss: 1.5186634063720703, Accuracy: 0.5546875\n",
      "Batch: 71, Loss: 1.3773475885391235, Accuracy: 0.57421875\n",
      "Batch: 72, Loss: 1.4751631021499634, Accuracy: 0.5361328125\n",
      "Batch: 73, Loss: 1.5691773891448975, Accuracy: 0.4931640625\n",
      "Batch: 74, Loss: 1.451046109199524, Accuracy: 0.525390625\n",
      "Batch: 75, Loss: 1.3180763721466064, Accuracy: 0.5712890625\n",
      "Batch: 76, Loss: 1.4303653240203857, Accuracy: 0.580078125\n",
      "Batch: 77, Loss: 1.5589817762374878, Accuracy: 0.546875\n",
      "Batch: 78, Loss: 1.464347004890442, Accuracy: 0.5341796875\n",
      "Batch: 79, Loss: 1.4428257942199707, Accuracy: 0.5341796875\n",
      "Batch: 80, Loss: 1.4777185916900635, Accuracy: 0.552734375\n",
      "Batch: 81, Loss: 1.3759682178497314, Accuracy: 0.54296875\n",
      "Batch: 82, Loss: 1.314974308013916, Accuracy: 0.587890625\n",
      "Batch: 83, Loss: 1.409468412399292, Accuracy: 0.5625\n",
      "Batch: 84, Loss: 1.3046081066131592, Accuracy: 0.5703125\n",
      "Batch: 85, Loss: 1.2856208086013794, Accuracy: 0.5927734375\n",
      "Batch: 86, Loss: 1.2698215246200562, Accuracy: 0.591796875\n",
      "Batch: 87, Loss: 1.2779581546783447, Accuracy: 0.59375\n",
      "Batch: 88, Loss: 1.3770906925201416, Accuracy: 0.548828125\n",
      "Batch: 89, Loss: 1.3488872051239014, Accuracy: 0.580078125\n",
      "Batch: 90, Loss: 1.3404197692871094, Accuracy: 0.578125\n",
      "Batch: 91, Loss: 1.382704496383667, Accuracy: 0.5625\n",
      "Batch: 92, Loss: 1.1910306215286255, Accuracy: 0.6220703125\n",
      "Batch: 93, Loss: 1.1280238628387451, Accuracy: 0.63671875\n",
      "Batch: 94, Loss: 1.2343887090682983, Accuracy: 0.611328125\n",
      "Batch: 95, Loss: 1.2741420269012451, Accuracy: 0.6005859375\n",
      "Batch: 96, Loss: 1.308242678642273, Accuracy: 0.5712890625\n",
      "Batch: 97, Loss: 1.2572699785232544, Accuracy: 0.5888671875\n",
      "Batch: 98, Loss: 1.3597756624221802, Accuracy: 0.576171875\n",
      "Batch: 99, Loss: 1.3033130168914795, Accuracy: 0.5966796875\n",
      "Batch: 100, Loss: 1.3979110717773438, Accuracy: 0.5712890625\n",
      "Batch: 101, Loss: 1.3186501264572144, Accuracy: 0.5986328125\n",
      "Batch: 102, Loss: 1.3394526243209839, Accuracy: 0.5791015625\n",
      "Batch: 103, Loss: 1.4530978202819824, Accuracy: 0.568359375\n",
      "Batch: 104, Loss: 1.389045000076294, Accuracy: 0.568359375\n",
      "Batch: 105, Loss: 1.2684634923934937, Accuracy: 0.5849609375\n",
      "Batch: 106, Loss: 1.2762389183044434, Accuracy: 0.5947265625\n",
      "Batch: 107, Loss: 1.3252711296081543, Accuracy: 0.5791015625\n",
      "Batch: 108, Loss: 1.2601803541183472, Accuracy: 0.607421875\n",
      "Batch: 109, Loss: 1.4059089422225952, Accuracy: 0.5859375\n",
      "Batch: 110, Loss: 1.330517053604126, Accuracy: 0.5986328125\n",
      "Batch: 111, Loss: 1.41750168800354, Accuracy: 0.564453125\n",
      "Batch: 112, Loss: 1.3111388683319092, Accuracy: 0.5595703125\n",
      "Epoch 5/90\n",
      "Batch: 1, Loss: 1.809152364730835, Accuracy: 0.498046875\n",
      "Batch: 2, Loss: 1.4710773229599, Accuracy: 0.5849609375\n",
      "Batch: 3, Loss: 1.4470572471618652, Accuracy: 0.56640625\n",
      "Batch: 4, Loss: 1.4462249279022217, Accuracy: 0.5859375\n",
      "Batch: 5, Loss: 1.4800772666931152, Accuracy: 0.5673828125\n",
      "Batch: 6, Loss: 1.522700309753418, Accuracy: 0.546875\n",
      "Batch: 7, Loss: 1.403440237045288, Accuracy: 0.5810546875\n",
      "Batch: 8, Loss: 1.4265363216400146, Accuracy: 0.580078125\n",
      "Batch: 9, Loss: 1.4994699954986572, Accuracy: 0.5478515625\n",
      "Batch: 10, Loss: 1.4662703275680542, Accuracy: 0.568359375\n",
      "Batch: 11, Loss: 1.355907678604126, Accuracy: 0.5927734375\n",
      "Batch: 12, Loss: 1.4008731842041016, Accuracy: 0.578125\n",
      "Batch: 13, Loss: 1.339580774307251, Accuracy: 0.603515625\n",
      "Batch: 14, Loss: 1.456589937210083, Accuracy: 0.5791015625\n",
      "Batch: 15, Loss: 1.3797935247421265, Accuracy: 0.6005859375\n",
      "Batch: 16, Loss: 1.4118537902832031, Accuracy: 0.5849609375\n",
      "Batch: 17, Loss: 1.3791526556015015, Accuracy: 0.607421875\n",
      "Batch: 18, Loss: 1.2935082912445068, Accuracy: 0.5986328125\n",
      "Batch: 19, Loss: 1.3333830833435059, Accuracy: 0.59765625\n",
      "Batch: 20, Loss: 1.327175259590149, Accuracy: 0.5927734375\n",
      "Batch: 21, Loss: 1.3309409618377686, Accuracy: 0.5947265625\n",
      "Batch: 22, Loss: 1.325580358505249, Accuracy: 0.5966796875\n",
      "Batch: 23, Loss: 1.4416325092315674, Accuracy: 0.5830078125\n",
      "Batch: 24, Loss: 1.4983538389205933, Accuracy: 0.568359375\n",
      "Batch: 25, Loss: 1.5195157527923584, Accuracy: 0.546875\n",
      "Batch: 26, Loss: 1.5428667068481445, Accuracy: 0.546875\n",
      "Batch: 27, Loss: 1.4637031555175781, Accuracy: 0.5703125\n",
      "Batch: 28, Loss: 1.1745996475219727, Accuracy: 0.626953125\n",
      "Batch: 29, Loss: 1.4119951725006104, Accuracy: 0.5703125\n",
      "Batch: 30, Loss: 1.4723730087280273, Accuracy: 0.564453125\n",
      "Batch: 31, Loss: 1.3722788095474243, Accuracy: 0.5849609375\n",
      "Batch: 32, Loss: 1.2967365980148315, Accuracy: 0.6064453125\n",
      "Batch: 33, Loss: 1.3248825073242188, Accuracy: 0.576171875\n",
      "Batch: 34, Loss: 1.311554193496704, Accuracy: 0.5703125\n",
      "Batch: 35, Loss: 1.4035176038742065, Accuracy: 0.5693359375\n",
      "Batch: 36, Loss: 1.305354356765747, Accuracy: 0.5986328125\n",
      "Batch: 37, Loss: 1.235275387763977, Accuracy: 0.6220703125\n",
      "Batch: 38, Loss: 1.3006707429885864, Accuracy: 0.5869140625\n",
      "Batch: 39, Loss: 1.3331332206726074, Accuracy: 0.5947265625\n",
      "Batch: 40, Loss: 1.4037981033325195, Accuracy: 0.564453125\n",
      "Batch: 41, Loss: 1.3791344165802002, Accuracy: 0.5908203125\n",
      "Batch: 42, Loss: 1.2907640933990479, Accuracy: 0.603515625\n",
      "Batch: 43, Loss: 1.360593557357788, Accuracy: 0.572265625\n",
      "Batch: 44, Loss: 1.4214751720428467, Accuracy: 0.55859375\n",
      "Batch: 45, Loss: 1.5421380996704102, Accuracy: 0.5419921875\n",
      "Batch: 46, Loss: 1.417446255683899, Accuracy: 0.564453125\n",
      "Batch: 47, Loss: 1.393459677696228, Accuracy: 0.546875\n",
      "Batch: 48, Loss: 1.5934193134307861, Accuracy: 0.5322265625\n",
      "Batch: 49, Loss: 1.637353539466858, Accuracy: 0.53515625\n",
      "Batch: 50, Loss: 1.4008729457855225, Accuracy: 0.5810546875\n",
      "Batch: 51, Loss: 1.4387469291687012, Accuracy: 0.5751953125\n",
      "Batch: 52, Loss: 1.3823736906051636, Accuracy: 0.5751953125\n",
      "Batch: 53, Loss: 1.638108491897583, Accuracy: 0.515625\n",
      "Batch: 54, Loss: 1.5514631271362305, Accuracy: 0.5234375\n",
      "Batch: 55, Loss: 1.5049971342086792, Accuracy: 0.5576171875\n",
      "Batch: 56, Loss: 1.4293038845062256, Accuracy: 0.5537109375\n",
      "Batch: 57, Loss: 1.6319911479949951, Accuracy: 0.505859375\n",
      "Batch: 58, Loss: 1.5398800373077393, Accuracy: 0.5498046875\n",
      "Batch: 59, Loss: 1.453866958618164, Accuracy: 0.5615234375\n",
      "Batch: 60, Loss: 1.581097960472107, Accuracy: 0.5390625\n",
      "Batch: 61, Loss: 1.5278552770614624, Accuracy: 0.546875\n",
      "Batch: 62, Loss: 1.4113184213638306, Accuracy: 0.5625\n",
      "Batch: 63, Loss: 1.2381591796875, Accuracy: 0.6220703125\n",
      "Batch: 64, Loss: 1.3932130336761475, Accuracy: 0.5869140625\n",
      "Batch: 65, Loss: 1.3104057312011719, Accuracy: 0.587890625\n",
      "Batch: 66, Loss: 1.3429160118103027, Accuracy: 0.5791015625\n",
      "Batch: 67, Loss: 1.4964025020599365, Accuracy: 0.5458984375\n",
      "Batch: 68, Loss: 1.621276617050171, Accuracy: 0.533203125\n",
      "Batch: 69, Loss: 1.4333195686340332, Accuracy: 0.5634765625\n",
      "Batch: 70, Loss: 1.33406662940979, Accuracy: 0.580078125\n",
      "Batch: 71, Loss: 1.2404499053955078, Accuracy: 0.59375\n",
      "Batch: 72, Loss: 1.32230544090271, Accuracy: 0.583984375\n",
      "Batch: 73, Loss: 1.424272060394287, Accuracy: 0.5517578125\n",
      "Batch: 74, Loss: 1.2951585054397583, Accuracy: 0.568359375\n",
      "Batch: 75, Loss: 1.1237674951553345, Accuracy: 0.634765625\n",
      "Batch: 76, Loss: 1.2921903133392334, Accuracy: 0.595703125\n",
      "Batch: 77, Loss: 1.4336909055709839, Accuracy: 0.5693359375\n",
      "Batch: 78, Loss: 1.3053309917449951, Accuracy: 0.5849609375\n",
      "Batch: 79, Loss: 1.3427150249481201, Accuracy: 0.578125\n",
      "Batch: 80, Loss: 1.3447757959365845, Accuracy: 0.583984375\n",
      "Batch: 81, Loss: 1.26912522315979, Accuracy: 0.5947265625\n",
      "Batch: 82, Loss: 1.1874756813049316, Accuracy: 0.6328125\n",
      "Batch: 83, Loss: 1.2485811710357666, Accuracy: 0.6064453125\n",
      "Batch: 84, Loss: 1.1841747760772705, Accuracy: 0.607421875\n",
      "Batch: 85, Loss: 1.1625850200653076, Accuracy: 0.6259765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 86, Loss: 1.1526849269866943, Accuracy: 0.6337890625\n",
      "Batch: 87, Loss: 1.161466360092163, Accuracy: 0.6328125\n",
      "Batch: 88, Loss: 1.2679462432861328, Accuracy: 0.6064453125\n",
      "Batch: 89, Loss: 1.2231674194335938, Accuracy: 0.6181640625\n",
      "Batch: 90, Loss: 1.228661060333252, Accuracy: 0.615234375\n",
      "Batch: 91, Loss: 1.29221510887146, Accuracy: 0.587890625\n",
      "Batch: 92, Loss: 1.0974726676940918, Accuracy: 0.6591796875\n",
      "Batch: 93, Loss: 1.0194964408874512, Accuracy: 0.6650390625\n",
      "Batch: 94, Loss: 1.1529686450958252, Accuracy: 0.640625\n",
      "Batch: 95, Loss: 1.1650117635726929, Accuracy: 0.6220703125\n",
      "Batch: 96, Loss: 1.202941656112671, Accuracy: 0.6025390625\n",
      "Batch: 97, Loss: 1.1920256614685059, Accuracy: 0.6201171875\n",
      "Batch: 98, Loss: 1.251636028289795, Accuracy: 0.591796875\n",
      "Batch: 99, Loss: 1.198056936264038, Accuracy: 0.611328125\n",
      "Batch: 100, Loss: 1.2957346439361572, Accuracy: 0.599609375\n",
      "Batch: 101, Loss: 1.2159703969955444, Accuracy: 0.6142578125\n",
      "Batch: 102, Loss: 1.2173455953598022, Accuracy: 0.6376953125\n",
      "Batch: 103, Loss: 1.3142739534378052, Accuracy: 0.6025390625\n",
      "Batch: 104, Loss: 1.2553000450134277, Accuracy: 0.619140625\n",
      "Batch: 105, Loss: 1.1231296062469482, Accuracy: 0.6435546875\n",
      "Batch: 106, Loss: 1.1485060453414917, Accuracy: 0.6416015625\n",
      "Batch: 107, Loss: 1.2426531314849854, Accuracy: 0.6181640625\n",
      "Batch: 108, Loss: 1.1808416843414307, Accuracy: 0.623046875\n",
      "Batch: 109, Loss: 1.2949528694152832, Accuracy: 0.6162109375\n",
      "Batch: 110, Loss: 1.2171164751052856, Accuracy: 0.6328125\n",
      "Batch: 111, Loss: 1.2967827320098877, Accuracy: 0.603515625\n",
      "Batch: 112, Loss: 1.1937416791915894, Accuracy: 0.6171875\n",
      "Epoch 6/90\n",
      "Batch: 1, Loss: 1.7356770038604736, Accuracy: 0.5078125\n",
      "Batch: 2, Loss: 1.3711947202682495, Accuracy: 0.5927734375\n",
      "Batch: 3, Loss: 1.3316514492034912, Accuracy: 0.599609375\n",
      "Batch: 4, Loss: 1.3200799226760864, Accuracy: 0.6044921875\n",
      "Batch: 5, Loss: 1.3731887340545654, Accuracy: 0.5849609375\n",
      "Batch: 6, Loss: 1.3766777515411377, Accuracy: 0.5927734375\n",
      "Batch: 7, Loss: 1.2976857423782349, Accuracy: 0.6103515625\n",
      "Batch: 8, Loss: 1.273451328277588, Accuracy: 0.6142578125\n",
      "Batch: 9, Loss: 1.3557157516479492, Accuracy: 0.580078125\n",
      "Batch: 10, Loss: 1.3339943885803223, Accuracy: 0.5947265625\n",
      "Batch: 11, Loss: 1.2334940433502197, Accuracy: 0.62109375\n",
      "Batch: 12, Loss: 1.260952115058899, Accuracy: 0.6298828125\n",
      "Batch: 13, Loss: 1.2381398677825928, Accuracy: 0.638671875\n",
      "Batch: 14, Loss: 1.351027011871338, Accuracy: 0.5908203125\n",
      "Batch: 15, Loss: 1.2745368480682373, Accuracy: 0.626953125\n",
      "Batch: 16, Loss: 1.3323506116867065, Accuracy: 0.6083984375\n",
      "Batch: 17, Loss: 1.271863341331482, Accuracy: 0.6240234375\n",
      "Batch: 18, Loss: 1.1944494247436523, Accuracy: 0.630859375\n",
      "Batch: 19, Loss: 1.2626529932022095, Accuracy: 0.603515625\n",
      "Batch: 20, Loss: 1.2558263540267944, Accuracy: 0.6123046875\n",
      "Batch: 21, Loss: 1.2241802215576172, Accuracy: 0.6240234375\n",
      "Batch: 22, Loss: 1.2032020092010498, Accuracy: 0.630859375\n",
      "Batch: 23, Loss: 1.3341400623321533, Accuracy: 0.6171875\n",
      "Batch: 24, Loss: 1.3694430589675903, Accuracy: 0.58203125\n",
      "Batch: 25, Loss: 1.4015610218048096, Accuracy: 0.580078125\n",
      "Batch: 26, Loss: 1.4264440536499023, Accuracy: 0.5751953125\n",
      "Batch: 27, Loss: 1.3649494647979736, Accuracy: 0.591796875\n",
      "Batch: 28, Loss: 1.1198234558105469, Accuracy: 0.64453125\n",
      "Batch: 29, Loss: 1.282011866569519, Accuracy: 0.6064453125\n",
      "Batch: 30, Loss: 1.3382389545440674, Accuracy: 0.58984375\n",
      "Batch: 31, Loss: 1.2496354579925537, Accuracy: 0.62109375\n",
      "Batch: 32, Loss: 1.2382538318634033, Accuracy: 0.60546875\n",
      "Batch: 33, Loss: 1.2246339321136475, Accuracy: 0.5966796875\n",
      "Batch: 34, Loss: 1.2007213830947876, Accuracy: 0.60546875\n",
      "Batch: 35, Loss: 1.2805299758911133, Accuracy: 0.599609375\n",
      "Batch: 36, Loss: 1.17557692527771, Accuracy: 0.62109375\n",
      "Batch: 37, Loss: 1.1315205097198486, Accuracy: 0.6455078125\n",
      "Batch: 38, Loss: 1.2029190063476562, Accuracy: 0.6103515625\n",
      "Batch: 39, Loss: 1.2047425508499146, Accuracy: 0.6171875\n",
      "Batch: 40, Loss: 1.2692296504974365, Accuracy: 0.6005859375\n",
      "Batch: 41, Loss: 1.2686588764190674, Accuracy: 0.59375\n",
      "Batch: 42, Loss: 1.1954073905944824, Accuracy: 0.615234375\n",
      "Batch: 43, Loss: 1.231726884841919, Accuracy: 0.599609375\n",
      "Batch: 44, Loss: 1.310673713684082, Accuracy: 0.6083984375\n",
      "Batch: 45, Loss: 1.4130423069000244, Accuracy: 0.5732421875\n",
      "Batch: 46, Loss: 1.31901216506958, Accuracy: 0.5966796875\n",
      "Batch: 47, Loss: 1.268768072128296, Accuracy: 0.6015625\n",
      "Batch: 48, Loss: 1.4577879905700684, Accuracy: 0.5771484375\n",
      "Batch: 49, Loss: 1.5443974733352661, Accuracy: 0.5478515625\n",
      "Batch: 50, Loss: 1.278244972229004, Accuracy: 0.6064453125\n",
      "Batch: 51, Loss: 1.3280507326126099, Accuracy: 0.5859375\n",
      "Batch: 52, Loss: 1.2520427703857422, Accuracy: 0.60546875\n",
      "Batch: 53, Loss: 1.4873802661895752, Accuracy: 0.55859375\n",
      "Batch: 54, Loss: 1.4335873126983643, Accuracy: 0.5615234375\n",
      "Batch: 55, Loss: 1.3875327110290527, Accuracy: 0.583984375\n",
      "Batch: 56, Loss: 1.3338102102279663, Accuracy: 0.595703125\n",
      "Batch: 57, Loss: 1.4995231628417969, Accuracy: 0.55078125\n",
      "Batch: 58, Loss: 1.419351577758789, Accuracy: 0.576171875\n",
      "Batch: 59, Loss: 1.3388677835464478, Accuracy: 0.58203125\n",
      "Batch: 60, Loss: 1.4766596555709839, Accuracy: 0.537109375\n",
      "Batch: 61, Loss: 1.4072705507278442, Accuracy: 0.5703125\n",
      "Batch: 62, Loss: 1.3087503910064697, Accuracy: 0.599609375\n",
      "Batch: 63, Loss: 1.111667275428772, Accuracy: 0.6611328125\n",
      "Batch: 64, Loss: 1.2988433837890625, Accuracy: 0.6044921875\n",
      "Batch: 65, Loss: 1.173058032989502, Accuracy: 0.623046875\n",
      "Batch: 66, Loss: 1.218174695968628, Accuracy: 0.619140625\n",
      "Batch: 67, Loss: 1.3683209419250488, Accuracy: 0.576171875\n",
      "Batch: 68, Loss: 1.483244776725769, Accuracy: 0.5556640625\n",
      "Batch: 69, Loss: 1.3303487300872803, Accuracy: 0.5859375\n",
      "Batch: 70, Loss: 1.23335862159729, Accuracy: 0.6025390625\n",
      "Batch: 71, Loss: 1.143104076385498, Accuracy: 0.62890625\n",
      "Batch: 72, Loss: 1.251171588897705, Accuracy: 0.60546875\n",
      "Batch: 73, Loss: 1.2874430418014526, Accuracy: 0.58984375\n",
      "Batch: 74, Loss: 1.2150897979736328, Accuracy: 0.60546875\n",
      "Batch: 75, Loss: 1.0471665859222412, Accuracy: 0.654296875\n",
      "Batch: 76, Loss: 1.2091052532196045, Accuracy: 0.6279296875\n",
      "Batch: 77, Loss: 1.3179798126220703, Accuracy: 0.59375\n",
      "Batch: 78, Loss: 1.2060003280639648, Accuracy: 0.615234375\n",
      "Batch: 79, Loss: 1.2432836294174194, Accuracy: 0.609375\n",
      "Batch: 80, Loss: 1.239805817604065, Accuracy: 0.607421875\n",
      "Batch: 81, Loss: 1.1737831830978394, Accuracy: 0.6240234375\n",
      "Batch: 82, Loss: 1.1041979789733887, Accuracy: 0.64453125\n",
      "Batch: 83, Loss: 1.1761367321014404, Accuracy: 0.6328125\n",
      "Batch: 84, Loss: 1.100661277770996, Accuracy: 0.6455078125\n",
      "Batch: 85, Loss: 1.1077913045883179, Accuracy: 0.654296875\n",
      "Batch: 86, Loss: 1.0676288604736328, Accuracy: 0.6484375\n",
      "Batch: 87, Loss: 1.0911316871643066, Accuracy: 0.6416015625\n",
      "Batch: 88, Loss: 1.1699533462524414, Accuracy: 0.630859375\n",
      "Batch: 89, Loss: 1.160853624343872, Accuracy: 0.6279296875\n",
      "Batch: 90, Loss: 1.153563141822815, Accuracy: 0.640625\n",
      "Batch: 91, Loss: 1.236316442489624, Accuracy: 0.599609375\n",
      "Batch: 92, Loss: 1.0316979885101318, Accuracy: 0.662109375\n",
      "Batch: 93, Loss: 0.9716995358467102, Accuracy: 0.67578125\n",
      "Batch: 94, Loss: 1.0861237049102783, Accuracy: 0.6552734375\n",
      "Batch: 95, Loss: 1.090167760848999, Accuracy: 0.6455078125\n",
      "Batch: 96, Loss: 1.0950708389282227, Accuracy: 0.63671875\n",
      "Batch: 97, Loss: 1.1150999069213867, Accuracy: 0.6396484375\n",
      "Batch: 98, Loss: 1.171162486076355, Accuracy: 0.625\n",
      "Batch: 99, Loss: 1.1273508071899414, Accuracy: 0.6435546875\n",
      "Batch: 100, Loss: 1.2266483306884766, Accuracy: 0.599609375\n",
      "Batch: 101, Loss: 1.135856032371521, Accuracy: 0.6484375\n",
      "Batch: 102, Loss: 1.1646080017089844, Accuracy: 0.638671875\n",
      "Batch: 103, Loss: 1.233309268951416, Accuracy: 0.6259765625\n",
      "Batch: 104, Loss: 1.202178955078125, Accuracy: 0.626953125\n",
      "Batch: 105, Loss: 1.062827229499817, Accuracy: 0.6640625\n",
      "Batch: 106, Loss: 1.1068146228790283, Accuracy: 0.65234375\n",
      "Batch: 107, Loss: 1.1261889934539795, Accuracy: 0.6455078125\n",
      "Batch: 108, Loss: 1.1086790561676025, Accuracy: 0.638671875\n",
      "Batch: 109, Loss: 1.1769843101501465, Accuracy: 0.654296875\n",
      "Batch: 110, Loss: 1.1230018138885498, Accuracy: 0.6611328125\n",
      "Batch: 111, Loss: 1.2188295125961304, Accuracy: 0.6337890625\n",
      "Batch: 112, Loss: 1.1266233921051025, Accuracy: 0.6474609375\n",
      "Epoch 7/90\n",
      "Batch: 1, Loss: 1.6752240657806396, Accuracy: 0.5419921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 2, Loss: 1.295896291732788, Accuracy: 0.6181640625\n",
      "Batch: 3, Loss: 1.2863463163375854, Accuracy: 0.615234375\n",
      "Batch: 4, Loss: 1.2574708461761475, Accuracy: 0.619140625\n",
      "Batch: 5, Loss: 1.2899351119995117, Accuracy: 0.6162109375\n",
      "Batch: 6, Loss: 1.269331455230713, Accuracy: 0.63671875\n",
      "Batch: 7, Loss: 1.2282973527908325, Accuracy: 0.623046875\n",
      "Batch: 8, Loss: 1.167865514755249, Accuracy: 0.63671875\n",
      "Batch: 9, Loss: 1.2093095779418945, Accuracy: 0.623046875\n",
      "Batch: 10, Loss: 1.2515811920166016, Accuracy: 0.62109375\n",
      "Batch: 11, Loss: 1.1362088918685913, Accuracy: 0.6513671875\n",
      "Batch: 12, Loss: 1.1735014915466309, Accuracy: 0.6513671875\n",
      "Batch: 13, Loss: 1.161440372467041, Accuracy: 0.6533203125\n",
      "Batch: 14, Loss: 1.2625226974487305, Accuracy: 0.6279296875\n",
      "Batch: 15, Loss: 1.1851674318313599, Accuracy: 0.6416015625\n",
      "Batch: 16, Loss: 1.2326719760894775, Accuracy: 0.6142578125\n",
      "Batch: 17, Loss: 1.2144122123718262, Accuracy: 0.6513671875\n",
      "Batch: 18, Loss: 1.1009180545806885, Accuracy: 0.6513671875\n",
      "Batch: 19, Loss: 1.145892858505249, Accuracy: 0.65625\n",
      "Batch: 20, Loss: 1.1773754358291626, Accuracy: 0.634765625\n",
      "Batch: 21, Loss: 1.1413471698760986, Accuracy: 0.650390625\n",
      "Batch: 22, Loss: 1.135216474533081, Accuracy: 0.6396484375\n",
      "Batch: 23, Loss: 1.276843547821045, Accuracy: 0.6328125\n",
      "Batch: 24, Loss: 1.2916836738586426, Accuracy: 0.6044921875\n",
      "Batch: 25, Loss: 1.3425726890563965, Accuracy: 0.5869140625\n",
      "Batch: 26, Loss: 1.3812609910964966, Accuracy: 0.5810546875\n",
      "Batch: 27, Loss: 1.263301968574524, Accuracy: 0.61328125\n",
      "Batch: 28, Loss: 1.086927056312561, Accuracy: 0.6396484375\n",
      "Batch: 29, Loss: 1.18129301071167, Accuracy: 0.6142578125\n",
      "Batch: 30, Loss: 1.249618649482727, Accuracy: 0.615234375\n",
      "Batch: 31, Loss: 1.1931085586547852, Accuracy: 0.6337890625\n",
      "Batch: 32, Loss: 1.1511765718460083, Accuracy: 0.642578125\n",
      "Batch: 33, Loss: 1.1770358085632324, Accuracy: 0.607421875\n",
      "Batch: 34, Loss: 1.1127126216888428, Accuracy: 0.646484375\n",
      "Batch: 35, Loss: 1.1799421310424805, Accuracy: 0.6259765625\n",
      "Batch: 36, Loss: 1.1453285217285156, Accuracy: 0.6220703125\n",
      "Batch: 37, Loss: 1.0888328552246094, Accuracy: 0.6650390625\n",
      "Batch: 38, Loss: 1.1366091966629028, Accuracy: 0.6298828125\n",
      "Batch: 39, Loss: 1.125076413154602, Accuracy: 0.619140625\n",
      "Batch: 40, Loss: 1.1997723579406738, Accuracy: 0.625\n",
      "Batch: 41, Loss: 1.1506164073944092, Accuracy: 0.6279296875\n",
      "Batch: 42, Loss: 1.1081562042236328, Accuracy: 0.63671875\n",
      "Batch: 43, Loss: 1.1619558334350586, Accuracy: 0.6240234375\n",
      "Batch: 44, Loss: 1.2378013134002686, Accuracy: 0.6162109375\n",
      "Batch: 45, Loss: 1.324047565460205, Accuracy: 0.59765625\n",
      "Batch: 46, Loss: 1.2475593090057373, Accuracy: 0.6103515625\n",
      "Batch: 47, Loss: 1.192328691482544, Accuracy: 0.61328125\n",
      "Batch: 48, Loss: 1.376140832901001, Accuracy: 0.5673828125\n",
      "Batch: 49, Loss: 1.4943205118179321, Accuracy: 0.5654296875\n",
      "Batch: 50, Loss: 1.1734886169433594, Accuracy: 0.62109375\n",
      "Batch: 51, Loss: 1.2442927360534668, Accuracy: 0.6142578125\n",
      "Batch: 52, Loss: 1.1381274461746216, Accuracy: 0.640625\n",
      "Batch: 53, Loss: 1.391552448272705, Accuracy: 0.587890625\n",
      "Batch: 54, Loss: 1.3333070278167725, Accuracy: 0.6015625\n",
      "Batch: 55, Loss: 1.2999992370605469, Accuracy: 0.6220703125\n",
      "Batch: 56, Loss: 1.237518548965454, Accuracy: 0.6279296875\n",
      "Batch: 57, Loss: 1.434154748916626, Accuracy: 0.57421875\n",
      "Batch: 58, Loss: 1.3865749835968018, Accuracy: 0.5888671875\n",
      "Batch: 59, Loss: 1.2715179920196533, Accuracy: 0.611328125\n",
      "Batch: 60, Loss: 1.4429047107696533, Accuracy: 0.5556640625\n",
      "Batch: 61, Loss: 1.3257464170455933, Accuracy: 0.58203125\n",
      "Batch: 62, Loss: 1.229710340499878, Accuracy: 0.6171875\n",
      "Batch: 63, Loss: 1.0329731702804565, Accuracy: 0.6845703125\n",
      "Batch: 64, Loss: 1.218559980392456, Accuracy: 0.6279296875\n",
      "Batch: 65, Loss: 1.138807773590088, Accuracy: 0.6455078125\n",
      "Batch: 66, Loss: 1.1277410984039307, Accuracy: 0.6328125\n",
      "Batch: 67, Loss: 1.2692471742630005, Accuracy: 0.59765625\n",
      "Batch: 68, Loss: 1.3768987655639648, Accuracy: 0.5869140625\n",
      "Batch: 69, Loss: 1.2230786085128784, Accuracy: 0.603515625\n",
      "Batch: 70, Loss: 1.1425589323043823, Accuracy: 0.6298828125\n",
      "Batch: 71, Loss: 1.0694926977157593, Accuracy: 0.6533203125\n",
      "Batch: 72, Loss: 1.1538424491882324, Accuracy: 0.6259765625\n",
      "Batch: 73, Loss: 1.219362497329712, Accuracy: 0.61328125\n",
      "Batch: 74, Loss: 1.1477102041244507, Accuracy: 0.6171875\n",
      "Batch: 75, Loss: 1.0056496858596802, Accuracy: 0.681640625\n",
      "Batch: 76, Loss: 1.1395800113677979, Accuracy: 0.6484375\n",
      "Batch: 77, Loss: 1.2614374160766602, Accuracy: 0.61328125\n",
      "Batch: 78, Loss: 1.1398181915283203, Accuracy: 0.634765625\n",
      "Batch: 79, Loss: 1.1926506757736206, Accuracy: 0.63671875\n",
      "Batch: 80, Loss: 1.172968864440918, Accuracy: 0.63671875\n",
      "Batch: 81, Loss: 1.1466245651245117, Accuracy: 0.619140625\n",
      "Batch: 82, Loss: 1.0370317697525024, Accuracy: 0.662109375\n",
      "Batch: 83, Loss: 1.0888677835464478, Accuracy: 0.6591796875\n",
      "Batch: 84, Loss: 1.046141266822815, Accuracy: 0.6572265625\n",
      "Batch: 85, Loss: 1.001535415649414, Accuracy: 0.6748046875\n",
      "Batch: 86, Loss: 1.0087767839431763, Accuracy: 0.681640625\n",
      "Batch: 87, Loss: 1.0359196662902832, Accuracy: 0.658203125\n",
      "Batch: 88, Loss: 1.122290015220642, Accuracy: 0.6435546875\n",
      "Batch: 89, Loss: 1.1045582294464111, Accuracy: 0.6416015625\n",
      "Batch: 90, Loss: 1.1059844493865967, Accuracy: 0.6494140625\n",
      "Batch: 91, Loss: 1.1784441471099854, Accuracy: 0.61328125\n",
      "Batch: 92, Loss: 1.0043962001800537, Accuracy: 0.6865234375\n",
      "Batch: 93, Loss: 0.95672607421875, Accuracy: 0.6806640625\n",
      "Batch: 94, Loss: 1.0300133228302002, Accuracy: 0.669921875\n",
      "Batch: 95, Loss: 1.0443803071975708, Accuracy: 0.6650390625\n",
      "Batch: 96, Loss: 1.0519940853118896, Accuracy: 0.6328125\n",
      "Batch: 97, Loss: 1.0354864597320557, Accuracy: 0.6630859375\n",
      "Batch: 98, Loss: 1.0998326539993286, Accuracy: 0.6513671875\n",
      "Batch: 99, Loss: 1.0877532958984375, Accuracy: 0.6494140625\n",
      "Batch: 100, Loss: 1.1645554304122925, Accuracy: 0.6455078125\n",
      "Batch: 101, Loss: 1.102461338043213, Accuracy: 0.65234375\n",
      "Batch: 102, Loss: 1.1143440008163452, Accuracy: 0.6640625\n",
      "Batch: 103, Loss: 1.1585800647735596, Accuracy: 0.6416015625\n",
      "Batch: 104, Loss: 1.1610721349716187, Accuracy: 0.64453125\n",
      "Batch: 105, Loss: 1.032102108001709, Accuracy: 0.67578125\n",
      "Batch: 106, Loss: 1.0396616458892822, Accuracy: 0.6591796875\n",
      "Batch: 107, Loss: 1.0779898166656494, Accuracy: 0.6484375\n",
      "Batch: 108, Loss: 1.0313242673873901, Accuracy: 0.673828125\n",
      "Batch: 109, Loss: 1.1366569995880127, Accuracy: 0.6748046875\n",
      "Batch: 110, Loss: 1.0506222248077393, Accuracy: 0.6767578125\n",
      "Batch: 111, Loss: 1.1560802459716797, Accuracy: 0.6455078125\n",
      "Batch: 112, Loss: 1.0655449628829956, Accuracy: 0.6630859375\n",
      "Epoch 8/90\n",
      "Batch: 1, Loss: 1.565007209777832, Accuracy: 0.5615234375\n",
      "Batch: 2, Loss: 1.233635425567627, Accuracy: 0.642578125\n",
      "Batch: 3, Loss: 1.2288074493408203, Accuracy: 0.619140625\n",
      "Batch: 4, Loss: 1.1949388980865479, Accuracy: 0.6357421875\n",
      "Batch: 5, Loss: 1.2128610610961914, Accuracy: 0.62890625\n",
      "Batch: 6, Loss: 1.2229547500610352, Accuracy: 0.640625\n",
      "Batch: 7, Loss: 1.1542311906814575, Accuracy: 0.65234375\n",
      "Batch: 8, Loss: 1.0951247215270996, Accuracy: 0.6669921875\n",
      "Batch: 9, Loss: 1.137416124343872, Accuracy: 0.6572265625\n",
      "Batch: 10, Loss: 1.171783685684204, Accuracy: 0.6171875\n",
      "Batch: 11, Loss: 1.0845400094985962, Accuracy: 0.6650390625\n",
      "Batch: 12, Loss: 1.1193069219589233, Accuracy: 0.658203125\n",
      "Batch: 13, Loss: 1.101823329925537, Accuracy: 0.6787109375\n",
      "Batch: 14, Loss: 1.172425389289856, Accuracy: 0.6279296875\n",
      "Batch: 15, Loss: 1.1140494346618652, Accuracy: 0.6474609375\n",
      "Batch: 16, Loss: 1.1483182907104492, Accuracy: 0.646484375\n",
      "Batch: 17, Loss: 1.1188263893127441, Accuracy: 0.6611328125\n",
      "Batch: 18, Loss: 1.024517297744751, Accuracy: 0.6630859375\n",
      "Batch: 19, Loss: 1.0859220027923584, Accuracy: 0.6552734375\n",
      "Batch: 20, Loss: 1.0861681699752808, Accuracy: 0.662109375\n",
      "Batch: 21, Loss: 1.05940842628479, Accuracy: 0.6689453125\n",
      "Batch: 22, Loss: 1.075608730316162, Accuracy: 0.666015625\n",
      "Batch: 23, Loss: 1.191821813583374, Accuracy: 0.6435546875\n",
      "Batch: 24, Loss: 1.2112888097763062, Accuracy: 0.6162109375\n",
      "Batch: 25, Loss: 1.2884336709976196, Accuracy: 0.6005859375\n",
      "Batch: 26, Loss: 1.314561367034912, Accuracy: 0.607421875\n",
      "Batch: 27, Loss: 1.2078279256820679, Accuracy: 0.62890625\n",
      "Batch: 28, Loss: 1.0062334537506104, Accuracy: 0.6640625\n",
      "Batch: 29, Loss: 1.1114157438278198, Accuracy: 0.6416015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 30, Loss: 1.1848547458648682, Accuracy: 0.625\n",
      "Batch: 31, Loss: 1.127704381942749, Accuracy: 0.6494140625\n",
      "Batch: 32, Loss: 1.0951396226882935, Accuracy: 0.63671875\n",
      "Batch: 33, Loss: 1.097179651260376, Accuracy: 0.6298828125\n",
      "Batch: 34, Loss: 1.081741452217102, Accuracy: 0.6572265625\n",
      "Batch: 35, Loss: 1.1541800498962402, Accuracy: 0.6259765625\n",
      "Batch: 36, Loss: 1.0743598937988281, Accuracy: 0.658203125\n",
      "Batch: 37, Loss: 1.0405253171920776, Accuracy: 0.6728515625\n",
      "Batch: 38, Loss: 1.1096004247665405, Accuracy: 0.640625\n",
      "Batch: 39, Loss: 1.0599770545959473, Accuracy: 0.6455078125\n",
      "Batch: 40, Loss: 1.1315056085586548, Accuracy: 0.64453125\n",
      "Batch: 41, Loss: 1.092771053314209, Accuracy: 0.6494140625\n",
      "Batch: 42, Loss: 1.0486094951629639, Accuracy: 0.6572265625\n",
      "Batch: 43, Loss: 1.1181390285491943, Accuracy: 0.6435546875\n",
      "Batch: 44, Loss: 1.1917665004730225, Accuracy: 0.638671875\n",
      "Batch: 45, Loss: 1.2875062227249146, Accuracy: 0.595703125\n",
      "Batch: 46, Loss: 1.1606042385101318, Accuracy: 0.6318359375\n",
      "Batch: 47, Loss: 1.1535154581069946, Accuracy: 0.623046875\n",
      "Batch: 48, Loss: 1.3119853734970093, Accuracy: 0.5927734375\n",
      "Batch: 49, Loss: 1.4069421291351318, Accuracy: 0.5703125\n",
      "Batch: 50, Loss: 1.1185598373413086, Accuracy: 0.6376953125\n",
      "Batch: 51, Loss: 1.1936964988708496, Accuracy: 0.625\n",
      "Batch: 52, Loss: 1.0899903774261475, Accuracy: 0.662109375\n",
      "Batch: 53, Loss: 1.3324201107025146, Accuracy: 0.6142578125\n",
      "Batch: 54, Loss: 1.2728934288024902, Accuracy: 0.619140625\n",
      "Batch: 55, Loss: 1.2525650262832642, Accuracy: 0.6279296875\n",
      "Batch: 56, Loss: 1.1938769817352295, Accuracy: 0.6220703125\n",
      "Batch: 57, Loss: 1.367661476135254, Accuracy: 0.587890625\n",
      "Batch: 58, Loss: 1.287194013595581, Accuracy: 0.6220703125\n",
      "Batch: 59, Loss: 1.1907455921173096, Accuracy: 0.6376953125\n",
      "Batch: 60, Loss: 1.3567752838134766, Accuracy: 0.568359375\n",
      "Batch: 61, Loss: 1.2646512985229492, Accuracy: 0.619140625\n",
      "Batch: 62, Loss: 1.150649070739746, Accuracy: 0.6376953125\n",
      "Batch: 63, Loss: 0.9703581929206848, Accuracy: 0.7060546875\n",
      "Batch: 64, Loss: 1.146963357925415, Accuracy: 0.65234375\n",
      "Batch: 65, Loss: 1.062886357307434, Accuracy: 0.6611328125\n",
      "Batch: 66, Loss: 1.0607610940933228, Accuracy: 0.6533203125\n",
      "Batch: 67, Loss: 1.1907299757003784, Accuracy: 0.626953125\n",
      "Batch: 68, Loss: 1.3129756450653076, Accuracy: 0.5947265625\n",
      "Batch: 69, Loss: 1.154271125793457, Accuracy: 0.630859375\n",
      "Batch: 70, Loss: 1.1342737674713135, Accuracy: 0.626953125\n",
      "Batch: 71, Loss: 1.0407278537750244, Accuracy: 0.6552734375\n",
      "Batch: 72, Loss: 1.0973745584487915, Accuracy: 0.6484375\n",
      "Batch: 73, Loss: 1.119322657585144, Accuracy: 0.646484375\n",
      "Batch: 74, Loss: 1.0627753734588623, Accuracy: 0.6552734375\n",
      "Batch: 75, Loss: 0.9451013803482056, Accuracy: 0.6953125\n",
      "Batch: 76, Loss: 1.101520299911499, Accuracy: 0.6552734375\n",
      "Batch: 77, Loss: 1.1975805759429932, Accuracy: 0.6279296875\n",
      "Batch: 78, Loss: 1.0888996124267578, Accuracy: 0.64453125\n",
      "Batch: 79, Loss: 1.141750693321228, Accuracy: 0.6435546875\n",
      "Batch: 80, Loss: 1.1018292903900146, Accuracy: 0.6494140625\n",
      "Batch: 81, Loss: 1.0892720222473145, Accuracy: 0.64453125\n",
      "Batch: 82, Loss: 0.9951696395874023, Accuracy: 0.6845703125\n",
      "Batch: 83, Loss: 1.0330735445022583, Accuracy: 0.6689453125\n",
      "Batch: 84, Loss: 0.9850869178771973, Accuracy: 0.6845703125\n",
      "Batch: 85, Loss: 0.9710530042648315, Accuracy: 0.6943359375\n",
      "Batch: 86, Loss: 0.9635965824127197, Accuracy: 0.6875\n",
      "Batch: 87, Loss: 0.9884903430938721, Accuracy: 0.673828125\n",
      "Batch: 88, Loss: 1.065722942352295, Accuracy: 0.65234375\n",
      "Batch: 89, Loss: 1.0942038297653198, Accuracy: 0.66015625\n",
      "Batch: 90, Loss: 1.0729866027832031, Accuracy: 0.65234375\n",
      "Batch: 91, Loss: 1.1309351921081543, Accuracy: 0.630859375\n",
      "Batch: 92, Loss: 0.9485545754432678, Accuracy: 0.69921875\n",
      "Batch: 93, Loss: 0.9144319891929626, Accuracy: 0.6982421875\n",
      "Batch: 94, Loss: 1.0205018520355225, Accuracy: 0.67578125\n",
      "Batch: 95, Loss: 1.0286335945129395, Accuracy: 0.671875\n",
      "Batch: 96, Loss: 1.02531898021698, Accuracy: 0.6455078125\n",
      "Batch: 97, Loss: 1.009989619255066, Accuracy: 0.6728515625\n",
      "Batch: 98, Loss: 1.08379065990448, Accuracy: 0.6484375\n",
      "Batch: 99, Loss: 1.051804542541504, Accuracy: 0.65625\n",
      "Batch: 100, Loss: 1.1283618211746216, Accuracy: 0.650390625\n",
      "Batch: 101, Loss: 1.0673227310180664, Accuracy: 0.6767578125\n",
      "Batch: 102, Loss: 1.0666389465332031, Accuracy: 0.66796875\n",
      "Batch: 103, Loss: 1.119652271270752, Accuracy: 0.646484375\n",
      "Batch: 104, Loss: 1.1047418117523193, Accuracy: 0.6474609375\n",
      "Batch: 105, Loss: 0.9820399880409241, Accuracy: 0.6845703125\n",
      "Batch: 106, Loss: 1.0084079504013062, Accuracy: 0.6884765625\n",
      "Batch: 107, Loss: 1.0372236967086792, Accuracy: 0.673828125\n",
      "Batch: 108, Loss: 0.9951064586639404, Accuracy: 0.677734375\n",
      "Batch: 109, Loss: 1.0650908946990967, Accuracy: 0.6953125\n",
      "Batch: 110, Loss: 1.001756191253662, Accuracy: 0.69921875\n",
      "Batch: 111, Loss: 1.0833585262298584, Accuracy: 0.6708984375\n",
      "Batch: 112, Loss: 1.0243377685546875, Accuracy: 0.666015625\n",
      "Epoch 9/90\n",
      "Batch: 1, Loss: 1.5237480401992798, Accuracy: 0.5712890625\n",
      "Batch: 2, Loss: 1.1861393451690674, Accuracy: 0.6455078125\n",
      "Batch: 3, Loss: 1.1759629249572754, Accuracy: 0.6337890625\n",
      "Batch: 4, Loss: 1.1370971202850342, Accuracy: 0.642578125\n",
      "Batch: 5, Loss: 1.164684772491455, Accuracy: 0.6416015625\n",
      "Batch: 6, Loss: 1.1698579788208008, Accuracy: 0.6630859375\n",
      "Batch: 7, Loss: 1.0758697986602783, Accuracy: 0.6767578125\n",
      "Batch: 8, Loss: 1.038377285003662, Accuracy: 0.681640625\n",
      "Batch: 9, Loss: 1.082601547241211, Accuracy: 0.658203125\n",
      "Batch: 10, Loss: 1.1256271600723267, Accuracy: 0.6416015625\n",
      "Batch: 11, Loss: 1.0086314678192139, Accuracy: 0.685546875\n",
      "Batch: 12, Loss: 1.0599334239959717, Accuracy: 0.6640625\n",
      "Batch: 13, Loss: 1.043945074081421, Accuracy: 0.7041015625\n",
      "Batch: 14, Loss: 1.1261143684387207, Accuracy: 0.6455078125\n",
      "Batch: 15, Loss: 1.0763030052185059, Accuracy: 0.6650390625\n",
      "Batch: 16, Loss: 1.1025978326797485, Accuracy: 0.65234375\n",
      "Batch: 17, Loss: 1.0765130519866943, Accuracy: 0.669921875\n",
      "Batch: 18, Loss: 0.9872230291366577, Accuracy: 0.68359375\n",
      "Batch: 19, Loss: 1.0248997211456299, Accuracy: 0.6796875\n",
      "Batch: 20, Loss: 1.0552409887313843, Accuracy: 0.6728515625\n",
      "Batch: 21, Loss: 0.9963203072547913, Accuracy: 0.6904296875\n",
      "Batch: 22, Loss: 1.0291250944137573, Accuracy: 0.66796875\n",
      "Batch: 23, Loss: 1.1478078365325928, Accuracy: 0.6689453125\n",
      "Batch: 24, Loss: 1.1401455402374268, Accuracy: 0.658203125\n",
      "Batch: 25, Loss: 1.2280488014221191, Accuracy: 0.6220703125\n",
      "Batch: 26, Loss: 1.2816214561462402, Accuracy: 0.6171875\n",
      "Batch: 27, Loss: 1.1584863662719727, Accuracy: 0.6357421875\n",
      "Batch: 28, Loss: 0.9988837242126465, Accuracy: 0.666015625\n",
      "Batch: 29, Loss: 1.0738486051559448, Accuracy: 0.6611328125\n",
      "Batch: 30, Loss: 1.1041890382766724, Accuracy: 0.6494140625\n",
      "Batch: 31, Loss: 1.086564302444458, Accuracy: 0.6630859375\n",
      "Batch: 32, Loss: 1.0570893287658691, Accuracy: 0.654296875\n",
      "Batch: 33, Loss: 1.0550942420959473, Accuracy: 0.6513671875\n",
      "Batch: 34, Loss: 1.0076978206634521, Accuracy: 0.6728515625\n",
      "Batch: 35, Loss: 1.1014454364776611, Accuracy: 0.6435546875\n",
      "Batch: 36, Loss: 1.0428470373153687, Accuracy: 0.6455078125\n",
      "Batch: 37, Loss: 0.9788511991500854, Accuracy: 0.6748046875\n",
      "Batch: 38, Loss: 1.0722088813781738, Accuracy: 0.6435546875\n",
      "Batch: 39, Loss: 1.046170711517334, Accuracy: 0.662109375\n",
      "Batch: 40, Loss: 1.0742206573486328, Accuracy: 0.6630859375\n",
      "Batch: 41, Loss: 1.0473864078521729, Accuracy: 0.6572265625\n",
      "Batch: 42, Loss: 0.9892135858535767, Accuracy: 0.666015625\n",
      "Batch: 43, Loss: 1.0773429870605469, Accuracy: 0.6552734375\n",
      "Batch: 44, Loss: 1.163119912147522, Accuracy: 0.6474609375\n",
      "Batch: 45, Loss: 1.2214293479919434, Accuracy: 0.609375\n",
      "Batch: 46, Loss: 1.1150028705596924, Accuracy: 0.6484375\n",
      "Batch: 47, Loss: 1.0982003211975098, Accuracy: 0.6328125\n",
      "Batch: 48, Loss: 1.2825345993041992, Accuracy: 0.60546875\n",
      "Batch: 49, Loss: 1.3686342239379883, Accuracy: 0.5751953125\n",
      "Batch: 50, Loss: 1.0778652429580688, Accuracy: 0.6513671875\n",
      "Batch: 51, Loss: 1.1255035400390625, Accuracy: 0.626953125\n",
      "Batch: 52, Loss: 1.0393211841583252, Accuracy: 0.666015625\n",
      "Batch: 53, Loss: 1.2957935333251953, Accuracy: 0.6123046875\n",
      "Batch: 54, Loss: 1.2203941345214844, Accuracy: 0.6328125\n",
      "Batch: 55, Loss: 1.2034478187561035, Accuracy: 0.6376953125\n",
      "Batch: 56, Loss: 1.121383786201477, Accuracy: 0.654296875\n",
      "Batch: 57, Loss: 1.3301079273223877, Accuracy: 0.59765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 58, Loss: 1.2314820289611816, Accuracy: 0.6357421875\n",
      "Batch: 59, Loss: 1.1590425968170166, Accuracy: 0.65234375\n",
      "Batch: 60, Loss: 1.3241969347000122, Accuracy: 0.5673828125\n",
      "Batch: 61, Loss: 1.2121987342834473, Accuracy: 0.6083984375\n",
      "Batch: 62, Loss: 1.1095116138458252, Accuracy: 0.6494140625\n",
      "Batch: 63, Loss: 0.9300808906555176, Accuracy: 0.71484375\n",
      "Batch: 64, Loss: 1.0815303325653076, Accuracy: 0.6572265625\n",
      "Batch: 65, Loss: 1.014425277709961, Accuracy: 0.6708984375\n",
      "Batch: 66, Loss: 1.0045174360275269, Accuracy: 0.68359375\n",
      "Batch: 67, Loss: 1.117326021194458, Accuracy: 0.642578125\n",
      "Batch: 68, Loss: 1.2130002975463867, Accuracy: 0.6220703125\n",
      "Batch: 69, Loss: 1.0758825540542603, Accuracy: 0.66015625\n",
      "Batch: 70, Loss: 1.0671030282974243, Accuracy: 0.640625\n",
      "Batch: 71, Loss: 0.979663074016571, Accuracy: 0.6748046875\n",
      "Batch: 72, Loss: 1.0540378093719482, Accuracy: 0.65234375\n",
      "Batch: 73, Loss: 1.0854580402374268, Accuracy: 0.6416015625\n",
      "Batch: 74, Loss: 1.0199512243270874, Accuracy: 0.6650390625\n",
      "Batch: 75, Loss: 0.9037907123565674, Accuracy: 0.69921875\n",
      "Batch: 76, Loss: 1.0363034009933472, Accuracy: 0.6630859375\n",
      "Batch: 77, Loss: 1.1328072547912598, Accuracy: 0.650390625\n",
      "Batch: 78, Loss: 1.0383274555206299, Accuracy: 0.6640625\n",
      "Batch: 79, Loss: 1.100179672241211, Accuracy: 0.662109375\n",
      "Batch: 80, Loss: 1.0816912651062012, Accuracy: 0.654296875\n",
      "Batch: 81, Loss: 1.0449848175048828, Accuracy: 0.6552734375\n",
      "Batch: 82, Loss: 0.9689954519271851, Accuracy: 0.6923828125\n",
      "Batch: 83, Loss: 0.9982398748397827, Accuracy: 0.6826171875\n",
      "Batch: 84, Loss: 0.9283705353736877, Accuracy: 0.708984375\n",
      "Batch: 85, Loss: 0.9321626424789429, Accuracy: 0.70703125\n",
      "Batch: 86, Loss: 0.9146600961685181, Accuracy: 0.69921875\n",
      "Batch: 87, Loss: 0.9487194418907166, Accuracy: 0.685546875\n",
      "Batch: 88, Loss: 1.0149822235107422, Accuracy: 0.662109375\n",
      "Batch: 89, Loss: 1.030002474784851, Accuracy: 0.654296875\n",
      "Batch: 90, Loss: 0.9976416826248169, Accuracy: 0.6669921875\n",
      "Batch: 91, Loss: 1.1152660846710205, Accuracy: 0.63671875\n",
      "Batch: 92, Loss: 0.9366054534912109, Accuracy: 0.6923828125\n",
      "Batch: 93, Loss: 0.9019201993942261, Accuracy: 0.689453125\n",
      "Batch: 94, Loss: 0.9922481179237366, Accuracy: 0.6826171875\n",
      "Batch: 95, Loss: 0.9770995378494263, Accuracy: 0.68359375\n",
      "Batch: 96, Loss: 0.9929302334785461, Accuracy: 0.673828125\n",
      "Batch: 97, Loss: 0.9613816738128662, Accuracy: 0.6875\n",
      "Batch: 98, Loss: 1.0449875593185425, Accuracy: 0.6640625\n",
      "Batch: 99, Loss: 1.0151710510253906, Accuracy: 0.6640625\n",
      "Batch: 100, Loss: 1.0944085121154785, Accuracy: 0.6484375\n",
      "Batch: 101, Loss: 0.9992912411689758, Accuracy: 0.681640625\n",
      "Batch: 102, Loss: 1.0207240581512451, Accuracy: 0.69140625\n",
      "Batch: 103, Loss: 1.0605024099349976, Accuracy: 0.6650390625\n",
      "Batch: 104, Loss: 1.0606417655944824, Accuracy: 0.64453125\n",
      "Batch: 105, Loss: 0.9439457058906555, Accuracy: 0.7119140625\n",
      "Batch: 106, Loss: 0.9615224599838257, Accuracy: 0.6962890625\n",
      "Batch: 107, Loss: 1.005333423614502, Accuracy: 0.6669921875\n",
      "Batch: 108, Loss: 0.9773431420326233, Accuracy: 0.6943359375\n",
      "Batch: 109, Loss: 1.0160675048828125, Accuracy: 0.7021484375\n",
      "Batch: 110, Loss: 0.958531379699707, Accuracy: 0.7001953125\n",
      "Batch: 111, Loss: 1.0464891195297241, Accuracy: 0.6875\n",
      "Batch: 112, Loss: 0.9738977551460266, Accuracy: 0.689453125\n",
      "Epoch 10/90\n",
      "Batch: 1, Loss: 1.4547946453094482, Accuracy: 0.58984375\n",
      "Batch: 2, Loss: 1.124566912651062, Accuracy: 0.6689453125\n",
      "Batch: 3, Loss: 1.1449207067489624, Accuracy: 0.6513671875\n",
      "Batch: 4, Loss: 1.0773429870605469, Accuracy: 0.658203125\n",
      "Batch: 5, Loss: 1.1449823379516602, Accuracy: 0.6455078125\n",
      "Batch: 6, Loss: 1.1012487411499023, Accuracy: 0.677734375\n",
      "Batch: 7, Loss: 1.0298328399658203, Accuracy: 0.6845703125\n",
      "Batch: 8, Loss: 0.9688220024108887, Accuracy: 0.697265625\n",
      "Batch: 9, Loss: 1.0104678869247437, Accuracy: 0.6865234375\n",
      "Batch: 10, Loss: 1.0683369636535645, Accuracy: 0.654296875\n",
      "Batch: 11, Loss: 0.9572452902793884, Accuracy: 0.6953125\n",
      "Batch: 12, Loss: 0.9990936517715454, Accuracy: 0.6748046875\n",
      "Batch: 13, Loss: 0.9836625456809998, Accuracy: 0.705078125\n",
      "Batch: 14, Loss: 1.0933188199996948, Accuracy: 0.658203125\n",
      "Batch: 15, Loss: 1.036339521408081, Accuracy: 0.677734375\n",
      "Batch: 16, Loss: 1.0582756996154785, Accuracy: 0.666015625\n",
      "Batch: 17, Loss: 1.022559404373169, Accuracy: 0.68359375\n",
      "Batch: 18, Loss: 0.9626012444496155, Accuracy: 0.6865234375\n",
      "Batch: 19, Loss: 0.992308497428894, Accuracy: 0.689453125\n",
      "Batch: 20, Loss: 1.0184953212738037, Accuracy: 0.689453125\n",
      "Batch: 21, Loss: 0.9707746505737305, Accuracy: 0.6884765625\n",
      "Batch: 22, Loss: 0.9797675013542175, Accuracy: 0.6884765625\n",
      "Batch: 23, Loss: 1.1019086837768555, Accuracy: 0.6845703125\n",
      "Batch: 24, Loss: 1.1172046661376953, Accuracy: 0.6572265625\n",
      "Batch: 25, Loss: 1.177019715309143, Accuracy: 0.6279296875\n",
      "Batch: 26, Loss: 1.2534677982330322, Accuracy: 0.6201171875\n",
      "Batch: 27, Loss: 1.0964106321334839, Accuracy: 0.66015625\n",
      "Batch: 28, Loss: 0.9425293207168579, Accuracy: 0.6826171875\n",
      "Batch: 29, Loss: 1.0430697202682495, Accuracy: 0.666015625\n",
      "Batch: 30, Loss: 1.093176007270813, Accuracy: 0.64453125\n",
      "Batch: 31, Loss: 1.037799596786499, Accuracy: 0.67578125\n",
      "Batch: 32, Loss: 1.021796703338623, Accuracy: 0.666015625\n",
      "Batch: 33, Loss: 1.0006251335144043, Accuracy: 0.658203125\n",
      "Batch: 34, Loss: 0.9573065638542175, Accuracy: 0.69140625\n",
      "Batch: 35, Loss: 1.0253725051879883, Accuracy: 0.6689453125\n",
      "Batch: 36, Loss: 1.0020846128463745, Accuracy: 0.671875\n",
      "Batch: 37, Loss: 0.9542842507362366, Accuracy: 0.6826171875\n",
      "Batch: 38, Loss: 1.0165445804595947, Accuracy: 0.6669921875\n",
      "Batch: 39, Loss: 0.9962806105613708, Accuracy: 0.6767578125\n",
      "Batch: 40, Loss: 1.0425193309783936, Accuracy: 0.662109375\n",
      "Batch: 41, Loss: 1.0124411582946777, Accuracy: 0.6650390625\n",
      "Batch: 42, Loss: 0.9539234638214111, Accuracy: 0.673828125\n",
      "Batch: 43, Loss: 1.021941900253296, Accuracy: 0.6669921875\n",
      "Batch: 44, Loss: 1.102705717086792, Accuracy: 0.658203125\n",
      "Batch: 45, Loss: 1.1987394094467163, Accuracy: 0.6279296875\n",
      "Batch: 46, Loss: 1.0520235300064087, Accuracy: 0.6552734375\n",
      "Batch: 47, Loss: 1.048719882965088, Accuracy: 0.6494140625\n",
      "Batch: 48, Loss: 1.2264373302459717, Accuracy: 0.6083984375\n",
      "Batch: 49, Loss: 1.3144967555999756, Accuracy: 0.5986328125\n",
      "Batch: 50, Loss: 1.0345032215118408, Accuracy: 0.662109375\n",
      "Batch: 51, Loss: 1.0810073614120483, Accuracy: 0.64453125\n",
      "Batch: 52, Loss: 1.0148707628250122, Accuracy: 0.6767578125\n",
      "Batch: 53, Loss: 1.2399250268936157, Accuracy: 0.625\n",
      "Batch: 54, Loss: 1.1709500551223755, Accuracy: 0.638671875\n",
      "Batch: 55, Loss: 1.1676374673843384, Accuracy: 0.646484375\n",
      "Batch: 56, Loss: 1.0901511907577515, Accuracy: 0.66015625\n",
      "Batch: 57, Loss: 1.2741011381149292, Accuracy: 0.6162109375\n",
      "Batch: 58, Loss: 1.214234471321106, Accuracy: 0.6376953125\n",
      "Batch: 59, Loss: 1.098636269569397, Accuracy: 0.654296875\n",
      "Batch: 60, Loss: 1.2728763818740845, Accuracy: 0.5888671875\n",
      "Batch: 61, Loss: 1.1576993465423584, Accuracy: 0.6396484375\n",
      "Batch: 62, Loss: 1.0754005908966064, Accuracy: 0.666015625\n",
      "Batch: 63, Loss: 0.8987256288528442, Accuracy: 0.73828125\n",
      "Batch: 64, Loss: 1.0672333240509033, Accuracy: 0.6689453125\n",
      "Batch: 65, Loss: 1.0088176727294922, Accuracy: 0.66796875\n",
      "Batch: 66, Loss: 0.9590575695037842, Accuracy: 0.689453125\n",
      "Batch: 67, Loss: 1.0693081617355347, Accuracy: 0.658203125\n",
      "Batch: 68, Loss: 1.1508591175079346, Accuracy: 0.6484375\n",
      "Batch: 69, Loss: 1.0218570232391357, Accuracy: 0.6748046875\n",
      "Batch: 70, Loss: 1.02214515209198, Accuracy: 0.66015625\n",
      "Batch: 71, Loss: 0.937264621257782, Accuracy: 0.677734375\n",
      "Batch: 72, Loss: 1.0263832807540894, Accuracy: 0.6640625\n",
      "Batch: 73, Loss: 1.0371623039245605, Accuracy: 0.658203125\n",
      "Batch: 74, Loss: 0.9759036898612976, Accuracy: 0.6689453125\n",
      "Batch: 75, Loss: 0.8907648324966431, Accuracy: 0.7109375\n",
      "Batch: 76, Loss: 0.9986292719841003, Accuracy: 0.685546875\n",
      "Batch: 77, Loss: 1.0935848951339722, Accuracy: 0.65625\n",
      "Batch: 78, Loss: 0.9946368932723999, Accuracy: 0.6787109375\n",
      "Batch: 79, Loss: 1.0425807237625122, Accuracy: 0.666015625\n",
      "Batch: 80, Loss: 1.0129307508468628, Accuracy: 0.6806640625\n",
      "Batch: 81, Loss: 0.9875215291976929, Accuracy: 0.6748046875\n",
      "Batch: 82, Loss: 0.9091353416442871, Accuracy: 0.70703125\n",
      "Batch: 83, Loss: 0.9529967904090881, Accuracy: 0.6923828125\n",
      "Batch: 84, Loss: 0.8914533257484436, Accuracy: 0.716796875\n",
      "Batch: 85, Loss: 0.90357506275177, Accuracy: 0.7177734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 86, Loss: 0.9043482542037964, Accuracy: 0.7099609375\n",
      "Batch: 87, Loss: 0.9249700307846069, Accuracy: 0.6953125\n",
      "Batch: 88, Loss: 0.9665412306785583, Accuracy: 0.6728515625\n",
      "Batch: 89, Loss: 0.9839483499526978, Accuracy: 0.6787109375\n",
      "Batch: 90, Loss: 0.988247275352478, Accuracy: 0.677734375\n",
      "Batch: 91, Loss: 1.0826780796051025, Accuracy: 0.6552734375\n",
      "Batch: 92, Loss: 0.894001841545105, Accuracy: 0.70703125\n",
      "Batch: 93, Loss: 0.872706949710846, Accuracy: 0.7119140625\n",
      "Batch: 94, Loss: 0.9586523175239563, Accuracy: 0.689453125\n",
      "Batch: 95, Loss: 0.9610880017280579, Accuracy: 0.6982421875\n",
      "Batch: 96, Loss: 0.9619752168655396, Accuracy: 0.6708984375\n",
      "Batch: 97, Loss: 0.943202555179596, Accuracy: 0.6845703125\n",
      "Batch: 98, Loss: 1.0215637683868408, Accuracy: 0.6708984375\n",
      "Batch: 99, Loss: 0.9540485739707947, Accuracy: 0.68359375\n",
      "Batch: 100, Loss: 1.054930329322815, Accuracy: 0.673828125\n",
      "Batch: 101, Loss: 0.9850850105285645, Accuracy: 0.69921875\n",
      "Batch: 102, Loss: 0.9844356775283813, Accuracy: 0.6865234375\n",
      "Batch: 103, Loss: 1.0310165882110596, Accuracy: 0.6650390625\n",
      "Batch: 104, Loss: 1.0312831401824951, Accuracy: 0.66015625\n",
      "Batch: 105, Loss: 0.8856188058853149, Accuracy: 0.712890625\n",
      "Batch: 106, Loss: 0.9471784830093384, Accuracy: 0.7080078125\n",
      "Batch: 107, Loss: 0.9593181610107422, Accuracy: 0.6845703125\n",
      "Batch: 108, Loss: 0.9040831327438354, Accuracy: 0.70703125\n",
      "Batch: 109, Loss: 0.9849029779434204, Accuracy: 0.70703125\n",
      "Batch: 110, Loss: 0.9296826124191284, Accuracy: 0.705078125\n",
      "Batch: 111, Loss: 1.0312222242355347, Accuracy: 0.6875\n",
      "Batch: 112, Loss: 0.9598859548568726, Accuracy: 0.701171875\n",
      "Saved Weights at epoch 10 to file Weights_10.h5\n",
      "Epoch 11/90\n",
      "Batch: 1, Loss: 1.4213464260101318, Accuracy: 0.5966796875\n",
      "Batch: 2, Loss: 1.0904744863510132, Accuracy: 0.6767578125\n",
      "Batch: 3, Loss: 1.1064268350601196, Accuracy: 0.6474609375\n",
      "Batch: 4, Loss: 1.062068223953247, Accuracy: 0.6611328125\n",
      "Batch: 5, Loss: 1.0848994255065918, Accuracy: 0.658203125\n",
      "Batch: 6, Loss: 1.0808489322662354, Accuracy: 0.671875\n",
      "Batch: 7, Loss: 0.999093234539032, Accuracy: 0.693359375\n",
      "Batch: 8, Loss: 0.9403133988380432, Accuracy: 0.6884765625\n",
      "Batch: 9, Loss: 0.9542791843414307, Accuracy: 0.703125\n",
      "Batch: 10, Loss: 1.0389800071716309, Accuracy: 0.6728515625\n",
      "Batch: 11, Loss: 0.913539469242096, Accuracy: 0.71484375\n",
      "Batch: 12, Loss: 0.9790564775466919, Accuracy: 0.6787109375\n",
      "Batch: 13, Loss: 0.94671630859375, Accuracy: 0.7177734375\n",
      "Batch: 14, Loss: 1.0536136627197266, Accuracy: 0.67578125\n",
      "Batch: 15, Loss: 0.986851692199707, Accuracy: 0.7021484375\n",
      "Batch: 16, Loss: 1.0201321840286255, Accuracy: 0.6806640625\n",
      "Batch: 17, Loss: 0.9927467703819275, Accuracy: 0.6787109375\n",
      "Batch: 18, Loss: 0.9226416349411011, Accuracy: 0.6962890625\n",
      "Batch: 19, Loss: 0.9643802046775818, Accuracy: 0.6845703125\n",
      "Batch: 20, Loss: 0.9686877727508545, Accuracy: 0.69921875\n",
      "Batch: 21, Loss: 0.9276756644248962, Accuracy: 0.7001953125\n",
      "Batch: 22, Loss: 0.9448171854019165, Accuracy: 0.693359375\n",
      "Batch: 23, Loss: 1.0549300909042358, Accuracy: 0.6806640625\n",
      "Batch: 24, Loss: 1.051736831665039, Accuracy: 0.6572265625\n",
      "Batch: 25, Loss: 1.1359777450561523, Accuracy: 0.634765625\n",
      "Batch: 26, Loss: 1.2458910942077637, Accuracy: 0.6142578125\n",
      "Batch: 27, Loss: 1.0716040134429932, Accuracy: 0.6552734375\n",
      "Batch: 28, Loss: 0.9309776425361633, Accuracy: 0.6806640625\n",
      "Batch: 29, Loss: 1.0093908309936523, Accuracy: 0.681640625\n",
      "Batch: 30, Loss: 1.033036470413208, Accuracy: 0.6669921875\n",
      "Batch: 31, Loss: 1.0096819400787354, Accuracy: 0.6845703125\n",
      "Batch: 32, Loss: 0.9893234968185425, Accuracy: 0.6708984375\n",
      "Batch: 33, Loss: 1.0009636878967285, Accuracy: 0.6650390625\n",
      "Batch: 34, Loss: 0.9158718585968018, Accuracy: 0.701171875\n",
      "Batch: 35, Loss: 0.9742020964622498, Accuracy: 0.6767578125\n",
      "Batch: 36, Loss: 0.9917680025100708, Accuracy: 0.6650390625\n",
      "Batch: 37, Loss: 0.9129576683044434, Accuracy: 0.693359375\n",
      "Batch: 38, Loss: 1.0018397569656372, Accuracy: 0.6611328125\n",
      "Batch: 39, Loss: 0.9592534899711609, Accuracy: 0.703125\n",
      "Batch: 40, Loss: 0.9923684000968933, Accuracy: 0.69140625\n",
      "Batch: 41, Loss: 0.9588971734046936, Accuracy: 0.681640625\n",
      "Batch: 42, Loss: 0.8892580270767212, Accuracy: 0.6982421875\n",
      "Batch: 43, Loss: 1.0012249946594238, Accuracy: 0.68359375\n",
      "Batch: 44, Loss: 1.0871514081954956, Accuracy: 0.669921875\n",
      "Batch: 45, Loss: 1.1566593647003174, Accuracy: 0.6474609375\n",
      "Batch: 46, Loss: 1.0156397819519043, Accuracy: 0.669921875\n",
      "Batch: 47, Loss: 1.0307767391204834, Accuracy: 0.640625\n",
      "Batch: 48, Loss: 1.1958348751068115, Accuracy: 0.6220703125\n",
      "Batch: 49, Loss: 1.2753422260284424, Accuracy: 0.5986328125\n",
      "Batch: 50, Loss: 0.995030403137207, Accuracy: 0.6875\n",
      "Batch: 51, Loss: 1.0701241493225098, Accuracy: 0.646484375\n",
      "Batch: 52, Loss: 0.999381422996521, Accuracy: 0.6826171875\n",
      "Batch: 53, Loss: 1.1999478340148926, Accuracy: 0.6533203125\n",
      "Batch: 54, Loss: 1.1256299018859863, Accuracy: 0.666015625\n",
      "Batch: 55, Loss: 1.1198742389678955, Accuracy: 0.673828125\n",
      "Batch: 56, Loss: 1.025282382965088, Accuracy: 0.6806640625\n",
      "Batch: 57, Loss: 1.2162796258926392, Accuracy: 0.62890625\n",
      "Batch: 58, Loss: 1.1757168769836426, Accuracy: 0.640625\n",
      "Batch: 59, Loss: 1.0508394241333008, Accuracy: 0.6748046875\n",
      "Batch: 60, Loss: 1.2033365964889526, Accuracy: 0.615234375\n",
      "Batch: 61, Loss: 1.1084926128387451, Accuracy: 0.654296875\n",
      "Batch: 62, Loss: 1.042036533355713, Accuracy: 0.6669921875\n",
      "Batch: 63, Loss: 0.8570783734321594, Accuracy: 0.724609375\n",
      "Batch: 64, Loss: 1.007483720779419, Accuracy: 0.6884765625\n",
      "Batch: 65, Loss: 0.9545896053314209, Accuracy: 0.6796875\n",
      "Batch: 66, Loss: 0.9160175323486328, Accuracy: 0.6962890625\n",
      "Batch: 67, Loss: 1.0011640787124634, Accuracy: 0.6904296875\n",
      "Batch: 68, Loss: 1.1082987785339355, Accuracy: 0.6591796875\n",
      "Batch: 69, Loss: 0.9733874797821045, Accuracy: 0.69140625\n",
      "Batch: 70, Loss: 0.965843915939331, Accuracy: 0.66796875\n",
      "Batch: 71, Loss: 0.902499258518219, Accuracy: 0.7021484375\n",
      "Batch: 72, Loss: 0.9757752418518066, Accuracy: 0.6806640625\n",
      "Batch: 73, Loss: 0.9903334975242615, Accuracy: 0.669921875\n",
      "Batch: 74, Loss: 0.9586794972419739, Accuracy: 0.662109375\n",
      "Batch: 75, Loss: 0.8580204248428345, Accuracy: 0.71875\n",
      "Batch: 76, Loss: 0.9482011198997498, Accuracy: 0.6923828125\n",
      "Batch: 77, Loss: 1.0542521476745605, Accuracy: 0.66015625\n",
      "Batch: 78, Loss: 0.959343433380127, Accuracy: 0.6884765625\n",
      "Batch: 79, Loss: 1.0304129123687744, Accuracy: 0.6728515625\n",
      "Batch: 80, Loss: 0.9576449990272522, Accuracy: 0.6962890625\n",
      "Batch: 81, Loss: 0.975931704044342, Accuracy: 0.67578125\n",
      "Batch: 82, Loss: 0.9100584387779236, Accuracy: 0.7021484375\n",
      "Batch: 83, Loss: 0.9201814532279968, Accuracy: 0.6962890625\n",
      "Batch: 84, Loss: 0.8444794416427612, Accuracy: 0.7421875\n",
      "Batch: 85, Loss: 0.8670610785484314, Accuracy: 0.71875\n",
      "Batch: 86, Loss: 0.8773802518844604, Accuracy: 0.7138671875\n",
      "Batch: 87, Loss: 0.8860104084014893, Accuracy: 0.708984375\n",
      "Batch: 88, Loss: 0.9429428577423096, Accuracy: 0.6962890625\n",
      "Batch: 89, Loss: 0.9813858270645142, Accuracy: 0.6875\n",
      "Batch: 90, Loss: 0.9548565149307251, Accuracy: 0.693359375\n",
      "Batch: 91, Loss: 1.0504531860351562, Accuracy: 0.662109375\n",
      "Batch: 92, Loss: 0.895894467830658, Accuracy: 0.7099609375\n",
      "Batch: 93, Loss: 0.8556755185127258, Accuracy: 0.72265625\n",
      "Batch: 94, Loss: 0.9395524263381958, Accuracy: 0.685546875\n",
      "Batch: 95, Loss: 0.9531317949295044, Accuracy: 0.6943359375\n",
      "Batch: 96, Loss: 0.9231319427490234, Accuracy: 0.69140625\n",
      "Batch: 97, Loss: 0.9051122069358826, Accuracy: 0.693359375\n",
      "Batch: 98, Loss: 0.9704437255859375, Accuracy: 0.6875\n",
      "Batch: 99, Loss: 0.9128061532974243, Accuracy: 0.705078125\n",
      "Batch: 100, Loss: 1.0200409889221191, Accuracy: 0.6708984375\n",
      "Batch: 101, Loss: 0.9460389018058777, Accuracy: 0.689453125\n",
      "Batch: 102, Loss: 0.9430687427520752, Accuracy: 0.7080078125\n",
      "Batch: 103, Loss: 0.9942189455032349, Accuracy: 0.6630859375\n",
      "Batch: 104, Loss: 0.9690321087837219, Accuracy: 0.671875\n",
      "Batch: 105, Loss: 0.8476564884185791, Accuracy: 0.73046875\n",
      "Batch: 106, Loss: 0.9058060646057129, Accuracy: 0.7060546875\n",
      "Batch: 107, Loss: 0.9124857187271118, Accuracy: 0.693359375\n",
      "Batch: 108, Loss: 0.8879498839378357, Accuracy: 0.716796875\n",
      "Batch: 109, Loss: 0.915761411190033, Accuracy: 0.724609375\n",
      "Batch: 110, Loss: 0.8992692828178406, Accuracy: 0.7197265625\n",
      "Batch: 111, Loss: 0.9695035219192505, Accuracy: 0.708984375\n",
      "Batch: 112, Loss: 0.9424270391464233, Accuracy: 0.7041015625\n",
      "Epoch 12/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 1, Loss: 1.3821274042129517, Accuracy: 0.5966796875\n",
      "Batch: 2, Loss: 1.05506432056427, Accuracy: 0.6806640625\n",
      "Batch: 3, Loss: 1.0667953491210938, Accuracy: 0.666015625\n",
      "Batch: 4, Loss: 1.0067933797836304, Accuracy: 0.6845703125\n",
      "Batch: 5, Loss: 1.0444570779800415, Accuracy: 0.67578125\n",
      "Batch: 6, Loss: 1.0432155132293701, Accuracy: 0.6845703125\n",
      "Batch: 7, Loss: 0.9747114181518555, Accuracy: 0.7041015625\n",
      "Batch: 8, Loss: 0.8756495714187622, Accuracy: 0.7294921875\n",
      "Batch: 9, Loss: 0.9303734302520752, Accuracy: 0.697265625\n",
      "Batch: 10, Loss: 0.9965612888336182, Accuracy: 0.66796875\n",
      "Batch: 11, Loss: 0.8924466967582703, Accuracy: 0.7177734375\n",
      "Batch: 12, Loss: 0.9251068234443665, Accuracy: 0.697265625\n",
      "Batch: 13, Loss: 0.906998872756958, Accuracy: 0.73046875\n",
      "Batch: 14, Loss: 1.008577585220337, Accuracy: 0.6806640625\n",
      "Batch: 15, Loss: 0.9628396034240723, Accuracy: 0.7041015625\n",
      "Batch: 16, Loss: 0.9995147585868835, Accuracy: 0.6875\n",
      "Batch: 17, Loss: 0.9618223905563354, Accuracy: 0.69140625\n",
      "Batch: 18, Loss: 0.8960822820663452, Accuracy: 0.6943359375\n",
      "Batch: 19, Loss: 0.9009323716163635, Accuracy: 0.7119140625\n",
      "Batch: 20, Loss: 0.9267892837524414, Accuracy: 0.703125\n",
      "Batch: 21, Loss: 0.9079208374023438, Accuracy: 0.7041015625\n",
      "Batch: 22, Loss: 0.8878776431083679, Accuracy: 0.7216796875\n",
      "Batch: 23, Loss: 1.0237256288528442, Accuracy: 0.6923828125\n",
      "Batch: 24, Loss: 1.009521722793579, Accuracy: 0.671875\n",
      "Batch: 25, Loss: 1.0981225967407227, Accuracy: 0.6484375\n",
      "Batch: 26, Loss: 1.199455738067627, Accuracy: 0.630859375\n",
      "Batch: 27, Loss: 1.043521761894226, Accuracy: 0.6689453125\n",
      "Batch: 28, Loss: 0.9153291583061218, Accuracy: 0.6884765625\n",
      "Batch: 29, Loss: 0.9749252796173096, Accuracy: 0.68359375\n",
      "Batch: 30, Loss: 0.9826819896697998, Accuracy: 0.6875\n",
      "Batch: 31, Loss: 0.977043867111206, Accuracy: 0.6748046875\n",
      "Batch: 32, Loss: 0.9353170990943909, Accuracy: 0.6884765625\n",
      "Batch: 33, Loss: 0.9486842155456543, Accuracy: 0.6787109375\n",
      "Batch: 34, Loss: 0.8703911900520325, Accuracy: 0.7255859375\n",
      "Batch: 35, Loss: 0.9323041439056396, Accuracy: 0.6875\n",
      "Batch: 36, Loss: 0.9342014193534851, Accuracy: 0.697265625\n",
      "Batch: 37, Loss: 0.8755478858947754, Accuracy: 0.701171875\n",
      "Batch: 38, Loss: 0.9683071374893188, Accuracy: 0.68359375\n",
      "Batch: 39, Loss: 0.9391719102859497, Accuracy: 0.69140625\n",
      "Batch: 40, Loss: 0.9543722867965698, Accuracy: 0.697265625\n",
      "Batch: 41, Loss: 0.9307729601860046, Accuracy: 0.6953125\n",
      "Batch: 42, Loss: 0.8705480098724365, Accuracy: 0.703125\n",
      "Batch: 43, Loss: 0.9686686992645264, Accuracy: 0.6904296875\n",
      "Batch: 44, Loss: 1.040454626083374, Accuracy: 0.677734375\n",
      "Batch: 45, Loss: 1.129889726638794, Accuracy: 0.6474609375\n",
      "Batch: 46, Loss: 0.9669776558876038, Accuracy: 0.6865234375\n",
      "Batch: 47, Loss: 0.9962508678436279, Accuracy: 0.6640625\n",
      "Batch: 48, Loss: 1.1499099731445312, Accuracy: 0.63671875\n",
      "Batch: 49, Loss: 1.241833209991455, Accuracy: 0.6259765625\n",
      "Batch: 50, Loss: 0.9415726065635681, Accuracy: 0.69140625\n",
      "Batch: 51, Loss: 1.0213671922683716, Accuracy: 0.669921875\n",
      "Batch: 52, Loss: 0.9412875771522522, Accuracy: 0.7041015625\n",
      "Batch: 53, Loss: 1.1647685766220093, Accuracy: 0.66015625\n",
      "Batch: 54, Loss: 1.1129662990570068, Accuracy: 0.681640625\n",
      "Batch: 55, Loss: 1.0776852369308472, Accuracy: 0.669921875\n",
      "Batch: 56, Loss: 0.997014045715332, Accuracy: 0.677734375\n",
      "Batch: 57, Loss: 1.198409914970398, Accuracy: 0.63671875\n",
      "Batch: 58, Loss: 1.1236517429351807, Accuracy: 0.6630859375\n",
      "Batch: 59, Loss: 1.0265464782714844, Accuracy: 0.673828125\n",
      "Batch: 60, Loss: 1.168235182762146, Accuracy: 0.6162109375\n",
      "Batch: 61, Loss: 1.0822432041168213, Accuracy: 0.6552734375\n",
      "Batch: 62, Loss: 1.0278640985488892, Accuracy: 0.6787109375\n",
      "Batch: 63, Loss: 0.8277542591094971, Accuracy: 0.744140625\n",
      "Batch: 64, Loss: 0.975969672203064, Accuracy: 0.6953125\n",
      "Batch: 65, Loss: 0.9223875999450684, Accuracy: 0.6875\n",
      "Batch: 66, Loss: 0.8931790590286255, Accuracy: 0.6982421875\n",
      "Batch: 67, Loss: 0.9439289569854736, Accuracy: 0.69921875\n",
      "Batch: 68, Loss: 1.054569959640503, Accuracy: 0.666015625\n",
      "Batch: 69, Loss: 0.9176856279373169, Accuracy: 0.701171875\n",
      "Batch: 70, Loss: 0.9412441849708557, Accuracy: 0.685546875\n",
      "Batch: 71, Loss: 0.8919669389724731, Accuracy: 0.69921875\n",
      "Batch: 72, Loss: 0.957316517829895, Accuracy: 0.6845703125\n",
      "Batch: 73, Loss: 0.9601110816001892, Accuracy: 0.689453125\n",
      "Batch: 74, Loss: 0.926324725151062, Accuracy: 0.69140625\n",
      "Batch: 75, Loss: 0.8163002133369446, Accuracy: 0.7412109375\n",
      "Batch: 76, Loss: 0.9140979051589966, Accuracy: 0.7021484375\n",
      "Batch: 77, Loss: 1.0316660404205322, Accuracy: 0.6728515625\n",
      "Batch: 78, Loss: 0.9364960193634033, Accuracy: 0.69140625\n",
      "Batch: 79, Loss: 0.9929704070091248, Accuracy: 0.6884765625\n",
      "Batch: 80, Loss: 0.9359877109527588, Accuracy: 0.69140625\n",
      "Batch: 81, Loss: 0.9358165264129639, Accuracy: 0.697265625\n",
      "Batch: 82, Loss: 0.8446782827377319, Accuracy: 0.73046875\n",
      "Batch: 83, Loss: 0.8977910876274109, Accuracy: 0.7177734375\n",
      "Batch: 84, Loss: 0.8216040134429932, Accuracy: 0.732421875\n",
      "Batch: 85, Loss: 0.8614088892936707, Accuracy: 0.71875\n",
      "Batch: 86, Loss: 0.830916702747345, Accuracy: 0.728515625\n",
      "Batch: 87, Loss: 0.8611453175544739, Accuracy: 0.732421875\n",
      "Batch: 88, Loss: 0.9088423252105713, Accuracy: 0.701171875\n",
      "Batch: 89, Loss: 0.9289321303367615, Accuracy: 0.7080078125\n",
      "Batch: 90, Loss: 0.9188319444656372, Accuracy: 0.69921875\n",
      "Batch: 91, Loss: 0.9881000518798828, Accuracy: 0.673828125\n",
      "Batch: 92, Loss: 0.8453918695449829, Accuracy: 0.71875\n",
      "Batch: 93, Loss: 0.8192356824874878, Accuracy: 0.73046875\n",
      "Batch: 94, Loss: 0.9015836715698242, Accuracy: 0.6962890625\n",
      "Batch: 95, Loss: 0.9169328808784485, Accuracy: 0.7001953125\n",
      "Batch: 96, Loss: 0.8987175226211548, Accuracy: 0.693359375\n",
      "Batch: 97, Loss: 0.8714727163314819, Accuracy: 0.7138671875\n",
      "Batch: 98, Loss: 0.9547988176345825, Accuracy: 0.6728515625\n",
      "Batch: 99, Loss: 0.9156515002250671, Accuracy: 0.6953125\n",
      "Batch: 100, Loss: 1.0066661834716797, Accuracy: 0.671875\n",
      "Batch: 101, Loss: 0.9093554019927979, Accuracy: 0.7109375\n",
      "Batch: 102, Loss: 0.908475399017334, Accuracy: 0.716796875\n",
      "Batch: 103, Loss: 0.9616876840591431, Accuracy: 0.67578125\n",
      "Batch: 104, Loss: 0.9390734434127808, Accuracy: 0.6943359375\n",
      "Batch: 105, Loss: 0.8380007147789001, Accuracy: 0.7412109375\n",
      "Batch: 106, Loss: 0.8972228765487671, Accuracy: 0.708984375\n",
      "Batch: 107, Loss: 0.8939809799194336, Accuracy: 0.712890625\n",
      "Batch: 108, Loss: 0.8540569543838501, Accuracy: 0.73046875\n",
      "Batch: 109, Loss: 0.8809962868690491, Accuracy: 0.7255859375\n",
      "Batch: 110, Loss: 0.8426817655563354, Accuracy: 0.73828125\n",
      "Batch: 111, Loss: 0.9326110482215881, Accuracy: 0.712890625\n",
      "Batch: 112, Loss: 0.8753038644790649, Accuracy: 0.716796875\n",
      "Epoch 13/90\n",
      "Batch: 1, Loss: 1.3314154148101807, Accuracy: 0.6220703125\n",
      "Batch: 2, Loss: 1.0359548330307007, Accuracy: 0.677734375\n",
      "Batch: 3, Loss: 1.0209323167800903, Accuracy: 0.66796875\n",
      "Batch: 4, Loss: 0.9806348085403442, Accuracy: 0.6796875\n",
      "Batch: 5, Loss: 0.9968804121017456, Accuracy: 0.6826171875\n",
      "Batch: 6, Loss: 1.0262281894683838, Accuracy: 0.6826171875\n",
      "Batch: 7, Loss: 0.9325369000434875, Accuracy: 0.7099609375\n",
      "Batch: 8, Loss: 0.8558879494667053, Accuracy: 0.7216796875\n",
      "Batch: 9, Loss: 0.8946112394332886, Accuracy: 0.7099609375\n",
      "Batch: 10, Loss: 0.9717175960540771, Accuracy: 0.685546875\n",
      "Batch: 11, Loss: 0.8663857579231262, Accuracy: 0.724609375\n",
      "Batch: 12, Loss: 0.9006810188293457, Accuracy: 0.712890625\n",
      "Batch: 13, Loss: 0.8640570640563965, Accuracy: 0.7412109375\n",
      "Batch: 14, Loss: 0.966899573802948, Accuracy: 0.6826171875\n",
      "Batch: 15, Loss: 0.9221941232681274, Accuracy: 0.7021484375\n",
      "Batch: 16, Loss: 0.9565484523773193, Accuracy: 0.693359375\n",
      "Batch: 17, Loss: 0.9338065385818481, Accuracy: 0.7060546875\n",
      "Batch: 18, Loss: 0.8692176342010498, Accuracy: 0.708984375\n",
      "Batch: 19, Loss: 0.8678834438323975, Accuracy: 0.7080078125\n",
      "Batch: 20, Loss: 0.9048535823822021, Accuracy: 0.7275390625\n",
      "Batch: 21, Loss: 0.8781082630157471, Accuracy: 0.712890625\n",
      "Batch: 22, Loss: 0.8614580631256104, Accuracy: 0.7236328125\n",
      "Batch: 23, Loss: 0.9880558848381042, Accuracy: 0.693359375\n",
      "Batch: 24, Loss: 0.9846621751785278, Accuracy: 0.689453125\n",
      "Batch: 25, Loss: 1.069044828414917, Accuracy: 0.6533203125\n",
      "Batch: 26, Loss: 1.1613333225250244, Accuracy: 0.6494140625\n",
      "Batch: 27, Loss: 1.003836750984192, Accuracy: 0.67578125\n",
      "Batch: 28, Loss: 0.873409628868103, Accuracy: 0.708984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 29, Loss: 0.9363045692443848, Accuracy: 0.6953125\n",
      "Batch: 30, Loss: 0.9773260951042175, Accuracy: 0.6767578125\n",
      "Batch: 31, Loss: 0.924317479133606, Accuracy: 0.693359375\n",
      "Batch: 32, Loss: 0.9012317657470703, Accuracy: 0.701171875\n",
      "Batch: 33, Loss: 0.8957928419113159, Accuracy: 0.6826171875\n",
      "Batch: 34, Loss: 0.8498258590698242, Accuracy: 0.71875\n",
      "Batch: 35, Loss: 0.899182140827179, Accuracy: 0.7021484375\n",
      "Batch: 36, Loss: 0.9335975050926208, Accuracy: 0.6884765625\n",
      "Batch: 37, Loss: 0.8481735587120056, Accuracy: 0.7216796875\n",
      "Batch: 38, Loss: 0.9420386552810669, Accuracy: 0.6796875\n",
      "Batch: 39, Loss: 0.9047837257385254, Accuracy: 0.70703125\n",
      "Batch: 40, Loss: 0.9041397571563721, Accuracy: 0.708984375\n",
      "Batch: 41, Loss: 0.9097154140472412, Accuracy: 0.6962890625\n",
      "Batch: 42, Loss: 0.8427169322967529, Accuracy: 0.7216796875\n",
      "Batch: 43, Loss: 0.9561982154846191, Accuracy: 0.7099609375\n",
      "Batch: 44, Loss: 0.995606541633606, Accuracy: 0.6875\n",
      "Batch: 45, Loss: 1.0969622135162354, Accuracy: 0.6552734375\n",
      "Batch: 46, Loss: 0.9292573928833008, Accuracy: 0.685546875\n",
      "Batch: 47, Loss: 0.9688588976860046, Accuracy: 0.666015625\n",
      "Batch: 48, Loss: 1.0743186473846436, Accuracy: 0.6689453125\n",
      "Batch: 49, Loss: 1.1973841190338135, Accuracy: 0.6337890625\n",
      "Batch: 50, Loss: 0.9071197509765625, Accuracy: 0.693359375\n",
      "Batch: 51, Loss: 1.0025321245193481, Accuracy: 0.6748046875\n",
      "Batch: 52, Loss: 0.9247631430625916, Accuracy: 0.7021484375\n",
      "Batch: 53, Loss: 1.1371099948883057, Accuracy: 0.66015625\n",
      "Batch: 54, Loss: 1.0582003593444824, Accuracy: 0.6748046875\n",
      "Batch: 55, Loss: 1.0360581874847412, Accuracy: 0.6708984375\n",
      "Batch: 56, Loss: 0.9741355180740356, Accuracy: 0.6806640625\n",
      "Batch: 57, Loss: 1.1362906694412231, Accuracy: 0.646484375\n",
      "Batch: 58, Loss: 1.0914418697357178, Accuracy: 0.65625\n",
      "Batch: 59, Loss: 0.979107141494751, Accuracy: 0.6875\n",
      "Batch: 60, Loss: 1.1152334213256836, Accuracy: 0.6328125\n",
      "Batch: 61, Loss: 1.0749151706695557, Accuracy: 0.6513671875\n",
      "Batch: 62, Loss: 0.9837674498558044, Accuracy: 0.693359375\n",
      "Batch: 63, Loss: 0.800767183303833, Accuracy: 0.7353515625\n",
      "Batch: 64, Loss: 0.9290177822113037, Accuracy: 0.705078125\n",
      "Batch: 65, Loss: 0.9277273416519165, Accuracy: 0.68359375\n",
      "Batch: 66, Loss: 0.8601616621017456, Accuracy: 0.7138671875\n",
      "Batch: 67, Loss: 0.9291093945503235, Accuracy: 0.7041015625\n",
      "Batch: 68, Loss: 1.0174049139022827, Accuracy: 0.671875\n",
      "Batch: 69, Loss: 0.8998008966445923, Accuracy: 0.7138671875\n",
      "Batch: 70, Loss: 0.8911242485046387, Accuracy: 0.7001953125\n",
      "Batch: 71, Loss: 0.8403456211090088, Accuracy: 0.7138671875\n",
      "Batch: 72, Loss: 0.9317635893821716, Accuracy: 0.69140625\n",
      "Batch: 73, Loss: 0.9321862459182739, Accuracy: 0.6884765625\n",
      "Batch: 74, Loss: 0.9009085893630981, Accuracy: 0.701171875\n",
      "Batch: 75, Loss: 0.8026663661003113, Accuracy: 0.7431640625\n",
      "Batch: 76, Loss: 0.9068112373352051, Accuracy: 0.7109375\n",
      "Batch: 77, Loss: 0.9817811846733093, Accuracy: 0.693359375\n",
      "Batch: 78, Loss: 0.9119173288345337, Accuracy: 0.6884765625\n",
      "Batch: 79, Loss: 0.9416577816009521, Accuracy: 0.7001953125\n",
      "Batch: 80, Loss: 0.9140045642852783, Accuracy: 0.697265625\n",
      "Batch: 81, Loss: 0.9028016328811646, Accuracy: 0.70703125\n",
      "Batch: 82, Loss: 0.8457338809967041, Accuracy: 0.7314453125\n",
      "Batch: 83, Loss: 0.844127893447876, Accuracy: 0.7265625\n",
      "Batch: 84, Loss: 0.7918648719787598, Accuracy: 0.7392578125\n",
      "Batch: 85, Loss: 0.8158697485923767, Accuracy: 0.734375\n",
      "Batch: 86, Loss: 0.8106428384780884, Accuracy: 0.732421875\n",
      "Batch: 87, Loss: 0.8316079378128052, Accuracy: 0.736328125\n",
      "Batch: 88, Loss: 0.8579839468002319, Accuracy: 0.71484375\n",
      "Batch: 89, Loss: 0.8972335457801819, Accuracy: 0.7041015625\n",
      "Batch: 90, Loss: 0.8889526128768921, Accuracy: 0.7060546875\n",
      "Batch: 91, Loss: 1.013342022895813, Accuracy: 0.677734375\n",
      "Batch: 92, Loss: 0.8337829113006592, Accuracy: 0.7197265625\n",
      "Batch: 93, Loss: 0.7978442907333374, Accuracy: 0.724609375\n",
      "Batch: 94, Loss: 0.8867431282997131, Accuracy: 0.70703125\n",
      "Batch: 95, Loss: 0.8907105922698975, Accuracy: 0.71484375\n",
      "Batch: 96, Loss: 0.8570277690887451, Accuracy: 0.7080078125\n",
      "Batch: 97, Loss: 0.847206711769104, Accuracy: 0.724609375\n",
      "Batch: 98, Loss: 0.9447964429855347, Accuracy: 0.693359375\n",
      "Batch: 99, Loss: 0.8871947526931763, Accuracy: 0.7060546875\n",
      "Batch: 100, Loss: 0.951413094997406, Accuracy: 0.6953125\n",
      "Batch: 101, Loss: 0.9059575796127319, Accuracy: 0.697265625\n",
      "Batch: 102, Loss: 0.9006619453430176, Accuracy: 0.7080078125\n",
      "Batch: 103, Loss: 0.9245349764823914, Accuracy: 0.697265625\n",
      "Batch: 104, Loss: 0.9442665576934814, Accuracy: 0.685546875\n",
      "Batch: 105, Loss: 0.8166000247001648, Accuracy: 0.7392578125\n",
      "Batch: 106, Loss: 0.8500548005104065, Accuracy: 0.7158203125\n",
      "Batch: 107, Loss: 0.8801103830337524, Accuracy: 0.6923828125\n",
      "Batch: 108, Loss: 0.8306134343147278, Accuracy: 0.7265625\n",
      "Batch: 109, Loss: 0.8478658199310303, Accuracy: 0.736328125\n",
      "Batch: 110, Loss: 0.8240169882774353, Accuracy: 0.740234375\n",
      "Batch: 111, Loss: 0.9326809048652649, Accuracy: 0.71875\n",
      "Batch: 112, Loss: 0.8753842115402222, Accuracy: 0.716796875\n",
      "Epoch 14/90\n",
      "Batch: 1, Loss: 1.2843722105026245, Accuracy: 0.6259765625\n",
      "Batch: 2, Loss: 1.0107033252716064, Accuracy: 0.69140625\n",
      "Batch: 3, Loss: 0.9869915246963501, Accuracy: 0.6865234375\n",
      "Batch: 4, Loss: 0.9392227530479431, Accuracy: 0.6923828125\n",
      "Batch: 5, Loss: 0.9709553718566895, Accuracy: 0.6875\n",
      "Batch: 6, Loss: 0.9768608212471008, Accuracy: 0.7099609375\n",
      "Batch: 7, Loss: 0.8860031962394714, Accuracy: 0.732421875\n",
      "Batch: 8, Loss: 0.8127840757369995, Accuracy: 0.73046875\n",
      "Batch: 9, Loss: 0.8414380550384521, Accuracy: 0.728515625\n",
      "Batch: 10, Loss: 0.9252433776855469, Accuracy: 0.7080078125\n",
      "Batch: 11, Loss: 0.8308993577957153, Accuracy: 0.73828125\n",
      "Batch: 12, Loss: 0.8612234592437744, Accuracy: 0.7373046875\n",
      "Batch: 13, Loss: 0.8484960794448853, Accuracy: 0.7431640625\n",
      "Batch: 14, Loss: 0.9439668655395508, Accuracy: 0.6953125\n",
      "Batch: 15, Loss: 0.8990447521209717, Accuracy: 0.71875\n",
      "Batch: 16, Loss: 0.9274994134902954, Accuracy: 0.7138671875\n",
      "Batch: 17, Loss: 0.9238348007202148, Accuracy: 0.705078125\n",
      "Batch: 18, Loss: 0.8144464492797852, Accuracy: 0.728515625\n",
      "Batch: 19, Loss: 0.8472909927368164, Accuracy: 0.7265625\n",
      "Batch: 20, Loss: 0.8937894105911255, Accuracy: 0.7158203125\n",
      "Batch: 21, Loss: 0.8601418733596802, Accuracy: 0.728515625\n",
      "Batch: 22, Loss: 0.832073986530304, Accuracy: 0.73046875\n",
      "Batch: 23, Loss: 0.9547887444496155, Accuracy: 0.701171875\n",
      "Batch: 24, Loss: 0.9665725231170654, Accuracy: 0.6884765625\n",
      "Batch: 25, Loss: 1.0499372482299805, Accuracy: 0.6650390625\n",
      "Batch: 26, Loss: 1.1314849853515625, Accuracy: 0.6513671875\n",
      "Batch: 27, Loss: 0.9705051183700562, Accuracy: 0.677734375\n",
      "Batch: 28, Loss: 0.8461266160011292, Accuracy: 0.708984375\n",
      "Batch: 29, Loss: 0.930730938911438, Accuracy: 0.697265625\n",
      "Batch: 30, Loss: 0.9228304624557495, Accuracy: 0.7060546875\n",
      "Batch: 31, Loss: 0.9230866432189941, Accuracy: 0.6875\n",
      "Batch: 32, Loss: 0.8800499439239502, Accuracy: 0.7021484375\n",
      "Batch: 33, Loss: 0.8941850662231445, Accuracy: 0.689453125\n",
      "Batch: 34, Loss: 0.8188836574554443, Accuracy: 0.7236328125\n",
      "Batch: 35, Loss: 0.8829888105392456, Accuracy: 0.7060546875\n",
      "Batch: 36, Loss: 0.914827287197113, Accuracy: 0.7080078125\n",
      "Batch: 37, Loss: 0.8376256227493286, Accuracy: 0.720703125\n",
      "Batch: 38, Loss: 0.9113386273384094, Accuracy: 0.69140625\n",
      "Batch: 39, Loss: 0.8940275311470032, Accuracy: 0.7109375\n",
      "Batch: 40, Loss: 0.8967134952545166, Accuracy: 0.703125\n",
      "Batch: 41, Loss: 0.8858413100242615, Accuracy: 0.7080078125\n",
      "Batch: 42, Loss: 0.8128313422203064, Accuracy: 0.7265625\n",
      "Batch: 43, Loss: 0.9216704368591309, Accuracy: 0.705078125\n",
      "Batch: 44, Loss: 0.9753936529159546, Accuracy: 0.693359375\n",
      "Batch: 45, Loss: 1.0385828018188477, Accuracy: 0.6611328125\n",
      "Batch: 46, Loss: 0.9052058458328247, Accuracy: 0.6923828125\n",
      "Batch: 47, Loss: 0.9279732704162598, Accuracy: 0.6845703125\n",
      "Batch: 48, Loss: 1.0471687316894531, Accuracy: 0.6826171875\n",
      "Batch: 49, Loss: 1.153994083404541, Accuracy: 0.6484375\n",
      "Batch: 50, Loss: 0.8959835767745972, Accuracy: 0.69921875\n",
      "Batch: 51, Loss: 0.9619430899620056, Accuracy: 0.677734375\n",
      "Batch: 52, Loss: 0.903590738773346, Accuracy: 0.701171875\n",
      "Batch: 53, Loss: 1.1022539138793945, Accuracy: 0.6650390625\n",
      "Batch: 54, Loss: 1.0396039485931396, Accuracy: 0.681640625\n",
      "Batch: 55, Loss: 0.9774736762046814, Accuracy: 0.703125\n",
      "Batch: 56, Loss: 0.9303455948829651, Accuracy: 0.697265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 57, Loss: 1.1200368404388428, Accuracy: 0.6611328125\n",
      "Batch: 58, Loss: 1.0665748119354248, Accuracy: 0.669921875\n",
      "Batch: 59, Loss: 0.9573167562484741, Accuracy: 0.69921875\n",
      "Batch: 60, Loss: 1.08357572555542, Accuracy: 0.6435546875\n",
      "Batch: 61, Loss: 1.0217959880828857, Accuracy: 0.666015625\n",
      "Batch: 62, Loss: 0.9655708074569702, Accuracy: 0.6875\n",
      "Batch: 63, Loss: 0.7753802537918091, Accuracy: 0.74609375\n",
      "Batch: 64, Loss: 0.9169712066650391, Accuracy: 0.6962890625\n",
      "Batch: 65, Loss: 0.8947451114654541, Accuracy: 0.705078125\n",
      "Batch: 66, Loss: 0.8548291921615601, Accuracy: 0.70703125\n",
      "Batch: 67, Loss: 0.8942837715148926, Accuracy: 0.7216796875\n",
      "Batch: 68, Loss: 0.9894404411315918, Accuracy: 0.666015625\n",
      "Batch: 69, Loss: 0.8781948089599609, Accuracy: 0.71484375\n",
      "Batch: 70, Loss: 0.8731392621994019, Accuracy: 0.7021484375\n",
      "Batch: 71, Loss: 0.8219144344329834, Accuracy: 0.7333984375\n",
      "Batch: 72, Loss: 0.917965829372406, Accuracy: 0.7041015625\n",
      "Batch: 73, Loss: 0.9259935617446899, Accuracy: 0.69140625\n",
      "Batch: 74, Loss: 0.8520234823226929, Accuracy: 0.71484375\n",
      "Batch: 75, Loss: 0.7524139285087585, Accuracy: 0.7568359375\n",
      "Batch: 76, Loss: 0.8624679446220398, Accuracy: 0.724609375\n",
      "Batch: 77, Loss: 0.9508171081542969, Accuracy: 0.7001953125\n",
      "Batch: 78, Loss: 0.8518293499946594, Accuracy: 0.7294921875\n",
      "Batch: 79, Loss: 0.9105855226516724, Accuracy: 0.7236328125\n",
      "Batch: 80, Loss: 0.892856240272522, Accuracy: 0.7177734375\n",
      "Batch: 81, Loss: 0.8799885511398315, Accuracy: 0.7177734375\n",
      "Batch: 82, Loss: 0.8241586685180664, Accuracy: 0.72265625\n",
      "Batch: 83, Loss: 0.8277965784072876, Accuracy: 0.7236328125\n",
      "Batch: 84, Loss: 0.7831875681877136, Accuracy: 0.75\n",
      "Batch: 85, Loss: 0.8202804923057556, Accuracy: 0.7333984375\n",
      "Batch: 86, Loss: 0.7747161388397217, Accuracy: 0.7431640625\n",
      "Batch: 87, Loss: 0.8076173067092896, Accuracy: 0.736328125\n",
      "Batch: 88, Loss: 0.8469741344451904, Accuracy: 0.7197265625\n",
      "Batch: 89, Loss: 0.8856356143951416, Accuracy: 0.7041015625\n",
      "Batch: 90, Loss: 0.8586864471435547, Accuracy: 0.7216796875\n",
      "Batch: 91, Loss: 0.9635230302810669, Accuracy: 0.6923828125\n",
      "Batch: 92, Loss: 0.808836042881012, Accuracy: 0.7294921875\n",
      "Batch: 93, Loss: 0.791156530380249, Accuracy: 0.744140625\n",
      "Batch: 94, Loss: 0.8794286847114563, Accuracy: 0.7060546875\n",
      "Batch: 95, Loss: 0.8650368452072144, Accuracy: 0.7216796875\n",
      "Batch: 96, Loss: 0.835867702960968, Accuracy: 0.7197265625\n",
      "Batch: 97, Loss: 0.8064227104187012, Accuracy: 0.7255859375\n",
      "Batch: 98, Loss: 0.9048717021942139, Accuracy: 0.69921875\n",
      "Batch: 99, Loss: 0.8701422810554504, Accuracy: 0.7216796875\n",
      "Batch: 100, Loss: 0.9262391328811646, Accuracy: 0.7060546875\n",
      "Batch: 101, Loss: 0.8649585247039795, Accuracy: 0.71484375\n",
      "Batch: 102, Loss: 0.8646746277809143, Accuracy: 0.7197265625\n",
      "Batch: 103, Loss: 0.9123275279998779, Accuracy: 0.703125\n",
      "Batch: 104, Loss: 0.8905569314956665, Accuracy: 0.703125\n",
      "Batch: 105, Loss: 0.7750125527381897, Accuracy: 0.75390625\n",
      "Batch: 106, Loss: 0.8375018239021301, Accuracy: 0.7236328125\n",
      "Batch: 107, Loss: 0.8448635935783386, Accuracy: 0.7216796875\n",
      "Batch: 108, Loss: 0.8127030730247498, Accuracy: 0.7236328125\n",
      "Batch: 109, Loss: 0.8325932025909424, Accuracy: 0.7470703125\n",
      "Batch: 110, Loss: 0.8110764622688293, Accuracy: 0.732421875\n",
      "Batch: 111, Loss: 0.8766725063323975, Accuracy: 0.7294921875\n",
      "Batch: 112, Loss: 0.8723962903022766, Accuracy: 0.7158203125\n",
      "Epoch 15/90\n",
      "Batch: 1, Loss: 1.255287766456604, Accuracy: 0.646484375\n",
      "Batch: 2, Loss: 0.9826376438140869, Accuracy: 0.701171875\n",
      "Batch: 3, Loss: 0.9786381125450134, Accuracy: 0.6923828125\n",
      "Batch: 4, Loss: 0.8976798057556152, Accuracy: 0.712890625\n",
      "Batch: 5, Loss: 0.9385775327682495, Accuracy: 0.7099609375\n",
      "Batch: 6, Loss: 0.9438632130622864, Accuracy: 0.7041015625\n",
      "Batch: 7, Loss: 0.8846195936203003, Accuracy: 0.732421875\n",
      "Batch: 8, Loss: 0.7682894468307495, Accuracy: 0.7509765625\n",
      "Batch: 9, Loss: 0.8429597020149231, Accuracy: 0.7333984375\n",
      "Batch: 10, Loss: 0.905701756477356, Accuracy: 0.712890625\n",
      "Batch: 11, Loss: 0.8235414028167725, Accuracy: 0.7314453125\n",
      "Batch: 12, Loss: 0.8408275842666626, Accuracy: 0.7333984375\n",
      "Batch: 13, Loss: 0.8194798827171326, Accuracy: 0.76171875\n",
      "Batch: 14, Loss: 0.9088494181632996, Accuracy: 0.705078125\n",
      "Batch: 15, Loss: 0.8986873030662537, Accuracy: 0.7080078125\n",
      "Batch: 16, Loss: 0.8984426259994507, Accuracy: 0.7294921875\n",
      "Batch: 17, Loss: 0.8899799585342407, Accuracy: 0.72265625\n",
      "Batch: 18, Loss: 0.8070841431617737, Accuracy: 0.7294921875\n",
      "Batch: 19, Loss: 0.8296093940734863, Accuracy: 0.7353515625\n",
      "Batch: 20, Loss: 0.883326530456543, Accuracy: 0.716796875\n",
      "Batch: 21, Loss: 0.8429365158081055, Accuracy: 0.7392578125\n",
      "Batch: 22, Loss: 0.8381763696670532, Accuracy: 0.736328125\n",
      "Batch: 23, Loss: 0.924247682094574, Accuracy: 0.7119140625\n",
      "Batch: 24, Loss: 0.9208091497421265, Accuracy: 0.7041015625\n",
      "Batch: 25, Loss: 1.01386559009552, Accuracy: 0.6875\n",
      "Batch: 26, Loss: 1.136075735092163, Accuracy: 0.654296875\n",
      "Batch: 27, Loss: 0.9315006732940674, Accuracy: 0.6962890625\n",
      "Batch: 28, Loss: 0.8199416399002075, Accuracy: 0.7275390625\n",
      "Batch: 29, Loss: 0.9076619148254395, Accuracy: 0.71484375\n",
      "Batch: 30, Loss: 0.8915055990219116, Accuracy: 0.69921875\n",
      "Batch: 31, Loss: 0.9001832604408264, Accuracy: 0.7001953125\n",
      "Batch: 32, Loss: 0.8637362122535706, Accuracy: 0.69921875\n",
      "Batch: 33, Loss: 0.8704458475112915, Accuracy: 0.7001953125\n",
      "Batch: 34, Loss: 0.7823023796081543, Accuracy: 0.740234375\n",
      "Batch: 35, Loss: 0.8640145063400269, Accuracy: 0.7109375\n",
      "Batch: 36, Loss: 0.8892248272895813, Accuracy: 0.705078125\n",
      "Batch: 37, Loss: 0.8056105971336365, Accuracy: 0.734375\n",
      "Batch: 38, Loss: 0.9120252728462219, Accuracy: 0.7138671875\n",
      "Batch: 39, Loss: 0.851064920425415, Accuracy: 0.7255859375\n",
      "Batch: 40, Loss: 0.8700864315032959, Accuracy: 0.724609375\n",
      "Batch: 41, Loss: 0.8562389612197876, Accuracy: 0.71875\n",
      "Batch: 42, Loss: 0.8143048286437988, Accuracy: 0.73046875\n",
      "Batch: 43, Loss: 0.9088900089263916, Accuracy: 0.7197265625\n",
      "Batch: 44, Loss: 0.9333010911941528, Accuracy: 0.7021484375\n",
      "Batch: 45, Loss: 1.0288783311843872, Accuracy: 0.6806640625\n",
      "Batch: 46, Loss: 0.8722586631774902, Accuracy: 0.7138671875\n",
      "Batch: 47, Loss: 0.908754825592041, Accuracy: 0.7099609375\n",
      "Batch: 48, Loss: 1.009798288345337, Accuracy: 0.68359375\n",
      "Batch: 49, Loss: 1.1365134716033936, Accuracy: 0.640625\n",
      "Batch: 50, Loss: 0.8447827696800232, Accuracy: 0.7294921875\n",
      "Batch: 51, Loss: 0.9339204430580139, Accuracy: 0.6962890625\n",
      "Batch: 52, Loss: 0.8876305818557739, Accuracy: 0.7265625\n",
      "Batch: 53, Loss: 1.0620365142822266, Accuracy: 0.6845703125\n",
      "Batch: 54, Loss: 1.0091907978057861, Accuracy: 0.685546875\n",
      "Batch: 55, Loss: 0.9672603607177734, Accuracy: 0.7060546875\n",
      "Batch: 56, Loss: 0.9094815850257874, Accuracy: 0.7119140625\n",
      "Batch: 57, Loss: 1.0852718353271484, Accuracy: 0.6630859375\n",
      "Batch: 58, Loss: 1.0627750158309937, Accuracy: 0.6806640625\n",
      "Batch: 59, Loss: 0.9323877096176147, Accuracy: 0.69921875\n",
      "Batch: 60, Loss: 1.0390758514404297, Accuracy: 0.6591796875\n",
      "Batch: 61, Loss: 0.9768110513687134, Accuracy: 0.689453125\n",
      "Batch: 62, Loss: 0.9381118416786194, Accuracy: 0.7041015625\n",
      "Batch: 63, Loss: 0.7427672743797302, Accuracy: 0.7646484375\n",
      "Batch: 64, Loss: 0.8775636553764343, Accuracy: 0.7041015625\n",
      "Batch: 65, Loss: 0.8742004632949829, Accuracy: 0.703125\n",
      "Batch: 66, Loss: 0.8168526887893677, Accuracy: 0.7275390625\n",
      "Batch: 67, Loss: 0.865986704826355, Accuracy: 0.7197265625\n",
      "Batch: 68, Loss: 0.9600287079811096, Accuracy: 0.6826171875\n",
      "Batch: 69, Loss: 0.8609922528266907, Accuracy: 0.72265625\n",
      "Batch: 70, Loss: 0.844367265701294, Accuracy: 0.7265625\n",
      "Batch: 71, Loss: 0.8099347949028015, Accuracy: 0.732421875\n",
      "Batch: 72, Loss: 0.8817348480224609, Accuracy: 0.70703125\n",
      "Batch: 73, Loss: 0.8913064002990723, Accuracy: 0.708984375\n",
      "Batch: 74, Loss: 0.826130747795105, Accuracy: 0.7333984375\n",
      "Batch: 75, Loss: 0.7457543611526489, Accuracy: 0.7529296875\n",
      "Batch: 76, Loss: 0.8439593315124512, Accuracy: 0.71875\n",
      "Batch: 77, Loss: 0.9416509866714478, Accuracy: 0.7109375\n",
      "Batch: 78, Loss: 0.8719727993011475, Accuracy: 0.7119140625\n",
      "Batch: 79, Loss: 0.8928244113922119, Accuracy: 0.724609375\n",
      "Batch: 80, Loss: 0.8551275134086609, Accuracy: 0.712890625\n",
      "Batch: 81, Loss: 0.8681424260139465, Accuracy: 0.70703125\n",
      "Batch: 82, Loss: 0.796603798866272, Accuracy: 0.736328125\n",
      "Batch: 83, Loss: 0.7874501943588257, Accuracy: 0.74609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 84, Loss: 0.7738485336303711, Accuracy: 0.7509765625\n",
      "Batch: 85, Loss: 0.7939651012420654, Accuracy: 0.73828125\n",
      "Batch: 86, Loss: 0.7511182427406311, Accuracy: 0.7392578125\n",
      "Batch: 87, Loss: 0.7920254468917847, Accuracy: 0.7509765625\n",
      "Batch: 88, Loss: 0.8315004110336304, Accuracy: 0.7216796875\n",
      "Batch: 89, Loss: 0.8534175157546997, Accuracy: 0.7255859375\n",
      "Batch: 90, Loss: 0.8524442911148071, Accuracy: 0.728515625\n",
      "Batch: 91, Loss: 0.9402740001678467, Accuracy: 0.6884765625\n",
      "Batch: 92, Loss: 0.807234525680542, Accuracy: 0.734375\n",
      "Batch: 93, Loss: 0.7937811613082886, Accuracy: 0.7392578125\n",
      "Batch: 94, Loss: 0.8593039512634277, Accuracy: 0.7109375\n",
      "Batch: 95, Loss: 0.8498866558074951, Accuracy: 0.7109375\n",
      "Batch: 96, Loss: 0.8291018605232239, Accuracy: 0.7265625\n",
      "Batch: 97, Loss: 0.7912365198135376, Accuracy: 0.7509765625\n",
      "Batch: 98, Loss: 0.8861658573150635, Accuracy: 0.712890625\n",
      "Batch: 99, Loss: 0.8361837267875671, Accuracy: 0.724609375\n",
      "Batch: 100, Loss: 0.9294936656951904, Accuracy: 0.689453125\n",
      "Batch: 101, Loss: 0.8418383598327637, Accuracy: 0.7119140625\n",
      "Batch: 102, Loss: 0.8375095129013062, Accuracy: 0.7314453125\n",
      "Batch: 103, Loss: 0.897895336151123, Accuracy: 0.7021484375\n",
      "Batch: 104, Loss: 0.8568227887153625, Accuracy: 0.7294921875\n",
      "Batch: 105, Loss: 0.7455021142959595, Accuracy: 0.7451171875\n",
      "Batch: 106, Loss: 0.8252084255218506, Accuracy: 0.7294921875\n",
      "Batch: 107, Loss: 0.8222458362579346, Accuracy: 0.728515625\n",
      "Batch: 108, Loss: 0.7881587743759155, Accuracy: 0.7392578125\n",
      "Batch: 109, Loss: 0.7997288107872009, Accuracy: 0.73828125\n",
      "Batch: 110, Loss: 0.7735031843185425, Accuracy: 0.751953125\n",
      "Batch: 111, Loss: 0.8616101145744324, Accuracy: 0.728515625\n",
      "Batch: 112, Loss: 0.8276323080062866, Accuracy: 0.7333984375\n",
      "Epoch 16/90\n",
      "Batch: 1, Loss: 1.240778923034668, Accuracy: 0.640625\n",
      "Batch: 2, Loss: 0.9388928413391113, Accuracy: 0.7138671875\n",
      "Batch: 3, Loss: 0.9446609020233154, Accuracy: 0.6953125\n",
      "Batch: 4, Loss: 0.8734489679336548, Accuracy: 0.7294921875\n",
      "Batch: 5, Loss: 0.8778800964355469, Accuracy: 0.7236328125\n",
      "Batch: 6, Loss: 0.9277944564819336, Accuracy: 0.7314453125\n",
      "Batch: 7, Loss: 0.8671735525131226, Accuracy: 0.7353515625\n",
      "Batch: 8, Loss: 0.7697957158088684, Accuracy: 0.7451171875\n",
      "Batch: 9, Loss: 0.8103733062744141, Accuracy: 0.7314453125\n",
      "Batch: 10, Loss: 0.8655035495758057, Accuracy: 0.7138671875\n",
      "Batch: 11, Loss: 0.8056319952011108, Accuracy: 0.7451171875\n",
      "Batch: 12, Loss: 0.80144864320755, Accuracy: 0.734375\n",
      "Batch: 13, Loss: 0.7822165489196777, Accuracy: 0.755859375\n",
      "Batch: 14, Loss: 0.8896797895431519, Accuracy: 0.7001953125\n",
      "Batch: 15, Loss: 0.8337142467498779, Accuracy: 0.734375\n",
      "Batch: 16, Loss: 0.8612895607948303, Accuracy: 0.7216796875\n",
      "Batch: 17, Loss: 0.8356146812438965, Accuracy: 0.7294921875\n",
      "Batch: 18, Loss: 0.7698800563812256, Accuracy: 0.7548828125\n",
      "Batch: 19, Loss: 0.8017082214355469, Accuracy: 0.7421875\n",
      "Batch: 20, Loss: 0.8187313079833984, Accuracy: 0.732421875\n",
      "Batch: 21, Loss: 0.8234410285949707, Accuracy: 0.7412109375\n",
      "Batch: 22, Loss: 0.7786982655525208, Accuracy: 0.73828125\n",
      "Batch: 23, Loss: 0.9007594585418701, Accuracy: 0.7119140625\n",
      "Batch: 24, Loss: 0.880867600440979, Accuracy: 0.72265625\n",
      "Batch: 25, Loss: 1.0058977603912354, Accuracy: 0.6806640625\n",
      "Batch: 26, Loss: 1.1097526550292969, Accuracy: 0.666015625\n",
      "Batch: 27, Loss: 0.929175615310669, Accuracy: 0.701171875\n",
      "Batch: 28, Loss: 0.8060396909713745, Accuracy: 0.7333984375\n",
      "Batch: 29, Loss: 0.851799726486206, Accuracy: 0.73828125\n",
      "Batch: 30, Loss: 0.8464177846908569, Accuracy: 0.71875\n",
      "Batch: 31, Loss: 0.867519736289978, Accuracy: 0.7119140625\n",
      "Batch: 32, Loss: 0.8508549928665161, Accuracy: 0.71484375\n",
      "Batch: 33, Loss: 0.8490896821022034, Accuracy: 0.7119140625\n",
      "Batch: 34, Loss: 0.7701785564422607, Accuracy: 0.734375\n",
      "Batch: 35, Loss: 0.8424985408782959, Accuracy: 0.7255859375\n",
      "Batch: 36, Loss: 0.8700417280197144, Accuracy: 0.7216796875\n",
      "Batch: 37, Loss: 0.7954561710357666, Accuracy: 0.7392578125\n",
      "Batch: 38, Loss: 0.8803904056549072, Accuracy: 0.712890625\n",
      "Batch: 39, Loss: 0.8326029777526855, Accuracy: 0.732421875\n",
      "Batch: 40, Loss: 0.8363282680511475, Accuracy: 0.732421875\n",
      "Batch: 41, Loss: 0.853040874004364, Accuracy: 0.7109375\n",
      "Batch: 42, Loss: 0.7900654077529907, Accuracy: 0.7353515625\n",
      "Batch: 43, Loss: 0.856164813041687, Accuracy: 0.7216796875\n",
      "Batch: 44, Loss: 0.9261842966079712, Accuracy: 0.69921875\n",
      "Batch: 45, Loss: 1.0111446380615234, Accuracy: 0.681640625\n",
      "Batch: 46, Loss: 0.8711442947387695, Accuracy: 0.70703125\n",
      "Batch: 47, Loss: 0.9115675091743469, Accuracy: 0.6962890625\n",
      "Batch: 48, Loss: 0.9895745515823364, Accuracy: 0.6884765625\n",
      "Batch: 49, Loss: 1.1235363483428955, Accuracy: 0.646484375\n",
      "Batch: 50, Loss: 0.8239974975585938, Accuracy: 0.740234375\n",
      "Batch: 51, Loss: 0.9160852432250977, Accuracy: 0.705078125\n",
      "Batch: 52, Loss: 0.8415857553482056, Accuracy: 0.734375\n",
      "Batch: 53, Loss: 1.0205910205841064, Accuracy: 0.6923828125\n",
      "Batch: 54, Loss: 0.9546571969985962, Accuracy: 0.69921875\n",
      "Batch: 55, Loss: 0.9302054643630981, Accuracy: 0.716796875\n",
      "Batch: 56, Loss: 0.8974288105964661, Accuracy: 0.71484375\n",
      "Batch: 57, Loss: 1.0586442947387695, Accuracy: 0.6728515625\n",
      "Batch: 58, Loss: 1.0345559120178223, Accuracy: 0.685546875\n",
      "Batch: 59, Loss: 0.8941570520401001, Accuracy: 0.7099609375\n",
      "Batch: 60, Loss: 1.030457615852356, Accuracy: 0.6640625\n",
      "Batch: 61, Loss: 0.9679002165794373, Accuracy: 0.6845703125\n",
      "Batch: 62, Loss: 0.9220342040061951, Accuracy: 0.7158203125\n",
      "Batch: 63, Loss: 0.7349053025245667, Accuracy: 0.7744140625\n",
      "Batch: 64, Loss: 0.8524024486541748, Accuracy: 0.71875\n",
      "Batch: 65, Loss: 0.8292794823646545, Accuracy: 0.724609375\n",
      "Batch: 66, Loss: 0.7973378300666809, Accuracy: 0.7373046875\n",
      "Batch: 67, Loss: 0.8264767527580261, Accuracy: 0.720703125\n",
      "Batch: 68, Loss: 0.9315527677536011, Accuracy: 0.6982421875\n",
      "Batch: 69, Loss: 0.8127750158309937, Accuracy: 0.736328125\n",
      "Batch: 70, Loss: 0.8300899267196655, Accuracy: 0.7197265625\n",
      "Batch: 71, Loss: 0.778278112411499, Accuracy: 0.7451171875\n",
      "Batch: 72, Loss: 0.866173505783081, Accuracy: 0.7099609375\n",
      "Batch: 73, Loss: 0.861390233039856, Accuracy: 0.7119140625\n",
      "Batch: 74, Loss: 0.8080224990844727, Accuracy: 0.7314453125\n",
      "Batch: 75, Loss: 0.7249408960342407, Accuracy: 0.759765625\n",
      "Batch: 76, Loss: 0.8139697909355164, Accuracy: 0.7294921875\n",
      "Batch: 77, Loss: 0.9098760485649109, Accuracy: 0.697265625\n",
      "Batch: 78, Loss: 0.8195603489875793, Accuracy: 0.7412109375\n",
      "Batch: 79, Loss: 0.8631846904754639, Accuracy: 0.724609375\n",
      "Batch: 80, Loss: 0.8411620855331421, Accuracy: 0.7333984375\n",
      "Batch: 81, Loss: 0.8470555543899536, Accuracy: 0.7216796875\n",
      "Batch: 82, Loss: 0.7769917249679565, Accuracy: 0.7373046875\n",
      "Batch: 83, Loss: 0.769240140914917, Accuracy: 0.751953125\n",
      "Batch: 84, Loss: 0.7520781755447388, Accuracy: 0.748046875\n",
      "Batch: 85, Loss: 0.7842956185340881, Accuracy: 0.7392578125\n",
      "Batch: 86, Loss: 0.7411794662475586, Accuracy: 0.7490234375\n",
      "Batch: 87, Loss: 0.75751793384552, Accuracy: 0.75390625\n",
      "Batch: 88, Loss: 0.7983324527740479, Accuracy: 0.744140625\n",
      "Batch: 89, Loss: 0.8249239921569824, Accuracy: 0.7275390625\n",
      "Batch: 90, Loss: 0.8225924372673035, Accuracy: 0.732421875\n",
      "Batch: 91, Loss: 0.9070800542831421, Accuracy: 0.716796875\n",
      "Batch: 92, Loss: 0.7871451377868652, Accuracy: 0.7412109375\n",
      "Batch: 93, Loss: 0.7725324034690857, Accuracy: 0.7314453125\n",
      "Batch: 94, Loss: 0.8593302965164185, Accuracy: 0.7158203125\n",
      "Batch: 95, Loss: 0.8369501829147339, Accuracy: 0.720703125\n",
      "Batch: 96, Loss: 0.8242048025131226, Accuracy: 0.72265625\n",
      "Batch: 97, Loss: 0.765295147895813, Accuracy: 0.755859375\n",
      "Batch: 98, Loss: 0.8753379583358765, Accuracy: 0.71484375\n",
      "Batch: 99, Loss: 0.8192089796066284, Accuracy: 0.7275390625\n",
      "Batch: 100, Loss: 0.8933429718017578, Accuracy: 0.71484375\n",
      "Batch: 101, Loss: 0.8052614331245422, Accuracy: 0.740234375\n",
      "Batch: 102, Loss: 0.8373580574989319, Accuracy: 0.734375\n",
      "Batch: 103, Loss: 0.8686215281486511, Accuracy: 0.7119140625\n",
      "Batch: 104, Loss: 0.8572897911071777, Accuracy: 0.7158203125\n",
      "Batch: 105, Loss: 0.7167840003967285, Accuracy: 0.76171875\n",
      "Batch: 106, Loss: 0.792998194694519, Accuracy: 0.7314453125\n",
      "Batch: 107, Loss: 0.7803844809532166, Accuracy: 0.7412109375\n",
      "Batch: 108, Loss: 0.768166720867157, Accuracy: 0.7431640625\n",
      "Batch: 109, Loss: 0.777690052986145, Accuracy: 0.7568359375\n",
      "Batch: 110, Loss: 0.7416127920150757, Accuracy: 0.7666015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 111, Loss: 0.848673939704895, Accuracy: 0.732421875\n",
      "Batch: 112, Loss: 0.7898354530334473, Accuracy: 0.740234375\n",
      "Epoch 17/90\n",
      "Batch: 1, Loss: 1.2386046648025513, Accuracy: 0.6455078125\n",
      "Batch: 2, Loss: 0.9320000410079956, Accuracy: 0.708984375\n",
      "Batch: 3, Loss: 0.9353315830230713, Accuracy: 0.703125\n",
      "Batch: 4, Loss: 0.8370466828346252, Accuracy: 0.724609375\n",
      "Batch: 5, Loss: 0.8775840997695923, Accuracy: 0.724609375\n",
      "Batch: 6, Loss: 0.9060567617416382, Accuracy: 0.7216796875\n",
      "Batch: 7, Loss: 0.8349816203117371, Accuracy: 0.7431640625\n",
      "Batch: 8, Loss: 0.7338575124740601, Accuracy: 0.7587890625\n",
      "Batch: 9, Loss: 0.8015824556350708, Accuracy: 0.73828125\n",
      "Batch: 10, Loss: 0.8544446229934692, Accuracy: 0.7109375\n",
      "Batch: 11, Loss: 0.7688974142074585, Accuracy: 0.755859375\n",
      "Batch: 12, Loss: 0.7912303805351257, Accuracy: 0.73828125\n",
      "Batch: 13, Loss: 0.7708777189254761, Accuracy: 0.7626953125\n",
      "Batch: 14, Loss: 0.8608484864234924, Accuracy: 0.7119140625\n",
      "Batch: 15, Loss: 0.8375877737998962, Accuracy: 0.7314453125\n",
      "Batch: 16, Loss: 0.846722424030304, Accuracy: 0.7275390625\n",
      "Batch: 17, Loss: 0.8368863463401794, Accuracy: 0.7333984375\n",
      "Batch: 18, Loss: 0.7557900547981262, Accuracy: 0.7568359375\n",
      "Batch: 19, Loss: 0.7529730796813965, Accuracy: 0.7509765625\n",
      "Batch: 20, Loss: 0.7860579490661621, Accuracy: 0.75\n",
      "Batch: 21, Loss: 0.8129154443740845, Accuracy: 0.740234375\n",
      "Batch: 22, Loss: 0.7918914556503296, Accuracy: 0.7373046875\n",
      "Batch: 23, Loss: 0.8629201650619507, Accuracy: 0.7412109375\n",
      "Batch: 24, Loss: 0.8611177206039429, Accuracy: 0.724609375\n",
      "Batch: 25, Loss: 0.9939030408859253, Accuracy: 0.6806640625\n",
      "Batch: 26, Loss: 1.0526502132415771, Accuracy: 0.68359375\n",
      "Batch: 27, Loss: 0.8855175971984863, Accuracy: 0.7216796875\n",
      "Batch: 28, Loss: 0.784873366355896, Accuracy: 0.744140625\n",
      "Batch: 29, Loss: 0.8545733094215393, Accuracy: 0.720703125\n",
      "Batch: 30, Loss: 0.8495970964431763, Accuracy: 0.720703125\n",
      "Batch: 31, Loss: 0.841254472732544, Accuracy: 0.7236328125\n",
      "Batch: 32, Loss: 0.8027195930480957, Accuracy: 0.7255859375\n",
      "Batch: 33, Loss: 0.7978319525718689, Accuracy: 0.72265625\n",
      "Batch: 34, Loss: 0.7453265190124512, Accuracy: 0.7509765625\n",
      "Batch: 35, Loss: 0.8116887211799622, Accuracy: 0.7294921875\n",
      "Batch: 36, Loss: 0.8527297973632812, Accuracy: 0.73046875\n",
      "Batch: 37, Loss: 0.7600371241569519, Accuracy: 0.75\n",
      "Batch: 38, Loss: 0.8552871346473694, Accuracy: 0.712890625\n",
      "Batch: 39, Loss: 0.7977861166000366, Accuracy: 0.7373046875\n",
      "Batch: 40, Loss: 0.8262012600898743, Accuracy: 0.7353515625\n",
      "Batch: 41, Loss: 0.8063660860061646, Accuracy: 0.7333984375\n",
      "Batch: 42, Loss: 0.7489019632339478, Accuracy: 0.740234375\n",
      "Batch: 43, Loss: 0.8560938835144043, Accuracy: 0.7216796875\n",
      "Batch: 44, Loss: 0.899305522441864, Accuracy: 0.7158203125\n",
      "Batch: 45, Loss: 0.9605076909065247, Accuracy: 0.6923828125\n",
      "Batch: 46, Loss: 0.8348640203475952, Accuracy: 0.724609375\n",
      "Batch: 47, Loss: 0.8713980913162231, Accuracy: 0.7109375\n",
      "Batch: 48, Loss: 0.9630160331726074, Accuracy: 0.7060546875\n",
      "Batch: 49, Loss: 1.0823163986206055, Accuracy: 0.6650390625\n",
      "Batch: 50, Loss: 0.8298694491386414, Accuracy: 0.740234375\n",
      "Batch: 51, Loss: 0.8955570459365845, Accuracy: 0.716796875\n",
      "Batch: 52, Loss: 0.8502023816108704, Accuracy: 0.734375\n",
      "Batch: 53, Loss: 0.9914617538452148, Accuracy: 0.69140625\n",
      "Batch: 54, Loss: 0.9442266821861267, Accuracy: 0.712890625\n",
      "Batch: 55, Loss: 0.895111083984375, Accuracy: 0.72265625\n",
      "Batch: 56, Loss: 0.8566842675209045, Accuracy: 0.7314453125\n",
      "Batch: 57, Loss: 1.0257147550582886, Accuracy: 0.6904296875\n",
      "Batch: 58, Loss: 1.0072611570358276, Accuracy: 0.6884765625\n",
      "Batch: 59, Loss: 0.8697423934936523, Accuracy: 0.7138671875\n",
      "Batch: 60, Loss: 0.9848668575286865, Accuracy: 0.6884765625\n",
      "Batch: 61, Loss: 0.9233076572418213, Accuracy: 0.69140625\n",
      "Batch: 62, Loss: 0.8984402418136597, Accuracy: 0.7236328125\n",
      "Batch: 63, Loss: 0.7074733972549438, Accuracy: 0.7724609375\n",
      "Batch: 64, Loss: 0.8480435013771057, Accuracy: 0.712890625\n",
      "Batch: 65, Loss: 0.8380833864212036, Accuracy: 0.7060546875\n",
      "Batch: 66, Loss: 0.7827107906341553, Accuracy: 0.740234375\n",
      "Batch: 67, Loss: 0.8139998316764832, Accuracy: 0.7314453125\n",
      "Batch: 68, Loss: 0.8827308416366577, Accuracy: 0.7060546875\n",
      "Batch: 69, Loss: 0.8014647960662842, Accuracy: 0.73828125\n",
      "Batch: 70, Loss: 0.8270174264907837, Accuracy: 0.72265625\n",
      "Batch: 71, Loss: 0.7565432786941528, Accuracy: 0.740234375\n",
      "Batch: 72, Loss: 0.8317651748657227, Accuracy: 0.7255859375\n",
      "Batch: 73, Loss: 0.8367761373519897, Accuracy: 0.7294921875\n",
      "Batch: 74, Loss: 0.7923132181167603, Accuracy: 0.7431640625\n",
      "Batch: 75, Loss: 0.7054673433303833, Accuracy: 0.7744140625\n",
      "Batch: 76, Loss: 0.7626287937164307, Accuracy: 0.74609375\n",
      "Batch: 77, Loss: 0.8820191025733948, Accuracy: 0.7177734375\n",
      "Batch: 78, Loss: 0.7938569784164429, Accuracy: 0.744140625\n",
      "Batch: 79, Loss: 0.8190442323684692, Accuracy: 0.7509765625\n",
      "Batch: 80, Loss: 0.8135626316070557, Accuracy: 0.740234375\n",
      "Batch: 81, Loss: 0.8098883628845215, Accuracy: 0.7275390625\n",
      "Batch: 82, Loss: 0.7490226030349731, Accuracy: 0.7529296875\n",
      "Batch: 83, Loss: 0.725792646408081, Accuracy: 0.7548828125\n",
      "Batch: 84, Loss: 0.7332503795623779, Accuracy: 0.7646484375\n",
      "Batch: 85, Loss: 0.7569980621337891, Accuracy: 0.7509765625\n",
      "Batch: 86, Loss: 0.7200161814689636, Accuracy: 0.75\n",
      "Batch: 87, Loss: 0.7341674566268921, Accuracy: 0.7587890625\n",
      "Batch: 88, Loss: 0.790683925151825, Accuracy: 0.734375\n",
      "Batch: 89, Loss: 0.8122295141220093, Accuracy: 0.7236328125\n",
      "Batch: 90, Loss: 0.8347609043121338, Accuracy: 0.7177734375\n",
      "Batch: 91, Loss: 0.9002432823181152, Accuracy: 0.716796875\n",
      "Batch: 92, Loss: 0.7822560667991638, Accuracy: 0.7451171875\n",
      "Batch: 93, Loss: 0.738335371017456, Accuracy: 0.7646484375\n",
      "Batch: 94, Loss: 0.8308319449424744, Accuracy: 0.732421875\n",
      "Batch: 95, Loss: 0.8015958070755005, Accuracy: 0.732421875\n",
      "Batch: 96, Loss: 0.7716099619865417, Accuracy: 0.7392578125\n",
      "Batch: 97, Loss: 0.7673786878585815, Accuracy: 0.7548828125\n",
      "Batch: 98, Loss: 0.8683333396911621, Accuracy: 0.7138671875\n",
      "Batch: 99, Loss: 0.8146270513534546, Accuracy: 0.720703125\n",
      "Batch: 100, Loss: 0.8739138841629028, Accuracy: 0.708984375\n",
      "Batch: 101, Loss: 0.8199397325515747, Accuracy: 0.7314453125\n",
      "Batch: 102, Loss: 0.816597580909729, Accuracy: 0.7265625\n",
      "Batch: 103, Loss: 0.8329583406448364, Accuracy: 0.7314453125\n",
      "Batch: 104, Loss: 0.8260798454284668, Accuracy: 0.7412109375\n",
      "Batch: 105, Loss: 0.7222007513046265, Accuracy: 0.7568359375\n",
      "Batch: 106, Loss: 0.7969402074813843, Accuracy: 0.73046875\n",
      "Batch: 107, Loss: 0.785711407661438, Accuracy: 0.73046875\n",
      "Batch: 108, Loss: 0.7429766058921814, Accuracy: 0.740234375\n",
      "Batch: 109, Loss: 0.747157871723175, Accuracy: 0.7666015625\n",
      "Batch: 110, Loss: 0.7266473174095154, Accuracy: 0.7685546875\n",
      "Batch: 111, Loss: 0.8129702210426331, Accuracy: 0.7373046875\n",
      "Batch: 112, Loss: 0.7661464214324951, Accuracy: 0.7529296875\n",
      "Epoch 18/90\n",
      "Batch: 1, Loss: 1.1828951835632324, Accuracy: 0.66015625\n",
      "Batch: 2, Loss: 0.8968743085861206, Accuracy: 0.7294921875\n",
      "Batch: 3, Loss: 0.9234427213668823, Accuracy: 0.7080078125\n",
      "Batch: 4, Loss: 0.8276355862617493, Accuracy: 0.7353515625\n",
      "Batch: 5, Loss: 0.8453658223152161, Accuracy: 0.7265625\n",
      "Batch: 6, Loss: 0.8572060465812683, Accuracy: 0.7431640625\n",
      "Batch: 7, Loss: 0.8140113949775696, Accuracy: 0.7470703125\n",
      "Batch: 8, Loss: 0.7017285227775574, Accuracy: 0.7763671875\n",
      "Batch: 9, Loss: 0.7986718416213989, Accuracy: 0.7333984375\n",
      "Batch: 10, Loss: 0.8597612380981445, Accuracy: 0.7158203125\n",
      "Batch: 11, Loss: 0.776746392250061, Accuracy: 0.73828125\n",
      "Batch: 12, Loss: 0.7643243074417114, Accuracy: 0.7529296875\n",
      "Batch: 13, Loss: 0.7321798205375671, Accuracy: 0.7783203125\n",
      "Batch: 14, Loss: 0.8652137517929077, Accuracy: 0.7099609375\n",
      "Batch: 15, Loss: 0.8252773284912109, Accuracy: 0.7421875\n",
      "Batch: 16, Loss: 0.8193409442901611, Accuracy: 0.7314453125\n",
      "Batch: 17, Loss: 0.8080978393554688, Accuracy: 0.7392578125\n",
      "Batch: 18, Loss: 0.7225024700164795, Accuracy: 0.7646484375\n",
      "Batch: 19, Loss: 0.7489240169525146, Accuracy: 0.7490234375\n",
      "Batch: 20, Loss: 0.8035417795181274, Accuracy: 0.7373046875\n",
      "Batch: 21, Loss: 0.7846637964248657, Accuracy: 0.75390625\n",
      "Batch: 22, Loss: 0.7533575296401978, Accuracy: 0.751953125\n",
      "Batch: 23, Loss: 0.8651983737945557, Accuracy: 0.7353515625\n",
      "Batch: 24, Loss: 0.8395936489105225, Accuracy: 0.734375\n",
      "Batch: 25, Loss: 0.9382224082946777, Accuracy: 0.6962890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 26, Loss: 1.0328011512756348, Accuracy: 0.681640625\n",
      "Batch: 27, Loss: 0.8641188740730286, Accuracy: 0.7197265625\n",
      "Batch: 28, Loss: 0.7778171300888062, Accuracy: 0.7421875\n",
      "Batch: 29, Loss: 0.8398853540420532, Accuracy: 0.73046875\n",
      "Batch: 30, Loss: 0.808294415473938, Accuracy: 0.7333984375\n",
      "Batch: 31, Loss: 0.8142738342285156, Accuracy: 0.72265625\n",
      "Batch: 32, Loss: 0.7838512063026428, Accuracy: 0.7314453125\n",
      "Batch: 33, Loss: 0.7789771556854248, Accuracy: 0.728515625\n",
      "Batch: 34, Loss: 0.7201452851295471, Accuracy: 0.771484375\n",
      "Batch: 35, Loss: 0.7909793257713318, Accuracy: 0.7412109375\n",
      "Batch: 36, Loss: 0.8311906456947327, Accuracy: 0.7294921875\n",
      "Batch: 37, Loss: 0.7404415011405945, Accuracy: 0.7509765625\n",
      "Batch: 38, Loss: 0.835902214050293, Accuracy: 0.72265625\n",
      "Batch: 39, Loss: 0.7665677666664124, Accuracy: 0.7529296875\n",
      "Batch: 40, Loss: 0.7765885591506958, Accuracy: 0.744140625\n",
      "Batch: 41, Loss: 0.7751742601394653, Accuracy: 0.732421875\n",
      "Batch: 42, Loss: 0.7147282361984253, Accuracy: 0.7412109375\n",
      "Batch: 43, Loss: 0.820747971534729, Accuracy: 0.732421875\n",
      "Batch: 44, Loss: 0.8803266882896423, Accuracy: 0.7138671875\n",
      "Batch: 45, Loss: 0.9342731833457947, Accuracy: 0.7080078125\n",
      "Batch: 46, Loss: 0.829548180103302, Accuracy: 0.7255859375\n",
      "Batch: 47, Loss: 0.8563369512557983, Accuracy: 0.720703125\n",
      "Batch: 48, Loss: 0.9234722852706909, Accuracy: 0.7109375\n",
      "Batch: 49, Loss: 1.0261722803115845, Accuracy: 0.66796875\n",
      "Batch: 50, Loss: 0.7555506229400635, Accuracy: 0.7607421875\n",
      "Batch: 51, Loss: 0.863263726234436, Accuracy: 0.7158203125\n",
      "Batch: 52, Loss: 0.8098254203796387, Accuracy: 0.740234375\n",
      "Batch: 53, Loss: 0.9811903238296509, Accuracy: 0.708984375\n",
      "Batch: 54, Loss: 0.9189677238464355, Accuracy: 0.716796875\n",
      "Batch: 55, Loss: 0.8748228549957275, Accuracy: 0.7314453125\n",
      "Batch: 56, Loss: 0.8413392305374146, Accuracy: 0.7373046875\n",
      "Batch: 57, Loss: 0.97542405128479, Accuracy: 0.693359375\n",
      "Batch: 58, Loss: 0.9327878952026367, Accuracy: 0.7099609375\n",
      "Batch: 59, Loss: 0.8413668870925903, Accuracy: 0.73046875\n",
      "Batch: 60, Loss: 0.9484666585922241, Accuracy: 0.6865234375\n",
      "Batch: 61, Loss: 0.9001875519752502, Accuracy: 0.7109375\n",
      "Batch: 62, Loss: 0.8786582350730896, Accuracy: 0.724609375\n",
      "Batch: 63, Loss: 0.6846717000007629, Accuracy: 0.7861328125\n",
      "Batch: 64, Loss: 0.8117556571960449, Accuracy: 0.7333984375\n",
      "Batch: 65, Loss: 0.8162157535552979, Accuracy: 0.736328125\n",
      "Batch: 66, Loss: 0.7504646182060242, Accuracy: 0.7529296875\n",
      "Batch: 67, Loss: 0.7963254451751709, Accuracy: 0.744140625\n",
      "Batch: 68, Loss: 0.8729515075683594, Accuracy: 0.71484375\n",
      "Batch: 69, Loss: 0.7790325880050659, Accuracy: 0.7578125\n",
      "Batch: 70, Loss: 0.7689064741134644, Accuracy: 0.7431640625\n",
      "Batch: 71, Loss: 0.7399915456771851, Accuracy: 0.7529296875\n",
      "Batch: 72, Loss: 0.8115047216415405, Accuracy: 0.720703125\n",
      "Batch: 73, Loss: 0.8164258003234863, Accuracy: 0.7275390625\n",
      "Batch: 74, Loss: 0.760941207408905, Accuracy: 0.7548828125\n",
      "Batch: 75, Loss: 0.6856296062469482, Accuracy: 0.7744140625\n",
      "Batch: 76, Loss: 0.7642353177070618, Accuracy: 0.74609375\n",
      "Batch: 77, Loss: 0.8529635071754456, Accuracy: 0.720703125\n",
      "Batch: 78, Loss: 0.7658663988113403, Accuracy: 0.7412109375\n",
      "Batch: 79, Loss: 0.8076279163360596, Accuracy: 0.7509765625\n",
      "Batch: 80, Loss: 0.7807766199111938, Accuracy: 0.7509765625\n",
      "Batch: 81, Loss: 0.8084311485290527, Accuracy: 0.7275390625\n",
      "Batch: 82, Loss: 0.7478263974189758, Accuracy: 0.7548828125\n",
      "Batch: 83, Loss: 0.7270239591598511, Accuracy: 0.767578125\n",
      "Batch: 84, Loss: 0.7116671204566956, Accuracy: 0.7626953125\n",
      "Batch: 85, Loss: 0.7623928785324097, Accuracy: 0.74609375\n",
      "Batch: 86, Loss: 0.7004267573356628, Accuracy: 0.7734375\n",
      "Batch: 87, Loss: 0.7189978361129761, Accuracy: 0.7744140625\n",
      "Batch: 88, Loss: 0.7640851736068726, Accuracy: 0.744140625\n",
      "Batch: 89, Loss: 0.7736399173736572, Accuracy: 0.74609375\n",
      "Batch: 90, Loss: 0.7986680269241333, Accuracy: 0.732421875\n",
      "Batch: 91, Loss: 0.8672844171524048, Accuracy: 0.7236328125\n",
      "Batch: 92, Loss: 0.7656655311584473, Accuracy: 0.7412109375\n",
      "Batch: 93, Loss: 0.7277155518531799, Accuracy: 0.7646484375\n",
      "Batch: 94, Loss: 0.7920725345611572, Accuracy: 0.7421875\n",
      "Batch: 95, Loss: 0.8021399974822998, Accuracy: 0.732421875\n",
      "Batch: 96, Loss: 0.7637026906013489, Accuracy: 0.74609375\n",
      "Batch: 97, Loss: 0.739253044128418, Accuracy: 0.775390625\n",
      "Batch: 98, Loss: 0.8321722745895386, Accuracy: 0.7177734375\n",
      "Batch: 99, Loss: 0.7792367935180664, Accuracy: 0.73828125\n",
      "Batch: 100, Loss: 0.8433780670166016, Accuracy: 0.7236328125\n",
      "Batch: 101, Loss: 0.7833899259567261, Accuracy: 0.7431640625\n",
      "Batch: 102, Loss: 0.80762779712677, Accuracy: 0.744140625\n",
      "Batch: 103, Loss: 0.7982926964759827, Accuracy: 0.7236328125\n",
      "Batch: 104, Loss: 0.7942514419555664, Accuracy: 0.7294921875\n",
      "Batch: 105, Loss: 0.7044984102249146, Accuracy: 0.765625\n",
      "Batch: 106, Loss: 0.7540761828422546, Accuracy: 0.7490234375\n",
      "Batch: 107, Loss: 0.7506211400032043, Accuracy: 0.732421875\n",
      "Batch: 108, Loss: 0.7413912415504456, Accuracy: 0.74609375\n",
      "Batch: 109, Loss: 0.7227540612220764, Accuracy: 0.7626953125\n",
      "Batch: 110, Loss: 0.7198706865310669, Accuracy: 0.7724609375\n",
      "Batch: 111, Loss: 0.7962830066680908, Accuracy: 0.7568359375\n",
      "Batch: 112, Loss: 0.7593488693237305, Accuracy: 0.734375\n",
      "Epoch 19/90\n",
      "Batch: 1, Loss: 1.1450481414794922, Accuracy: 0.65625\n",
      "Batch: 2, Loss: 0.8943065404891968, Accuracy: 0.720703125\n",
      "Batch: 3, Loss: 0.88376384973526, Accuracy: 0.7294921875\n",
      "Batch: 4, Loss: 0.7826747298240662, Accuracy: 0.755859375\n",
      "Batch: 5, Loss: 0.8247262239456177, Accuracy: 0.748046875\n",
      "Batch: 6, Loss: 0.8504756689071655, Accuracy: 0.73828125\n",
      "Batch: 7, Loss: 0.7869632244110107, Accuracy: 0.7548828125\n",
      "Batch: 8, Loss: 0.6903458833694458, Accuracy: 0.783203125\n",
      "Batch: 9, Loss: 0.7424681782722473, Accuracy: 0.7529296875\n",
      "Batch: 10, Loss: 0.7990416288375854, Accuracy: 0.7431640625\n",
      "Batch: 11, Loss: 0.7347872257232666, Accuracy: 0.76953125\n",
      "Batch: 12, Loss: 0.745262861251831, Accuracy: 0.751953125\n",
      "Batch: 13, Loss: 0.7102968692779541, Accuracy: 0.78515625\n",
      "Batch: 14, Loss: 0.8051370978355408, Accuracy: 0.7333984375\n",
      "Batch: 15, Loss: 0.7869105935096741, Accuracy: 0.7470703125\n",
      "Batch: 16, Loss: 0.8129644989967346, Accuracy: 0.7314453125\n",
      "Batch: 17, Loss: 0.7928887009620667, Accuracy: 0.744140625\n",
      "Batch: 18, Loss: 0.7158905267715454, Accuracy: 0.7666015625\n",
      "Batch: 19, Loss: 0.7041018605232239, Accuracy: 0.7734375\n",
      "Batch: 20, Loss: 0.7631250619888306, Accuracy: 0.75390625\n",
      "Batch: 21, Loss: 0.759700357913971, Accuracy: 0.7529296875\n",
      "Batch: 22, Loss: 0.7403889894485474, Accuracy: 0.75390625\n",
      "Batch: 23, Loss: 0.8308717012405396, Accuracy: 0.734375\n",
      "Batch: 24, Loss: 0.8135275840759277, Accuracy: 0.7373046875\n",
      "Batch: 25, Loss: 0.9218156337738037, Accuracy: 0.69140625\n",
      "Batch: 26, Loss: 0.9957619309425354, Accuracy: 0.69140625\n",
      "Batch: 27, Loss: 0.8513159155845642, Accuracy: 0.7158203125\n",
      "Batch: 28, Loss: 0.7484728097915649, Accuracy: 0.7548828125\n",
      "Batch: 29, Loss: 0.8255922794342041, Accuracy: 0.7216796875\n",
      "Batch: 30, Loss: 0.8041820526123047, Accuracy: 0.7294921875\n",
      "Batch: 31, Loss: 0.7988954782485962, Accuracy: 0.720703125\n",
      "Batch: 32, Loss: 0.7864677906036377, Accuracy: 0.732421875\n",
      "Batch: 33, Loss: 0.7775523662567139, Accuracy: 0.7314453125\n",
      "Batch: 34, Loss: 0.7122390270233154, Accuracy: 0.7509765625\n",
      "Batch: 35, Loss: 0.7628373503684998, Accuracy: 0.75\n",
      "Batch: 36, Loss: 0.8212364912033081, Accuracy: 0.7373046875\n",
      "Batch: 37, Loss: 0.730643093585968, Accuracy: 0.755859375\n",
      "Batch: 38, Loss: 0.8354803919792175, Accuracy: 0.7255859375\n",
      "Batch: 39, Loss: 0.7630364298820496, Accuracy: 0.7607421875\n",
      "Batch: 40, Loss: 0.8035138845443726, Accuracy: 0.7421875\n",
      "Batch: 41, Loss: 0.7733189463615417, Accuracy: 0.7431640625\n",
      "Batch: 42, Loss: 0.7212704420089722, Accuracy: 0.7470703125\n",
      "Batch: 43, Loss: 0.7997251749038696, Accuracy: 0.744140625\n",
      "Batch: 44, Loss: 0.8562941551208496, Accuracy: 0.732421875\n",
      "Batch: 45, Loss: 0.9190361499786377, Accuracy: 0.716796875\n",
      "Batch: 46, Loss: 0.7936311960220337, Accuracy: 0.73828125\n",
      "Batch: 47, Loss: 0.8475393652915955, Accuracy: 0.73046875\n",
      "Batch: 48, Loss: 0.8979008197784424, Accuracy: 0.71875\n",
      "Batch: 49, Loss: 1.0196497440338135, Accuracy: 0.6826171875\n",
      "Batch: 50, Loss: 0.7562602758407593, Accuracy: 0.76953125\n",
      "Batch: 51, Loss: 0.8561000227928162, Accuracy: 0.7294921875\n",
      "Batch: 52, Loss: 0.7950076460838318, Accuracy: 0.7529296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 53, Loss: 0.9544325470924377, Accuracy: 0.7255859375\n",
      "Batch: 54, Loss: 0.8913872838020325, Accuracy: 0.724609375\n",
      "Batch: 55, Loss: 0.8652668595314026, Accuracy: 0.73828125\n",
      "Batch: 56, Loss: 0.8159213066101074, Accuracy: 0.7431640625\n",
      "Batch: 57, Loss: 0.9671222567558289, Accuracy: 0.703125\n",
      "Batch: 58, Loss: 0.9567073583602905, Accuracy: 0.7158203125\n",
      "Batch: 59, Loss: 0.8190184831619263, Accuracy: 0.7373046875\n",
      "Batch: 60, Loss: 0.9203436374664307, Accuracy: 0.68359375\n",
      "Batch: 61, Loss: 0.88253253698349, Accuracy: 0.7197265625\n",
      "Batch: 62, Loss: 0.8669012784957886, Accuracy: 0.72265625\n",
      "Batch: 63, Loss: 0.6676515340805054, Accuracy: 0.78515625\n",
      "Batch: 64, Loss: 0.8040103316307068, Accuracy: 0.7275390625\n",
      "Batch: 65, Loss: 0.8059496879577637, Accuracy: 0.7333984375\n",
      "Batch: 66, Loss: 0.751619815826416, Accuracy: 0.7490234375\n",
      "Batch: 67, Loss: 0.7870168089866638, Accuracy: 0.736328125\n",
      "Batch: 68, Loss: 0.8631283640861511, Accuracy: 0.716796875\n",
      "Batch: 69, Loss: 0.7735229730606079, Accuracy: 0.7421875\n",
      "Batch: 70, Loss: 0.7655460834503174, Accuracy: 0.75390625\n",
      "Batch: 71, Loss: 0.736420750617981, Accuracy: 0.7529296875\n",
      "Batch: 72, Loss: 0.8084096312522888, Accuracy: 0.7255859375\n",
      "Batch: 73, Loss: 0.7879860401153564, Accuracy: 0.7314453125\n",
      "Batch: 74, Loss: 0.7567697167396545, Accuracy: 0.759765625\n",
      "Batch: 75, Loss: 0.6724403500556946, Accuracy: 0.779296875\n",
      "Batch: 76, Loss: 0.7517057657241821, Accuracy: 0.748046875\n",
      "Batch: 77, Loss: 0.8334697484970093, Accuracy: 0.736328125\n",
      "Batch: 78, Loss: 0.7522450089454651, Accuracy: 0.748046875\n",
      "Batch: 79, Loss: 0.802417516708374, Accuracy: 0.759765625\n",
      "Batch: 80, Loss: 0.7768517732620239, Accuracy: 0.7470703125\n",
      "Batch: 81, Loss: 0.7782447338104248, Accuracy: 0.7421875\n",
      "Batch: 82, Loss: 0.7327907681465149, Accuracy: 0.7646484375\n",
      "Batch: 83, Loss: 0.6999385356903076, Accuracy: 0.7724609375\n",
      "Batch: 84, Loss: 0.6969259977340698, Accuracy: 0.7802734375\n",
      "Batch: 85, Loss: 0.7479082345962524, Accuracy: 0.7470703125\n",
      "Batch: 86, Loss: 0.703022837638855, Accuracy: 0.7529296875\n",
      "Batch: 87, Loss: 0.6935176849365234, Accuracy: 0.771484375\n",
      "Batch: 88, Loss: 0.7376718521118164, Accuracy: 0.75390625\n",
      "Batch: 89, Loss: 0.7689306735992432, Accuracy: 0.7509765625\n",
      "Batch: 90, Loss: 0.7772130370140076, Accuracy: 0.74609375\n",
      "Batch: 91, Loss: 0.8561878204345703, Accuracy: 0.7255859375\n",
      "Batch: 92, Loss: 0.730615496635437, Accuracy: 0.7587890625\n",
      "Batch: 93, Loss: 0.7275627851486206, Accuracy: 0.759765625\n",
      "Batch: 94, Loss: 0.8019607067108154, Accuracy: 0.7392578125\n",
      "Batch: 95, Loss: 0.7941193580627441, Accuracy: 0.73828125\n",
      "Batch: 96, Loss: 0.7465354204177856, Accuracy: 0.7509765625\n",
      "Batch: 97, Loss: 0.7439419627189636, Accuracy: 0.755859375\n",
      "Batch: 98, Loss: 0.8431470394134521, Accuracy: 0.7294921875\n",
      "Batch: 99, Loss: 0.7648022174835205, Accuracy: 0.74609375\n",
      "Batch: 100, Loss: 0.8428880572319031, Accuracy: 0.724609375\n",
      "Batch: 101, Loss: 0.7787286043167114, Accuracy: 0.744140625\n",
      "Batch: 102, Loss: 0.7826260328292847, Accuracy: 0.7431640625\n",
      "Batch: 103, Loss: 0.8152470588684082, Accuracy: 0.7314453125\n",
      "Batch: 104, Loss: 0.8009452223777771, Accuracy: 0.736328125\n",
      "Batch: 105, Loss: 0.7035133242607117, Accuracy: 0.7646484375\n",
      "Batch: 106, Loss: 0.7586785554885864, Accuracy: 0.7421875\n",
      "Batch: 107, Loss: 0.756474494934082, Accuracy: 0.75\n",
      "Batch: 108, Loss: 0.7415570616722107, Accuracy: 0.7470703125\n",
      "Batch: 109, Loss: 0.7187418937683105, Accuracy: 0.7646484375\n",
      "Batch: 110, Loss: 0.6930577158927917, Accuracy: 0.7822265625\n",
      "Batch: 111, Loss: 0.7762691974639893, Accuracy: 0.751953125\n",
      "Batch: 112, Loss: 0.7327945828437805, Accuracy: 0.765625\n",
      "Epoch 20/90\n",
      "Batch: 1, Loss: 1.1388914585113525, Accuracy: 0.671875\n",
      "Batch: 2, Loss: 0.8861964344978333, Accuracy: 0.732421875\n",
      "Batch: 3, Loss: 0.8404954671859741, Accuracy: 0.748046875\n",
      "Batch: 4, Loss: 0.7747547030448914, Accuracy: 0.7431640625\n",
      "Batch: 5, Loss: 0.8058104515075684, Accuracy: 0.732421875\n",
      "Batch: 6, Loss: 0.8217006921768188, Accuracy: 0.74609375\n",
      "Batch: 7, Loss: 0.7808792591094971, Accuracy: 0.7587890625\n",
      "Batch: 8, Loss: 0.681042492389679, Accuracy: 0.7705078125\n",
      "Batch: 9, Loss: 0.7347874641418457, Accuracy: 0.7607421875\n",
      "Batch: 10, Loss: 0.8089085221290588, Accuracy: 0.732421875\n",
      "Batch: 11, Loss: 0.7201570868492126, Accuracy: 0.767578125\n",
      "Batch: 12, Loss: 0.7328474521636963, Accuracy: 0.7587890625\n",
      "Batch: 13, Loss: 0.7022061347961426, Accuracy: 0.7763671875\n",
      "Batch: 14, Loss: 0.818999171257019, Accuracy: 0.73046875\n",
      "Batch: 15, Loss: 0.7920135259628296, Accuracy: 0.755859375\n",
      "Batch: 16, Loss: 0.7807493209838867, Accuracy: 0.75390625\n",
      "Batch: 17, Loss: 0.772964596748352, Accuracy: 0.744140625\n",
      "Batch: 18, Loss: 0.6807916164398193, Accuracy: 0.775390625\n",
      "Batch: 19, Loss: 0.7284337282180786, Accuracy: 0.763671875\n",
      "Batch: 20, Loss: 0.7284979820251465, Accuracy: 0.7568359375\n",
      "Batch: 21, Loss: 0.7427816390991211, Accuracy: 0.7607421875\n",
      "Batch: 22, Loss: 0.7203789949417114, Accuracy: 0.765625\n",
      "Batch: 23, Loss: 0.8211961984634399, Accuracy: 0.7451171875\n",
      "Batch: 24, Loss: 0.8071731328964233, Accuracy: 0.7412109375\n",
      "Batch: 25, Loss: 0.8847841620445251, Accuracy: 0.6923828125\n",
      "Batch: 26, Loss: 0.9887904524803162, Accuracy: 0.701171875\n",
      "Batch: 27, Loss: 0.8325799703598022, Accuracy: 0.7294921875\n",
      "Batch: 28, Loss: 0.7388749122619629, Accuracy: 0.755859375\n",
      "Batch: 29, Loss: 0.8159521818161011, Accuracy: 0.7412109375\n",
      "Batch: 30, Loss: 0.7868462800979614, Accuracy: 0.7431640625\n",
      "Batch: 31, Loss: 0.766899824142456, Accuracy: 0.7509765625\n",
      "Batch: 32, Loss: 0.7493354678153992, Accuracy: 0.7392578125\n",
      "Batch: 33, Loss: 0.7431439161300659, Accuracy: 0.734375\n",
      "Batch: 34, Loss: 0.6871826648712158, Accuracy: 0.7744140625\n",
      "Batch: 35, Loss: 0.7435530424118042, Accuracy: 0.759765625\n",
      "Batch: 36, Loss: 0.8216803073883057, Accuracy: 0.732421875\n",
      "Batch: 37, Loss: 0.7079950571060181, Accuracy: 0.7568359375\n",
      "Batch: 38, Loss: 0.7893646955490112, Accuracy: 0.740234375\n",
      "Batch: 39, Loss: 0.7445878982543945, Accuracy: 0.7666015625\n",
      "Batch: 40, Loss: 0.7857403755187988, Accuracy: 0.751953125\n",
      "Batch: 41, Loss: 0.7323858141899109, Accuracy: 0.7509765625\n",
      "Batch: 42, Loss: 0.7211112976074219, Accuracy: 0.759765625\n",
      "Batch: 43, Loss: 0.7670645117759705, Accuracy: 0.7470703125\n",
      "Batch: 44, Loss: 0.8333442211151123, Accuracy: 0.7255859375\n",
      "Batch: 45, Loss: 0.901953935623169, Accuracy: 0.7158203125\n",
      "Batch: 46, Loss: 0.7761188745498657, Accuracy: 0.7431640625\n",
      "Batch: 47, Loss: 0.815688967704773, Accuracy: 0.728515625\n",
      "Batch: 48, Loss: 0.8632516264915466, Accuracy: 0.716796875\n",
      "Batch: 49, Loss: 1.0113041400909424, Accuracy: 0.6982421875\n",
      "Batch: 50, Loss: 0.7326110601425171, Accuracy: 0.76171875\n",
      "Batch: 51, Loss: 0.7932836413383484, Accuracy: 0.7509765625\n",
      "Batch: 52, Loss: 0.7915460467338562, Accuracy: 0.7353515625\n",
      "Batch: 53, Loss: 0.9371363520622253, Accuracy: 0.7041015625\n",
      "Batch: 54, Loss: 0.856907308101654, Accuracy: 0.7333984375\n",
      "Batch: 55, Loss: 0.8144373893737793, Accuracy: 0.74609375\n",
      "Batch: 56, Loss: 0.8037550449371338, Accuracy: 0.7421875\n",
      "Batch: 57, Loss: 0.940248966217041, Accuracy: 0.71484375\n",
      "Batch: 58, Loss: 0.9221577644348145, Accuracy: 0.708984375\n",
      "Batch: 59, Loss: 0.824836790561676, Accuracy: 0.7314453125\n",
      "Batch: 60, Loss: 0.882422149181366, Accuracy: 0.7060546875\n",
      "Batch: 61, Loss: 0.8678130507469177, Accuracy: 0.724609375\n",
      "Batch: 62, Loss: 0.8338940143585205, Accuracy: 0.7451171875\n",
      "Batch: 63, Loss: 0.6483229398727417, Accuracy: 0.7900390625\n",
      "Batch: 64, Loss: 0.7732895612716675, Accuracy: 0.740234375\n",
      "Batch: 65, Loss: 0.7999927401542664, Accuracy: 0.7216796875\n",
      "Batch: 66, Loss: 0.7265859842300415, Accuracy: 0.763671875\n",
      "Batch: 67, Loss: 0.7431509494781494, Accuracy: 0.744140625\n",
      "Batch: 68, Loss: 0.8177384734153748, Accuracy: 0.732421875\n",
      "Batch: 69, Loss: 0.7425103187561035, Accuracy: 0.7666015625\n",
      "Batch: 70, Loss: 0.7559729218482971, Accuracy: 0.744140625\n",
      "Batch: 71, Loss: 0.7126872539520264, Accuracy: 0.7529296875\n",
      "Batch: 72, Loss: 0.7980603575706482, Accuracy: 0.734375\n",
      "Batch: 73, Loss: 0.7845476269721985, Accuracy: 0.7421875\n",
      "Batch: 74, Loss: 0.7279716730117798, Accuracy: 0.75\n",
      "Batch: 75, Loss: 0.6561631560325623, Accuracy: 0.779296875\n",
      "Batch: 76, Loss: 0.708080530166626, Accuracy: 0.76953125\n",
      "Batch: 77, Loss: 0.7973358035087585, Accuracy: 0.75\n",
      "Batch: 78, Loss: 0.73689204454422, Accuracy: 0.755859375\n",
      "Batch: 79, Loss: 0.7663754820823669, Accuracy: 0.76953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 80, Loss: 0.7500475645065308, Accuracy: 0.7412109375\n",
      "Batch: 81, Loss: 0.7630964517593384, Accuracy: 0.7470703125\n",
      "Batch: 82, Loss: 0.7163411974906921, Accuracy: 0.751953125\n",
      "Batch: 83, Loss: 0.670867919921875, Accuracy: 0.7744140625\n",
      "Batch: 84, Loss: 0.6799772381782532, Accuracy: 0.779296875\n",
      "Batch: 85, Loss: 0.6851842403411865, Accuracy: 0.7705078125\n",
      "Batch: 86, Loss: 0.6887102127075195, Accuracy: 0.763671875\n",
      "Batch: 87, Loss: 0.6627150774002075, Accuracy: 0.7880859375\n",
      "Batch: 88, Loss: 0.7421740293502808, Accuracy: 0.7470703125\n",
      "Batch: 89, Loss: 0.7406507730484009, Accuracy: 0.763671875\n",
      "Batch: 90, Loss: 0.7624269723892212, Accuracy: 0.7451171875\n",
      "Batch: 91, Loss: 0.8582417368888855, Accuracy: 0.7294921875\n",
      "Batch: 92, Loss: 0.7194550633430481, Accuracy: 0.75\n",
      "Batch: 93, Loss: 0.6959697008132935, Accuracy: 0.7685546875\n",
      "Batch: 94, Loss: 0.7630020976066589, Accuracy: 0.7529296875\n",
      "Batch: 95, Loss: 0.7813749313354492, Accuracy: 0.744140625\n",
      "Batch: 96, Loss: 0.725446879863739, Accuracy: 0.7509765625\n",
      "Batch: 97, Loss: 0.7011900544166565, Accuracy: 0.7744140625\n",
      "Batch: 98, Loss: 0.8037358522415161, Accuracy: 0.7275390625\n",
      "Batch: 99, Loss: 0.7634557485580444, Accuracy: 0.73828125\n",
      "Batch: 100, Loss: 0.8119047284126282, Accuracy: 0.7333984375\n",
      "Batch: 101, Loss: 0.7412469387054443, Accuracy: 0.7548828125\n",
      "Batch: 102, Loss: 0.7513989210128784, Accuracy: 0.751953125\n",
      "Batch: 103, Loss: 0.7872389554977417, Accuracy: 0.748046875\n",
      "Batch: 104, Loss: 0.7784104347229004, Accuracy: 0.75\n",
      "Batch: 105, Loss: 0.6668973565101624, Accuracy: 0.7685546875\n",
      "Batch: 106, Loss: 0.7585104703903198, Accuracy: 0.744140625\n",
      "Batch: 107, Loss: 0.7065092921257019, Accuracy: 0.7587890625\n",
      "Batch: 108, Loss: 0.6929003000259399, Accuracy: 0.7578125\n",
      "Batch: 109, Loss: 0.6979103088378906, Accuracy: 0.7705078125\n",
      "Batch: 110, Loss: 0.6800397038459778, Accuracy: 0.7802734375\n",
      "Batch: 111, Loss: 0.7720737457275391, Accuracy: 0.7578125\n",
      "Batch: 112, Loss: 0.7228570580482483, Accuracy: 0.759765625\n",
      "Saved Weights at epoch 20 to file Weights_20.h5\n",
      "Epoch 21/90\n",
      "Batch: 1, Loss: 1.0931450128555298, Accuracy: 0.6962890625\n",
      "Batch: 2, Loss: 0.8400660157203674, Accuracy: 0.7529296875\n",
      "Batch: 3, Loss: 0.828850507736206, Accuracy: 0.74609375\n",
      "Batch: 4, Loss: 0.7613139748573303, Accuracy: 0.7607421875\n",
      "Batch: 5, Loss: 0.7805449962615967, Accuracy: 0.75\n",
      "Batch: 6, Loss: 0.8047072291374207, Accuracy: 0.7451171875\n",
      "Batch: 7, Loss: 0.7456331849098206, Accuracy: 0.765625\n",
      "Batch: 8, Loss: 0.6635080575942993, Accuracy: 0.7724609375\n",
      "Batch: 9, Loss: 0.7190513610839844, Accuracy: 0.76953125\n",
      "Batch: 10, Loss: 0.7589993476867676, Accuracy: 0.751953125\n",
      "Batch: 11, Loss: 0.7264434099197388, Accuracy: 0.7626953125\n",
      "Batch: 12, Loss: 0.715997576713562, Accuracy: 0.765625\n",
      "Batch: 13, Loss: 0.6714913249015808, Accuracy: 0.80078125\n",
      "Batch: 14, Loss: 0.7815808057785034, Accuracy: 0.7451171875\n",
      "Batch: 15, Loss: 0.7701016664505005, Accuracy: 0.75390625\n",
      "Batch: 16, Loss: 0.7508606910705566, Accuracy: 0.7626953125\n",
      "Batch: 17, Loss: 0.760459303855896, Accuracy: 0.75390625\n",
      "Batch: 18, Loss: 0.6665518283843994, Accuracy: 0.7822265625\n",
      "Batch: 19, Loss: 0.7054692506790161, Accuracy: 0.765625\n",
      "Batch: 20, Loss: 0.732623815536499, Accuracy: 0.75390625\n",
      "Batch: 21, Loss: 0.7405786514282227, Accuracy: 0.7568359375\n",
      "Batch: 22, Loss: 0.695838212966919, Accuracy: 0.7734375\n",
      "Batch: 23, Loss: 0.7904907464981079, Accuracy: 0.7529296875\n",
      "Batch: 24, Loss: 0.7959485054016113, Accuracy: 0.7451171875\n",
      "Batch: 25, Loss: 0.8597991466522217, Accuracy: 0.712890625\n",
      "Batch: 26, Loss: 0.9677903652191162, Accuracy: 0.701171875\n",
      "Batch: 27, Loss: 0.8353552222251892, Accuracy: 0.734375\n",
      "Batch: 28, Loss: 0.7173014879226685, Accuracy: 0.763671875\n",
      "Batch: 29, Loss: 0.7803166508674622, Accuracy: 0.74609375\n",
      "Batch: 30, Loss: 0.7401256561279297, Accuracy: 0.75390625\n",
      "Batch: 31, Loss: 0.7701253890991211, Accuracy: 0.7451171875\n",
      "Batch: 32, Loss: 0.7485790252685547, Accuracy: 0.7353515625\n",
      "Batch: 33, Loss: 0.7131961584091187, Accuracy: 0.748046875\n",
      "Batch: 34, Loss: 0.6670976877212524, Accuracy: 0.7666015625\n",
      "Batch: 35, Loss: 0.7409158945083618, Accuracy: 0.7421875\n",
      "Batch: 36, Loss: 0.772534191608429, Accuracy: 0.7548828125\n",
      "Batch: 37, Loss: 0.6935704350471497, Accuracy: 0.7666015625\n",
      "Batch: 38, Loss: 0.7941890954971313, Accuracy: 0.7421875\n",
      "Batch: 39, Loss: 0.7175781726837158, Accuracy: 0.7626953125\n",
      "Batch: 40, Loss: 0.732441782951355, Accuracy: 0.763671875\n",
      "Batch: 41, Loss: 0.7480586171150208, Accuracy: 0.7470703125\n",
      "Batch: 42, Loss: 0.6700831055641174, Accuracy: 0.77734375\n",
      "Batch: 43, Loss: 0.751869261264801, Accuracy: 0.76171875\n",
      "Batch: 44, Loss: 0.7999144792556763, Accuracy: 0.748046875\n",
      "Batch: 45, Loss: 0.8708136081695557, Accuracy: 0.7216796875\n",
      "Batch: 46, Loss: 0.7408227920532227, Accuracy: 0.7646484375\n",
      "Batch: 47, Loss: 0.7984532117843628, Accuracy: 0.72265625\n",
      "Batch: 48, Loss: 0.8492520451545715, Accuracy: 0.7353515625\n",
      "Batch: 49, Loss: 0.9722049832344055, Accuracy: 0.6953125\n",
      "Batch: 50, Loss: 0.7066078186035156, Accuracy: 0.7744140625\n",
      "Batch: 51, Loss: 0.7884373664855957, Accuracy: 0.75\n",
      "Batch: 52, Loss: 0.7849870920181274, Accuracy: 0.7470703125\n",
      "Batch: 53, Loss: 0.9097030162811279, Accuracy: 0.7255859375\n",
      "Batch: 54, Loss: 0.8380373120307922, Accuracy: 0.7392578125\n",
      "Batch: 55, Loss: 0.7949786186218262, Accuracy: 0.759765625\n",
      "Batch: 56, Loss: 0.7794365286827087, Accuracy: 0.7509765625\n",
      "Batch: 57, Loss: 0.9170071482658386, Accuracy: 0.7119140625\n",
      "Batch: 58, Loss: 0.9088016152381897, Accuracy: 0.7177734375\n",
      "Batch: 59, Loss: 0.7850567102432251, Accuracy: 0.74609375\n",
      "Batch: 60, Loss: 0.8502477407455444, Accuracy: 0.7275390625\n",
      "Batch: 61, Loss: 0.843626856803894, Accuracy: 0.7265625\n",
      "Batch: 62, Loss: 0.8033937215805054, Accuracy: 0.7373046875\n",
      "Batch: 63, Loss: 0.6270229816436768, Accuracy: 0.79296875\n",
      "Batch: 64, Loss: 0.7553040385246277, Accuracy: 0.73828125\n",
      "Batch: 65, Loss: 0.7678645849227905, Accuracy: 0.744140625\n",
      "Batch: 66, Loss: 0.70075923204422, Accuracy: 0.7666015625\n",
      "Batch: 67, Loss: 0.6966320276260376, Accuracy: 0.7705078125\n",
      "Batch: 68, Loss: 0.8026864528656006, Accuracy: 0.7314453125\n",
      "Batch: 69, Loss: 0.713444709777832, Accuracy: 0.7685546875\n",
      "Batch: 70, Loss: 0.7294197082519531, Accuracy: 0.75\n",
      "Batch: 71, Loss: 0.6905103921890259, Accuracy: 0.7685546875\n",
      "Batch: 72, Loss: 0.7447541952133179, Accuracy: 0.7587890625\n",
      "Batch: 73, Loss: 0.7603573799133301, Accuracy: 0.74609375\n",
      "Batch: 74, Loss: 0.7280484437942505, Accuracy: 0.76171875\n",
      "Batch: 75, Loss: 0.6519931554794312, Accuracy: 0.7783203125\n",
      "Batch: 76, Loss: 0.6864411234855652, Accuracy: 0.76953125\n",
      "Batch: 77, Loss: 0.8065277338027954, Accuracy: 0.75\n",
      "Batch: 78, Loss: 0.7023564577102661, Accuracy: 0.7666015625\n",
      "Batch: 79, Loss: 0.745719313621521, Accuracy: 0.7666015625\n",
      "Batch: 80, Loss: 0.7115006446838379, Accuracy: 0.7578125\n",
      "Batch: 81, Loss: 0.7422041893005371, Accuracy: 0.7578125\n",
      "Batch: 82, Loss: 0.7081541419029236, Accuracy: 0.76171875\n",
      "Batch: 83, Loss: 0.6370706558227539, Accuracy: 0.7783203125\n",
      "Batch: 84, Loss: 0.6803961396217346, Accuracy: 0.77734375\n",
      "Batch: 85, Loss: 0.7045372724533081, Accuracy: 0.76953125\n",
      "Batch: 86, Loss: 0.6735032796859741, Accuracy: 0.76953125\n",
      "Batch: 87, Loss: 0.6674086451530457, Accuracy: 0.77734375\n",
      "Batch: 88, Loss: 0.7307717204093933, Accuracy: 0.751953125\n",
      "Batch: 89, Loss: 0.7170587778091431, Accuracy: 0.7763671875\n",
      "Batch: 90, Loss: 0.762477695941925, Accuracy: 0.7470703125\n",
      "Batch: 91, Loss: 0.8278371095657349, Accuracy: 0.728515625\n",
      "Batch: 92, Loss: 0.6955926418304443, Accuracy: 0.76953125\n",
      "Batch: 93, Loss: 0.7007944583892822, Accuracy: 0.76953125\n",
      "Batch: 94, Loss: 0.7297381162643433, Accuracy: 0.7607421875\n",
      "Batch: 95, Loss: 0.7706159949302673, Accuracy: 0.748046875\n",
      "Batch: 96, Loss: 0.7200189828872681, Accuracy: 0.7568359375\n",
      "Batch: 97, Loss: 0.6889193654060364, Accuracy: 0.7744140625\n",
      "Batch: 98, Loss: 0.7478141784667969, Accuracy: 0.7421875\n",
      "Batch: 99, Loss: 0.7234290838241577, Accuracy: 0.7548828125\n",
      "Batch: 100, Loss: 0.7792532444000244, Accuracy: 0.7314453125\n",
      "Batch: 101, Loss: 0.7398355007171631, Accuracy: 0.751953125\n",
      "Batch: 102, Loss: 0.7323564291000366, Accuracy: 0.7529296875\n",
      "Batch: 103, Loss: 0.7717759609222412, Accuracy: 0.7392578125\n",
      "Batch: 104, Loss: 0.7517250776290894, Accuracy: 0.75\n",
      "Batch: 105, Loss: 0.6503242254257202, Accuracy: 0.79296875\n",
      "Batch: 106, Loss: 0.7110593318939209, Accuracy: 0.7724609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 107, Loss: 0.6995546817779541, Accuracy: 0.755859375\n",
      "Batch: 108, Loss: 0.6844910383224487, Accuracy: 0.7685546875\n",
      "Batch: 109, Loss: 0.675717830657959, Accuracy: 0.77734375\n",
      "Batch: 110, Loss: 0.661784827709198, Accuracy: 0.7900390625\n",
      "Batch: 111, Loss: 0.7280597686767578, Accuracy: 0.763671875\n",
      "Batch: 112, Loss: 0.6881414651870728, Accuracy: 0.7744140625\n",
      "Epoch 22/90\n",
      "Batch: 1, Loss: 1.0574160814285278, Accuracy: 0.6923828125\n",
      "Batch: 2, Loss: 0.7949280142784119, Accuracy: 0.7587890625\n",
      "Batch: 3, Loss: 0.8057760000228882, Accuracy: 0.7529296875\n",
      "Batch: 4, Loss: 0.7352872490882874, Accuracy: 0.759765625\n",
      "Batch: 5, Loss: 0.7253106236457825, Accuracy: 0.7646484375\n",
      "Batch: 6, Loss: 0.7840636968612671, Accuracy: 0.75390625\n",
      "Batch: 7, Loss: 0.7096585035324097, Accuracy: 0.779296875\n",
      "Batch: 8, Loss: 0.6572118401527405, Accuracy: 0.7802734375\n",
      "Batch: 9, Loss: 0.6998319625854492, Accuracy: 0.7744140625\n",
      "Batch: 10, Loss: 0.7478307485580444, Accuracy: 0.75\n",
      "Batch: 11, Loss: 0.6755286455154419, Accuracy: 0.7890625\n",
      "Batch: 12, Loss: 0.6973557472229004, Accuracy: 0.7666015625\n",
      "Batch: 13, Loss: 0.6695934534072876, Accuracy: 0.794921875\n",
      "Batch: 14, Loss: 0.7462440729141235, Accuracy: 0.74609375\n",
      "Batch: 15, Loss: 0.7343682050704956, Accuracy: 0.7626953125\n",
      "Batch: 16, Loss: 0.7548510432243347, Accuracy: 0.75390625\n",
      "Batch: 17, Loss: 0.74044269323349, Accuracy: 0.7646484375\n",
      "Batch: 18, Loss: 0.66960608959198, Accuracy: 0.76953125\n",
      "Batch: 19, Loss: 0.6601312756538391, Accuracy: 0.783203125\n",
      "Batch: 20, Loss: 0.7244554758071899, Accuracy: 0.7626953125\n",
      "Batch: 21, Loss: 0.7287744283676147, Accuracy: 0.767578125\n",
      "Batch: 22, Loss: 0.7081149816513062, Accuracy: 0.759765625\n",
      "Batch: 23, Loss: 0.7663712501525879, Accuracy: 0.74609375\n",
      "Batch: 24, Loss: 0.7661430835723877, Accuracy: 0.755859375\n",
      "Batch: 25, Loss: 0.8237693309783936, Accuracy: 0.7177734375\n",
      "Batch: 26, Loss: 0.9412767887115479, Accuracy: 0.72265625\n",
      "Batch: 27, Loss: 0.8054990768432617, Accuracy: 0.7373046875\n",
      "Batch: 28, Loss: 0.6992709636688232, Accuracy: 0.76171875\n",
      "Batch: 29, Loss: 0.766589879989624, Accuracy: 0.75390625\n",
      "Batch: 30, Loss: 0.7226154208183289, Accuracy: 0.767578125\n",
      "Batch: 31, Loss: 0.7485399842262268, Accuracy: 0.7451171875\n",
      "Batch: 32, Loss: 0.7129509449005127, Accuracy: 0.7607421875\n",
      "Batch: 33, Loss: 0.702986478805542, Accuracy: 0.759765625\n",
      "Batch: 34, Loss: 0.6590656638145447, Accuracy: 0.7802734375\n",
      "Batch: 35, Loss: 0.7335519790649414, Accuracy: 0.767578125\n",
      "Batch: 36, Loss: 0.7764372825622559, Accuracy: 0.75390625\n",
      "Batch: 37, Loss: 0.661017656326294, Accuracy: 0.7783203125\n",
      "Batch: 38, Loss: 0.7731534242630005, Accuracy: 0.7392578125\n",
      "Batch: 39, Loss: 0.7111303210258484, Accuracy: 0.763671875\n",
      "Batch: 40, Loss: 0.7274314165115356, Accuracy: 0.7529296875\n",
      "Batch: 41, Loss: 0.7000635862350464, Accuracy: 0.7666015625\n",
      "Batch: 42, Loss: 0.6754992604255676, Accuracy: 0.7666015625\n",
      "Batch: 43, Loss: 0.7323541045188904, Accuracy: 0.7529296875\n",
      "Batch: 44, Loss: 0.7990020513534546, Accuracy: 0.75\n",
      "Batch: 45, Loss: 0.8611076474189758, Accuracy: 0.7373046875\n",
      "Batch: 46, Loss: 0.7400650382041931, Accuracy: 0.75\n",
      "Batch: 47, Loss: 0.7638270854949951, Accuracy: 0.736328125\n",
      "Batch: 48, Loss: 0.8048116564750671, Accuracy: 0.7548828125\n",
      "Batch: 49, Loss: 0.9252378344535828, Accuracy: 0.7021484375\n",
      "Batch: 50, Loss: 0.6879217624664307, Accuracy: 0.783203125\n",
      "Batch: 51, Loss: 0.7853270173072815, Accuracy: 0.734375\n",
      "Batch: 52, Loss: 0.747010350227356, Accuracy: 0.751953125\n",
      "Batch: 53, Loss: 0.8898913860321045, Accuracy: 0.7265625\n",
      "Batch: 54, Loss: 0.8121411204338074, Accuracy: 0.7421875\n",
      "Batch: 55, Loss: 0.8141579627990723, Accuracy: 0.751953125\n",
      "Batch: 56, Loss: 0.7859855890274048, Accuracy: 0.7548828125\n",
      "Batch: 57, Loss: 0.8965566754341125, Accuracy: 0.7236328125\n",
      "Batch: 58, Loss: 0.8871030807495117, Accuracy: 0.716796875\n",
      "Batch: 59, Loss: 0.763102650642395, Accuracy: 0.7451171875\n",
      "Batch: 60, Loss: 0.8360493183135986, Accuracy: 0.734375\n",
      "Batch: 61, Loss: 0.8163106441497803, Accuracy: 0.732421875\n",
      "Batch: 62, Loss: 0.8013380765914917, Accuracy: 0.7470703125\n",
      "Batch: 63, Loss: 0.6349673271179199, Accuracy: 0.7958984375\n",
      "Batch: 64, Loss: 0.7157881259918213, Accuracy: 0.7587890625\n",
      "Batch: 65, Loss: 0.7465528249740601, Accuracy: 0.74609375\n",
      "Batch: 66, Loss: 0.6687010526657104, Accuracy: 0.77734375\n",
      "Batch: 67, Loss: 0.7119370102882385, Accuracy: 0.763671875\n",
      "Batch: 68, Loss: 0.7731422781944275, Accuracy: 0.75390625\n",
      "Batch: 69, Loss: 0.6843125820159912, Accuracy: 0.767578125\n",
      "Batch: 70, Loss: 0.7199556827545166, Accuracy: 0.7578125\n",
      "Batch: 71, Loss: 0.6733031272888184, Accuracy: 0.775390625\n",
      "Batch: 72, Loss: 0.7451186180114746, Accuracy: 0.748046875\n",
      "Batch: 73, Loss: 0.7436679601669312, Accuracy: 0.7587890625\n",
      "Batch: 74, Loss: 0.7004140615463257, Accuracy: 0.7734375\n",
      "Batch: 75, Loss: 0.6304105520248413, Accuracy: 0.79296875\n",
      "Batch: 76, Loss: 0.6781688928604126, Accuracy: 0.7705078125\n",
      "Batch: 77, Loss: 0.7624768018722534, Accuracy: 0.755859375\n",
      "Batch: 78, Loss: 0.6874430179595947, Accuracy: 0.775390625\n",
      "Batch: 79, Loss: 0.7160816192626953, Accuracy: 0.7685546875\n",
      "Batch: 80, Loss: 0.7026163339614868, Accuracy: 0.775390625\n",
      "Batch: 81, Loss: 0.7367000579833984, Accuracy: 0.7529296875\n",
      "Batch: 82, Loss: 0.6984908580780029, Accuracy: 0.779296875\n",
      "Batch: 83, Loss: 0.6456100940704346, Accuracy: 0.775390625\n",
      "Batch: 84, Loss: 0.6525608897209167, Accuracy: 0.7822265625\n",
      "Batch: 85, Loss: 0.6717381477355957, Accuracy: 0.767578125\n",
      "Batch: 86, Loss: 0.6511195302009583, Accuracy: 0.77734375\n",
      "Batch: 87, Loss: 0.6415724158287048, Accuracy: 0.7958984375\n",
      "Batch: 88, Loss: 0.6799361705780029, Accuracy: 0.7724609375\n",
      "Batch: 89, Loss: 0.7016491889953613, Accuracy: 0.7744140625\n",
      "Batch: 90, Loss: 0.7384554147720337, Accuracy: 0.76171875\n",
      "Batch: 91, Loss: 0.8007057309150696, Accuracy: 0.7412109375\n",
      "Batch: 92, Loss: 0.7014410495758057, Accuracy: 0.7578125\n",
      "Batch: 93, Loss: 0.6975276470184326, Accuracy: 0.7666015625\n",
      "Batch: 94, Loss: 0.7376810312271118, Accuracy: 0.763671875\n",
      "Batch: 95, Loss: 0.7334058284759521, Accuracy: 0.75\n",
      "Batch: 96, Loss: 0.6942098140716553, Accuracy: 0.7685546875\n",
      "Batch: 97, Loss: 0.6849374771118164, Accuracy: 0.7705078125\n",
      "Batch: 98, Loss: 0.747504472732544, Accuracy: 0.744140625\n",
      "Batch: 99, Loss: 0.7058534622192383, Accuracy: 0.767578125\n",
      "Batch: 100, Loss: 0.7645223140716553, Accuracy: 0.7529296875\n",
      "Batch: 101, Loss: 0.7054411768913269, Accuracy: 0.767578125\n",
      "Batch: 102, Loss: 0.73702073097229, Accuracy: 0.7607421875\n",
      "Batch: 103, Loss: 0.7554192543029785, Accuracy: 0.75\n",
      "Batch: 104, Loss: 0.7303658723831177, Accuracy: 0.7607421875\n",
      "Batch: 105, Loss: 0.6299744844436646, Accuracy: 0.7783203125\n",
      "Batch: 106, Loss: 0.7067208290100098, Accuracy: 0.7685546875\n",
      "Batch: 107, Loss: 0.6884663105010986, Accuracy: 0.7734375\n",
      "Batch: 108, Loss: 0.6753255128860474, Accuracy: 0.7666015625\n",
      "Batch: 109, Loss: 0.638261079788208, Accuracy: 0.7919921875\n",
      "Batch: 110, Loss: 0.6302722692489624, Accuracy: 0.7919921875\n",
      "Batch: 111, Loss: 0.7383084297180176, Accuracy: 0.7470703125\n",
      "Batch: 112, Loss: 0.7067403197288513, Accuracy: 0.76953125\n",
      "Epoch 23/90\n",
      "Batch: 1, Loss: 1.0612226724624634, Accuracy: 0.7001953125\n",
      "Batch: 2, Loss: 0.7961463928222656, Accuracy: 0.748046875\n",
      "Batch: 3, Loss: 0.7739771008491516, Accuracy: 0.7578125\n",
      "Batch: 4, Loss: 0.7179214954376221, Accuracy: 0.7763671875\n",
      "Batch: 5, Loss: 0.7344713807106018, Accuracy: 0.7548828125\n",
      "Batch: 6, Loss: 0.7612417936325073, Accuracy: 0.763671875\n",
      "Batch: 7, Loss: 0.6876931190490723, Accuracy: 0.779296875\n",
      "Batch: 8, Loss: 0.6280784010887146, Accuracy: 0.79296875\n",
      "Batch: 9, Loss: 0.6932080388069153, Accuracy: 0.78125\n",
      "Batch: 10, Loss: 0.7506946325302124, Accuracy: 0.751953125\n",
      "Batch: 11, Loss: 0.6673866510391235, Accuracy: 0.7861328125\n",
      "Batch: 12, Loss: 0.6730585098266602, Accuracy: 0.78125\n",
      "Batch: 13, Loss: 0.6213947534561157, Accuracy: 0.8056640625\n",
      "Batch: 14, Loss: 0.7197960615158081, Accuracy: 0.759765625\n",
      "Batch: 15, Loss: 0.7285597324371338, Accuracy: 0.76171875\n",
      "Batch: 16, Loss: 0.7400118112564087, Accuracy: 0.759765625\n",
      "Batch: 17, Loss: 0.7294018268585205, Accuracy: 0.7666015625\n",
      "Batch: 18, Loss: 0.6363325119018555, Accuracy: 0.7880859375\n",
      "Batch: 19, Loss: 0.6507798433303833, Accuracy: 0.791015625\n",
      "Batch: 20, Loss: 0.6827151775360107, Accuracy: 0.771484375\n",
      "Batch: 21, Loss: 0.6859888434410095, Accuracy: 0.787109375\n",
      "Batch: 22, Loss: 0.6373596787452698, Accuracy: 0.791015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 23, Loss: 0.7523859143257141, Accuracy: 0.767578125\n",
      "Batch: 24, Loss: 0.7492333054542542, Accuracy: 0.765625\n",
      "Batch: 25, Loss: 0.8269627094268799, Accuracy: 0.724609375\n",
      "Batch: 26, Loss: 0.9182555675506592, Accuracy: 0.7275390625\n",
      "Batch: 27, Loss: 0.798118531703949, Accuracy: 0.75\n",
      "Batch: 28, Loss: 0.6939248442649841, Accuracy: 0.7646484375\n",
      "Batch: 29, Loss: 0.748446524143219, Accuracy: 0.755859375\n",
      "Batch: 30, Loss: 0.6836647987365723, Accuracy: 0.775390625\n",
      "Batch: 31, Loss: 0.713707685470581, Accuracy: 0.7607421875\n",
      "Batch: 32, Loss: 0.6857894062995911, Accuracy: 0.755859375\n",
      "Batch: 33, Loss: 0.7109405994415283, Accuracy: 0.759765625\n",
      "Batch: 34, Loss: 0.6400028467178345, Accuracy: 0.7861328125\n",
      "Batch: 35, Loss: 0.7080786228179932, Accuracy: 0.765625\n",
      "Batch: 36, Loss: 0.7387251257896423, Accuracy: 0.7626953125\n",
      "Batch: 37, Loss: 0.659034252166748, Accuracy: 0.779296875\n",
      "Batch: 38, Loss: 0.7228289246559143, Accuracy: 0.763671875\n",
      "Batch: 39, Loss: 0.6896704435348511, Accuracy: 0.7861328125\n",
      "Batch: 40, Loss: 0.7222640514373779, Accuracy: 0.7705078125\n",
      "Batch: 41, Loss: 0.7084033489227295, Accuracy: 0.7529296875\n",
      "Batch: 42, Loss: 0.6545541286468506, Accuracy: 0.77734375\n",
      "Batch: 43, Loss: 0.7282816767692566, Accuracy: 0.7490234375\n",
      "Batch: 44, Loss: 0.7704210877418518, Accuracy: 0.75390625\n",
      "Batch: 45, Loss: 0.8446675539016724, Accuracy: 0.7294921875\n",
      "Batch: 46, Loss: 0.7247471809387207, Accuracy: 0.7568359375\n",
      "Batch: 47, Loss: 0.7708386182785034, Accuracy: 0.7431640625\n",
      "Batch: 48, Loss: 0.8080496788024902, Accuracy: 0.74609375\n",
      "Batch: 49, Loss: 0.9176018834114075, Accuracy: 0.708984375\n",
      "Batch: 50, Loss: 0.6509937047958374, Accuracy: 0.8017578125\n",
      "Batch: 51, Loss: 0.7483121156692505, Accuracy: 0.748046875\n",
      "Batch: 52, Loss: 0.7192435264587402, Accuracy: 0.7626953125\n",
      "Batch: 53, Loss: 0.8686078786849976, Accuracy: 0.7373046875\n",
      "Batch: 54, Loss: 0.8004650473594666, Accuracy: 0.748046875\n",
      "Batch: 55, Loss: 0.7820721864700317, Accuracy: 0.759765625\n",
      "Batch: 56, Loss: 0.740297794342041, Accuracy: 0.7685546875\n",
      "Batch: 57, Loss: 0.8676359057426453, Accuracy: 0.7333984375\n",
      "Batch: 58, Loss: 0.8769771456718445, Accuracy: 0.7275390625\n",
      "Batch: 59, Loss: 0.7589849233627319, Accuracy: 0.7470703125\n",
      "Batch: 60, Loss: 0.8196487426757812, Accuracy: 0.724609375\n",
      "Batch: 61, Loss: 0.8014906644821167, Accuracy: 0.73046875\n",
      "Batch: 62, Loss: 0.7743818759918213, Accuracy: 0.76171875\n",
      "Batch: 63, Loss: 0.6114693880081177, Accuracy: 0.80078125\n",
      "Batch: 64, Loss: 0.6999930143356323, Accuracy: 0.767578125\n",
      "Batch: 65, Loss: 0.725927472114563, Accuracy: 0.7470703125\n",
      "Batch: 66, Loss: 0.6715894937515259, Accuracy: 0.783203125\n",
      "Batch: 67, Loss: 0.6977832913398743, Accuracy: 0.763671875\n",
      "Batch: 68, Loss: 0.7438406944274902, Accuracy: 0.7607421875\n",
      "Batch: 69, Loss: 0.6626591682434082, Accuracy: 0.7890625\n",
      "Batch: 70, Loss: 0.6942299008369446, Accuracy: 0.7724609375\n",
      "Batch: 71, Loss: 0.6487821936607361, Accuracy: 0.7900390625\n",
      "Batch: 72, Loss: 0.7258381247520447, Accuracy: 0.755859375\n",
      "Batch: 73, Loss: 0.7237339019775391, Accuracy: 0.7626953125\n",
      "Batch: 74, Loss: 0.6596433520317078, Accuracy: 0.794921875\n",
      "Batch: 75, Loss: 0.623322606086731, Accuracy: 0.7890625\n",
      "Batch: 76, Loss: 0.6614487767219543, Accuracy: 0.783203125\n",
      "Batch: 77, Loss: 0.7550877332687378, Accuracy: 0.7421875\n",
      "Batch: 78, Loss: 0.6733849048614502, Accuracy: 0.7802734375\n",
      "Batch: 79, Loss: 0.7048496603965759, Accuracy: 0.7861328125\n",
      "Batch: 80, Loss: 0.7104828357696533, Accuracy: 0.76171875\n",
      "Batch: 81, Loss: 0.7188188433647156, Accuracy: 0.76171875\n",
      "Batch: 82, Loss: 0.6685994863510132, Accuracy: 0.7587890625\n",
      "Batch: 83, Loss: 0.6328885555267334, Accuracy: 0.7802734375\n",
      "Batch: 84, Loss: 0.6445899605751038, Accuracy: 0.791015625\n",
      "Batch: 85, Loss: 0.6611906886100769, Accuracy: 0.783203125\n",
      "Batch: 86, Loss: 0.6226727962493896, Accuracy: 0.7958984375\n",
      "Batch: 87, Loss: 0.6281414031982422, Accuracy: 0.8037109375\n",
      "Batch: 88, Loss: 0.6701595783233643, Accuracy: 0.783203125\n",
      "Batch: 89, Loss: 0.6656298637390137, Accuracy: 0.7724609375\n",
      "Batch: 90, Loss: 0.7135064005851746, Accuracy: 0.7646484375\n",
      "Batch: 91, Loss: 0.7729783058166504, Accuracy: 0.7509765625\n",
      "Batch: 92, Loss: 0.6747195720672607, Accuracy: 0.765625\n",
      "Batch: 93, Loss: 0.6607873439788818, Accuracy: 0.77734375\n",
      "Batch: 94, Loss: 0.7183692455291748, Accuracy: 0.759765625\n",
      "Batch: 95, Loss: 0.7031051516532898, Accuracy: 0.7734375\n",
      "Batch: 96, Loss: 0.7027088403701782, Accuracy: 0.7509765625\n",
      "Batch: 97, Loss: 0.67256760597229, Accuracy: 0.7705078125\n",
      "Batch: 98, Loss: 0.7583647966384888, Accuracy: 0.7353515625\n",
      "Batch: 99, Loss: 0.6841278672218323, Accuracy: 0.7607421875\n",
      "Batch: 100, Loss: 0.7341453433036804, Accuracy: 0.751953125\n",
      "Batch: 101, Loss: 0.6918159127235413, Accuracy: 0.771484375\n",
      "Batch: 102, Loss: 0.6712157726287842, Accuracy: 0.7734375\n",
      "Batch: 103, Loss: 0.7270342707633972, Accuracy: 0.75\n",
      "Batch: 104, Loss: 0.7231426239013672, Accuracy: 0.7607421875\n",
      "Batch: 105, Loss: 0.6138783097267151, Accuracy: 0.806640625\n",
      "Batch: 106, Loss: 0.6756141185760498, Accuracy: 0.7802734375\n",
      "Batch: 107, Loss: 0.6591475009918213, Accuracy: 0.76953125\n",
      "Batch: 108, Loss: 0.6487915515899658, Accuracy: 0.771484375\n",
      "Batch: 109, Loss: 0.616887092590332, Accuracy: 0.7939453125\n",
      "Batch: 110, Loss: 0.6260901093482971, Accuracy: 0.794921875\n",
      "Batch: 111, Loss: 0.6968933343887329, Accuracy: 0.7734375\n",
      "Batch: 112, Loss: 0.6793789863586426, Accuracy: 0.7841796875\n",
      "Epoch 24/90\n",
      "Batch: 1, Loss: 1.0437228679656982, Accuracy: 0.697265625\n",
      "Batch: 2, Loss: 0.7811876535415649, Accuracy: 0.7744140625\n",
      "Batch: 3, Loss: 0.7540270686149597, Accuracy: 0.7646484375\n",
      "Batch: 4, Loss: 0.6882973909378052, Accuracy: 0.775390625\n",
      "Batch: 5, Loss: 0.699418306350708, Accuracy: 0.76953125\n",
      "Batch: 6, Loss: 0.7354152202606201, Accuracy: 0.7666015625\n",
      "Batch: 7, Loss: 0.6893831491470337, Accuracy: 0.7861328125\n",
      "Batch: 8, Loss: 0.5897030830383301, Accuracy: 0.8017578125\n",
      "Batch: 9, Loss: 0.6932357549667358, Accuracy: 0.76953125\n",
      "Batch: 10, Loss: 0.7207538485527039, Accuracy: 0.755859375\n",
      "Batch: 11, Loss: 0.6769895553588867, Accuracy: 0.787109375\n",
      "Batch: 12, Loss: 0.6377619504928589, Accuracy: 0.7978515625\n",
      "Batch: 13, Loss: 0.6363152265548706, Accuracy: 0.8095703125\n",
      "Batch: 14, Loss: 0.6948884725570679, Accuracy: 0.76953125\n",
      "Batch: 15, Loss: 0.7159997224807739, Accuracy: 0.765625\n",
      "Batch: 16, Loss: 0.6939200162887573, Accuracy: 0.77734375\n",
      "Batch: 17, Loss: 0.7213050723075867, Accuracy: 0.76953125\n",
      "Batch: 18, Loss: 0.6276933550834656, Accuracy: 0.78515625\n",
      "Batch: 19, Loss: 0.6227490305900574, Accuracy: 0.796875\n",
      "Batch: 20, Loss: 0.6883252263069153, Accuracy: 0.7724609375\n",
      "Batch: 21, Loss: 0.6758103966712952, Accuracy: 0.7861328125\n",
      "Batch: 22, Loss: 0.6300268173217773, Accuracy: 0.7919921875\n",
      "Batch: 23, Loss: 0.7488662004470825, Accuracy: 0.767578125\n",
      "Batch: 24, Loss: 0.7573855519294739, Accuracy: 0.759765625\n",
      "Batch: 25, Loss: 0.7859750986099243, Accuracy: 0.751953125\n",
      "Batch: 26, Loss: 0.8755468130111694, Accuracy: 0.736328125\n",
      "Batch: 27, Loss: 0.7498840093612671, Accuracy: 0.765625\n",
      "Batch: 28, Loss: 0.6664509773254395, Accuracy: 0.7724609375\n",
      "Batch: 29, Loss: 0.7432297468185425, Accuracy: 0.755859375\n",
      "Batch: 30, Loss: 0.6752766370773315, Accuracy: 0.7666015625\n",
      "Batch: 31, Loss: 0.7294589281082153, Accuracy: 0.759765625\n",
      "Batch: 32, Loss: 0.6824233531951904, Accuracy: 0.7666015625\n",
      "Batch: 33, Loss: 0.6836299896240234, Accuracy: 0.7509765625\n",
      "Batch: 34, Loss: 0.6339782476425171, Accuracy: 0.7880859375\n",
      "Batch: 35, Loss: 0.686121940612793, Accuracy: 0.767578125\n",
      "Batch: 36, Loss: 0.7142772078514099, Accuracy: 0.771484375\n",
      "Batch: 37, Loss: 0.650891900062561, Accuracy: 0.7802734375\n",
      "Batch: 38, Loss: 0.7333724498748779, Accuracy: 0.7587890625\n",
      "Batch: 39, Loss: 0.6805925369262695, Accuracy: 0.7900390625\n",
      "Batch: 40, Loss: 0.696693480014801, Accuracy: 0.7626953125\n",
      "Batch: 41, Loss: 0.6767681837081909, Accuracy: 0.77734375\n",
      "Batch: 42, Loss: 0.6439660787582397, Accuracy: 0.7939453125\n",
      "Batch: 43, Loss: 0.6935403347015381, Accuracy: 0.7666015625\n",
      "Batch: 44, Loss: 0.7466936707496643, Accuracy: 0.7646484375\n",
      "Batch: 45, Loss: 0.8289871215820312, Accuracy: 0.73046875\n",
      "Batch: 46, Loss: 0.7132073640823364, Accuracy: 0.763671875\n",
      "Batch: 47, Loss: 0.7378648519515991, Accuracy: 0.7451171875\n",
      "Batch: 48, Loss: 0.7703927755355835, Accuracy: 0.7646484375\n",
      "Batch: 49, Loss: 0.8824285864830017, Accuracy: 0.734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 50, Loss: 0.658768355846405, Accuracy: 0.796875\n",
      "Batch: 51, Loss: 0.7261155843734741, Accuracy: 0.7626953125\n",
      "Batch: 52, Loss: 0.7199729084968567, Accuracy: 0.7685546875\n",
      "Batch: 53, Loss: 0.8207772374153137, Accuracy: 0.7421875\n",
      "Batch: 54, Loss: 0.7818463444709778, Accuracy: 0.7568359375\n",
      "Batch: 55, Loss: 0.7438339591026306, Accuracy: 0.7763671875\n",
      "Batch: 56, Loss: 0.7101976871490479, Accuracy: 0.76171875\n",
      "Batch: 57, Loss: 0.859677791595459, Accuracy: 0.7314453125\n",
      "Batch: 58, Loss: 0.8354026079177856, Accuracy: 0.7314453125\n",
      "Batch: 59, Loss: 0.7236088514328003, Accuracy: 0.767578125\n",
      "Batch: 60, Loss: 0.7793977856636047, Accuracy: 0.7392578125\n",
      "Batch: 61, Loss: 0.7666919231414795, Accuracy: 0.7470703125\n",
      "Batch: 62, Loss: 0.7556272149085999, Accuracy: 0.7587890625\n",
      "Batch: 63, Loss: 0.5902660489082336, Accuracy: 0.7998046875\n",
      "Batch: 64, Loss: 0.709219217300415, Accuracy: 0.76953125\n",
      "Batch: 65, Loss: 0.6989415884017944, Accuracy: 0.7626953125\n",
      "Batch: 66, Loss: 0.6389882564544678, Accuracy: 0.7958984375\n",
      "Batch: 67, Loss: 0.6637400984764099, Accuracy: 0.77734375\n",
      "Batch: 68, Loss: 0.7266139984130859, Accuracy: 0.759765625\n",
      "Batch: 69, Loss: 0.6634376645088196, Accuracy: 0.7861328125\n",
      "Batch: 70, Loss: 0.6660382747650146, Accuracy: 0.779296875\n",
      "Batch: 71, Loss: 0.6410105228424072, Accuracy: 0.783203125\n",
      "Batch: 72, Loss: 0.6910468339920044, Accuracy: 0.7744140625\n",
      "Batch: 73, Loss: 0.7086169719696045, Accuracy: 0.7587890625\n",
      "Batch: 74, Loss: 0.6533157229423523, Accuracy: 0.7822265625\n",
      "Batch: 75, Loss: 0.6001913547515869, Accuracy: 0.798828125\n",
      "Batch: 76, Loss: 0.6439142823219299, Accuracy: 0.7861328125\n",
      "Batch: 77, Loss: 0.7115981578826904, Accuracy: 0.771484375\n",
      "Batch: 78, Loss: 0.6506171226501465, Accuracy: 0.7919921875\n",
      "Batch: 79, Loss: 0.7048506736755371, Accuracy: 0.787109375\n",
      "Batch: 80, Loss: 0.6639949083328247, Accuracy: 0.7705078125\n",
      "Batch: 81, Loss: 0.7122722864151001, Accuracy: 0.7529296875\n",
      "Batch: 82, Loss: 0.6797428727149963, Accuracy: 0.77734375\n",
      "Batch: 83, Loss: 0.6297144293785095, Accuracy: 0.7822265625\n",
      "Batch: 84, Loss: 0.6314381957054138, Accuracy: 0.794921875\n",
      "Batch: 85, Loss: 0.6457206010818481, Accuracy: 0.775390625\n",
      "Batch: 86, Loss: 0.644249439239502, Accuracy: 0.7783203125\n",
      "Batch: 87, Loss: 0.6017606258392334, Accuracy: 0.798828125\n",
      "Batch: 88, Loss: 0.6564063429832458, Accuracy: 0.791015625\n",
      "Batch: 89, Loss: 0.6711751818656921, Accuracy: 0.77734375\n",
      "Batch: 90, Loss: 0.7072363495826721, Accuracy: 0.76171875\n",
      "Batch: 91, Loss: 0.7689146995544434, Accuracy: 0.759765625\n",
      "Batch: 92, Loss: 0.6651701331138611, Accuracy: 0.765625\n",
      "Batch: 93, Loss: 0.6359673738479614, Accuracy: 0.7861328125\n",
      "Batch: 94, Loss: 0.6857040524482727, Accuracy: 0.775390625\n",
      "Batch: 95, Loss: 0.7093114852905273, Accuracy: 0.7724609375\n",
      "Batch: 96, Loss: 0.6782861948013306, Accuracy: 0.7666015625\n",
      "Batch: 97, Loss: 0.6146279573440552, Accuracy: 0.794921875\n",
      "Batch: 98, Loss: 0.7259324193000793, Accuracy: 0.755859375\n",
      "Batch: 99, Loss: 0.6613434553146362, Accuracy: 0.7734375\n",
      "Batch: 100, Loss: 0.711393415927887, Accuracy: 0.7568359375\n",
      "Batch: 101, Loss: 0.6796435713768005, Accuracy: 0.76953125\n",
      "Batch: 102, Loss: 0.6542635560035706, Accuracy: 0.79296875\n",
      "Batch: 103, Loss: 0.7024295926094055, Accuracy: 0.7646484375\n",
      "Batch: 104, Loss: 0.6747716069221497, Accuracy: 0.7666015625\n",
      "Batch: 105, Loss: 0.6006035804748535, Accuracy: 0.802734375\n",
      "Batch: 106, Loss: 0.6861911416053772, Accuracy: 0.7763671875\n",
      "Batch: 107, Loss: 0.6524998545646667, Accuracy: 0.7744140625\n",
      "Batch: 108, Loss: 0.6467441320419312, Accuracy: 0.7763671875\n",
      "Batch: 109, Loss: 0.5866997838020325, Accuracy: 0.8095703125\n",
      "Batch: 110, Loss: 0.6031689643859863, Accuracy: 0.7998046875\n",
      "Batch: 111, Loss: 0.6832048892974854, Accuracy: 0.77734375\n",
      "Batch: 112, Loss: 0.6569163799285889, Accuracy: 0.7802734375\n",
      "Epoch 25/90\n",
      "Batch: 1, Loss: 0.9660272002220154, Accuracy: 0.724609375\n",
      "Batch: 2, Loss: 0.7359418869018555, Accuracy: 0.7724609375\n",
      "Batch: 3, Loss: 0.7374739050865173, Accuracy: 0.7646484375\n",
      "Batch: 4, Loss: 0.6807602643966675, Accuracy: 0.783203125\n",
      "Batch: 5, Loss: 0.681625247001648, Accuracy: 0.78515625\n",
      "Batch: 6, Loss: 0.7419346570968628, Accuracy: 0.7607421875\n",
      "Batch: 7, Loss: 0.6468774080276489, Accuracy: 0.798828125\n",
      "Batch: 8, Loss: 0.5649002194404602, Accuracy: 0.8193359375\n",
      "Batch: 9, Loss: 0.6556975841522217, Accuracy: 0.7919921875\n",
      "Batch: 10, Loss: 0.6896259784698486, Accuracy: 0.7666015625\n",
      "Batch: 11, Loss: 0.6386733651161194, Accuracy: 0.7919921875\n",
      "Batch: 12, Loss: 0.6203263998031616, Accuracy: 0.8037109375\n",
      "Batch: 13, Loss: 0.6000531911849976, Accuracy: 0.8095703125\n",
      "Batch: 14, Loss: 0.6721951961517334, Accuracy: 0.7841796875\n",
      "Batch: 15, Loss: 0.6936237812042236, Accuracy: 0.76953125\n",
      "Batch: 16, Loss: 0.6842429637908936, Accuracy: 0.775390625\n",
      "Batch: 17, Loss: 0.7053183317184448, Accuracy: 0.7763671875\n",
      "Batch: 18, Loss: 0.6077837944030762, Accuracy: 0.787109375\n",
      "Batch: 19, Loss: 0.6181660890579224, Accuracy: 0.802734375\n",
      "Batch: 20, Loss: 0.6556668281555176, Accuracy: 0.775390625\n",
      "Batch: 21, Loss: 0.6638403534889221, Accuracy: 0.7861328125\n",
      "Batch: 22, Loss: 0.6183474659919739, Accuracy: 0.7998046875\n",
      "Batch: 23, Loss: 0.6957269906997681, Accuracy: 0.7841796875\n",
      "Batch: 24, Loss: 0.7372288107872009, Accuracy: 0.771484375\n",
      "Batch: 25, Loss: 0.7958520650863647, Accuracy: 0.734375\n",
      "Batch: 26, Loss: 0.8441608548164368, Accuracy: 0.7353515625\n",
      "Batch: 27, Loss: 0.784472644329071, Accuracy: 0.7412109375\n",
      "Batch: 28, Loss: 0.6563163995742798, Accuracy: 0.767578125\n",
      "Batch: 29, Loss: 0.7293897867202759, Accuracy: 0.7666015625\n",
      "Batch: 30, Loss: 0.6521099805831909, Accuracy: 0.7890625\n",
      "Batch: 31, Loss: 0.6854479312896729, Accuracy: 0.7744140625\n",
      "Batch: 32, Loss: 0.6543499231338501, Accuracy: 0.779296875\n",
      "Batch: 33, Loss: 0.6695848703384399, Accuracy: 0.75\n",
      "Batch: 34, Loss: 0.6066382527351379, Accuracy: 0.796875\n",
      "Batch: 35, Loss: 0.6436783075332642, Accuracy: 0.78515625\n",
      "Batch: 36, Loss: 0.7403193712234497, Accuracy: 0.7646484375\n",
      "Batch: 37, Loss: 0.6193047761917114, Accuracy: 0.7861328125\n",
      "Batch: 38, Loss: 0.7012345194816589, Accuracy: 0.7578125\n",
      "Batch: 39, Loss: 0.6336328983306885, Accuracy: 0.8115234375\n",
      "Batch: 40, Loss: 0.6661829948425293, Accuracy: 0.779296875\n",
      "Batch: 41, Loss: 0.658726155757904, Accuracy: 0.7783203125\n",
      "Batch: 42, Loss: 0.6277809143066406, Accuracy: 0.7802734375\n",
      "Batch: 43, Loss: 0.696661651134491, Accuracy: 0.7802734375\n",
      "Batch: 44, Loss: 0.7342706322669983, Accuracy: 0.755859375\n",
      "Batch: 45, Loss: 0.7983803153038025, Accuracy: 0.744140625\n",
      "Batch: 46, Loss: 0.6892427802085876, Accuracy: 0.7890625\n",
      "Batch: 47, Loss: 0.7158786058425903, Accuracy: 0.7646484375\n",
      "Batch: 48, Loss: 0.7653756737709045, Accuracy: 0.771484375\n",
      "Batch: 49, Loss: 0.8549606800079346, Accuracy: 0.73828125\n",
      "Batch: 50, Loss: 0.6340569257736206, Accuracy: 0.806640625\n",
      "Batch: 51, Loss: 0.6976951360702515, Accuracy: 0.779296875\n",
      "Batch: 52, Loss: 0.6987661719322205, Accuracy: 0.7705078125\n",
      "Batch: 53, Loss: 0.8291504383087158, Accuracy: 0.7353515625\n",
      "Batch: 54, Loss: 0.7263079881668091, Accuracy: 0.7578125\n",
      "Batch: 55, Loss: 0.7628644704818726, Accuracy: 0.779296875\n",
      "Batch: 56, Loss: 0.6723398566246033, Accuracy: 0.7861328125\n",
      "Batch: 57, Loss: 0.7991116046905518, Accuracy: 0.748046875\n",
      "Batch: 58, Loss: 0.8075696229934692, Accuracy: 0.732421875\n",
      "Batch: 59, Loss: 0.7235336303710938, Accuracy: 0.76171875\n",
      "Batch: 60, Loss: 0.7866806983947754, Accuracy: 0.751953125\n",
      "Batch: 61, Loss: 0.7556746602058411, Accuracy: 0.755859375\n",
      "Batch: 62, Loss: 0.7259848117828369, Accuracy: 0.7626953125\n",
      "Batch: 63, Loss: 0.5690030455589294, Accuracy: 0.8193359375\n",
      "Batch: 64, Loss: 0.6777143478393555, Accuracy: 0.76953125\n",
      "Batch: 65, Loss: 0.6835764646530151, Accuracy: 0.763671875\n",
      "Batch: 66, Loss: 0.6564781665802002, Accuracy: 0.783203125\n",
      "Batch: 67, Loss: 0.6721795201301575, Accuracy: 0.7685546875\n",
      "Batch: 68, Loss: 0.7130922079086304, Accuracy: 0.7734375\n",
      "Batch: 69, Loss: 0.634557843208313, Accuracy: 0.79296875\n",
      "Batch: 70, Loss: 0.6348826885223389, Accuracy: 0.794921875\n",
      "Batch: 71, Loss: 0.6215094923973083, Accuracy: 0.796875\n",
      "Batch: 72, Loss: 0.6789843440055847, Accuracy: 0.7666015625\n",
      "Batch: 73, Loss: 0.6803888082504272, Accuracy: 0.7734375\n",
      "Batch: 74, Loss: 0.6350215673446655, Accuracy: 0.7861328125\n",
      "Batch: 75, Loss: 0.5632506012916565, Accuracy: 0.8095703125\n",
      "Batch: 76, Loss: 0.6135212779045105, Accuracy: 0.80078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 77, Loss: 0.7041937708854675, Accuracy: 0.7822265625\n",
      "Batch: 78, Loss: 0.651894211769104, Accuracy: 0.787109375\n",
      "Batch: 79, Loss: 0.6677684187889099, Accuracy: 0.7861328125\n",
      "Batch: 80, Loss: 0.6777403354644775, Accuracy: 0.77734375\n",
      "Batch: 81, Loss: 0.690457284450531, Accuracy: 0.767578125\n",
      "Batch: 82, Loss: 0.6512091159820557, Accuracy: 0.78515625\n",
      "Batch: 83, Loss: 0.598530650138855, Accuracy: 0.7998046875\n",
      "Batch: 84, Loss: 0.6349613070487976, Accuracy: 0.794921875\n",
      "Batch: 85, Loss: 0.659359335899353, Accuracy: 0.7822265625\n",
      "Batch: 86, Loss: 0.6234818696975708, Accuracy: 0.7890625\n",
      "Batch: 87, Loss: 0.6185293197631836, Accuracy: 0.7919921875\n",
      "Batch: 88, Loss: 0.6474754810333252, Accuracy: 0.7705078125\n",
      "Batch: 89, Loss: 0.623417854309082, Accuracy: 0.796875\n",
      "Batch: 90, Loss: 0.6820448637008667, Accuracy: 0.779296875\n",
      "Batch: 91, Loss: 0.7575517892837524, Accuracy: 0.759765625\n",
      "Batch: 92, Loss: 0.6367261409759521, Accuracy: 0.7763671875\n",
      "Batch: 93, Loss: 0.6315335631370544, Accuracy: 0.791015625\n",
      "Batch: 94, Loss: 0.6865661144256592, Accuracy: 0.767578125\n",
      "Batch: 95, Loss: 0.6697144508361816, Accuracy: 0.7861328125\n",
      "Batch: 96, Loss: 0.658280611038208, Accuracy: 0.7890625\n",
      "Batch: 97, Loss: 0.6189217567443848, Accuracy: 0.796875\n",
      "Batch: 98, Loss: 0.6757091879844666, Accuracy: 0.7734375\n",
      "Batch: 99, Loss: 0.6501840353012085, Accuracy: 0.78125\n",
      "Batch: 100, Loss: 0.7125656604766846, Accuracy: 0.76171875\n",
      "Batch: 101, Loss: 0.6821118593215942, Accuracy: 0.7744140625\n",
      "Batch: 102, Loss: 0.6485236883163452, Accuracy: 0.779296875\n",
      "Batch: 103, Loss: 0.6969462633132935, Accuracy: 0.779296875\n",
      "Batch: 104, Loss: 0.6665859222412109, Accuracy: 0.77734375\n",
      "Batch: 105, Loss: 0.5915765762329102, Accuracy: 0.7939453125\n",
      "Batch: 106, Loss: 0.6624250411987305, Accuracy: 0.7724609375\n",
      "Batch: 107, Loss: 0.6218940019607544, Accuracy: 0.787109375\n",
      "Batch: 108, Loss: 0.6155858635902405, Accuracy: 0.7998046875\n",
      "Batch: 109, Loss: 0.5506496429443359, Accuracy: 0.8251953125\n",
      "Batch: 110, Loss: 0.5913012623786926, Accuracy: 0.802734375\n",
      "Batch: 111, Loss: 0.6691817045211792, Accuracy: 0.7841796875\n",
      "Batch: 112, Loss: 0.6299917697906494, Accuracy: 0.7900390625\n",
      "Epoch 26/90\n",
      "Batch: 1, Loss: 0.9461027979850769, Accuracy: 0.734375\n",
      "Batch: 2, Loss: 0.7174555659294128, Accuracy: 0.7841796875\n",
      "Batch: 3, Loss: 0.6991139650344849, Accuracy: 0.7880859375\n",
      "Batch: 4, Loss: 0.6261866688728333, Accuracy: 0.8037109375\n",
      "Batch: 5, Loss: 0.6629896759986877, Accuracy: 0.787109375\n",
      "Batch: 6, Loss: 0.6898416876792908, Accuracy: 0.791015625\n",
      "Batch: 7, Loss: 0.6533395051956177, Accuracy: 0.7958984375\n",
      "Batch: 8, Loss: 0.5382522940635681, Accuracy: 0.818359375\n",
      "Batch: 9, Loss: 0.6345245838165283, Accuracy: 0.794921875\n",
      "Batch: 10, Loss: 0.6857243180274963, Accuracy: 0.779296875\n",
      "Batch: 11, Loss: 0.6229758262634277, Accuracy: 0.8017578125\n",
      "Batch: 12, Loss: 0.6098718047142029, Accuracy: 0.8125\n",
      "Batch: 13, Loss: 0.6078084707260132, Accuracy: 0.80859375\n",
      "Batch: 14, Loss: 0.6743758320808411, Accuracy: 0.779296875\n",
      "Batch: 15, Loss: 0.6761555671691895, Accuracy: 0.78125\n",
      "Batch: 16, Loss: 0.6744961738586426, Accuracy: 0.78125\n",
      "Batch: 17, Loss: 0.6775878667831421, Accuracy: 0.7822265625\n",
      "Batch: 18, Loss: 0.5924450159072876, Accuracy: 0.8056640625\n",
      "Batch: 19, Loss: 0.5898525714874268, Accuracy: 0.8095703125\n",
      "Batch: 20, Loss: 0.6565240025520325, Accuracy: 0.7822265625\n",
      "Batch: 21, Loss: 0.6667922139167786, Accuracy: 0.7841796875\n",
      "Batch: 22, Loss: 0.5953465104103088, Accuracy: 0.806640625\n",
      "Batch: 23, Loss: 0.6999011039733887, Accuracy: 0.775390625\n",
      "Batch: 24, Loss: 0.6806817054748535, Accuracy: 0.7783203125\n",
      "Batch: 25, Loss: 0.7453243136405945, Accuracy: 0.7451171875\n",
      "Batch: 26, Loss: 0.825380802154541, Accuracy: 0.7509765625\n",
      "Batch: 27, Loss: 0.7300788760185242, Accuracy: 0.767578125\n",
      "Batch: 28, Loss: 0.64945387840271, Accuracy: 0.7880859375\n",
      "Batch: 29, Loss: 0.698904812335968, Accuracy: 0.775390625\n",
      "Batch: 30, Loss: 0.6235373020172119, Accuracy: 0.794921875\n",
      "Batch: 31, Loss: 0.6348813772201538, Accuracy: 0.7978515625\n",
      "Batch: 32, Loss: 0.6405879259109497, Accuracy: 0.7900390625\n",
      "Batch: 33, Loss: 0.6273927688598633, Accuracy: 0.7841796875\n",
      "Batch: 34, Loss: 0.6057872176170349, Accuracy: 0.8017578125\n",
      "Batch: 35, Loss: 0.6539994478225708, Accuracy: 0.7744140625\n",
      "Batch: 36, Loss: 0.7100956439971924, Accuracy: 0.7734375\n",
      "Batch: 37, Loss: 0.5887417793273926, Accuracy: 0.8037109375\n",
      "Batch: 38, Loss: 0.6596313118934631, Accuracy: 0.78125\n",
      "Batch: 39, Loss: 0.6211219429969788, Accuracy: 0.8017578125\n",
      "Batch: 40, Loss: 0.6598609089851379, Accuracy: 0.7783203125\n",
      "Batch: 41, Loss: 0.6610612869262695, Accuracy: 0.7783203125\n",
      "Batch: 42, Loss: 0.6425938010215759, Accuracy: 0.7822265625\n",
      "Batch: 43, Loss: 0.675740122795105, Accuracy: 0.7763671875\n",
      "Batch: 44, Loss: 0.723365306854248, Accuracy: 0.7685546875\n",
      "Batch: 45, Loss: 0.7492526173591614, Accuracy: 0.7705078125\n",
      "Batch: 46, Loss: 0.6728137135505676, Accuracy: 0.767578125\n",
      "Batch: 47, Loss: 0.7181665897369385, Accuracy: 0.763671875\n",
      "Batch: 48, Loss: 0.7259042263031006, Accuracy: 0.7802734375\n",
      "Batch: 49, Loss: 0.8441823124885559, Accuracy: 0.73828125\n",
      "Batch: 50, Loss: 0.6255989074707031, Accuracy: 0.8095703125\n",
      "Batch: 51, Loss: 0.6821482181549072, Accuracy: 0.779296875\n",
      "Batch: 52, Loss: 0.6984357833862305, Accuracy: 0.775390625\n",
      "Batch: 53, Loss: 0.7817740440368652, Accuracy: 0.748046875\n",
      "Batch: 54, Loss: 0.6936914920806885, Accuracy: 0.77734375\n",
      "Batch: 55, Loss: 0.7229962944984436, Accuracy: 0.77734375\n",
      "Batch: 56, Loss: 0.6470245122909546, Accuracy: 0.78515625\n",
      "Batch: 57, Loss: 0.7674477696418762, Accuracy: 0.76171875\n",
      "Batch: 58, Loss: 0.7872073650360107, Accuracy: 0.7509765625\n",
      "Batch: 59, Loss: 0.6872828006744385, Accuracy: 0.767578125\n",
      "Batch: 60, Loss: 0.7298627495765686, Accuracy: 0.7529296875\n",
      "Batch: 61, Loss: 0.7161287665367126, Accuracy: 0.7666015625\n",
      "Batch: 62, Loss: 0.7358810305595398, Accuracy: 0.767578125\n",
      "Batch: 63, Loss: 0.5703266859054565, Accuracy: 0.8134765625\n",
      "Batch: 64, Loss: 0.6750986576080322, Accuracy: 0.771484375\n",
      "Batch: 65, Loss: 0.6608767509460449, Accuracy: 0.7763671875\n",
      "Batch: 66, Loss: 0.6064677238464355, Accuracy: 0.806640625\n",
      "Batch: 67, Loss: 0.6405296921730042, Accuracy: 0.7861328125\n",
      "Batch: 68, Loss: 0.6929701566696167, Accuracy: 0.7705078125\n",
      "Batch: 69, Loss: 0.6159871220588684, Accuracy: 0.8017578125\n",
      "Batch: 70, Loss: 0.6531502604484558, Accuracy: 0.783203125\n",
      "Batch: 71, Loss: 0.6107707023620605, Accuracy: 0.80078125\n",
      "Batch: 72, Loss: 0.6761157512664795, Accuracy: 0.78125\n",
      "Batch: 73, Loss: 0.6696585416793823, Accuracy: 0.7724609375\n",
      "Batch: 74, Loss: 0.61436527967453, Accuracy: 0.7900390625\n",
      "Batch: 75, Loss: 0.5689767599105835, Accuracy: 0.8037109375\n",
      "Batch: 76, Loss: 0.5968589782714844, Accuracy: 0.7919921875\n",
      "Batch: 77, Loss: 0.6881827116012573, Accuracy: 0.7734375\n",
      "Batch: 78, Loss: 0.6113412380218506, Accuracy: 0.7978515625\n",
      "Batch: 79, Loss: 0.6516031622886658, Accuracy: 0.8046875\n",
      "Batch: 80, Loss: 0.6431639790534973, Accuracy: 0.78515625\n",
      "Batch: 81, Loss: 0.6562214493751526, Accuracy: 0.7744140625\n",
      "Batch: 82, Loss: 0.638286292552948, Accuracy: 0.79296875\n",
      "Batch: 83, Loss: 0.5842761993408203, Accuracy: 0.798828125\n",
      "Batch: 84, Loss: 0.5995233058929443, Accuracy: 0.8056640625\n",
      "Batch: 85, Loss: 0.6420629024505615, Accuracy: 0.7841796875\n",
      "Batch: 86, Loss: 0.5885049700737, Accuracy: 0.7978515625\n",
      "Batch: 87, Loss: 0.5964992642402649, Accuracy: 0.7998046875\n",
      "Batch: 88, Loss: 0.6349976062774658, Accuracy: 0.78515625\n",
      "Batch: 89, Loss: 0.6213493347167969, Accuracy: 0.802734375\n",
      "Batch: 90, Loss: 0.6547704935073853, Accuracy: 0.7822265625\n",
      "Batch: 91, Loss: 0.716215968132019, Accuracy: 0.763671875\n",
      "Batch: 92, Loss: 0.6323233842849731, Accuracy: 0.7802734375\n",
      "Batch: 93, Loss: 0.634394109249115, Accuracy: 0.8017578125\n",
      "Batch: 94, Loss: 0.675530195236206, Accuracy: 0.7734375\n",
      "Batch: 95, Loss: 0.6620223522186279, Accuracy: 0.783203125\n",
      "Batch: 96, Loss: 0.6443707942962646, Accuracy: 0.7841796875\n",
      "Batch: 97, Loss: 0.626334547996521, Accuracy: 0.8017578125\n",
      "Batch: 98, Loss: 0.7039824724197388, Accuracy: 0.7646484375\n",
      "Batch: 99, Loss: 0.6476771235466003, Accuracy: 0.783203125\n",
      "Batch: 100, Loss: 0.6862183809280396, Accuracy: 0.76953125\n",
      "Batch: 101, Loss: 0.6261597275733948, Accuracy: 0.8056640625\n",
      "Batch: 102, Loss: 0.632822573184967, Accuracy: 0.7958984375\n",
      "Batch: 103, Loss: 0.6801420450210571, Accuracy: 0.77734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 104, Loss: 0.6634405255317688, Accuracy: 0.77734375\n",
      "Batch: 105, Loss: 0.5699758529663086, Accuracy: 0.8017578125\n",
      "Batch: 106, Loss: 0.6519479751586914, Accuracy: 0.775390625\n",
      "Batch: 107, Loss: 0.5925810933113098, Accuracy: 0.798828125\n",
      "Batch: 108, Loss: 0.5681970119476318, Accuracy: 0.8193359375\n",
      "Batch: 109, Loss: 0.5509637594223022, Accuracy: 0.82421875\n",
      "Batch: 110, Loss: 0.5793410539627075, Accuracy: 0.826171875\n",
      "Batch: 111, Loss: 0.6390732526779175, Accuracy: 0.78125\n",
      "Batch: 112, Loss: 0.6140109300613403, Accuracy: 0.7998046875\n",
      "Epoch 27/90\n",
      "Batch: 1, Loss: 0.9023691415786743, Accuracy: 0.740234375\n",
      "Batch: 2, Loss: 0.7120116949081421, Accuracy: 0.7783203125\n",
      "Batch: 3, Loss: 0.6660231351852417, Accuracy: 0.7890625\n",
      "Batch: 4, Loss: 0.619895875453949, Accuracy: 0.7978515625\n",
      "Batch: 5, Loss: 0.6198596954345703, Accuracy: 0.8076171875\n",
      "Batch: 6, Loss: 0.6690807342529297, Accuracy: 0.779296875\n",
      "Batch: 7, Loss: 0.6122467517852783, Accuracy: 0.8125\n",
      "Batch: 8, Loss: 0.5386373996734619, Accuracy: 0.8193359375\n",
      "Batch: 9, Loss: 0.631621241569519, Accuracy: 0.791015625\n",
      "Batch: 10, Loss: 0.6365537643432617, Accuracy: 0.7958984375\n",
      "Batch: 11, Loss: 0.6197096109390259, Accuracy: 0.8076171875\n",
      "Batch: 12, Loss: 0.584336519241333, Accuracy: 0.80859375\n",
      "Batch: 13, Loss: 0.5728978514671326, Accuracy: 0.814453125\n",
      "Batch: 14, Loss: 0.631346583366394, Accuracy: 0.7900390625\n",
      "Batch: 15, Loss: 0.6738234758377075, Accuracy: 0.7861328125\n",
      "Batch: 16, Loss: 0.6372185349464417, Accuracy: 0.8056640625\n",
      "Batch: 17, Loss: 0.6545442342758179, Accuracy: 0.7822265625\n",
      "Batch: 18, Loss: 0.5765135288238525, Accuracy: 0.802734375\n",
      "Batch: 19, Loss: 0.5534375309944153, Accuracy: 0.810546875\n",
      "Batch: 20, Loss: 0.6206604242324829, Accuracy: 0.8037109375\n",
      "Batch: 21, Loss: 0.6468559503555298, Accuracy: 0.7861328125\n",
      "Batch: 22, Loss: 0.6010704040527344, Accuracy: 0.8017578125\n",
      "Batch: 23, Loss: 0.6928523778915405, Accuracy: 0.7724609375\n",
      "Batch: 24, Loss: 0.6725224852561951, Accuracy: 0.7822265625\n",
      "Batch: 25, Loss: 0.7727632522583008, Accuracy: 0.7490234375\n",
      "Batch: 26, Loss: 0.8023132085800171, Accuracy: 0.7548828125\n",
      "Batch: 27, Loss: 0.7223573923110962, Accuracy: 0.7646484375\n",
      "Batch: 28, Loss: 0.63200843334198, Accuracy: 0.791015625\n",
      "Batch: 29, Loss: 0.6947311162948608, Accuracy: 0.775390625\n",
      "Batch: 30, Loss: 0.6205095052719116, Accuracy: 0.8017578125\n",
      "Batch: 31, Loss: 0.6378237009048462, Accuracy: 0.78515625\n",
      "Batch: 32, Loss: 0.6107800006866455, Accuracy: 0.7939453125\n",
      "Batch: 33, Loss: 0.6374450922012329, Accuracy: 0.78125\n",
      "Batch: 34, Loss: 0.5810555815696716, Accuracy: 0.806640625\n",
      "Batch: 35, Loss: 0.6412298679351807, Accuracy: 0.7861328125\n",
      "Batch: 36, Loss: 0.7054339647293091, Accuracy: 0.7685546875\n",
      "Batch: 37, Loss: 0.5782270431518555, Accuracy: 0.80078125\n",
      "Batch: 38, Loss: 0.6641092300415039, Accuracy: 0.7900390625\n",
      "Batch: 39, Loss: 0.6029568314552307, Accuracy: 0.8037109375\n",
      "Batch: 40, Loss: 0.6054449081420898, Accuracy: 0.7939453125\n",
      "Batch: 41, Loss: 0.6382144689559937, Accuracy: 0.7890625\n",
      "Batch: 42, Loss: 0.5927530527114868, Accuracy: 0.802734375\n",
      "Batch: 43, Loss: 0.658561110496521, Accuracy: 0.7919921875\n",
      "Batch: 44, Loss: 0.6853108406066895, Accuracy: 0.7734375\n",
      "Batch: 45, Loss: 0.7419265508651733, Accuracy: 0.76171875\n",
      "Batch: 46, Loss: 0.6308218240737915, Accuracy: 0.7939453125\n",
      "Batch: 47, Loss: 0.6475083231925964, Accuracy: 0.779296875\n",
      "Batch: 48, Loss: 0.7019882202148438, Accuracy: 0.7763671875\n",
      "Batch: 49, Loss: 0.8043383359909058, Accuracy: 0.7431640625\n",
      "Batch: 50, Loss: 0.6015461683273315, Accuracy: 0.8134765625\n",
      "Batch: 51, Loss: 0.6659871339797974, Accuracy: 0.7763671875\n",
      "Batch: 52, Loss: 0.695083737373352, Accuracy: 0.7802734375\n",
      "Batch: 53, Loss: 0.7893653512001038, Accuracy: 0.7490234375\n",
      "Batch: 54, Loss: 0.6770843267440796, Accuracy: 0.7841796875\n",
      "Batch: 55, Loss: 0.7018367052078247, Accuracy: 0.77734375\n",
      "Batch: 56, Loss: 0.6400238275527954, Accuracy: 0.78515625\n",
      "Batch: 57, Loss: 0.7398852705955505, Accuracy: 0.7607421875\n",
      "Batch: 58, Loss: 0.7610529661178589, Accuracy: 0.75\n",
      "Batch: 59, Loss: 0.6697009801864624, Accuracy: 0.7900390625\n",
      "Batch: 60, Loss: 0.7367247939109802, Accuracy: 0.7587890625\n",
      "Batch: 61, Loss: 0.6974445581436157, Accuracy: 0.7705078125\n",
      "Batch: 62, Loss: 0.7066431045532227, Accuracy: 0.775390625\n",
      "Batch: 63, Loss: 0.5439466834068298, Accuracy: 0.8330078125\n",
      "Batch: 64, Loss: 0.6645584106445312, Accuracy: 0.76953125\n",
      "Batch: 65, Loss: 0.6298279762268066, Accuracy: 0.7734375\n",
      "Batch: 66, Loss: 0.5850671529769897, Accuracy: 0.814453125\n",
      "Batch: 67, Loss: 0.6042373180389404, Accuracy: 0.79296875\n",
      "Batch: 68, Loss: 0.6475626826286316, Accuracy: 0.7939453125\n",
      "Batch: 69, Loss: 0.6204923987388611, Accuracy: 0.7958984375\n",
      "Batch: 70, Loss: 0.6296007633209229, Accuracy: 0.7939453125\n",
      "Batch: 71, Loss: 0.5838082432746887, Accuracy: 0.8115234375\n",
      "Batch: 72, Loss: 0.6435847878456116, Accuracy: 0.7822265625\n",
      "Batch: 73, Loss: 0.6581321954727173, Accuracy: 0.7734375\n",
      "Batch: 74, Loss: 0.6143016815185547, Accuracy: 0.806640625\n",
      "Batch: 75, Loss: 0.5555798411369324, Accuracy: 0.810546875\n",
      "Batch: 76, Loss: 0.604781448841095, Accuracy: 0.80078125\n",
      "Batch: 77, Loss: 0.6817141771316528, Accuracy: 0.78125\n",
      "Batch: 78, Loss: 0.5917870998382568, Accuracy: 0.7998046875\n",
      "Batch: 79, Loss: 0.6443431377410889, Accuracy: 0.7939453125\n",
      "Batch: 80, Loss: 0.6111091375350952, Accuracy: 0.7978515625\n",
      "Batch: 81, Loss: 0.6377532482147217, Accuracy: 0.7900390625\n",
      "Batch: 82, Loss: 0.6317774653434753, Accuracy: 0.7900390625\n",
      "Batch: 83, Loss: 0.5620347857475281, Accuracy: 0.8046875\n",
      "Batch: 84, Loss: 0.575428307056427, Accuracy: 0.8203125\n",
      "Batch: 85, Loss: 0.6383855938911438, Accuracy: 0.7880859375\n",
      "Batch: 86, Loss: 0.5872283577919006, Accuracy: 0.7939453125\n",
      "Batch: 87, Loss: 0.5947597622871399, Accuracy: 0.802734375\n",
      "Batch: 88, Loss: 0.6296886205673218, Accuracy: 0.7822265625\n",
      "Batch: 89, Loss: 0.5961049795150757, Accuracy: 0.8046875\n",
      "Batch: 90, Loss: 0.6860259771347046, Accuracy: 0.765625\n",
      "Batch: 91, Loss: 0.7144365310668945, Accuracy: 0.7646484375\n",
      "Batch: 92, Loss: 0.6280399560928345, Accuracy: 0.78125\n",
      "Batch: 93, Loss: 0.5878026485443115, Accuracy: 0.8037109375\n",
      "Batch: 94, Loss: 0.6112509965896606, Accuracy: 0.8017578125\n",
      "Batch: 95, Loss: 0.6538444757461548, Accuracy: 0.7744140625\n",
      "Batch: 96, Loss: 0.637488067150116, Accuracy: 0.7861328125\n",
      "Batch: 97, Loss: 0.6145131587982178, Accuracy: 0.8095703125\n",
      "Batch: 98, Loss: 0.6643166542053223, Accuracy: 0.7734375\n",
      "Batch: 99, Loss: 0.6300185322761536, Accuracy: 0.7880859375\n",
      "Batch: 100, Loss: 0.6752235889434814, Accuracy: 0.7763671875\n",
      "Batch: 101, Loss: 0.6252135038375854, Accuracy: 0.77734375\n",
      "Batch: 102, Loss: 0.6339030265808105, Accuracy: 0.779296875\n",
      "Batch: 103, Loss: 0.6747296452522278, Accuracy: 0.7744140625\n",
      "Batch: 104, Loss: 0.6538827419281006, Accuracy: 0.7900390625\n",
      "Batch: 105, Loss: 0.547042191028595, Accuracy: 0.8046875\n",
      "Batch: 106, Loss: 0.6242433190345764, Accuracy: 0.7958984375\n",
      "Batch: 107, Loss: 0.5927937030792236, Accuracy: 0.7919921875\n",
      "Batch: 108, Loss: 0.5713188648223877, Accuracy: 0.806640625\n",
      "Batch: 109, Loss: 0.554559588432312, Accuracy: 0.822265625\n",
      "Batch: 110, Loss: 0.5498866438865662, Accuracy: 0.822265625\n",
      "Batch: 111, Loss: 0.6439851522445679, Accuracy: 0.783203125\n",
      "Batch: 112, Loss: 0.6028307676315308, Accuracy: 0.7978515625\n",
      "Epoch 28/90\n",
      "Batch: 1, Loss: 0.8744474649429321, Accuracy: 0.744140625\n",
      "Batch: 2, Loss: 0.6791370511054993, Accuracy: 0.7958984375\n",
      "Batch: 3, Loss: 0.6499675512313843, Accuracy: 0.791015625\n",
      "Batch: 4, Loss: 0.6081620454788208, Accuracy: 0.8076171875\n",
      "Batch: 5, Loss: 0.5895557403564453, Accuracy: 0.802734375\n",
      "Batch: 6, Loss: 0.6259641051292419, Accuracy: 0.7998046875\n",
      "Batch: 7, Loss: 0.5912977457046509, Accuracy: 0.81640625\n",
      "Batch: 8, Loss: 0.5509326457977295, Accuracy: 0.810546875\n",
      "Batch: 9, Loss: 0.5807707905769348, Accuracy: 0.8046875\n",
      "Batch: 10, Loss: 0.645955502986908, Accuracy: 0.7744140625\n",
      "Batch: 11, Loss: 0.5937603712081909, Accuracy: 0.8095703125\n",
      "Batch: 12, Loss: 0.5608071088790894, Accuracy: 0.802734375\n",
      "Batch: 13, Loss: 0.5279464721679688, Accuracy: 0.8369140625\n",
      "Batch: 14, Loss: 0.6115623712539673, Accuracy: 0.79296875\n",
      "Batch: 15, Loss: 0.6402063965797424, Accuracy: 0.7939453125\n",
      "Batch: 16, Loss: 0.6226309537887573, Accuracy: 0.796875\n",
      "Batch: 17, Loss: 0.6362694501876831, Accuracy: 0.7919921875\n",
      "Batch: 18, Loss: 0.5606024861335754, Accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 19, Loss: 0.5747987031936646, Accuracy: 0.8076171875\n",
      "Batch: 20, Loss: 0.6106075644493103, Accuracy: 0.79296875\n",
      "Batch: 21, Loss: 0.603717029094696, Accuracy: 0.8037109375\n",
      "Batch: 22, Loss: 0.601952075958252, Accuracy: 0.798828125\n",
      "Batch: 23, Loss: 0.6627384424209595, Accuracy: 0.7763671875\n",
      "Batch: 24, Loss: 0.6760375499725342, Accuracy: 0.7685546875\n",
      "Batch: 25, Loss: 0.7047282457351685, Accuracy: 0.7646484375\n",
      "Batch: 26, Loss: 0.7714290618896484, Accuracy: 0.763671875\n",
      "Batch: 27, Loss: 0.7353968024253845, Accuracy: 0.759765625\n",
      "Batch: 28, Loss: 0.5870698690414429, Accuracy: 0.7998046875\n",
      "Batch: 29, Loss: 0.6859695911407471, Accuracy: 0.7724609375\n",
      "Batch: 30, Loss: 0.5927838087081909, Accuracy: 0.8046875\n",
      "Batch: 31, Loss: 0.648555338382721, Accuracy: 0.7919921875\n",
      "Batch: 32, Loss: 0.6217124462127686, Accuracy: 0.7841796875\n",
      "Batch: 33, Loss: 0.6253615021705627, Accuracy: 0.77734375\n",
      "Batch: 34, Loss: 0.5504258871078491, Accuracy: 0.7978515625\n",
      "Batch: 35, Loss: 0.6114262342453003, Accuracy: 0.7919921875\n",
      "Batch: 36, Loss: 0.7023531198501587, Accuracy: 0.7724609375\n",
      "Batch: 37, Loss: 0.5698971748352051, Accuracy: 0.80859375\n",
      "Batch: 38, Loss: 0.647457480430603, Accuracy: 0.787109375\n",
      "Batch: 39, Loss: 0.595414400100708, Accuracy: 0.8046875\n",
      "Batch: 40, Loss: 0.6301783919334412, Accuracy: 0.796875\n",
      "Batch: 41, Loss: 0.610032856464386, Accuracy: 0.796875\n",
      "Batch: 42, Loss: 0.5954709053039551, Accuracy: 0.7939453125\n",
      "Batch: 43, Loss: 0.6362643837928772, Accuracy: 0.798828125\n",
      "Batch: 44, Loss: 0.6859161257743835, Accuracy: 0.771484375\n",
      "Batch: 45, Loss: 0.7308526039123535, Accuracy: 0.765625\n",
      "Batch: 46, Loss: 0.6317564249038696, Accuracy: 0.7978515625\n",
      "Batch: 47, Loss: 0.672152042388916, Accuracy: 0.7626953125\n",
      "Batch: 48, Loss: 0.6796633005142212, Accuracy: 0.7880859375\n",
      "Batch: 49, Loss: 0.7552083134651184, Accuracy: 0.7626953125\n",
      "Batch: 50, Loss: 0.5751965641975403, Accuracy: 0.8291015625\n",
      "Batch: 51, Loss: 0.6444947123527527, Accuracy: 0.7890625\n",
      "Batch: 52, Loss: 0.6288873553276062, Accuracy: 0.7900390625\n",
      "Batch: 53, Loss: 0.7572441101074219, Accuracy: 0.7626953125\n",
      "Batch: 54, Loss: 0.6796770095825195, Accuracy: 0.7939453125\n",
      "Batch: 55, Loss: 0.6822745203971863, Accuracy: 0.77734375\n",
      "Batch: 56, Loss: 0.6290671825408936, Accuracy: 0.796875\n",
      "Batch: 57, Loss: 0.717456579208374, Accuracy: 0.7734375\n",
      "Batch: 58, Loss: 0.7327649593353271, Accuracy: 0.7724609375\n",
      "Batch: 59, Loss: 0.6791371703147888, Accuracy: 0.779296875\n",
      "Batch: 60, Loss: 0.6789379119873047, Accuracy: 0.775390625\n",
      "Batch: 61, Loss: 0.6411241292953491, Accuracy: 0.791015625\n",
      "Batch: 62, Loss: 0.6825371980667114, Accuracy: 0.7919921875\n",
      "Batch: 63, Loss: 0.5370733737945557, Accuracy: 0.8271484375\n",
      "Batch: 64, Loss: 0.6379063725471497, Accuracy: 0.779296875\n",
      "Batch: 65, Loss: 0.6373342275619507, Accuracy: 0.7802734375\n",
      "Batch: 66, Loss: 0.5807961225509644, Accuracy: 0.8115234375\n",
      "Batch: 67, Loss: 0.6002777814865112, Accuracy: 0.802734375\n",
      "Batch: 68, Loss: 0.6438679099082947, Accuracy: 0.7763671875\n",
      "Batch: 69, Loss: 0.5896037817001343, Accuracy: 0.802734375\n",
      "Batch: 70, Loss: 0.5909847617149353, Accuracy: 0.8056640625\n",
      "Batch: 71, Loss: 0.6011093258857727, Accuracy: 0.7978515625\n",
      "Batch: 72, Loss: 0.6505851149559021, Accuracy: 0.7880859375\n",
      "Batch: 73, Loss: 0.6361472606658936, Accuracy: 0.7919921875\n",
      "Batch: 74, Loss: 0.5881764888763428, Accuracy: 0.8037109375\n",
      "Batch: 75, Loss: 0.5361444354057312, Accuracy: 0.8291015625\n",
      "Batch: 76, Loss: 0.5433403849601746, Accuracy: 0.8154296875\n",
      "Batch: 77, Loss: 0.6286938190460205, Accuracy: 0.7880859375\n",
      "Batch: 78, Loss: 0.599551796913147, Accuracy: 0.8017578125\n",
      "Batch: 79, Loss: 0.6130329370498657, Accuracy: 0.8134765625\n",
      "Batch: 80, Loss: 0.6247683167457581, Accuracy: 0.7841796875\n",
      "Batch: 81, Loss: 0.6314682960510254, Accuracy: 0.78125\n",
      "Batch: 82, Loss: 0.6037594676017761, Accuracy: 0.796875\n",
      "Batch: 83, Loss: 0.5459280014038086, Accuracy: 0.810546875\n",
      "Batch: 84, Loss: 0.5738455057144165, Accuracy: 0.81640625\n",
      "Batch: 85, Loss: 0.609120786190033, Accuracy: 0.7998046875\n",
      "Batch: 86, Loss: 0.5662193894386292, Accuracy: 0.8037109375\n",
      "Batch: 87, Loss: 0.5356965065002441, Accuracy: 0.818359375\n",
      "Batch: 88, Loss: 0.602838933467865, Accuracy: 0.7958984375\n",
      "Batch: 89, Loss: 0.6029290556907654, Accuracy: 0.8115234375\n",
      "Batch: 90, Loss: 0.643688440322876, Accuracy: 0.79296875\n",
      "Batch: 91, Loss: 0.7046447992324829, Accuracy: 0.7666015625\n",
      "Batch: 92, Loss: 0.59763503074646, Accuracy: 0.79296875\n",
      "Batch: 93, Loss: 0.5965473651885986, Accuracy: 0.8017578125\n",
      "Batch: 94, Loss: 0.6390570402145386, Accuracy: 0.791015625\n",
      "Batch: 95, Loss: 0.6495619416236877, Accuracy: 0.7802734375\n",
      "Batch: 96, Loss: 0.6175646781921387, Accuracy: 0.7900390625\n",
      "Batch: 97, Loss: 0.5790219306945801, Accuracy: 0.8154296875\n",
      "Batch: 98, Loss: 0.6662170886993408, Accuracy: 0.78125\n",
      "Batch: 99, Loss: 0.6293299198150635, Accuracy: 0.7880859375\n",
      "Batch: 100, Loss: 0.6417990922927856, Accuracy: 0.7802734375\n",
      "Batch: 101, Loss: 0.612520158290863, Accuracy: 0.796875\n",
      "Batch: 102, Loss: 0.6307054758071899, Accuracy: 0.7978515625\n",
      "Batch: 103, Loss: 0.6306593418121338, Accuracy: 0.78515625\n",
      "Batch: 104, Loss: 0.6291002631187439, Accuracy: 0.7861328125\n",
      "Batch: 105, Loss: 0.5510673522949219, Accuracy: 0.806640625\n",
      "Batch: 106, Loss: 0.6235506534576416, Accuracy: 0.7998046875\n",
      "Batch: 107, Loss: 0.5924855470657349, Accuracy: 0.798828125\n",
      "Batch: 108, Loss: 0.5698076486587524, Accuracy: 0.7998046875\n",
      "Batch: 109, Loss: 0.5220683217048645, Accuracy: 0.826171875\n",
      "Batch: 110, Loss: 0.5401610136032104, Accuracy: 0.8154296875\n",
      "Batch: 111, Loss: 0.6241286396980286, Accuracy: 0.794921875\n",
      "Batch: 112, Loss: 0.581538200378418, Accuracy: 0.8046875\n",
      "Epoch 29/90\n",
      "Batch: 1, Loss: 0.8811094164848328, Accuracy: 0.751953125\n",
      "Batch: 2, Loss: 0.67341148853302, Accuracy: 0.7880859375\n",
      "Batch: 3, Loss: 0.6695883274078369, Accuracy: 0.78515625\n",
      "Batch: 4, Loss: 0.6041926145553589, Accuracy: 0.80859375\n",
      "Batch: 5, Loss: 0.5945758819580078, Accuracy: 0.8076171875\n",
      "Batch: 6, Loss: 0.618553876876831, Accuracy: 0.8056640625\n",
      "Batch: 7, Loss: 0.5998309850692749, Accuracy: 0.8095703125\n",
      "Batch: 8, Loss: 0.5209605097770691, Accuracy: 0.830078125\n",
      "Batch: 9, Loss: 0.608801543712616, Accuracy: 0.7998046875\n",
      "Batch: 10, Loss: 0.6118452548980713, Accuracy: 0.7939453125\n",
      "Batch: 11, Loss: 0.5664430856704712, Accuracy: 0.82421875\n",
      "Batch: 12, Loss: 0.5610160827636719, Accuracy: 0.8125\n",
      "Batch: 13, Loss: 0.5366131067276001, Accuracy: 0.833984375\n",
      "Batch: 14, Loss: 0.6029701232910156, Accuracy: 0.7978515625\n",
      "Batch: 15, Loss: 0.6167709231376648, Accuracy: 0.7939453125\n",
      "Batch: 16, Loss: 0.6076580286026001, Accuracy: 0.8037109375\n",
      "Batch: 17, Loss: 0.6200289726257324, Accuracy: 0.80859375\n",
      "Batch: 18, Loss: 0.5360561609268188, Accuracy: 0.806640625\n",
      "Batch: 19, Loss: 0.5416834354400635, Accuracy: 0.822265625\n",
      "Batch: 20, Loss: 0.584225594997406, Accuracy: 0.791015625\n",
      "Batch: 21, Loss: 0.6057077646255493, Accuracy: 0.80078125\n",
      "Batch: 22, Loss: 0.5636073350906372, Accuracy: 0.8115234375\n",
      "Batch: 23, Loss: 0.6410195827484131, Accuracy: 0.8046875\n",
      "Batch: 24, Loss: 0.6594356894493103, Accuracy: 0.78125\n",
      "Batch: 25, Loss: 0.7239171266555786, Accuracy: 0.7548828125\n",
      "Batch: 26, Loss: 0.7593140006065369, Accuracy: 0.7607421875\n",
      "Batch: 27, Loss: 0.6847873330116272, Accuracy: 0.775390625\n",
      "Batch: 28, Loss: 0.587897777557373, Accuracy: 0.7939453125\n",
      "Batch: 29, Loss: 0.6529473066329956, Accuracy: 0.78515625\n",
      "Batch: 30, Loss: 0.5863471627235413, Accuracy: 0.8037109375\n",
      "Batch: 31, Loss: 0.6258947849273682, Accuracy: 0.7958984375\n",
      "Batch: 32, Loss: 0.6282545328140259, Accuracy: 0.7919921875\n",
      "Batch: 33, Loss: 0.6133382320404053, Accuracy: 0.7861328125\n",
      "Batch: 34, Loss: 0.5497288107872009, Accuracy: 0.8095703125\n",
      "Batch: 35, Loss: 0.5819399356842041, Accuracy: 0.798828125\n",
      "Batch: 36, Loss: 0.6717993021011353, Accuracy: 0.791015625\n",
      "Batch: 37, Loss: 0.5661900043487549, Accuracy: 0.8037109375\n",
      "Batch: 38, Loss: 0.6144994497299194, Accuracy: 0.802734375\n",
      "Batch: 39, Loss: 0.5974684953689575, Accuracy: 0.806640625\n",
      "Batch: 40, Loss: 0.619225025177002, Accuracy: 0.79296875\n",
      "Batch: 41, Loss: 0.5878286361694336, Accuracy: 0.8046875\n",
      "Batch: 42, Loss: 0.5987018346786499, Accuracy: 0.7998046875\n",
      "Batch: 43, Loss: 0.6000540256500244, Accuracy: 0.7900390625\n",
      "Batch: 44, Loss: 0.6616343855857849, Accuracy: 0.794921875\n",
      "Batch: 45, Loss: 0.7348039746284485, Accuracy: 0.77734375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 46, Loss: 0.6195286512374878, Accuracy: 0.7880859375\n",
      "Batch: 47, Loss: 0.6353235244750977, Accuracy: 0.775390625\n",
      "Batch: 48, Loss: 0.6841903924942017, Accuracy: 0.783203125\n",
      "Batch: 49, Loss: 0.7484472393989563, Accuracy: 0.7724609375\n",
      "Batch: 50, Loss: 0.5753671526908875, Accuracy: 0.8271484375\n",
      "Batch: 51, Loss: 0.6435477137565613, Accuracy: 0.8017578125\n",
      "Batch: 52, Loss: 0.6214697360992432, Accuracy: 0.7841796875\n",
      "Batch: 53, Loss: 0.719566822052002, Accuracy: 0.779296875\n",
      "Batch: 54, Loss: 0.632270336151123, Accuracy: 0.8046875\n",
      "Batch: 55, Loss: 0.6765487790107727, Accuracy: 0.80078125\n",
      "Batch: 56, Loss: 0.5984945297241211, Accuracy: 0.8056640625\n",
      "Batch: 57, Loss: 0.7220702767372131, Accuracy: 0.7666015625\n",
      "Batch: 58, Loss: 0.6972225308418274, Accuracy: 0.779296875\n",
      "Batch: 59, Loss: 0.6289194226264954, Accuracy: 0.7841796875\n",
      "Batch: 60, Loss: 0.6484123468399048, Accuracy: 0.7880859375\n",
      "Batch: 61, Loss: 0.6316238641738892, Accuracy: 0.7939453125\n",
      "Batch: 62, Loss: 0.6868627071380615, Accuracy: 0.7685546875\n",
      "Batch: 63, Loss: 0.5147982835769653, Accuracy: 0.83203125\n",
      "Batch: 64, Loss: 0.6000951528549194, Accuracy: 0.7998046875\n",
      "Batch: 65, Loss: 0.5996121168136597, Accuracy: 0.7998046875\n",
      "Batch: 66, Loss: 0.551521897315979, Accuracy: 0.8115234375\n",
      "Batch: 67, Loss: 0.5758074522018433, Accuracy: 0.8037109375\n",
      "Batch: 68, Loss: 0.6270307302474976, Accuracy: 0.791015625\n",
      "Batch: 69, Loss: 0.5548558831214905, Accuracy: 0.8173828125\n",
      "Batch: 70, Loss: 0.5825538039207458, Accuracy: 0.8154296875\n",
      "Batch: 71, Loss: 0.5627363920211792, Accuracy: 0.814453125\n",
      "Batch: 72, Loss: 0.5930501222610474, Accuracy: 0.8115234375\n",
      "Batch: 73, Loss: 0.625807523727417, Accuracy: 0.7900390625\n",
      "Batch: 74, Loss: 0.5641012787818909, Accuracy: 0.806640625\n",
      "Batch: 75, Loss: 0.5184563398361206, Accuracy: 0.8271484375\n",
      "Batch: 76, Loss: 0.5594197511672974, Accuracy: 0.8046875\n",
      "Batch: 77, Loss: 0.6384878158569336, Accuracy: 0.80078125\n",
      "Batch: 78, Loss: 0.555862307548523, Accuracy: 0.8203125\n",
      "Batch: 79, Loss: 0.5970959663391113, Accuracy: 0.8095703125\n",
      "Batch: 80, Loss: 0.6033773422241211, Accuracy: 0.796875\n",
      "Batch: 81, Loss: 0.6222211122512817, Accuracy: 0.7880859375\n",
      "Batch: 82, Loss: 0.5892864465713501, Accuracy: 0.8125\n",
      "Batch: 83, Loss: 0.5244288444519043, Accuracy: 0.822265625\n",
      "Batch: 84, Loss: 0.5438432693481445, Accuracy: 0.8232421875\n",
      "Batch: 85, Loss: 0.5985510349273682, Accuracy: 0.8017578125\n",
      "Batch: 86, Loss: 0.5467202663421631, Accuracy: 0.81640625\n",
      "Batch: 87, Loss: 0.5476320385932922, Accuracy: 0.8193359375\n",
      "Batch: 88, Loss: 0.5673198699951172, Accuracy: 0.8193359375\n",
      "Batch: 89, Loss: 0.5511347055435181, Accuracy: 0.818359375\n",
      "Batch: 90, Loss: 0.6512582302093506, Accuracy: 0.7724609375\n",
      "Batch: 91, Loss: 0.6467576026916504, Accuracy: 0.794921875\n",
      "Batch: 92, Loss: 0.592200517654419, Accuracy: 0.79296875\n",
      "Batch: 93, Loss: 0.5816344022750854, Accuracy: 0.8193359375\n",
      "Batch: 94, Loss: 0.6190446615219116, Accuracy: 0.7998046875\n",
      "Batch: 95, Loss: 0.621675968170166, Accuracy: 0.79296875\n",
      "Batch: 96, Loss: 0.5745105743408203, Accuracy: 0.8095703125\n",
      "Batch: 97, Loss: 0.5863804817199707, Accuracy: 0.8125\n",
      "Batch: 98, Loss: 0.6634441018104553, Accuracy: 0.779296875\n",
      "Batch: 99, Loss: 0.5978633165359497, Accuracy: 0.794921875\n",
      "Batch: 100, Loss: 0.6384519338607788, Accuracy: 0.7841796875\n",
      "Batch: 101, Loss: 0.6271837949752808, Accuracy: 0.787109375\n",
      "Batch: 102, Loss: 0.608049213886261, Accuracy: 0.79296875\n",
      "Batch: 103, Loss: 0.6158078908920288, Accuracy: 0.7841796875\n",
      "Batch: 104, Loss: 0.6152774095535278, Accuracy: 0.7841796875\n",
      "Batch: 105, Loss: 0.542316198348999, Accuracy: 0.82421875\n",
      "Batch: 106, Loss: 0.6170845031738281, Accuracy: 0.783203125\n",
      "Batch: 107, Loss: 0.5679076313972473, Accuracy: 0.8076171875\n",
      "Batch: 108, Loss: 0.5357307195663452, Accuracy: 0.8232421875\n",
      "Batch: 109, Loss: 0.49627041816711426, Accuracy: 0.8427734375\n",
      "Batch: 110, Loss: 0.5341851115226746, Accuracy: 0.837890625\n",
      "Batch: 111, Loss: 0.6047929525375366, Accuracy: 0.8115234375\n",
      "Batch: 112, Loss: 0.5692523717880249, Accuracy: 0.8193359375\n",
      "Epoch 30/90\n",
      "Batch: 1, Loss: 0.8222934007644653, Accuracy: 0.7529296875\n",
      "Batch: 2, Loss: 0.6448431015014648, Accuracy: 0.7998046875\n",
      "Batch: 3, Loss: 0.6462576389312744, Accuracy: 0.8046875\n",
      "Batch: 4, Loss: 0.5994817018508911, Accuracy: 0.806640625\n",
      "Batch: 5, Loss: 0.5759587287902832, Accuracy: 0.8134765625\n",
      "Batch: 6, Loss: 0.6229357123374939, Accuracy: 0.796875\n",
      "Batch: 7, Loss: 0.5641036629676819, Accuracy: 0.82421875\n",
      "Batch: 8, Loss: 0.5286242961883545, Accuracy: 0.833984375\n",
      "Batch: 9, Loss: 0.5683391094207764, Accuracy: 0.8154296875\n",
      "Batch: 10, Loss: 0.6200829744338989, Accuracy: 0.7978515625\n",
      "Batch: 11, Loss: 0.5766156911849976, Accuracy: 0.8125\n",
      "Batch: 12, Loss: 0.5587800145149231, Accuracy: 0.8232421875\n",
      "Batch: 13, Loss: 0.5184214115142822, Accuracy: 0.833984375\n",
      "Batch: 14, Loss: 0.5923497676849365, Accuracy: 0.8076171875\n",
      "Batch: 15, Loss: 0.6069973707199097, Accuracy: 0.7978515625\n",
      "Batch: 16, Loss: 0.5984117984771729, Accuracy: 0.8056640625\n",
      "Batch: 17, Loss: 0.6227149367332458, Accuracy: 0.798828125\n",
      "Batch: 18, Loss: 0.5385469198226929, Accuracy: 0.8193359375\n",
      "Batch: 19, Loss: 0.5383505821228027, Accuracy: 0.8212890625\n",
      "Batch: 20, Loss: 0.5998073220252991, Accuracy: 0.7861328125\n",
      "Batch: 21, Loss: 0.5969136357307434, Accuracy: 0.7890625\n",
      "Batch: 22, Loss: 0.580930233001709, Accuracy: 0.814453125\n",
      "Batch: 23, Loss: 0.6177763938903809, Accuracy: 0.802734375\n",
      "Batch: 24, Loss: 0.6467230319976807, Accuracy: 0.7919921875\n",
      "Batch: 25, Loss: 0.6882613301277161, Accuracy: 0.7744140625\n",
      "Batch: 26, Loss: 0.7182736396789551, Accuracy: 0.7880859375\n",
      "Batch: 27, Loss: 0.6792269945144653, Accuracy: 0.791015625\n",
      "Batch: 28, Loss: 0.5824729204177856, Accuracy: 0.7939453125\n",
      "Batch: 29, Loss: 0.6439838409423828, Accuracy: 0.7734375\n",
      "Batch: 30, Loss: 0.5871649980545044, Accuracy: 0.796875\n",
      "Batch: 31, Loss: 0.5986555814743042, Accuracy: 0.794921875\n",
      "Batch: 32, Loss: 0.5923156142234802, Accuracy: 0.8115234375\n",
      "Batch: 33, Loss: 0.5756301283836365, Accuracy: 0.791015625\n",
      "Batch: 34, Loss: 0.5596208572387695, Accuracy: 0.8046875\n",
      "Batch: 35, Loss: 0.5891005992889404, Accuracy: 0.802734375\n",
      "Batch: 36, Loss: 0.6469632387161255, Accuracy: 0.77734375\n",
      "Batch: 37, Loss: 0.5537161231040955, Accuracy: 0.8134765625\n",
      "Batch: 38, Loss: 0.5954766273498535, Accuracy: 0.8046875\n",
      "Batch: 39, Loss: 0.574095606803894, Accuracy: 0.818359375\n",
      "Batch: 40, Loss: 0.6026737093925476, Accuracy: 0.810546875\n",
      "Batch: 41, Loss: 0.5948278903961182, Accuracy: 0.794921875\n",
      "Batch: 42, Loss: 0.5497809648513794, Accuracy: 0.8154296875\n",
      "Batch: 43, Loss: 0.5902050733566284, Accuracy: 0.80078125\n",
      "Batch: 44, Loss: 0.63097083568573, Accuracy: 0.7919921875\n",
      "Batch: 45, Loss: 0.7166659832000732, Accuracy: 0.7724609375\n",
      "Batch: 46, Loss: 0.6141748428344727, Accuracy: 0.7890625\n",
      "Batch: 47, Loss: 0.6285470724105835, Accuracy: 0.7744140625\n",
      "Batch: 48, Loss: 0.6809964776039124, Accuracy: 0.771484375\n",
      "Batch: 49, Loss: 0.6952260732650757, Accuracy: 0.7861328125\n",
      "Batch: 50, Loss: 0.545395016670227, Accuracy: 0.82421875\n",
      "Batch: 51, Loss: 0.6241300702095032, Accuracy: 0.794921875\n",
      "Batch: 52, Loss: 0.6230961084365845, Accuracy: 0.787109375\n",
      "Batch: 53, Loss: 0.7162637710571289, Accuracy: 0.765625\n",
      "Batch: 54, Loss: 0.6287125945091248, Accuracy: 0.810546875\n",
      "Batch: 55, Loss: 0.6714156866073608, Accuracy: 0.79296875\n",
      "Batch: 56, Loss: 0.6094105243682861, Accuracy: 0.8056640625\n",
      "Batch: 57, Loss: 0.6754345893859863, Accuracy: 0.791015625\n",
      "Batch: 58, Loss: 0.7006739377975464, Accuracy: 0.7744140625\n",
      "Batch: 59, Loss: 0.6354584097862244, Accuracy: 0.7880859375\n",
      "Batch: 60, Loss: 0.6568164825439453, Accuracy: 0.771484375\n",
      "Batch: 61, Loss: 0.6085104942321777, Accuracy: 0.802734375\n",
      "Batch: 62, Loss: 0.6376498937606812, Accuracy: 0.783203125\n",
      "Batch: 63, Loss: 0.5126695036888123, Accuracy: 0.828125\n",
      "Batch: 64, Loss: 0.5769166946411133, Accuracy: 0.7919921875\n",
      "Batch: 65, Loss: 0.5995386838912964, Accuracy: 0.7890625\n",
      "Batch: 66, Loss: 0.5549902319908142, Accuracy: 0.80859375\n",
      "Batch: 67, Loss: 0.5837491154670715, Accuracy: 0.8115234375\n",
      "Batch: 68, Loss: 0.5951604247093201, Accuracy: 0.80859375\n",
      "Batch: 69, Loss: 0.5441727638244629, Accuracy: 0.810546875\n",
      "Batch: 70, Loss: 0.5635257959365845, Accuracy: 0.8056640625\n",
      "Batch: 71, Loss: 0.5682809948921204, Accuracy: 0.8037109375\n",
      "Batch: 72, Loss: 0.6012800931930542, Accuracy: 0.7978515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 73, Loss: 0.5884944200515747, Accuracy: 0.798828125\n",
      "Batch: 74, Loss: 0.5645300149917603, Accuracy: 0.8154296875\n",
      "Batch: 75, Loss: 0.4982694089412689, Accuracy: 0.82421875\n",
      "Batch: 76, Loss: 0.5353381633758545, Accuracy: 0.8232421875\n",
      "Batch: 77, Loss: 0.6340681314468384, Accuracy: 0.7958984375\n",
      "Batch: 78, Loss: 0.572330117225647, Accuracy: 0.8125\n",
      "Batch: 79, Loss: 0.584025502204895, Accuracy: 0.8203125\n",
      "Batch: 80, Loss: 0.5644868612289429, Accuracy: 0.814453125\n",
      "Batch: 81, Loss: 0.601142942905426, Accuracy: 0.7998046875\n",
      "Batch: 82, Loss: 0.5887899398803711, Accuracy: 0.80078125\n",
      "Batch: 83, Loss: 0.5293647646903992, Accuracy: 0.826171875\n",
      "Batch: 84, Loss: 0.5628657341003418, Accuracy: 0.80859375\n",
      "Batch: 85, Loss: 0.5906636714935303, Accuracy: 0.7958984375\n",
      "Batch: 86, Loss: 0.5455210208892822, Accuracy: 0.8046875\n",
      "Batch: 87, Loss: 0.5431772470474243, Accuracy: 0.8203125\n",
      "Batch: 88, Loss: 0.5500144362449646, Accuracy: 0.8251953125\n",
      "Batch: 89, Loss: 0.5445598363876343, Accuracy: 0.8095703125\n",
      "Batch: 90, Loss: 0.6194654107093811, Accuracy: 0.78125\n",
      "Batch: 91, Loss: 0.6567818522453308, Accuracy: 0.767578125\n",
      "Batch: 92, Loss: 0.590175449848175, Accuracy: 0.8017578125\n",
      "Batch: 93, Loss: 0.5569491982460022, Accuracy: 0.8212890625\n",
      "Batch: 94, Loss: 0.6084503531455994, Accuracy: 0.796875\n",
      "Batch: 95, Loss: 0.5858862400054932, Accuracy: 0.814453125\n",
      "Batch: 96, Loss: 0.5754972696304321, Accuracy: 0.8056640625\n",
      "Batch: 97, Loss: 0.5593774318695068, Accuracy: 0.8212890625\n",
      "Batch: 98, Loss: 0.6290149688720703, Accuracy: 0.7900390625\n",
      "Batch: 99, Loss: 0.5848687887191772, Accuracy: 0.8076171875\n",
      "Batch: 100, Loss: 0.5938843488693237, Accuracy: 0.802734375\n",
      "Batch: 101, Loss: 0.5930986404418945, Accuracy: 0.7880859375\n",
      "Batch: 102, Loss: 0.5818252563476562, Accuracy: 0.8046875\n",
      "Batch: 103, Loss: 0.6026609539985657, Accuracy: 0.7978515625\n",
      "Batch: 104, Loss: 0.6037859916687012, Accuracy: 0.802734375\n",
      "Batch: 105, Loss: 0.5060585737228394, Accuracy: 0.8251953125\n",
      "Batch: 106, Loss: 0.6014226078987122, Accuracy: 0.794921875\n",
      "Batch: 107, Loss: 0.5327776670455933, Accuracy: 0.814453125\n",
      "Batch: 108, Loss: 0.5403164029121399, Accuracy: 0.8310546875\n",
      "Batch: 109, Loss: 0.4753986597061157, Accuracy: 0.8388671875\n",
      "Batch: 110, Loss: 0.5169677734375, Accuracy: 0.8330078125\n",
      "Batch: 111, Loss: 0.5832078456878662, Accuracy: 0.8037109375\n",
      "Batch: 112, Loss: 0.5707749128341675, Accuracy: 0.80859375\n",
      "Saved Weights at epoch 30 to file Weights_30.h5\n",
      "Epoch 31/90\n",
      "Batch: 1, Loss: 0.8003683686256409, Accuracy: 0.763671875\n",
      "Batch: 2, Loss: 0.604178786277771, Accuracy: 0.802734375\n",
      "Batch: 3, Loss: 0.6120811700820923, Accuracy: 0.802734375\n",
      "Batch: 4, Loss: 0.5429612398147583, Accuracy: 0.8193359375\n",
      "Batch: 5, Loss: 0.575459897518158, Accuracy: 0.8193359375\n",
      "Batch: 6, Loss: 0.6262432932853699, Accuracy: 0.796875\n",
      "Batch: 7, Loss: 0.5775318145751953, Accuracy: 0.806640625\n",
      "Batch: 8, Loss: 0.5032965540885925, Accuracy: 0.84375\n",
      "Batch: 9, Loss: 0.548048734664917, Accuracy: 0.8203125\n",
      "Batch: 10, Loss: 0.6072436571121216, Accuracy: 0.7978515625\n",
      "Batch: 11, Loss: 0.5478641390800476, Accuracy: 0.8271484375\n",
      "Batch: 12, Loss: 0.5356770753860474, Accuracy: 0.82421875\n",
      "Batch: 13, Loss: 0.5043116807937622, Accuracy: 0.8486328125\n",
      "Batch: 14, Loss: 0.5860637426376343, Accuracy: 0.8046875\n",
      "Batch: 15, Loss: 0.5757620334625244, Accuracy: 0.8193359375\n",
      "Batch: 16, Loss: 0.580884575843811, Accuracy: 0.8193359375\n",
      "Batch: 17, Loss: 0.5932906866073608, Accuracy: 0.80078125\n",
      "Batch: 18, Loss: 0.5394085049629211, Accuracy: 0.818359375\n",
      "Batch: 19, Loss: 0.5156927108764648, Accuracy: 0.833984375\n",
      "Batch: 20, Loss: 0.5762771964073181, Accuracy: 0.802734375\n",
      "Batch: 21, Loss: 0.5759704113006592, Accuracy: 0.8154296875\n",
      "Batch: 22, Loss: 0.5451155304908752, Accuracy: 0.82421875\n",
      "Batch: 23, Loss: 0.5987067222595215, Accuracy: 0.806640625\n",
      "Batch: 24, Loss: 0.6065757870674133, Accuracy: 0.8076171875\n",
      "Batch: 25, Loss: 0.6359227299690247, Accuracy: 0.79296875\n",
      "Batch: 26, Loss: 0.7036775350570679, Accuracy: 0.78515625\n",
      "Batch: 27, Loss: 0.6581771373748779, Accuracy: 0.787109375\n",
      "Batch: 28, Loss: 0.5594489574432373, Accuracy: 0.8134765625\n",
      "Batch: 29, Loss: 0.6242907643318176, Accuracy: 0.7900390625\n",
      "Batch: 30, Loss: 0.5235508680343628, Accuracy: 0.8271484375\n",
      "Batch: 31, Loss: 0.5761292576789856, Accuracy: 0.8134765625\n",
      "Batch: 32, Loss: 0.5535234212875366, Accuracy: 0.8173828125\n",
      "Batch: 33, Loss: 0.5642942190170288, Accuracy: 0.7939453125\n",
      "Batch: 34, Loss: 0.5399920344352722, Accuracy: 0.82421875\n",
      "Batch: 35, Loss: 0.5800180435180664, Accuracy: 0.806640625\n",
      "Batch: 36, Loss: 0.6492537260055542, Accuracy: 0.7978515625\n",
      "Batch: 37, Loss: 0.5610934495925903, Accuracy: 0.806640625\n",
      "Batch: 38, Loss: 0.5872055292129517, Accuracy: 0.8017578125\n",
      "Batch: 39, Loss: 0.5722975730895996, Accuracy: 0.8154296875\n",
      "Batch: 40, Loss: 0.584862470626831, Accuracy: 0.787109375\n",
      "Batch: 41, Loss: 0.6107720732688904, Accuracy: 0.783203125\n",
      "Batch: 42, Loss: 0.5730209350585938, Accuracy: 0.8046875\n",
      "Batch: 43, Loss: 0.5962519645690918, Accuracy: 0.79296875\n",
      "Batch: 44, Loss: 0.6062242388725281, Accuracy: 0.8115234375\n",
      "Batch: 45, Loss: 0.7124220132827759, Accuracy: 0.7802734375\n",
      "Batch: 46, Loss: 0.6004192233085632, Accuracy: 0.8056640625\n",
      "Batch: 47, Loss: 0.5998293161392212, Accuracy: 0.798828125\n",
      "Batch: 48, Loss: 0.6468756198883057, Accuracy: 0.78125\n",
      "Batch: 49, Loss: 0.7094982266426086, Accuracy: 0.7734375\n",
      "Batch: 50, Loss: 0.5241720676422119, Accuracy: 0.84375\n",
      "Batch: 51, Loss: 0.6003818511962891, Accuracy: 0.806640625\n",
      "Batch: 52, Loss: 0.6264972686767578, Accuracy: 0.7998046875\n",
      "Batch: 53, Loss: 0.7116392850875854, Accuracy: 0.765625\n",
      "Batch: 54, Loss: 0.6256335973739624, Accuracy: 0.7958984375\n",
      "Batch: 55, Loss: 0.6348981857299805, Accuracy: 0.7978515625\n",
      "Batch: 56, Loss: 0.5856766104698181, Accuracy: 0.8115234375\n",
      "Batch: 57, Loss: 0.6686569452285767, Accuracy: 0.7802734375\n",
      "Batch: 58, Loss: 0.6805168986320496, Accuracy: 0.7763671875\n",
      "Batch: 59, Loss: 0.5980623960494995, Accuracy: 0.798828125\n",
      "Batch: 60, Loss: 0.6288425326347351, Accuracy: 0.7900390625\n",
      "Batch: 61, Loss: 0.6030436158180237, Accuracy: 0.8134765625\n",
      "Batch: 62, Loss: 0.6350284814834595, Accuracy: 0.79296875\n",
      "Batch: 63, Loss: 0.4898643493652344, Accuracy: 0.8349609375\n",
      "Batch: 64, Loss: 0.5604491233825684, Accuracy: 0.8076171875\n",
      "Batch: 65, Loss: 0.5471526384353638, Accuracy: 0.8125\n",
      "Batch: 66, Loss: 0.5126547813415527, Accuracy: 0.8310546875\n",
      "Batch: 67, Loss: 0.5476202964782715, Accuracy: 0.81640625\n",
      "Batch: 68, Loss: 0.5550398230552673, Accuracy: 0.8310546875\n",
      "Batch: 69, Loss: 0.537593424320221, Accuracy: 0.8193359375\n",
      "Batch: 70, Loss: 0.5564150810241699, Accuracy: 0.8134765625\n",
      "Batch: 71, Loss: 0.5116493105888367, Accuracy: 0.833984375\n",
      "Batch: 72, Loss: 0.602141261100769, Accuracy: 0.7978515625\n",
      "Batch: 73, Loss: 0.5664074420928955, Accuracy: 0.818359375\n",
      "Batch: 74, Loss: 0.5483208894729614, Accuracy: 0.8173828125\n",
      "Batch: 75, Loss: 0.5215108394622803, Accuracy: 0.8115234375\n",
      "Batch: 76, Loss: 0.5195788145065308, Accuracy: 0.822265625\n",
      "Batch: 77, Loss: 0.6272323727607727, Accuracy: 0.7900390625\n",
      "Batch: 78, Loss: 0.5425217151641846, Accuracy: 0.8173828125\n",
      "Batch: 79, Loss: 0.5371125936508179, Accuracy: 0.8359375\n",
      "Batch: 80, Loss: 0.5644041299819946, Accuracy: 0.8134765625\n",
      "Batch: 81, Loss: 0.5947903394699097, Accuracy: 0.7939453125\n",
      "Batch: 82, Loss: 0.5791639685630798, Accuracy: 0.82421875\n",
      "Batch: 83, Loss: 0.5153243541717529, Accuracy: 0.82421875\n",
      "Batch: 84, Loss: 0.5363582372665405, Accuracy: 0.8173828125\n",
      "Batch: 85, Loss: 0.5618691444396973, Accuracy: 0.81640625\n",
      "Batch: 86, Loss: 0.5404164791107178, Accuracy: 0.81640625\n",
      "Batch: 87, Loss: 0.5091387033462524, Accuracy: 0.830078125\n",
      "Batch: 88, Loss: 0.5361906290054321, Accuracy: 0.806640625\n",
      "Batch: 89, Loss: 0.5495707392692566, Accuracy: 0.8232421875\n",
      "Batch: 90, Loss: 0.6189945936203003, Accuracy: 0.775390625\n",
      "Batch: 91, Loss: 0.6462743282318115, Accuracy: 0.7861328125\n",
      "Batch: 92, Loss: 0.5777300596237183, Accuracy: 0.794921875\n",
      "Batch: 93, Loss: 0.5369390249252319, Accuracy: 0.828125\n",
      "Batch: 94, Loss: 0.6123228073120117, Accuracy: 0.8017578125\n",
      "Batch: 95, Loss: 0.5790295600891113, Accuracy: 0.8134765625\n",
      "Batch: 96, Loss: 0.5524816513061523, Accuracy: 0.8125\n",
      "Batch: 97, Loss: 0.5436521768569946, Accuracy: 0.8212890625\n",
      "Batch: 98, Loss: 0.5959067940711975, Accuracy: 0.7900390625\n",
      "Batch: 99, Loss: 0.5484766960144043, Accuracy: 0.80078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 100, Loss: 0.6014144420623779, Accuracy: 0.8017578125\n",
      "Batch: 101, Loss: 0.5633097887039185, Accuracy: 0.80859375\n",
      "Batch: 102, Loss: 0.57172030210495, Accuracy: 0.7978515625\n",
      "Batch: 103, Loss: 0.5900155901908875, Accuracy: 0.79296875\n",
      "Batch: 104, Loss: 0.5683605670928955, Accuracy: 0.8115234375\n",
      "Batch: 105, Loss: 0.48287224769592285, Accuracy: 0.83984375\n",
      "Batch: 106, Loss: 0.5750439763069153, Accuracy: 0.7890625\n",
      "Batch: 107, Loss: 0.5309566259384155, Accuracy: 0.82421875\n",
      "Batch: 108, Loss: 0.5034264922142029, Accuracy: 0.830078125\n",
      "Batch: 109, Loss: 0.4639400541782379, Accuracy: 0.849609375\n",
      "Batch: 110, Loss: 0.49849486351013184, Accuracy: 0.84375\n",
      "Batch: 111, Loss: 0.5767450332641602, Accuracy: 0.8212890625\n",
      "Batch: 112, Loss: 0.5213102698326111, Accuracy: 0.8369140625\n",
      "Epoch 32/90\n",
      "Batch: 1, Loss: 0.7865747213363647, Accuracy: 0.7744140625\n",
      "Batch: 2, Loss: 0.605300784111023, Accuracy: 0.806640625\n",
      "Batch: 3, Loss: 0.5890182256698608, Accuracy: 0.8115234375\n",
      "Batch: 4, Loss: 0.5544770359992981, Accuracy: 0.8212890625\n",
      "Batch: 5, Loss: 0.5588915348052979, Accuracy: 0.826171875\n",
      "Batch: 6, Loss: 0.5801262855529785, Accuracy: 0.8076171875\n",
      "Batch: 7, Loss: 0.5492962002754211, Accuracy: 0.822265625\n",
      "Batch: 8, Loss: 0.4713580906391144, Accuracy: 0.84375\n",
      "Batch: 9, Loss: 0.5209586024284363, Accuracy: 0.8203125\n",
      "Batch: 10, Loss: 0.5785526037216187, Accuracy: 0.80859375\n",
      "Batch: 11, Loss: 0.5511929988861084, Accuracy: 0.818359375\n",
      "Batch: 12, Loss: 0.5287358164787292, Accuracy: 0.828125\n",
      "Batch: 13, Loss: 0.502053439617157, Accuracy: 0.83984375\n",
      "Batch: 14, Loss: 0.5654441714286804, Accuracy: 0.806640625\n",
      "Batch: 15, Loss: 0.5601882338523865, Accuracy: 0.806640625\n",
      "Batch: 16, Loss: 0.5598586201667786, Accuracy: 0.8173828125\n",
      "Batch: 17, Loss: 0.595481276512146, Accuracy: 0.802734375\n",
      "Batch: 18, Loss: 0.5059237480163574, Accuracy: 0.830078125\n",
      "Batch: 19, Loss: 0.5026776790618896, Accuracy: 0.84375\n",
      "Batch: 20, Loss: 0.5255910754203796, Accuracy: 0.8271484375\n",
      "Batch: 21, Loss: 0.5732086300849915, Accuracy: 0.82421875\n",
      "Batch: 22, Loss: 0.527194619178772, Accuracy: 0.8388671875\n",
      "Batch: 23, Loss: 0.5824666619300842, Accuracy: 0.8125\n",
      "Batch: 24, Loss: 0.5887712240219116, Accuracy: 0.810546875\n",
      "Batch: 25, Loss: 0.6594010591506958, Accuracy: 0.77734375\n",
      "Batch: 26, Loss: 0.6580618619918823, Accuracy: 0.7998046875\n",
      "Batch: 27, Loss: 0.6391420960426331, Accuracy: 0.787109375\n",
      "Batch: 28, Loss: 0.5611217617988586, Accuracy: 0.8115234375\n",
      "Batch: 29, Loss: 0.6094133257865906, Accuracy: 0.810546875\n",
      "Batch: 30, Loss: 0.5359085202217102, Accuracy: 0.818359375\n",
      "Batch: 31, Loss: 0.5572859644889832, Accuracy: 0.8125\n",
      "Batch: 32, Loss: 0.554291307926178, Accuracy: 0.8232421875\n",
      "Batch: 33, Loss: 0.5619573593139648, Accuracy: 0.802734375\n",
      "Batch: 34, Loss: 0.5013135671615601, Accuracy: 0.83984375\n",
      "Batch: 35, Loss: 0.555432915687561, Accuracy: 0.8125\n",
      "Batch: 36, Loss: 0.6264377236366272, Accuracy: 0.7998046875\n",
      "Batch: 37, Loss: 0.5079137682914734, Accuracy: 0.8427734375\n",
      "Batch: 38, Loss: 0.5692797899246216, Accuracy: 0.80859375\n",
      "Batch: 39, Loss: 0.5463136434555054, Accuracy: 0.8232421875\n",
      "Batch: 40, Loss: 0.5564396381378174, Accuracy: 0.814453125\n",
      "Batch: 41, Loss: 0.5733136534690857, Accuracy: 0.7919921875\n",
      "Batch: 42, Loss: 0.5306413173675537, Accuracy: 0.82421875\n",
      "Batch: 43, Loss: 0.5675636529922485, Accuracy: 0.8046875\n",
      "Batch: 44, Loss: 0.604922890663147, Accuracy: 0.8056640625\n",
      "Batch: 45, Loss: 0.65474933385849, Accuracy: 0.7919921875\n",
      "Batch: 46, Loss: 0.5690852999687195, Accuracy: 0.8037109375\n",
      "Batch: 47, Loss: 0.5963184833526611, Accuracy: 0.791015625\n",
      "Batch: 48, Loss: 0.6058768033981323, Accuracy: 0.8076171875\n",
      "Batch: 49, Loss: 0.6605636477470398, Accuracy: 0.7890625\n",
      "Batch: 50, Loss: 0.5181915760040283, Accuracy: 0.8349609375\n",
      "Batch: 51, Loss: 0.5795168280601501, Accuracy: 0.814453125\n",
      "Batch: 52, Loss: 0.582788348197937, Accuracy: 0.8095703125\n",
      "Batch: 53, Loss: 0.6552203893661499, Accuracy: 0.78125\n",
      "Batch: 54, Loss: 0.5900126695632935, Accuracy: 0.8232421875\n",
      "Batch: 55, Loss: 0.6091822981834412, Accuracy: 0.8125\n",
      "Batch: 56, Loss: 0.5460408926010132, Accuracy: 0.8154296875\n",
      "Batch: 57, Loss: 0.6604551672935486, Accuracy: 0.7783203125\n",
      "Batch: 58, Loss: 0.657346248626709, Accuracy: 0.78515625\n",
      "Batch: 59, Loss: 0.5957938432693481, Accuracy: 0.8134765625\n",
      "Batch: 60, Loss: 0.629427969455719, Accuracy: 0.7822265625\n",
      "Batch: 61, Loss: 0.5878643989562988, Accuracy: 0.8056640625\n",
      "Batch: 62, Loss: 0.6093501448631287, Accuracy: 0.7978515625\n",
      "Batch: 63, Loss: 0.47321248054504395, Accuracy: 0.8408203125\n",
      "Batch: 64, Loss: 0.5511155128479004, Accuracy: 0.802734375\n",
      "Batch: 65, Loss: 0.5333101749420166, Accuracy: 0.8125\n",
      "Batch: 66, Loss: 0.4958701431751251, Accuracy: 0.84765625\n",
      "Batch: 67, Loss: 0.5336976647377014, Accuracy: 0.8212890625\n",
      "Batch: 68, Loss: 0.5592025518417358, Accuracy: 0.8095703125\n",
      "Batch: 69, Loss: 0.5083318948745728, Accuracy: 0.8388671875\n",
      "Batch: 70, Loss: 0.5294238328933716, Accuracy: 0.8193359375\n",
      "Batch: 71, Loss: 0.5118138790130615, Accuracy: 0.82421875\n",
      "Batch: 72, Loss: 0.6032209396362305, Accuracy: 0.810546875\n",
      "Batch: 73, Loss: 0.5786551833152771, Accuracy: 0.8056640625\n",
      "Batch: 74, Loss: 0.5423901081085205, Accuracy: 0.8212890625\n",
      "Batch: 75, Loss: 0.5047093629837036, Accuracy: 0.8369140625\n",
      "Batch: 76, Loss: 0.5038626194000244, Accuracy: 0.826171875\n",
      "Batch: 77, Loss: 0.6029393076896667, Accuracy: 0.8154296875\n",
      "Batch: 78, Loss: 0.5459398031234741, Accuracy: 0.8125\n",
      "Batch: 79, Loss: 0.5571211576461792, Accuracy: 0.8251953125\n",
      "Batch: 80, Loss: 0.5321218967437744, Accuracy: 0.8330078125\n",
      "Batch: 81, Loss: 0.5756834745407104, Accuracy: 0.7998046875\n",
      "Batch: 82, Loss: 0.5510697364807129, Accuracy: 0.8115234375\n",
      "Batch: 83, Loss: 0.47288626432418823, Accuracy: 0.8369140625\n",
      "Batch: 84, Loss: 0.5288550853729248, Accuracy: 0.8193359375\n",
      "Batch: 85, Loss: 0.570759654045105, Accuracy: 0.8076171875\n",
      "Batch: 86, Loss: 0.5238617658615112, Accuracy: 0.826171875\n",
      "Batch: 87, Loss: 0.48602959513664246, Accuracy: 0.8388671875\n",
      "Batch: 88, Loss: 0.5035812258720398, Accuracy: 0.8349609375\n",
      "Batch: 89, Loss: 0.5293686389923096, Accuracy: 0.8388671875\n",
      "Batch: 90, Loss: 0.5748497247695923, Accuracy: 0.8095703125\n",
      "Batch: 91, Loss: 0.6287417411804199, Accuracy: 0.7822265625\n",
      "Batch: 92, Loss: 0.5343769788742065, Accuracy: 0.8076171875\n",
      "Batch: 93, Loss: 0.5543870329856873, Accuracy: 0.81640625\n",
      "Batch: 94, Loss: 0.5739744901657104, Accuracy: 0.810546875\n",
      "Batch: 95, Loss: 0.551734447479248, Accuracy: 0.81640625\n",
      "Batch: 96, Loss: 0.5644746422767639, Accuracy: 0.8095703125\n",
      "Batch: 97, Loss: 0.5165982842445374, Accuracy: 0.837890625\n",
      "Batch: 98, Loss: 0.6065877079963684, Accuracy: 0.7919921875\n",
      "Batch: 99, Loss: 0.5537223815917969, Accuracy: 0.8017578125\n",
      "Batch: 100, Loss: 0.5774511098861694, Accuracy: 0.8046875\n",
      "Batch: 101, Loss: 0.5472990274429321, Accuracy: 0.7958984375\n",
      "Batch: 102, Loss: 0.5607727766036987, Accuracy: 0.81640625\n",
      "Batch: 103, Loss: 0.5556594133377075, Accuracy: 0.8037109375\n",
      "Batch: 104, Loss: 0.5613718032836914, Accuracy: 0.8095703125\n",
      "Batch: 105, Loss: 0.4946654140949249, Accuracy: 0.8291015625\n",
      "Batch: 106, Loss: 0.5557805299758911, Accuracy: 0.8134765625\n",
      "Batch: 107, Loss: 0.5386660099029541, Accuracy: 0.8271484375\n",
      "Batch: 108, Loss: 0.5049629211425781, Accuracy: 0.8427734375\n",
      "Batch: 109, Loss: 0.46337294578552246, Accuracy: 0.853515625\n",
      "Batch: 110, Loss: 0.47577518224716187, Accuracy: 0.84765625\n",
      "Batch: 111, Loss: 0.5857139825820923, Accuracy: 0.8017578125\n",
      "Batch: 112, Loss: 0.507210910320282, Accuracy: 0.8291015625\n",
      "Epoch 33/90\n",
      "Batch: 1, Loss: 0.7628097534179688, Accuracy: 0.7880859375\n",
      "Batch: 2, Loss: 0.5937027335166931, Accuracy: 0.8134765625\n",
      "Batch: 3, Loss: 0.5497258901596069, Accuracy: 0.822265625\n",
      "Batch: 4, Loss: 0.5351910591125488, Accuracy: 0.83984375\n",
      "Batch: 5, Loss: 0.5115193128585815, Accuracy: 0.8408203125\n",
      "Batch: 6, Loss: 0.5684624910354614, Accuracy: 0.826171875\n",
      "Batch: 7, Loss: 0.5200837850570679, Accuracy: 0.8359375\n",
      "Batch: 8, Loss: 0.4815920293331146, Accuracy: 0.84765625\n",
      "Batch: 9, Loss: 0.5533928275108337, Accuracy: 0.8046875\n",
      "Batch: 10, Loss: 0.5778786540031433, Accuracy: 0.80859375\n",
      "Batch: 11, Loss: 0.520376443862915, Accuracy: 0.828125\n",
      "Batch: 12, Loss: 0.4997231066226959, Accuracy: 0.8408203125\n",
      "Batch: 13, Loss: 0.4735950231552124, Accuracy: 0.84375\n",
      "Batch: 14, Loss: 0.5590533018112183, Accuracy: 0.806640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 15, Loss: 0.563873291015625, Accuracy: 0.8115234375\n",
      "Batch: 16, Loss: 0.5591733455657959, Accuracy: 0.8056640625\n",
      "Batch: 17, Loss: 0.5487285256385803, Accuracy: 0.8193359375\n",
      "Batch: 18, Loss: 0.4954589605331421, Accuracy: 0.8291015625\n",
      "Batch: 19, Loss: 0.4868883788585663, Accuracy: 0.85546875\n",
      "Batch: 20, Loss: 0.5341333150863647, Accuracy: 0.82421875\n",
      "Batch: 21, Loss: 0.5755165219306946, Accuracy: 0.7998046875\n",
      "Batch: 22, Loss: 0.5250163674354553, Accuracy: 0.8125\n",
      "Batch: 23, Loss: 0.613544225692749, Accuracy: 0.8056640625\n",
      "Batch: 24, Loss: 0.5898280143737793, Accuracy: 0.7978515625\n",
      "Batch: 25, Loss: 0.6351502537727356, Accuracy: 0.7802734375\n",
      "Batch: 26, Loss: 0.6528868675231934, Accuracy: 0.8037109375\n",
      "Batch: 27, Loss: 0.6386072635650635, Accuracy: 0.7978515625\n",
      "Batch: 28, Loss: 0.5559314489364624, Accuracy: 0.822265625\n",
      "Batch: 29, Loss: 0.5859293937683105, Accuracy: 0.810546875\n",
      "Batch: 30, Loss: 0.5264103412628174, Accuracy: 0.81640625\n",
      "Batch: 31, Loss: 0.5815691947937012, Accuracy: 0.8115234375\n",
      "Batch: 32, Loss: 0.5536365509033203, Accuracy: 0.8115234375\n",
      "Batch: 33, Loss: 0.5470918416976929, Accuracy: 0.798828125\n",
      "Batch: 34, Loss: 0.5046972036361694, Accuracy: 0.822265625\n",
      "Batch: 35, Loss: 0.5370633006095886, Accuracy: 0.8349609375\n",
      "Batch: 36, Loss: 0.6234593987464905, Accuracy: 0.802734375\n",
      "Batch: 37, Loss: 0.5139315128326416, Accuracy: 0.8291015625\n",
      "Batch: 38, Loss: 0.5665370225906372, Accuracy: 0.82421875\n",
      "Batch: 39, Loss: 0.5525454878807068, Accuracy: 0.818359375\n",
      "Batch: 40, Loss: 0.5597703456878662, Accuracy: 0.8251953125\n",
      "Batch: 41, Loss: 0.5996048450469971, Accuracy: 0.791015625\n",
      "Batch: 42, Loss: 0.5356943011283875, Accuracy: 0.8232421875\n",
      "Batch: 43, Loss: 0.5785961151123047, Accuracy: 0.8115234375\n",
      "Batch: 44, Loss: 0.5810742378234863, Accuracy: 0.8046875\n",
      "Batch: 45, Loss: 0.6268359422683716, Accuracy: 0.8037109375\n",
      "Batch: 46, Loss: 0.5711356401443481, Accuracy: 0.8125\n",
      "Batch: 47, Loss: 0.5808638334274292, Accuracy: 0.8037109375\n",
      "Batch: 48, Loss: 0.607505202293396, Accuracy: 0.7958984375\n",
      "Batch: 49, Loss: 0.6500728130340576, Accuracy: 0.8037109375\n",
      "Batch: 50, Loss: 0.48481377959251404, Accuracy: 0.85546875\n",
      "Batch: 51, Loss: 0.549796998500824, Accuracy: 0.8349609375\n",
      "Batch: 52, Loss: 0.5738717913627625, Accuracy: 0.806640625\n",
      "Batch: 53, Loss: 0.6623640060424805, Accuracy: 0.796875\n",
      "Batch: 54, Loss: 0.5846348404884338, Accuracy: 0.8173828125\n",
      "Batch: 55, Loss: 0.605129063129425, Accuracy: 0.8125\n",
      "Batch: 56, Loss: 0.52735435962677, Accuracy: 0.826171875\n",
      "Batch: 57, Loss: 0.6135945320129395, Accuracy: 0.8056640625\n",
      "Batch: 58, Loss: 0.643052339553833, Accuracy: 0.7783203125\n",
      "Batch: 59, Loss: 0.5823248624801636, Accuracy: 0.8134765625\n",
      "Batch: 60, Loss: 0.5950514078140259, Accuracy: 0.798828125\n",
      "Batch: 61, Loss: 0.5522714853286743, Accuracy: 0.8203125\n",
      "Batch: 62, Loss: 0.5901967883110046, Accuracy: 0.8095703125\n",
      "Batch: 63, Loss: 0.4557414948940277, Accuracy: 0.8408203125\n",
      "Batch: 64, Loss: 0.5507520437240601, Accuracy: 0.8125\n",
      "Batch: 65, Loss: 0.5461161732673645, Accuracy: 0.8115234375\n",
      "Batch: 66, Loss: 0.4902105927467346, Accuracy: 0.826171875\n",
      "Batch: 67, Loss: 0.5168660879135132, Accuracy: 0.822265625\n",
      "Batch: 68, Loss: 0.5305423736572266, Accuracy: 0.833984375\n",
      "Batch: 69, Loss: 0.5128777623176575, Accuracy: 0.8251953125\n",
      "Batch: 70, Loss: 0.5154623985290527, Accuracy: 0.8251953125\n",
      "Batch: 71, Loss: 0.5197253227233887, Accuracy: 0.8349609375\n",
      "Batch: 72, Loss: 0.5582435727119446, Accuracy: 0.8095703125\n",
      "Batch: 73, Loss: 0.538547933101654, Accuracy: 0.82421875\n",
      "Batch: 74, Loss: 0.5217217803001404, Accuracy: 0.8232421875\n",
      "Batch: 75, Loss: 0.4743060767650604, Accuracy: 0.8369140625\n",
      "Batch: 76, Loss: 0.48087701201438904, Accuracy: 0.83984375\n",
      "Batch: 77, Loss: 0.5547611713409424, Accuracy: 0.8212890625\n",
      "Batch: 78, Loss: 0.5165707468986511, Accuracy: 0.830078125\n",
      "Batch: 79, Loss: 0.5375640392303467, Accuracy: 0.82421875\n",
      "Batch: 80, Loss: 0.541633665561676, Accuracy: 0.8154296875\n",
      "Batch: 81, Loss: 0.5523867607116699, Accuracy: 0.828125\n",
      "Batch: 82, Loss: 0.5329691767692566, Accuracy: 0.83203125\n",
      "Batch: 83, Loss: 0.4718674123287201, Accuracy: 0.83984375\n",
      "Batch: 84, Loss: 0.5178989171981812, Accuracy: 0.830078125\n",
      "Batch: 85, Loss: 0.5466626882553101, Accuracy: 0.8232421875\n",
      "Batch: 86, Loss: 0.5116513967514038, Accuracy: 0.8134765625\n",
      "Batch: 87, Loss: 0.49062252044677734, Accuracy: 0.830078125\n",
      "Batch: 88, Loss: 0.5353769063949585, Accuracy: 0.826171875\n",
      "Batch: 89, Loss: 0.5061385035514832, Accuracy: 0.8359375\n",
      "Batch: 90, Loss: 0.5719132423400879, Accuracy: 0.8056640625\n",
      "Batch: 91, Loss: 0.628088116645813, Accuracy: 0.7919921875\n",
      "Batch: 92, Loss: 0.5329009294509888, Accuracy: 0.8154296875\n",
      "Batch: 93, Loss: 0.5452167391777039, Accuracy: 0.83203125\n",
      "Batch: 94, Loss: 0.5809741020202637, Accuracy: 0.8076171875\n",
      "Batch: 95, Loss: 0.5766000747680664, Accuracy: 0.7939453125\n",
      "Batch: 96, Loss: 0.5378192663192749, Accuracy: 0.818359375\n",
      "Batch: 97, Loss: 0.4901723563671112, Accuracy: 0.8310546875\n",
      "Batch: 98, Loss: 0.5844337344169617, Accuracy: 0.810546875\n",
      "Batch: 99, Loss: 0.5313756465911865, Accuracy: 0.828125\n",
      "Batch: 100, Loss: 0.5757073760032654, Accuracy: 0.7998046875\n",
      "Batch: 101, Loss: 0.5304539203643799, Accuracy: 0.8125\n",
      "Batch: 102, Loss: 0.5447697043418884, Accuracy: 0.8115234375\n",
      "Batch: 103, Loss: 0.5417487025260925, Accuracy: 0.8154296875\n",
      "Batch: 104, Loss: 0.5502641797065735, Accuracy: 0.8115234375\n",
      "Batch: 105, Loss: 0.47141164541244507, Accuracy: 0.8408203125\n",
      "Batch: 106, Loss: 0.5625042915344238, Accuracy: 0.8037109375\n",
      "Batch: 107, Loss: 0.521390438079834, Accuracy: 0.830078125\n",
      "Batch: 108, Loss: 0.5008819699287415, Accuracy: 0.84375\n",
      "Batch: 109, Loss: 0.44906702637672424, Accuracy: 0.857421875\n",
      "Batch: 110, Loss: 0.45624110102653503, Accuracy: 0.8583984375\n",
      "Batch: 111, Loss: 0.5104986429214478, Accuracy: 0.8408203125\n",
      "Batch: 112, Loss: 0.5187852382659912, Accuracy: 0.82421875\n",
      "Epoch 34/90\n",
      "Batch: 1, Loss: 0.7032454013824463, Accuracy: 0.7880859375\n",
      "Batch: 2, Loss: 0.565132737159729, Accuracy: 0.8212890625\n",
      "Batch: 3, Loss: 0.5300142168998718, Accuracy: 0.837890625\n",
      "Batch: 4, Loss: 0.5433299541473389, Accuracy: 0.828125\n",
      "Batch: 5, Loss: 0.4858100414276123, Accuracy: 0.8359375\n",
      "Batch: 6, Loss: 0.5407576560974121, Accuracy: 0.826171875\n",
      "Batch: 7, Loss: 0.5064759254455566, Accuracy: 0.841796875\n",
      "Batch: 8, Loss: 0.4650258421897888, Accuracy: 0.8486328125\n",
      "Batch: 9, Loss: 0.5012369155883789, Accuracy: 0.8251953125\n",
      "Batch: 10, Loss: 0.535435676574707, Accuracy: 0.8232421875\n",
      "Batch: 11, Loss: 0.5093721747398376, Accuracy: 0.8359375\n",
      "Batch: 12, Loss: 0.4699772000312805, Accuracy: 0.841796875\n",
      "Batch: 13, Loss: 0.46973302960395813, Accuracy: 0.849609375\n",
      "Batch: 14, Loss: 0.5512233376502991, Accuracy: 0.8193359375\n",
      "Batch: 15, Loss: 0.5278832912445068, Accuracy: 0.82421875\n",
      "Batch: 16, Loss: 0.5384494066238403, Accuracy: 0.8291015625\n",
      "Batch: 17, Loss: 0.571749746799469, Accuracy: 0.82421875\n",
      "Batch: 18, Loss: 0.48438355326652527, Accuracy: 0.830078125\n",
      "Batch: 19, Loss: 0.45429521799087524, Accuracy: 0.8466796875\n",
      "Batch: 20, Loss: 0.5198084712028503, Accuracy: 0.828125\n",
      "Batch: 21, Loss: 0.5361295342445374, Accuracy: 0.82421875\n",
      "Batch: 22, Loss: 0.4612429141998291, Accuracy: 0.845703125\n",
      "Batch: 23, Loss: 0.5320878028869629, Accuracy: 0.8330078125\n",
      "Batch: 24, Loss: 0.5793358087539673, Accuracy: 0.82421875\n",
      "Batch: 25, Loss: 0.604102373123169, Accuracy: 0.7900390625\n",
      "Batch: 26, Loss: 0.6394553184509277, Accuracy: 0.798828125\n",
      "Batch: 27, Loss: 0.6376240253448486, Accuracy: 0.783203125\n",
      "Batch: 28, Loss: 0.5738506317138672, Accuracy: 0.8212890625\n",
      "Batch: 29, Loss: 0.5797576904296875, Accuracy: 0.8125\n",
      "Batch: 30, Loss: 0.4940376281738281, Accuracy: 0.8408203125\n",
      "Batch: 31, Loss: 0.5453227162361145, Accuracy: 0.826171875\n",
      "Batch: 32, Loss: 0.5268309116363525, Accuracy: 0.833984375\n",
      "Batch: 33, Loss: 0.5301699042320251, Accuracy: 0.80859375\n",
      "Batch: 34, Loss: 0.4918944239616394, Accuracy: 0.8369140625\n",
      "Batch: 35, Loss: 0.5345858931541443, Accuracy: 0.8203125\n",
      "Batch: 36, Loss: 0.5928311944007874, Accuracy: 0.80859375\n",
      "Batch: 37, Loss: 0.5119949579238892, Accuracy: 0.8212890625\n",
      "Batch: 38, Loss: 0.561007559299469, Accuracy: 0.8154296875\n",
      "Batch: 39, Loss: 0.5337105989456177, Accuracy: 0.8193359375\n",
      "Batch: 40, Loss: 0.5186638832092285, Accuracy: 0.830078125\n",
      "Batch: 41, Loss: 0.552781343460083, Accuracy: 0.8154296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 42, Loss: 0.5417979955673218, Accuracy: 0.814453125\n",
      "Batch: 43, Loss: 0.5380052328109741, Accuracy: 0.8232421875\n",
      "Batch: 44, Loss: 0.5793719291687012, Accuracy: 0.8115234375\n",
      "Batch: 45, Loss: 0.6373409628868103, Accuracy: 0.7900390625\n",
      "Batch: 46, Loss: 0.5842298269271851, Accuracy: 0.796875\n",
      "Batch: 47, Loss: 0.5636195540428162, Accuracy: 0.8037109375\n",
      "Batch: 48, Loss: 0.5820325613021851, Accuracy: 0.8134765625\n",
      "Batch: 49, Loss: 0.6491307020187378, Accuracy: 0.7998046875\n",
      "Batch: 50, Loss: 0.48257318139076233, Accuracy: 0.85546875\n",
      "Batch: 51, Loss: 0.5381717681884766, Accuracy: 0.8271484375\n",
      "Batch: 52, Loss: 0.5457203388214111, Accuracy: 0.822265625\n",
      "Batch: 53, Loss: 0.6381762027740479, Accuracy: 0.798828125\n",
      "Batch: 54, Loss: 0.5701260566711426, Accuracy: 0.822265625\n",
      "Batch: 55, Loss: 0.5694668292999268, Accuracy: 0.8251953125\n",
      "Batch: 56, Loss: 0.5240451097488403, Accuracy: 0.83203125\n",
      "Batch: 57, Loss: 0.6354284286499023, Accuracy: 0.7939453125\n",
      "Batch: 58, Loss: 0.6362591981887817, Accuracy: 0.79296875\n",
      "Batch: 59, Loss: 0.566331148147583, Accuracy: 0.8125\n",
      "Batch: 60, Loss: 0.6026791930198669, Accuracy: 0.7880859375\n",
      "Batch: 61, Loss: 0.5833099484443665, Accuracy: 0.8076171875\n",
      "Batch: 62, Loss: 0.5921071767807007, Accuracy: 0.810546875\n",
      "Batch: 63, Loss: 0.46107107400894165, Accuracy: 0.853515625\n",
      "Batch: 64, Loss: 0.5160948038101196, Accuracy: 0.8232421875\n",
      "Batch: 65, Loss: 0.559648334980011, Accuracy: 0.806640625\n",
      "Batch: 66, Loss: 0.48878222703933716, Accuracy: 0.83203125\n",
      "Batch: 67, Loss: 0.5038782358169556, Accuracy: 0.8232421875\n",
      "Batch: 68, Loss: 0.5189976096153259, Accuracy: 0.83203125\n",
      "Batch: 69, Loss: 0.4967361390590668, Accuracy: 0.830078125\n",
      "Batch: 70, Loss: 0.5087314248085022, Accuracy: 0.837890625\n",
      "Batch: 71, Loss: 0.5027345418930054, Accuracy: 0.830078125\n",
      "Batch: 72, Loss: 0.5559794306755066, Accuracy: 0.814453125\n",
      "Batch: 73, Loss: 0.5391172170639038, Accuracy: 0.81640625\n",
      "Batch: 74, Loss: 0.5099287033081055, Accuracy: 0.8310546875\n",
      "Batch: 75, Loss: 0.45366182923316956, Accuracy: 0.8525390625\n",
      "Batch: 76, Loss: 0.46437862515449524, Accuracy: 0.8427734375\n",
      "Batch: 77, Loss: 0.5231195688247681, Accuracy: 0.828125\n",
      "Batch: 78, Loss: 0.5182063579559326, Accuracy: 0.8232421875\n",
      "Batch: 79, Loss: 0.5310553908348083, Accuracy: 0.8291015625\n",
      "Batch: 80, Loss: 0.49348339438438416, Accuracy: 0.837890625\n",
      "Batch: 81, Loss: 0.5650496482849121, Accuracy: 0.8095703125\n",
      "Batch: 82, Loss: 0.5403411388397217, Accuracy: 0.814453125\n",
      "Batch: 83, Loss: 0.44788262248039246, Accuracy: 0.8447265625\n",
      "Batch: 84, Loss: 0.49632173776626587, Accuracy: 0.8310546875\n",
      "Batch: 85, Loss: 0.5399676561355591, Accuracy: 0.8125\n",
      "Batch: 86, Loss: 0.5065206289291382, Accuracy: 0.830078125\n",
      "Batch: 87, Loss: 0.4843962788581848, Accuracy: 0.84375\n",
      "Batch: 88, Loss: 0.4953765869140625, Accuracy: 0.8359375\n",
      "Batch: 89, Loss: 0.5047935843467712, Accuracy: 0.841796875\n",
      "Batch: 90, Loss: 0.5573040843009949, Accuracy: 0.8037109375\n",
      "Batch: 91, Loss: 0.612363338470459, Accuracy: 0.7978515625\n",
      "Batch: 92, Loss: 0.5290968418121338, Accuracy: 0.814453125\n",
      "Batch: 93, Loss: 0.536428689956665, Accuracy: 0.8212890625\n",
      "Batch: 94, Loss: 0.5520570278167725, Accuracy: 0.806640625\n",
      "Batch: 95, Loss: 0.5259768962860107, Accuracy: 0.8232421875\n",
      "Batch: 96, Loss: 0.5290415287017822, Accuracy: 0.8193359375\n",
      "Batch: 97, Loss: 0.5032075643539429, Accuracy: 0.837890625\n",
      "Batch: 98, Loss: 0.59590744972229, Accuracy: 0.8046875\n",
      "Batch: 99, Loss: 0.517329216003418, Accuracy: 0.8232421875\n",
      "Batch: 100, Loss: 0.5483547449111938, Accuracy: 0.818359375\n",
      "Batch: 101, Loss: 0.5419343709945679, Accuracy: 0.806640625\n",
      "Batch: 102, Loss: 0.5467140078544617, Accuracy: 0.814453125\n",
      "Batch: 103, Loss: 0.5635189414024353, Accuracy: 0.8271484375\n",
      "Batch: 104, Loss: 0.5391845703125, Accuracy: 0.822265625\n",
      "Batch: 105, Loss: 0.47857990860939026, Accuracy: 0.8330078125\n",
      "Batch: 106, Loss: 0.5325168967247009, Accuracy: 0.83203125\n",
      "Batch: 107, Loss: 0.5024303793907166, Accuracy: 0.830078125\n",
      "Batch: 108, Loss: 0.485137939453125, Accuracy: 0.8349609375\n",
      "Batch: 109, Loss: 0.43542051315307617, Accuracy: 0.861328125\n",
      "Batch: 110, Loss: 0.46575674414634705, Accuracy: 0.8505859375\n",
      "Batch: 111, Loss: 0.5268585681915283, Accuracy: 0.828125\n",
      "Batch: 112, Loss: 0.5230376124382019, Accuracy: 0.81640625\n",
      "Epoch 35/90\n",
      "Batch: 1, Loss: 0.6892796754837036, Accuracy: 0.7880859375\n",
      "Batch: 2, Loss: 0.5694801211357117, Accuracy: 0.8173828125\n",
      "Batch: 3, Loss: 0.5252993702888489, Accuracy: 0.82421875\n",
      "Batch: 4, Loss: 0.5179668664932251, Accuracy: 0.837890625\n",
      "Batch: 5, Loss: 0.4677669405937195, Accuracy: 0.8544921875\n",
      "Batch: 6, Loss: 0.5420308113098145, Accuracy: 0.83203125\n",
      "Batch: 7, Loss: 0.4996579885482788, Accuracy: 0.8369140625\n",
      "Batch: 8, Loss: 0.46164920926094055, Accuracy: 0.859375\n",
      "Batch: 9, Loss: 0.5128502249717712, Accuracy: 0.8173828125\n",
      "Batch: 10, Loss: 0.5903434157371521, Accuracy: 0.80078125\n",
      "Batch: 11, Loss: 0.501365065574646, Accuracy: 0.8359375\n",
      "Batch: 12, Loss: 0.4608721137046814, Accuracy: 0.8583984375\n",
      "Batch: 13, Loss: 0.4570019543170929, Accuracy: 0.8525390625\n",
      "Batch: 14, Loss: 0.5257556438446045, Accuracy: 0.830078125\n",
      "Batch: 15, Loss: 0.513802170753479, Accuracy: 0.83203125\n",
      "Batch: 16, Loss: 0.5186536312103271, Accuracy: 0.8349609375\n",
      "Batch: 17, Loss: 0.5527335405349731, Accuracy: 0.818359375\n",
      "Batch: 18, Loss: 0.473680704832077, Accuracy: 0.8330078125\n",
      "Batch: 19, Loss: 0.46762213110923767, Accuracy: 0.8486328125\n",
      "Batch: 20, Loss: 0.5098001956939697, Accuracy: 0.82421875\n",
      "Batch: 21, Loss: 0.5406830310821533, Accuracy: 0.8134765625\n",
      "Batch: 22, Loss: 0.5108142495155334, Accuracy: 0.83203125\n",
      "Batch: 23, Loss: 0.5751649737358093, Accuracy: 0.8134765625\n",
      "Batch: 24, Loss: 0.5616768598556519, Accuracy: 0.8154296875\n",
      "Batch: 25, Loss: 0.5880847573280334, Accuracy: 0.8046875\n",
      "Batch: 26, Loss: 0.6051570177078247, Accuracy: 0.818359375\n",
      "Batch: 27, Loss: 0.6234590411186218, Accuracy: 0.791015625\n",
      "Batch: 28, Loss: 0.5298721790313721, Accuracy: 0.8232421875\n",
      "Batch: 29, Loss: 0.5715932846069336, Accuracy: 0.8232421875\n",
      "Batch: 30, Loss: 0.47550058364868164, Accuracy: 0.841796875\n",
      "Batch: 31, Loss: 0.552158534526825, Accuracy: 0.8076171875\n",
      "Batch: 32, Loss: 0.5023329257965088, Accuracy: 0.83203125\n",
      "Batch: 33, Loss: 0.5209519863128662, Accuracy: 0.8193359375\n",
      "Batch: 34, Loss: 0.46709248423576355, Accuracy: 0.8447265625\n",
      "Batch: 35, Loss: 0.5394880175590515, Accuracy: 0.828125\n",
      "Batch: 36, Loss: 0.5853110551834106, Accuracy: 0.8173828125\n",
      "Batch: 37, Loss: 0.4785952568054199, Accuracy: 0.8427734375\n",
      "Batch: 38, Loss: 0.5285114049911499, Accuracy: 0.830078125\n",
      "Batch: 39, Loss: 0.5195512175559998, Accuracy: 0.830078125\n",
      "Batch: 40, Loss: 0.5329090356826782, Accuracy: 0.8291015625\n",
      "Batch: 41, Loss: 0.5376474261283875, Accuracy: 0.81640625\n",
      "Batch: 42, Loss: 0.526451826095581, Accuracy: 0.8134765625\n",
      "Batch: 43, Loss: 0.5163166522979736, Accuracy: 0.8251953125\n",
      "Batch: 44, Loss: 0.5521047711372375, Accuracy: 0.8193359375\n",
      "Batch: 45, Loss: 0.5796172618865967, Accuracy: 0.80859375\n",
      "Batch: 46, Loss: 0.5361695289611816, Accuracy: 0.8203125\n",
      "Batch: 47, Loss: 0.5348518490791321, Accuracy: 0.81640625\n",
      "Batch: 48, Loss: 0.5685298442840576, Accuracy: 0.8271484375\n",
      "Batch: 49, Loss: 0.607138991355896, Accuracy: 0.8115234375\n",
      "Batch: 50, Loss: 0.4620247483253479, Accuracy: 0.8583984375\n",
      "Batch: 51, Loss: 0.5174071788787842, Accuracy: 0.8359375\n",
      "Batch: 52, Loss: 0.5433285236358643, Accuracy: 0.818359375\n",
      "Batch: 53, Loss: 0.6443997025489807, Accuracy: 0.7919921875\n",
      "Batch: 54, Loss: 0.5671085715293884, Accuracy: 0.818359375\n",
      "Batch: 55, Loss: 0.5649089813232422, Accuracy: 0.8369140625\n",
      "Batch: 56, Loss: 0.5252703428268433, Accuracy: 0.8251953125\n",
      "Batch: 57, Loss: 0.5923334360122681, Accuracy: 0.8017578125\n",
      "Batch: 58, Loss: 0.6143158674240112, Accuracy: 0.806640625\n",
      "Batch: 59, Loss: 0.5577452778816223, Accuracy: 0.8173828125\n",
      "Batch: 60, Loss: 0.5774668455123901, Accuracy: 0.794921875\n",
      "Batch: 61, Loss: 0.5421662330627441, Accuracy: 0.8212890625\n",
      "Batch: 62, Loss: 0.5713715553283691, Accuracy: 0.80859375\n",
      "Batch: 63, Loss: 0.44685181975364685, Accuracy: 0.853515625\n",
      "Batch: 64, Loss: 0.5280246734619141, Accuracy: 0.8232421875\n",
      "Batch: 65, Loss: 0.5206729173660278, Accuracy: 0.8212890625\n",
      "Batch: 66, Loss: 0.45750144124031067, Accuracy: 0.8349609375\n",
      "Batch: 67, Loss: 0.47893574833869934, Accuracy: 0.8291015625\n",
      "Batch: 68, Loss: 0.5017254948616028, Accuracy: 0.837890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 69, Loss: 0.4853397607803345, Accuracy: 0.8408203125\n",
      "Batch: 70, Loss: 0.5049353241920471, Accuracy: 0.8310546875\n",
      "Batch: 71, Loss: 0.4773203134536743, Accuracy: 0.8359375\n",
      "Batch: 72, Loss: 0.5562940835952759, Accuracy: 0.8115234375\n",
      "Batch: 73, Loss: 0.5231871008872986, Accuracy: 0.830078125\n",
      "Batch: 74, Loss: 0.5110316872596741, Accuracy: 0.822265625\n",
      "Batch: 75, Loss: 0.4491179585456848, Accuracy: 0.8525390625\n",
      "Batch: 76, Loss: 0.46126705408096313, Accuracy: 0.83203125\n",
      "Batch: 77, Loss: 0.5560956597328186, Accuracy: 0.8154296875\n",
      "Batch: 78, Loss: 0.4991180896759033, Accuracy: 0.83203125\n",
      "Batch: 79, Loss: 0.477017879486084, Accuracy: 0.8447265625\n",
      "Batch: 80, Loss: 0.49564000964164734, Accuracy: 0.8388671875\n",
      "Batch: 81, Loss: 0.5324841737747192, Accuracy: 0.80859375\n",
      "Batch: 82, Loss: 0.5088357925415039, Accuracy: 0.8330078125\n",
      "Batch: 83, Loss: 0.47138917446136475, Accuracy: 0.8330078125\n",
      "Batch: 84, Loss: 0.4918711483478546, Accuracy: 0.8388671875\n",
      "Batch: 85, Loss: 0.520555853843689, Accuracy: 0.8212890625\n",
      "Batch: 86, Loss: 0.49547940492630005, Accuracy: 0.8349609375\n",
      "Batch: 87, Loss: 0.4786835014820099, Accuracy: 0.8330078125\n",
      "Batch: 88, Loss: 0.48771876096725464, Accuracy: 0.83203125\n",
      "Batch: 89, Loss: 0.4814261496067047, Accuracy: 0.8466796875\n",
      "Batch: 90, Loss: 0.5713846683502197, Accuracy: 0.8046875\n",
      "Batch: 91, Loss: 0.5819721817970276, Accuracy: 0.7998046875\n",
      "Batch: 92, Loss: 0.5292953252792358, Accuracy: 0.814453125\n",
      "Batch: 93, Loss: 0.5447037220001221, Accuracy: 0.8212890625\n",
      "Batch: 94, Loss: 0.5225656032562256, Accuracy: 0.8291015625\n",
      "Batch: 95, Loss: 0.5554568767547607, Accuracy: 0.8193359375\n",
      "Batch: 96, Loss: 0.4998866319656372, Accuracy: 0.8408203125\n",
      "Batch: 97, Loss: 0.517432689666748, Accuracy: 0.8232421875\n",
      "Batch: 98, Loss: 0.5462039709091187, Accuracy: 0.80859375\n",
      "Batch: 99, Loss: 0.5004148483276367, Accuracy: 0.826171875\n",
      "Batch: 100, Loss: 0.5619534254074097, Accuracy: 0.806640625\n",
      "Batch: 101, Loss: 0.5182994604110718, Accuracy: 0.8291015625\n",
      "Batch: 102, Loss: 0.49715301394462585, Accuracy: 0.830078125\n",
      "Batch: 103, Loss: 0.5230316519737244, Accuracy: 0.8369140625\n",
      "Batch: 104, Loss: 0.519548237323761, Accuracy: 0.8271484375\n",
      "Batch: 105, Loss: 0.4282904863357544, Accuracy: 0.8603515625\n",
      "Batch: 106, Loss: 0.533443808555603, Accuracy: 0.8212890625\n",
      "Batch: 107, Loss: 0.4915893077850342, Accuracy: 0.8369140625\n",
      "Batch: 108, Loss: 0.47759175300598145, Accuracy: 0.8349609375\n",
      "Batch: 109, Loss: 0.41442301869392395, Accuracy: 0.86328125\n",
      "Batch: 110, Loss: 0.4607779383659363, Accuracy: 0.8544921875\n",
      "Batch: 111, Loss: 0.5224405527114868, Accuracy: 0.828125\n",
      "Batch: 112, Loss: 0.4795536994934082, Accuracy: 0.8359375\n",
      "Epoch 36/90\n",
      "Batch: 1, Loss: 0.6680561304092407, Accuracy: 0.802734375\n",
      "Batch: 2, Loss: 0.548009991645813, Accuracy: 0.8251953125\n",
      "Batch: 3, Loss: 0.5229604244232178, Accuracy: 0.8310546875\n",
      "Batch: 4, Loss: 0.47416990995407104, Accuracy: 0.8505859375\n",
      "Batch: 5, Loss: 0.4693692624568939, Accuracy: 0.8427734375\n",
      "Batch: 6, Loss: 0.5218755602836609, Accuracy: 0.8291015625\n",
      "Batch: 7, Loss: 0.4808060824871063, Accuracy: 0.8447265625\n",
      "Batch: 8, Loss: 0.46371766924858093, Accuracy: 0.8505859375\n",
      "Batch: 9, Loss: 0.4691244661808014, Accuracy: 0.845703125\n",
      "Batch: 10, Loss: 0.5406817197799683, Accuracy: 0.814453125\n",
      "Batch: 11, Loss: 0.4822540283203125, Accuracy: 0.837890625\n",
      "Batch: 12, Loss: 0.45057618618011475, Accuracy: 0.857421875\n",
      "Batch: 13, Loss: 0.4373452663421631, Accuracy: 0.8603515625\n",
      "Batch: 14, Loss: 0.5117167234420776, Accuracy: 0.82421875\n",
      "Batch: 15, Loss: 0.5315843224525452, Accuracy: 0.818359375\n",
      "Batch: 16, Loss: 0.4939593970775604, Accuracy: 0.83203125\n",
      "Batch: 17, Loss: 0.5081808567047119, Accuracy: 0.83203125\n",
      "Batch: 18, Loss: 0.4748436510562897, Accuracy: 0.8427734375\n",
      "Batch: 19, Loss: 0.4363998770713806, Accuracy: 0.869140625\n",
      "Batch: 20, Loss: 0.49966758489608765, Accuracy: 0.8330078125\n",
      "Batch: 21, Loss: 0.5138590931892395, Accuracy: 0.828125\n",
      "Batch: 22, Loss: 0.4906902313232422, Accuracy: 0.8330078125\n",
      "Batch: 23, Loss: 0.5127339363098145, Accuracy: 0.8330078125\n",
      "Batch: 24, Loss: 0.5526953935623169, Accuracy: 0.80859375\n",
      "Batch: 25, Loss: 0.6077867746353149, Accuracy: 0.794921875\n",
      "Batch: 26, Loss: 0.601283848285675, Accuracy: 0.8076171875\n",
      "Batch: 27, Loss: 0.5961142778396606, Accuracy: 0.8037109375\n",
      "Batch: 28, Loss: 0.5220819115638733, Accuracy: 0.8173828125\n",
      "Batch: 29, Loss: 0.563987135887146, Accuracy: 0.80859375\n",
      "Batch: 30, Loss: 0.4628007113933563, Accuracy: 0.8515625\n",
      "Batch: 31, Loss: 0.5344579815864563, Accuracy: 0.814453125\n",
      "Batch: 32, Loss: 0.5104495882987976, Accuracy: 0.822265625\n",
      "Batch: 33, Loss: 0.49003130197525024, Accuracy: 0.8310546875\n",
      "Batch: 34, Loss: 0.47911661863327026, Accuracy: 0.84375\n",
      "Batch: 35, Loss: 0.5090697407722473, Accuracy: 0.8427734375\n",
      "Batch: 36, Loss: 0.5688424110412598, Accuracy: 0.818359375\n",
      "Batch: 37, Loss: 0.466425359249115, Accuracy: 0.830078125\n",
      "Batch: 38, Loss: 0.5303843021392822, Accuracy: 0.810546875\n",
      "Batch: 39, Loss: 0.5064036250114441, Accuracy: 0.8310546875\n",
      "Batch: 40, Loss: 0.5135408639907837, Accuracy: 0.83203125\n",
      "Batch: 41, Loss: 0.5240870118141174, Accuracy: 0.8232421875\n",
      "Batch: 42, Loss: 0.505354642868042, Accuracy: 0.8251953125\n",
      "Batch: 43, Loss: 0.5127959251403809, Accuracy: 0.8359375\n",
      "Batch: 44, Loss: 0.5377500057220459, Accuracy: 0.8193359375\n",
      "Batch: 45, Loss: 0.6031728982925415, Accuracy: 0.8154296875\n",
      "Batch: 46, Loss: 0.5487096905708313, Accuracy: 0.8173828125\n",
      "Batch: 47, Loss: 0.5621502995491028, Accuracy: 0.8173828125\n",
      "Batch: 48, Loss: 0.5444584488868713, Accuracy: 0.8232421875\n",
      "Batch: 49, Loss: 0.5851156711578369, Accuracy: 0.81640625\n",
      "Batch: 50, Loss: 0.4461873471736908, Accuracy: 0.865234375\n",
      "Batch: 51, Loss: 0.5231940746307373, Accuracy: 0.8271484375\n",
      "Batch: 52, Loss: 0.5261964797973633, Accuracy: 0.8271484375\n",
      "Batch: 53, Loss: 0.6389867067337036, Accuracy: 0.791015625\n",
      "Batch: 54, Loss: 0.5187643766403198, Accuracy: 0.8291015625\n",
      "Batch: 55, Loss: 0.5814184546470642, Accuracy: 0.8125\n",
      "Batch: 56, Loss: 0.5090199112892151, Accuracy: 0.8359375\n",
      "Batch: 57, Loss: 0.586450457572937, Accuracy: 0.806640625\n",
      "Batch: 58, Loss: 0.6011847853660583, Accuracy: 0.8037109375\n",
      "Batch: 59, Loss: 0.5613522529602051, Accuracy: 0.8203125\n",
      "Batch: 60, Loss: 0.5355713963508606, Accuracy: 0.8203125\n",
      "Batch: 61, Loss: 0.5237815380096436, Accuracy: 0.837890625\n",
      "Batch: 62, Loss: 0.536552906036377, Accuracy: 0.818359375\n",
      "Batch: 63, Loss: 0.4342464506626129, Accuracy: 0.86328125\n",
      "Batch: 64, Loss: 0.5382367372512817, Accuracy: 0.822265625\n",
      "Batch: 65, Loss: 0.4710650146007538, Accuracy: 0.83203125\n",
      "Batch: 66, Loss: 0.44475001096725464, Accuracy: 0.8544921875\n",
      "Batch: 67, Loss: 0.4685940146446228, Accuracy: 0.8369140625\n",
      "Batch: 68, Loss: 0.5052981376647949, Accuracy: 0.8359375\n",
      "Batch: 69, Loss: 0.47152864933013916, Accuracy: 0.8388671875\n",
      "Batch: 70, Loss: 0.4605944752693176, Accuracy: 0.8525390625\n",
      "Batch: 71, Loss: 0.4866127669811249, Accuracy: 0.841796875\n",
      "Batch: 72, Loss: 0.5369936227798462, Accuracy: 0.828125\n",
      "Batch: 73, Loss: 0.49870753288269043, Accuracy: 0.830078125\n",
      "Batch: 74, Loss: 0.4912039041519165, Accuracy: 0.84765625\n",
      "Batch: 75, Loss: 0.42338651418685913, Accuracy: 0.8525390625\n",
      "Batch: 76, Loss: 0.4418686032295227, Accuracy: 0.85546875\n",
      "Batch: 77, Loss: 0.5331034660339355, Accuracy: 0.8388671875\n",
      "Batch: 78, Loss: 0.480258584022522, Accuracy: 0.841796875\n",
      "Batch: 79, Loss: 0.4961410164833069, Accuracy: 0.84765625\n",
      "Batch: 80, Loss: 0.4703255295753479, Accuracy: 0.845703125\n",
      "Batch: 81, Loss: 0.510280430316925, Accuracy: 0.8154296875\n",
      "Batch: 82, Loss: 0.503219723701477, Accuracy: 0.8212890625\n",
      "Batch: 83, Loss: 0.42345601320266724, Accuracy: 0.8505859375\n",
      "Batch: 84, Loss: 0.47316497564315796, Accuracy: 0.8349609375\n",
      "Batch: 85, Loss: 0.517877995967865, Accuracy: 0.8291015625\n",
      "Batch: 86, Loss: 0.46417495608329773, Accuracy: 0.8466796875\n",
      "Batch: 87, Loss: 0.45670652389526367, Accuracy: 0.853515625\n",
      "Batch: 88, Loss: 0.460888147354126, Accuracy: 0.8369140625\n",
      "Batch: 89, Loss: 0.48344284296035767, Accuracy: 0.84765625\n",
      "Batch: 90, Loss: 0.5426130890846252, Accuracy: 0.81640625\n",
      "Batch: 91, Loss: 0.5731098651885986, Accuracy: 0.8095703125\n",
      "Batch: 92, Loss: 0.505081832408905, Accuracy: 0.8271484375\n",
      "Batch: 93, Loss: 0.5205898880958557, Accuracy: 0.8193359375\n",
      "Batch: 94, Loss: 0.523664116859436, Accuracy: 0.8251953125\n",
      "Batch: 95, Loss: 0.5313971638679504, Accuracy: 0.8154296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 96, Loss: 0.5077799558639526, Accuracy: 0.826171875\n",
      "Batch: 97, Loss: 0.46853360533714294, Accuracy: 0.8525390625\n",
      "Batch: 98, Loss: 0.5493972301483154, Accuracy: 0.802734375\n",
      "Batch: 99, Loss: 0.47527602314949036, Accuracy: 0.830078125\n",
      "Batch: 100, Loss: 0.5468134880065918, Accuracy: 0.8203125\n",
      "Batch: 101, Loss: 0.5100531578063965, Accuracy: 0.8232421875\n",
      "Batch: 102, Loss: 0.49002504348754883, Accuracy: 0.841796875\n",
      "Batch: 103, Loss: 0.5250603556632996, Accuracy: 0.8291015625\n",
      "Batch: 104, Loss: 0.5029566884040833, Accuracy: 0.8232421875\n",
      "Batch: 105, Loss: 0.42582374811172485, Accuracy: 0.86328125\n",
      "Batch: 106, Loss: 0.530346155166626, Accuracy: 0.8115234375\n",
      "Batch: 107, Loss: 0.47406473755836487, Accuracy: 0.8330078125\n",
      "Batch: 108, Loss: 0.4594499468803406, Accuracy: 0.849609375\n",
      "Batch: 109, Loss: 0.39394766092300415, Accuracy: 0.875\n",
      "Batch: 110, Loss: 0.4215892553329468, Accuracy: 0.875\n",
      "Batch: 111, Loss: 0.5011158585548401, Accuracy: 0.8486328125\n",
      "Batch: 112, Loss: 0.47799381613731384, Accuracy: 0.830078125\n",
      "Epoch 37/90\n",
      "Batch: 1, Loss: 0.6822654604911804, Accuracy: 0.796875\n",
      "Batch: 2, Loss: 0.54134202003479, Accuracy: 0.8203125\n",
      "Batch: 3, Loss: 0.4973510801792145, Accuracy: 0.837890625\n",
      "Batch: 4, Loss: 0.48306378722190857, Accuracy: 0.841796875\n",
      "Batch: 5, Loss: 0.4761500954627991, Accuracy: 0.837890625\n",
      "Batch: 6, Loss: 0.5022169351577759, Accuracy: 0.8359375\n",
      "Batch: 7, Loss: 0.470073401927948, Accuracy: 0.849609375\n",
      "Batch: 8, Loss: 0.42613494396209717, Accuracy: 0.8701171875\n",
      "Batch: 9, Loss: 0.4893966019153595, Accuracy: 0.8310546875\n",
      "Batch: 10, Loss: 0.5143298506736755, Accuracy: 0.814453125\n",
      "Batch: 11, Loss: 0.46754640340805054, Accuracy: 0.8427734375\n",
      "Batch: 12, Loss: 0.4727945327758789, Accuracy: 0.8486328125\n",
      "Batch: 13, Loss: 0.4295423626899719, Accuracy: 0.865234375\n",
      "Batch: 14, Loss: 0.5092071294784546, Accuracy: 0.830078125\n",
      "Batch: 15, Loss: 0.5156822800636292, Accuracy: 0.83984375\n",
      "Batch: 16, Loss: 0.5096211433410645, Accuracy: 0.83203125\n",
      "Batch: 17, Loss: 0.49510031938552856, Accuracy: 0.837890625\n",
      "Batch: 18, Loss: 0.4450666010379791, Accuracy: 0.8623046875\n",
      "Batch: 19, Loss: 0.4425524175167084, Accuracy: 0.8466796875\n",
      "Batch: 20, Loss: 0.47690874338150024, Accuracy: 0.84375\n",
      "Batch: 21, Loss: 0.4987541735172272, Accuracy: 0.828125\n",
      "Batch: 22, Loss: 0.4727339446544647, Accuracy: 0.8466796875\n",
      "Batch: 23, Loss: 0.5602814555168152, Accuracy: 0.810546875\n",
      "Batch: 24, Loss: 0.5427646040916443, Accuracy: 0.8291015625\n",
      "Batch: 25, Loss: 0.5627858638763428, Accuracy: 0.8056640625\n",
      "Batch: 26, Loss: 0.5954656600952148, Accuracy: 0.8173828125\n",
      "Batch: 27, Loss: 0.575099766254425, Accuracy: 0.8125\n",
      "Batch: 28, Loss: 0.5105078220367432, Accuracy: 0.833984375\n",
      "Batch: 29, Loss: 0.5687781572341919, Accuracy: 0.82421875\n",
      "Batch: 30, Loss: 0.46877521276474, Accuracy: 0.845703125\n",
      "Batch: 31, Loss: 0.5278103351593018, Accuracy: 0.828125\n",
      "Batch: 32, Loss: 0.501691460609436, Accuracy: 0.83203125\n",
      "Batch: 33, Loss: 0.4769323170185089, Accuracy: 0.83203125\n",
      "Batch: 34, Loss: 0.4521278738975525, Accuracy: 0.8544921875\n",
      "Batch: 35, Loss: 0.49788233637809753, Accuracy: 0.8271484375\n",
      "Batch: 36, Loss: 0.5508682727813721, Accuracy: 0.818359375\n",
      "Batch: 37, Loss: 0.46009403467178345, Accuracy: 0.8466796875\n",
      "Batch: 38, Loss: 0.5073807835578918, Accuracy: 0.8251953125\n",
      "Batch: 39, Loss: 0.49563533067703247, Accuracy: 0.8388671875\n",
      "Batch: 40, Loss: 0.5107899308204651, Accuracy: 0.830078125\n",
      "Batch: 41, Loss: 0.5213630199432373, Accuracy: 0.822265625\n",
      "Batch: 42, Loss: 0.4886630177497864, Accuracy: 0.8330078125\n",
      "Batch: 43, Loss: 0.4965130090713501, Accuracy: 0.837890625\n",
      "Batch: 44, Loss: 0.5318542718887329, Accuracy: 0.8310546875\n",
      "Batch: 45, Loss: 0.5759766101837158, Accuracy: 0.8115234375\n",
      "Batch: 46, Loss: 0.5163265466690063, Accuracy: 0.8271484375\n",
      "Batch: 47, Loss: 0.5252609252929688, Accuracy: 0.82421875\n",
      "Batch: 48, Loss: 0.5449800491333008, Accuracy: 0.818359375\n",
      "Batch: 49, Loss: 0.5860387086868286, Accuracy: 0.802734375\n",
      "Batch: 50, Loss: 0.4320274889469147, Accuracy: 0.87109375\n",
      "Batch: 51, Loss: 0.4942862391471863, Accuracy: 0.8359375\n",
      "Batch: 52, Loss: 0.5396051406860352, Accuracy: 0.826171875\n",
      "Batch: 53, Loss: 0.6110997200012207, Accuracy: 0.7890625\n",
      "Batch: 54, Loss: 0.5161734223365784, Accuracy: 0.8310546875\n",
      "Batch: 55, Loss: 0.5404033064842224, Accuracy: 0.8349609375\n",
      "Batch: 56, Loss: 0.4920637011528015, Accuracy: 0.833984375\n",
      "Batch: 57, Loss: 0.5786088705062866, Accuracy: 0.8154296875\n",
      "Batch: 58, Loss: 0.5886987447738647, Accuracy: 0.8046875\n",
      "Batch: 59, Loss: 0.5231879949569702, Accuracy: 0.822265625\n",
      "Batch: 60, Loss: 0.5104066133499146, Accuracy: 0.828125\n",
      "Batch: 61, Loss: 0.508834958076477, Accuracy: 0.8369140625\n",
      "Batch: 62, Loss: 0.5158155560493469, Accuracy: 0.826171875\n",
      "Batch: 63, Loss: 0.4235331416130066, Accuracy: 0.8603515625\n",
      "Batch: 64, Loss: 0.4964970350265503, Accuracy: 0.8408203125\n",
      "Batch: 65, Loss: 0.5049780607223511, Accuracy: 0.8193359375\n",
      "Batch: 66, Loss: 0.4617392420768738, Accuracy: 0.8486328125\n",
      "Batch: 67, Loss: 0.49387580156326294, Accuracy: 0.83203125\n",
      "Batch: 68, Loss: 0.4874113202095032, Accuracy: 0.849609375\n",
      "Batch: 69, Loss: 0.4369528889656067, Accuracy: 0.8583984375\n",
      "Batch: 70, Loss: 0.4864845275878906, Accuracy: 0.8408203125\n",
      "Batch: 71, Loss: 0.4512075185775757, Accuracy: 0.853515625\n",
      "Batch: 72, Loss: 0.4932793974876404, Accuracy: 0.8349609375\n",
      "Batch: 73, Loss: 0.48265743255615234, Accuracy: 0.8427734375\n",
      "Batch: 74, Loss: 0.47977638244628906, Accuracy: 0.8408203125\n",
      "Batch: 75, Loss: 0.43676772713661194, Accuracy: 0.8564453125\n",
      "Batch: 76, Loss: 0.4051845669746399, Accuracy: 0.8701171875\n",
      "Batch: 77, Loss: 0.5224061012268066, Accuracy: 0.833984375\n",
      "Batch: 78, Loss: 0.48098501563072205, Accuracy: 0.8447265625\n",
      "Batch: 79, Loss: 0.4840068221092224, Accuracy: 0.84375\n",
      "Batch: 80, Loss: 0.4729306399822235, Accuracy: 0.8408203125\n",
      "Batch: 81, Loss: 0.49511367082595825, Accuracy: 0.82421875\n",
      "Batch: 82, Loss: 0.5028395652770996, Accuracy: 0.8193359375\n",
      "Batch: 83, Loss: 0.4283559322357178, Accuracy: 0.86328125\n",
      "Batch: 84, Loss: 0.4754564166069031, Accuracy: 0.8310546875\n",
      "Batch: 85, Loss: 0.5073159337043762, Accuracy: 0.8271484375\n",
      "Batch: 86, Loss: 0.4768451750278473, Accuracy: 0.8359375\n",
      "Batch: 87, Loss: 0.4301903545856476, Accuracy: 0.8505859375\n",
      "Batch: 88, Loss: 0.452996164560318, Accuracy: 0.849609375\n",
      "Batch: 89, Loss: 0.4765883684158325, Accuracy: 0.8486328125\n",
      "Batch: 90, Loss: 0.542245626449585, Accuracy: 0.8291015625\n",
      "Batch: 91, Loss: 0.5958532094955444, Accuracy: 0.8056640625\n",
      "Batch: 92, Loss: 0.5156924724578857, Accuracy: 0.8076171875\n",
      "Batch: 93, Loss: 0.5226476788520813, Accuracy: 0.822265625\n",
      "Batch: 94, Loss: 0.5367406010627747, Accuracy: 0.8251953125\n",
      "Batch: 95, Loss: 0.515825092792511, Accuracy: 0.822265625\n",
      "Batch: 96, Loss: 0.48689812421798706, Accuracy: 0.8310546875\n",
      "Batch: 97, Loss: 0.47448188066482544, Accuracy: 0.8369140625\n",
      "Batch: 98, Loss: 0.5393790006637573, Accuracy: 0.814453125\n",
      "Batch: 99, Loss: 0.4704676866531372, Accuracy: 0.8447265625\n",
      "Batch: 100, Loss: 0.5250384211540222, Accuracy: 0.81640625\n",
      "Batch: 101, Loss: 0.49312931299209595, Accuracy: 0.828125\n",
      "Batch: 102, Loss: 0.4918243885040283, Accuracy: 0.8330078125\n",
      "Batch: 103, Loss: 0.49899330735206604, Accuracy: 0.8330078125\n",
      "Batch: 104, Loss: 0.5061998963356018, Accuracy: 0.8369140625\n",
      "Batch: 105, Loss: 0.4161723256111145, Accuracy: 0.85546875\n",
      "Batch: 106, Loss: 0.49436062574386597, Accuracy: 0.8271484375\n",
      "Batch: 107, Loss: 0.476176381111145, Accuracy: 0.8427734375\n",
      "Batch: 108, Loss: 0.44580140709877014, Accuracy: 0.8623046875\n",
      "Batch: 109, Loss: 0.3890233635902405, Accuracy: 0.873046875\n",
      "Batch: 110, Loss: 0.4304129481315613, Accuracy: 0.8623046875\n",
      "Batch: 111, Loss: 0.49808305501937866, Accuracy: 0.8388671875\n",
      "Batch: 112, Loss: 0.481078565120697, Accuracy: 0.8359375\n",
      "Epoch 38/90\n",
      "Batch: 1, Loss: 0.6705023050308228, Accuracy: 0.80859375\n",
      "Batch: 2, Loss: 0.5213385820388794, Accuracy: 0.8349609375\n",
      "Batch: 3, Loss: 0.4936903417110443, Accuracy: 0.8447265625\n",
      "Batch: 4, Loss: 0.5029374361038208, Accuracy: 0.8310546875\n",
      "Batch: 5, Loss: 0.4381577968597412, Accuracy: 0.86328125\n",
      "Batch: 6, Loss: 0.4776056706905365, Accuracy: 0.85546875\n",
      "Batch: 7, Loss: 0.4441249668598175, Accuracy: 0.853515625\n",
      "Batch: 8, Loss: 0.43506866693496704, Accuracy: 0.8642578125\n",
      "Batch: 9, Loss: 0.4599362909793854, Accuracy: 0.8544921875\n",
      "Batch: 10, Loss: 0.5167302489280701, Accuracy: 0.8212890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 11, Loss: 0.49969246983528137, Accuracy: 0.8330078125\n",
      "Batch: 12, Loss: 0.4288349747657776, Accuracy: 0.86328125\n",
      "Batch: 13, Loss: 0.4262188971042633, Accuracy: 0.8544921875\n",
      "Batch: 14, Loss: 0.48032355308532715, Accuracy: 0.8330078125\n",
      "Batch: 15, Loss: 0.46971967816352844, Accuracy: 0.853515625\n",
      "Batch: 16, Loss: 0.5095776915550232, Accuracy: 0.8310546875\n",
      "Batch: 17, Loss: 0.49915042519569397, Accuracy: 0.837890625\n",
      "Batch: 18, Loss: 0.4225572645664215, Accuracy: 0.8515625\n",
      "Batch: 19, Loss: 0.42664438486099243, Accuracy: 0.845703125\n",
      "Batch: 20, Loss: 0.48145490884780884, Accuracy: 0.8349609375\n",
      "Batch: 21, Loss: 0.48541516065597534, Accuracy: 0.837890625\n",
      "Batch: 22, Loss: 0.45962607860565186, Accuracy: 0.8466796875\n",
      "Batch: 23, Loss: 0.5481275320053101, Accuracy: 0.8408203125\n",
      "Batch: 24, Loss: 0.5428517460823059, Accuracy: 0.8251953125\n",
      "Batch: 25, Loss: 0.5757797956466675, Accuracy: 0.79296875\n",
      "Batch: 26, Loss: 0.5774029493331909, Accuracy: 0.8251953125\n",
      "Batch: 27, Loss: 0.5600103139877319, Accuracy: 0.8271484375\n",
      "Batch: 28, Loss: 0.4727211892604828, Accuracy: 0.84375\n",
      "Batch: 29, Loss: 0.5176272392272949, Accuracy: 0.8310546875\n",
      "Batch: 30, Loss: 0.4638904631137848, Accuracy: 0.84375\n",
      "Batch: 31, Loss: 0.5195255279541016, Accuracy: 0.8349609375\n",
      "Batch: 32, Loss: 0.4917897582054138, Accuracy: 0.837890625\n",
      "Batch: 33, Loss: 0.47318193316459656, Accuracy: 0.837890625\n",
      "Batch: 34, Loss: 0.4515077769756317, Accuracy: 0.84375\n",
      "Batch: 35, Loss: 0.4976327121257782, Accuracy: 0.82421875\n",
      "Batch: 36, Loss: 0.5293552279472351, Accuracy: 0.8271484375\n",
      "Batch: 37, Loss: 0.4481116235256195, Accuracy: 0.8466796875\n",
      "Batch: 38, Loss: 0.5060776472091675, Accuracy: 0.8291015625\n",
      "Batch: 39, Loss: 0.4770837426185608, Accuracy: 0.8388671875\n",
      "Batch: 40, Loss: 0.4759688377380371, Accuracy: 0.8349609375\n",
      "Batch: 41, Loss: 0.494226336479187, Accuracy: 0.8291015625\n",
      "Batch: 42, Loss: 0.470246285200119, Accuracy: 0.8369140625\n",
      "Batch: 43, Loss: 0.491895854473114, Accuracy: 0.8359375\n",
      "Batch: 44, Loss: 0.500860333442688, Accuracy: 0.8388671875\n",
      "Batch: 45, Loss: 0.5451323986053467, Accuracy: 0.8134765625\n",
      "Batch: 46, Loss: 0.5041285157203674, Accuracy: 0.822265625\n",
      "Batch: 47, Loss: 0.4964112341403961, Accuracy: 0.83984375\n",
      "Batch: 48, Loss: 0.5499690175056458, Accuracy: 0.826171875\n",
      "Batch: 49, Loss: 0.5516724586486816, Accuracy: 0.8212890625\n",
      "Batch: 50, Loss: 0.43370750546455383, Accuracy: 0.8623046875\n",
      "Batch: 51, Loss: 0.4935133755207062, Accuracy: 0.84375\n",
      "Batch: 52, Loss: 0.5238829851150513, Accuracy: 0.8359375\n",
      "Batch: 53, Loss: 0.5642889738082886, Accuracy: 0.8125\n",
      "Batch: 54, Loss: 0.5124890208244324, Accuracy: 0.8369140625\n",
      "Batch: 55, Loss: 0.5467215776443481, Accuracy: 0.83203125\n",
      "Batch: 56, Loss: 0.44833678007125854, Accuracy: 0.8486328125\n",
      "Batch: 57, Loss: 0.5381395220756531, Accuracy: 0.81640625\n",
      "Batch: 58, Loss: 0.5544253587722778, Accuracy: 0.8203125\n",
      "Batch: 59, Loss: 0.5158766508102417, Accuracy: 0.8359375\n",
      "Batch: 60, Loss: 0.5336397290229797, Accuracy: 0.8115234375\n",
      "Batch: 61, Loss: 0.5014472007751465, Accuracy: 0.849609375\n",
      "Batch: 62, Loss: 0.532849907875061, Accuracy: 0.8271484375\n",
      "Batch: 63, Loss: 0.40820473432540894, Accuracy: 0.8642578125\n",
      "Batch: 64, Loss: 0.4717736840248108, Accuracy: 0.837890625\n",
      "Batch: 65, Loss: 0.49232351779937744, Accuracy: 0.8291015625\n",
      "Batch: 66, Loss: 0.4315800666809082, Accuracy: 0.8564453125\n",
      "Batch: 67, Loss: 0.4515810012817383, Accuracy: 0.8359375\n",
      "Batch: 68, Loss: 0.46724140644073486, Accuracy: 0.845703125\n",
      "Batch: 69, Loss: 0.44133925437927246, Accuracy: 0.8583984375\n",
      "Batch: 70, Loss: 0.4668031334877014, Accuracy: 0.8427734375\n",
      "Batch: 71, Loss: 0.46289944648742676, Accuracy: 0.8466796875\n",
      "Batch: 72, Loss: 0.4890221059322357, Accuracy: 0.8466796875\n",
      "Batch: 73, Loss: 0.46777889132499695, Accuracy: 0.8369140625\n",
      "Batch: 74, Loss: 0.46444809436798096, Accuracy: 0.8447265625\n",
      "Batch: 75, Loss: 0.4184659719467163, Accuracy: 0.8603515625\n",
      "Batch: 76, Loss: 0.4256647229194641, Accuracy: 0.85546875\n",
      "Batch: 77, Loss: 0.4924430549144745, Accuracy: 0.8388671875\n",
      "Batch: 78, Loss: 0.47493940591812134, Accuracy: 0.837890625\n",
      "Batch: 79, Loss: 0.47560998797416687, Accuracy: 0.8583984375\n",
      "Batch: 80, Loss: 0.4830462336540222, Accuracy: 0.8388671875\n",
      "Batch: 81, Loss: 0.512313961982727, Accuracy: 0.833984375\n",
      "Batch: 82, Loss: 0.4673500955104828, Accuracy: 0.841796875\n",
      "Batch: 83, Loss: 0.42894694209098816, Accuracy: 0.8603515625\n",
      "Batch: 84, Loss: 0.47943416237831116, Accuracy: 0.8427734375\n",
      "Batch: 85, Loss: 0.49255090951919556, Accuracy: 0.841796875\n",
      "Batch: 86, Loss: 0.47569966316223145, Accuracy: 0.8330078125\n",
      "Batch: 87, Loss: 0.4389593303203583, Accuracy: 0.849609375\n",
      "Batch: 88, Loss: 0.47470226883888245, Accuracy: 0.8330078125\n",
      "Batch: 89, Loss: 0.4590257704257965, Accuracy: 0.8515625\n",
      "Batch: 90, Loss: 0.5527280569076538, Accuracy: 0.818359375\n",
      "Batch: 91, Loss: 0.5698967576026917, Accuracy: 0.8154296875\n",
      "Batch: 92, Loss: 0.48642879724502563, Accuracy: 0.8359375\n",
      "Batch: 93, Loss: 0.5132173299789429, Accuracy: 0.818359375\n",
      "Batch: 94, Loss: 0.4981503486633301, Accuracy: 0.830078125\n",
      "Batch: 95, Loss: 0.50674968957901, Accuracy: 0.83203125\n",
      "Batch: 96, Loss: 0.4876210391521454, Accuracy: 0.8486328125\n",
      "Batch: 97, Loss: 0.4412877559661865, Accuracy: 0.859375\n",
      "Batch: 98, Loss: 0.5253321528434753, Accuracy: 0.822265625\n",
      "Batch: 99, Loss: 0.4739905893802643, Accuracy: 0.826171875\n",
      "Batch: 100, Loss: 0.5144451856613159, Accuracy: 0.82421875\n",
      "Batch: 101, Loss: 0.49579399824142456, Accuracy: 0.828125\n",
      "Batch: 102, Loss: 0.4678874611854553, Accuracy: 0.8564453125\n",
      "Batch: 103, Loss: 0.47109776735305786, Accuracy: 0.8427734375\n",
      "Batch: 104, Loss: 0.4711754322052002, Accuracy: 0.8447265625\n",
      "Batch: 105, Loss: 0.4103753864765167, Accuracy: 0.8623046875\n",
      "Batch: 106, Loss: 0.5007662773132324, Accuracy: 0.828125\n",
      "Batch: 107, Loss: 0.4554004371166229, Accuracy: 0.8515625\n",
      "Batch: 108, Loss: 0.44172218441963196, Accuracy: 0.8466796875\n",
      "Batch: 109, Loss: 0.36850082874298096, Accuracy: 0.8759765625\n",
      "Batch: 110, Loss: 0.4079587459564209, Accuracy: 0.8720703125\n",
      "Batch: 111, Loss: 0.48140498995780945, Accuracy: 0.837890625\n",
      "Batch: 112, Loss: 0.48501163721084595, Accuracy: 0.8349609375\n",
      "Epoch 39/90\n",
      "Batch: 1, Loss: 0.6495004892349243, Accuracy: 0.8193359375\n",
      "Batch: 2, Loss: 0.49654892086982727, Accuracy: 0.83984375\n",
      "Batch: 3, Loss: 0.5018998384475708, Accuracy: 0.84375\n",
      "Batch: 4, Loss: 0.4603332281112671, Accuracy: 0.8447265625\n",
      "Batch: 5, Loss: 0.4352448582649231, Accuracy: 0.85546875\n",
      "Batch: 6, Loss: 0.49465739727020264, Accuracy: 0.83984375\n",
      "Batch: 7, Loss: 0.44983842968940735, Accuracy: 0.861328125\n",
      "Batch: 8, Loss: 0.4008796215057373, Accuracy: 0.86328125\n",
      "Batch: 9, Loss: 0.48516780138015747, Accuracy: 0.84765625\n",
      "Batch: 10, Loss: 0.5103878974914551, Accuracy: 0.8173828125\n",
      "Batch: 11, Loss: 0.4861452579498291, Accuracy: 0.83984375\n",
      "Batch: 12, Loss: 0.43045392632484436, Accuracy: 0.8583984375\n",
      "Batch: 13, Loss: 0.4100966453552246, Accuracy: 0.869140625\n",
      "Batch: 14, Loss: 0.4993998408317566, Accuracy: 0.833984375\n",
      "Batch: 15, Loss: 0.4796103835105896, Accuracy: 0.837890625\n",
      "Batch: 16, Loss: 0.461785227060318, Accuracy: 0.859375\n",
      "Batch: 17, Loss: 0.49553537368774414, Accuracy: 0.8486328125\n",
      "Batch: 18, Loss: 0.4097071886062622, Accuracy: 0.865234375\n",
      "Batch: 19, Loss: 0.40688470005989075, Accuracy: 0.86328125\n",
      "Batch: 20, Loss: 0.45577672123908997, Accuracy: 0.8505859375\n",
      "Batch: 21, Loss: 0.4839189946651459, Accuracy: 0.84765625\n",
      "Batch: 22, Loss: 0.45041561126708984, Accuracy: 0.841796875\n",
      "Batch: 23, Loss: 0.5186767578125, Accuracy: 0.833984375\n",
      "Batch: 24, Loss: 0.47458285093307495, Accuracy: 0.8408203125\n",
      "Batch: 25, Loss: 0.5244170427322388, Accuracy: 0.8173828125\n",
      "Batch: 26, Loss: 0.5393742322921753, Accuracy: 0.830078125\n",
      "Batch: 27, Loss: 0.5423519015312195, Accuracy: 0.818359375\n",
      "Batch: 28, Loss: 0.4961217939853668, Accuracy: 0.8408203125\n",
      "Batch: 29, Loss: 0.5074188709259033, Accuracy: 0.830078125\n",
      "Batch: 30, Loss: 0.4264466166496277, Accuracy: 0.857421875\n",
      "Batch: 31, Loss: 0.4732379913330078, Accuracy: 0.8359375\n",
      "Batch: 32, Loss: 0.48659035563468933, Accuracy: 0.8330078125\n",
      "Batch: 33, Loss: 0.44662755727767944, Accuracy: 0.8447265625\n",
      "Batch: 34, Loss: 0.42643603682518005, Accuracy: 0.8662109375\n",
      "Batch: 35, Loss: 0.45657920837402344, Accuracy: 0.8408203125\n",
      "Batch: 36, Loss: 0.5191255807876587, Accuracy: 0.8427734375\n",
      "Batch: 37, Loss: 0.44149547815322876, Accuracy: 0.83984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 38, Loss: 0.46909618377685547, Accuracy: 0.8330078125\n",
      "Batch: 39, Loss: 0.48324739933013916, Accuracy: 0.8408203125\n",
      "Batch: 40, Loss: 0.4500853419303894, Accuracy: 0.8603515625\n",
      "Batch: 41, Loss: 0.48327866196632385, Accuracy: 0.826171875\n",
      "Batch: 42, Loss: 0.4537799656391144, Accuracy: 0.8369140625\n",
      "Batch: 43, Loss: 0.45635682344436646, Accuracy: 0.8447265625\n",
      "Batch: 44, Loss: 0.48616498708724976, Accuracy: 0.8349609375\n",
      "Batch: 45, Loss: 0.5380275249481201, Accuracy: 0.83203125\n",
      "Batch: 46, Loss: 0.46488165855407715, Accuracy: 0.8544921875\n",
      "Batch: 47, Loss: 0.4723113775253296, Accuracy: 0.8330078125\n",
      "Batch: 48, Loss: 0.5279858112335205, Accuracy: 0.8232421875\n",
      "Batch: 49, Loss: 0.5548481345176697, Accuracy: 0.8291015625\n",
      "Batch: 50, Loss: 0.41711345314979553, Accuracy: 0.8642578125\n",
      "Batch: 51, Loss: 0.47684139013290405, Accuracy: 0.84765625\n",
      "Batch: 52, Loss: 0.4991875886917114, Accuracy: 0.8388671875\n",
      "Batch: 53, Loss: 0.5668702721595764, Accuracy: 0.8212890625\n",
      "Batch: 54, Loss: 0.5159379243850708, Accuracy: 0.8408203125\n",
      "Batch: 55, Loss: 0.5422993898391724, Accuracy: 0.8251953125\n",
      "Batch: 56, Loss: 0.458565890789032, Accuracy: 0.845703125\n",
      "Batch: 57, Loss: 0.5229687094688416, Accuracy: 0.8173828125\n",
      "Batch: 58, Loss: 0.5292817950248718, Accuracy: 0.8349609375\n",
      "Batch: 59, Loss: 0.5012267827987671, Accuracy: 0.8271484375\n",
      "Batch: 60, Loss: 0.49614661931991577, Accuracy: 0.837890625\n",
      "Batch: 61, Loss: 0.4837764501571655, Accuracy: 0.8447265625\n",
      "Batch: 62, Loss: 0.5025295615196228, Accuracy: 0.8330078125\n",
      "Batch: 63, Loss: 0.40469199419021606, Accuracy: 0.869140625\n",
      "Batch: 64, Loss: 0.4779479205608368, Accuracy: 0.837890625\n",
      "Batch: 65, Loss: 0.4863484501838684, Accuracy: 0.82421875\n",
      "Batch: 66, Loss: 0.44206929206848145, Accuracy: 0.857421875\n",
      "Batch: 67, Loss: 0.4398761987686157, Accuracy: 0.8505859375\n",
      "Batch: 68, Loss: 0.4532349109649658, Accuracy: 0.84765625\n",
      "Batch: 69, Loss: 0.39822468161582947, Accuracy: 0.8759765625\n",
      "Batch: 70, Loss: 0.4422704577445984, Accuracy: 0.8505859375\n",
      "Batch: 71, Loss: 0.4383516013622284, Accuracy: 0.8544921875\n",
      "Batch: 72, Loss: 0.48810067772865295, Accuracy: 0.8359375\n",
      "Batch: 73, Loss: 0.45632582902908325, Accuracy: 0.8486328125\n",
      "Batch: 74, Loss: 0.4538038671016693, Accuracy: 0.841796875\n",
      "Batch: 75, Loss: 0.4207022786140442, Accuracy: 0.8515625\n",
      "Batch: 76, Loss: 0.40602707862854004, Accuracy: 0.8642578125\n",
      "Batch: 77, Loss: 0.47660157084465027, Accuracy: 0.84765625\n",
      "Batch: 78, Loss: 0.44432762265205383, Accuracy: 0.853515625\n",
      "Batch: 79, Loss: 0.45280104875564575, Accuracy: 0.8623046875\n",
      "Batch: 80, Loss: 0.44765931367874146, Accuracy: 0.84765625\n",
      "Batch: 81, Loss: 0.4934351444244385, Accuracy: 0.8369140625\n",
      "Batch: 82, Loss: 0.4858171343803406, Accuracy: 0.83203125\n",
      "Batch: 83, Loss: 0.40607935190200806, Accuracy: 0.8583984375\n",
      "Batch: 84, Loss: 0.454677939414978, Accuracy: 0.8466796875\n",
      "Batch: 85, Loss: 0.5072973966598511, Accuracy: 0.833984375\n",
      "Batch: 86, Loss: 0.43640756607055664, Accuracy: 0.8525390625\n",
      "Batch: 87, Loss: 0.43945080041885376, Accuracy: 0.8525390625\n",
      "Batch: 88, Loss: 0.45887866616249084, Accuracy: 0.8525390625\n",
      "Batch: 89, Loss: 0.45448294281959534, Accuracy: 0.8564453125\n",
      "Batch: 90, Loss: 0.5287764072418213, Accuracy: 0.826171875\n",
      "Batch: 91, Loss: 0.5424178838729858, Accuracy: 0.818359375\n",
      "Batch: 92, Loss: 0.46616238355636597, Accuracy: 0.8349609375\n",
      "Batch: 93, Loss: 0.5162472724914551, Accuracy: 0.8291015625\n",
      "Batch: 94, Loss: 0.497793972492218, Accuracy: 0.8212890625\n",
      "Batch: 95, Loss: 0.5171346664428711, Accuracy: 0.83203125\n",
      "Batch: 96, Loss: 0.4651709198951721, Accuracy: 0.84765625\n",
      "Batch: 97, Loss: 0.462861567735672, Accuracy: 0.841796875\n",
      "Batch: 98, Loss: 0.5226436853408813, Accuracy: 0.828125\n",
      "Batch: 99, Loss: 0.4644277095794678, Accuracy: 0.841796875\n",
      "Batch: 100, Loss: 0.5158090591430664, Accuracy: 0.8232421875\n",
      "Batch: 101, Loss: 0.4742479920387268, Accuracy: 0.83203125\n",
      "Batch: 102, Loss: 0.4425017833709717, Accuracy: 0.8466796875\n",
      "Batch: 103, Loss: 0.47597622871398926, Accuracy: 0.84765625\n",
      "Batch: 104, Loss: 0.46923089027404785, Accuracy: 0.8408203125\n",
      "Batch: 105, Loss: 0.41170018911361694, Accuracy: 0.85546875\n",
      "Batch: 106, Loss: 0.4808526039123535, Accuracy: 0.8349609375\n",
      "Batch: 107, Loss: 0.4369645118713379, Accuracy: 0.8544921875\n",
      "Batch: 108, Loss: 0.4406529664993286, Accuracy: 0.8603515625\n",
      "Batch: 109, Loss: 0.3760935068130493, Accuracy: 0.8740234375\n",
      "Batch: 110, Loss: 0.3927718997001648, Accuracy: 0.8779296875\n",
      "Batch: 111, Loss: 0.4722382128238678, Accuracy: 0.8525390625\n",
      "Batch: 112, Loss: 0.46208280324935913, Accuracy: 0.8525390625\n",
      "Epoch 40/90\n",
      "Batch: 1, Loss: 0.6371086835861206, Accuracy: 0.818359375\n",
      "Batch: 2, Loss: 0.49762973189353943, Accuracy: 0.83984375\n",
      "Batch: 3, Loss: 0.4928285479545593, Accuracy: 0.8369140625\n",
      "Batch: 4, Loss: 0.43096283078193665, Accuracy: 0.857421875\n",
      "Batch: 5, Loss: 0.409309446811676, Accuracy: 0.8798828125\n",
      "Batch: 6, Loss: 0.4821891188621521, Accuracy: 0.84765625\n",
      "Batch: 7, Loss: 0.4439203143119812, Accuracy: 0.8642578125\n",
      "Batch: 8, Loss: 0.4092665910720825, Accuracy: 0.873046875\n",
      "Batch: 9, Loss: 0.44987571239471436, Accuracy: 0.849609375\n",
      "Batch: 10, Loss: 0.509016752243042, Accuracy: 0.8291015625\n",
      "Batch: 11, Loss: 0.4738968014717102, Accuracy: 0.83984375\n",
      "Batch: 12, Loss: 0.4343204200267792, Accuracy: 0.857421875\n",
      "Batch: 13, Loss: 0.4056012034416199, Accuracy: 0.875\n",
      "Batch: 14, Loss: 0.4368065595626831, Accuracy: 0.85546875\n",
      "Batch: 15, Loss: 0.4557461440563202, Accuracy: 0.8544921875\n",
      "Batch: 16, Loss: 0.47441279888153076, Accuracy: 0.8515625\n",
      "Batch: 17, Loss: 0.4831923544406891, Accuracy: 0.84375\n",
      "Batch: 18, Loss: 0.4042852520942688, Accuracy: 0.8642578125\n",
      "Batch: 19, Loss: 0.4150997996330261, Accuracy: 0.86328125\n",
      "Batch: 20, Loss: 0.4434818625450134, Accuracy: 0.8466796875\n",
      "Batch: 21, Loss: 0.48612135648727417, Accuracy: 0.8447265625\n",
      "Batch: 22, Loss: 0.4273695647716522, Accuracy: 0.8603515625\n",
      "Batch: 23, Loss: 0.489977091550827, Accuracy: 0.8408203125\n",
      "Batch: 24, Loss: 0.511920690536499, Accuracy: 0.814453125\n",
      "Batch: 25, Loss: 0.5368301272392273, Accuracy: 0.806640625\n",
      "Batch: 26, Loss: 0.547889232635498, Accuracy: 0.8173828125\n",
      "Batch: 27, Loss: 0.5399524569511414, Accuracy: 0.822265625\n",
      "Batch: 28, Loss: 0.5166064500808716, Accuracy: 0.83203125\n",
      "Batch: 29, Loss: 0.508660078048706, Accuracy: 0.833984375\n",
      "Batch: 30, Loss: 0.4336267113685608, Accuracy: 0.853515625\n",
      "Batch: 31, Loss: 0.4462316632270813, Accuracy: 0.84765625\n",
      "Batch: 32, Loss: 0.4517149329185486, Accuracy: 0.8515625\n",
      "Batch: 33, Loss: 0.4668312072753906, Accuracy: 0.837890625\n",
      "Batch: 34, Loss: 0.42879587411880493, Accuracy: 0.8583984375\n",
      "Batch: 35, Loss: 0.4544362425804138, Accuracy: 0.8515625\n",
      "Batch: 36, Loss: 0.5261709094047546, Accuracy: 0.837890625\n",
      "Batch: 37, Loss: 0.43340885639190674, Accuracy: 0.8603515625\n",
      "Batch: 38, Loss: 0.48325592279434204, Accuracy: 0.8505859375\n",
      "Batch: 39, Loss: 0.47808292508125305, Accuracy: 0.849609375\n",
      "Batch: 40, Loss: 0.4839031398296356, Accuracy: 0.8369140625\n",
      "Batch: 41, Loss: 0.4889683127403259, Accuracy: 0.8359375\n",
      "Batch: 42, Loss: 0.4587312936782837, Accuracy: 0.8525390625\n",
      "Batch: 43, Loss: 0.4600704312324524, Accuracy: 0.84375\n",
      "Batch: 44, Loss: 0.4889979362487793, Accuracy: 0.8359375\n",
      "Batch: 45, Loss: 0.5282778739929199, Accuracy: 0.8369140625\n",
      "Batch: 46, Loss: 0.4919637441635132, Accuracy: 0.82421875\n",
      "Batch: 47, Loss: 0.47568652033805847, Accuracy: 0.8427734375\n",
      "Batch: 48, Loss: 0.4677238464355469, Accuracy: 0.8486328125\n",
      "Batch: 49, Loss: 0.49064064025878906, Accuracy: 0.8408203125\n",
      "Batch: 50, Loss: 0.44424548745155334, Accuracy: 0.8623046875\n",
      "Batch: 51, Loss: 0.48165377974510193, Accuracy: 0.8349609375\n",
      "Batch: 52, Loss: 0.5081448554992676, Accuracy: 0.8427734375\n",
      "Batch: 53, Loss: 0.5450864434242249, Accuracy: 0.833984375\n",
      "Batch: 54, Loss: 0.4900067448616028, Accuracy: 0.8447265625\n",
      "Batch: 55, Loss: 0.5094622373580933, Accuracy: 0.826171875\n",
      "Batch: 56, Loss: 0.4610840380191803, Accuracy: 0.8447265625\n",
      "Batch: 57, Loss: 0.5152637362480164, Accuracy: 0.8212890625\n",
      "Batch: 58, Loss: 0.541922926902771, Accuracy: 0.8271484375\n",
      "Batch: 59, Loss: 0.4896315336227417, Accuracy: 0.8291015625\n",
      "Batch: 60, Loss: 0.4919847249984741, Accuracy: 0.8291015625\n",
      "Batch: 61, Loss: 0.48674124479293823, Accuracy: 0.8359375\n",
      "Batch: 62, Loss: 0.5055830478668213, Accuracy: 0.828125\n",
      "Batch: 63, Loss: 0.4020451009273529, Accuracy: 0.880859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 64, Loss: 0.45682066679000854, Accuracy: 0.8505859375\n",
      "Batch: 65, Loss: 0.4501224458217621, Accuracy: 0.83984375\n",
      "Batch: 66, Loss: 0.4127868711948395, Accuracy: 0.87109375\n",
      "Batch: 67, Loss: 0.44831711053848267, Accuracy: 0.8486328125\n",
      "Batch: 68, Loss: 0.43878835439682007, Accuracy: 0.859375\n",
      "Batch: 69, Loss: 0.4223504662513733, Accuracy: 0.8447265625\n",
      "Batch: 70, Loss: 0.42352163791656494, Accuracy: 0.8486328125\n",
      "Batch: 71, Loss: 0.4268585443496704, Accuracy: 0.86328125\n",
      "Batch: 72, Loss: 0.4885827898979187, Accuracy: 0.833984375\n",
      "Batch: 73, Loss: 0.45453351736068726, Accuracy: 0.8388671875\n",
      "Batch: 74, Loss: 0.44084787368774414, Accuracy: 0.8447265625\n",
      "Batch: 75, Loss: 0.4132903218269348, Accuracy: 0.8623046875\n",
      "Batch: 76, Loss: 0.4114287793636322, Accuracy: 0.8681640625\n",
      "Batch: 77, Loss: 0.4720346927642822, Accuracy: 0.8505859375\n",
      "Batch: 78, Loss: 0.4611244797706604, Accuracy: 0.845703125\n",
      "Batch: 79, Loss: 0.42716115713119507, Accuracy: 0.8525390625\n",
      "Batch: 80, Loss: 0.47220945358276367, Accuracy: 0.845703125\n",
      "Batch: 81, Loss: 0.48650264739990234, Accuracy: 0.833984375\n",
      "Batch: 82, Loss: 0.45380228757858276, Accuracy: 0.8408203125\n",
      "Batch: 83, Loss: 0.4143705368041992, Accuracy: 0.861328125\n",
      "Batch: 84, Loss: 0.42377805709838867, Accuracy: 0.8505859375\n",
      "Batch: 85, Loss: 0.47639498114585876, Accuracy: 0.84765625\n",
      "Batch: 86, Loss: 0.44372156262397766, Accuracy: 0.84765625\n",
      "Batch: 87, Loss: 0.42242106795310974, Accuracy: 0.8505859375\n",
      "Batch: 88, Loss: 0.46233147382736206, Accuracy: 0.8525390625\n",
      "Batch: 89, Loss: 0.4330030083656311, Accuracy: 0.84765625\n",
      "Batch: 90, Loss: 0.5174723863601685, Accuracy: 0.8173828125\n",
      "Batch: 91, Loss: 0.5048159956932068, Accuracy: 0.8349609375\n",
      "Batch: 92, Loss: 0.46792545914649963, Accuracy: 0.8349609375\n",
      "Batch: 93, Loss: 0.4726232886314392, Accuracy: 0.8466796875\n",
      "Batch: 94, Loss: 0.526217520236969, Accuracy: 0.8134765625\n",
      "Batch: 95, Loss: 0.48549404740333557, Accuracy: 0.826171875\n",
      "Batch: 96, Loss: 0.4616309106349945, Accuracy: 0.8515625\n",
      "Batch: 97, Loss: 0.44717320799827576, Accuracy: 0.8544921875\n",
      "Batch: 98, Loss: 0.5137103796005249, Accuracy: 0.8330078125\n",
      "Batch: 99, Loss: 0.42320960760116577, Accuracy: 0.8662109375\n",
      "Batch: 100, Loss: 0.4655109643936157, Accuracy: 0.8369140625\n",
      "Batch: 101, Loss: 0.46600615978240967, Accuracy: 0.8466796875\n",
      "Batch: 102, Loss: 0.4480385482311249, Accuracy: 0.861328125\n",
      "Batch: 103, Loss: 0.4433870315551758, Accuracy: 0.8525390625\n",
      "Batch: 104, Loss: 0.44607871770858765, Accuracy: 0.857421875\n",
      "Batch: 105, Loss: 0.3865130543708801, Accuracy: 0.869140625\n",
      "Batch: 106, Loss: 0.4519376754760742, Accuracy: 0.861328125\n",
      "Batch: 107, Loss: 0.4155881106853485, Accuracy: 0.859375\n",
      "Batch: 108, Loss: 0.4139835834503174, Accuracy: 0.8740234375\n",
      "Batch: 109, Loss: 0.36347872018814087, Accuracy: 0.8828125\n",
      "Batch: 110, Loss: 0.3773126006126404, Accuracy: 0.8828125\n",
      "Batch: 111, Loss: 0.44053590297698975, Accuracy: 0.8583984375\n",
      "Batch: 112, Loss: 0.43612176179885864, Accuracy: 0.8505859375\n",
      "Saved Weights at epoch 40 to file Weights_40.h5\n",
      "Epoch 41/90\n",
      "Batch: 1, Loss: 0.5969266891479492, Accuracy: 0.8212890625\n",
      "Batch: 2, Loss: 0.4971606135368347, Accuracy: 0.85546875\n",
      "Batch: 3, Loss: 0.45142626762390137, Accuracy: 0.849609375\n",
      "Batch: 4, Loss: 0.4412133991718292, Accuracy: 0.857421875\n",
      "Batch: 5, Loss: 0.3966968059539795, Accuracy: 0.8798828125\n",
      "Batch: 6, Loss: 0.4475831389427185, Accuracy: 0.8603515625\n",
      "Batch: 7, Loss: 0.4370708465576172, Accuracy: 0.859375\n",
      "Batch: 8, Loss: 0.38369131088256836, Accuracy: 0.8759765625\n",
      "Batch: 9, Loss: 0.4292032718658447, Accuracy: 0.8583984375\n",
      "Batch: 10, Loss: 0.49617892503738403, Accuracy: 0.8271484375\n",
      "Batch: 11, Loss: 0.44651687145233154, Accuracy: 0.85546875\n",
      "Batch: 12, Loss: 0.38979893922805786, Accuracy: 0.8701171875\n",
      "Batch: 13, Loss: 0.39742809534072876, Accuracy: 0.8701171875\n",
      "Batch: 14, Loss: 0.4536346197128296, Accuracy: 0.8564453125\n",
      "Batch: 15, Loss: 0.45309364795684814, Accuracy: 0.84765625\n",
      "Batch: 16, Loss: 0.4438331723213196, Accuracy: 0.8583984375\n",
      "Batch: 17, Loss: 0.46921515464782715, Accuracy: 0.8515625\n",
      "Batch: 18, Loss: 0.39917299151420593, Accuracy: 0.8603515625\n",
      "Batch: 19, Loss: 0.3881220817565918, Accuracy: 0.8701171875\n",
      "Batch: 20, Loss: 0.445308655500412, Accuracy: 0.857421875\n",
      "Batch: 21, Loss: 0.44972583651542664, Accuracy: 0.853515625\n",
      "Batch: 22, Loss: 0.42919743061065674, Accuracy: 0.85546875\n",
      "Batch: 23, Loss: 0.49212753772735596, Accuracy: 0.841796875\n",
      "Batch: 24, Loss: 0.5148316025733948, Accuracy: 0.8310546875\n",
      "Batch: 25, Loss: 0.5074239373207092, Accuracy: 0.82421875\n",
      "Batch: 26, Loss: 0.5117028951644897, Accuracy: 0.837890625\n",
      "Batch: 27, Loss: 0.5251824259757996, Accuracy: 0.833984375\n",
      "Batch: 28, Loss: 0.48856788873672485, Accuracy: 0.83203125\n",
      "Batch: 29, Loss: 0.49596357345581055, Accuracy: 0.82421875\n",
      "Batch: 30, Loss: 0.3999558091163635, Accuracy: 0.8671875\n",
      "Batch: 31, Loss: 0.4751737117767334, Accuracy: 0.8359375\n",
      "Batch: 32, Loss: 0.43885424733161926, Accuracy: 0.85546875\n",
      "Batch: 33, Loss: 0.4542413353919983, Accuracy: 0.84375\n",
      "Batch: 34, Loss: 0.4234248399734497, Accuracy: 0.8583984375\n",
      "Batch: 35, Loss: 0.446412593126297, Accuracy: 0.8525390625\n",
      "Batch: 36, Loss: 0.5155830979347229, Accuracy: 0.837890625\n",
      "Batch: 37, Loss: 0.4012013077735901, Accuracy: 0.8525390625\n",
      "Batch: 38, Loss: 0.4488154649734497, Accuracy: 0.8447265625\n",
      "Batch: 39, Loss: 0.43523406982421875, Accuracy: 0.8515625\n",
      "Batch: 40, Loss: 0.4486375153064728, Accuracy: 0.8515625\n",
      "Batch: 41, Loss: 0.4644654393196106, Accuracy: 0.8525390625\n",
      "Batch: 42, Loss: 0.4467695355415344, Accuracy: 0.8525390625\n",
      "Batch: 43, Loss: 0.4672187566757202, Accuracy: 0.8349609375\n",
      "Batch: 44, Loss: 0.4907875955104828, Accuracy: 0.845703125\n",
      "Batch: 45, Loss: 0.5048998594284058, Accuracy: 0.828125\n",
      "Batch: 46, Loss: 0.45713162422180176, Accuracy: 0.8408203125\n",
      "Batch: 47, Loss: 0.47294074296951294, Accuracy: 0.8369140625\n",
      "Batch: 48, Loss: 0.48334312438964844, Accuracy: 0.849609375\n",
      "Batch: 49, Loss: 0.5043096542358398, Accuracy: 0.83203125\n",
      "Batch: 50, Loss: 0.41352343559265137, Accuracy: 0.875\n",
      "Batch: 51, Loss: 0.43344905972480774, Accuracy: 0.8583984375\n",
      "Batch: 52, Loss: 0.47618773579597473, Accuracy: 0.8408203125\n",
      "Batch: 53, Loss: 0.53521728515625, Accuracy: 0.82421875\n",
      "Batch: 54, Loss: 0.46178945899009705, Accuracy: 0.865234375\n",
      "Batch: 55, Loss: 0.5103585720062256, Accuracy: 0.8310546875\n",
      "Batch: 56, Loss: 0.4339257478713989, Accuracy: 0.8525390625\n",
      "Batch: 57, Loss: 0.4806898832321167, Accuracy: 0.84765625\n",
      "Batch: 58, Loss: 0.5198854804039001, Accuracy: 0.830078125\n",
      "Batch: 59, Loss: 0.47564420104026794, Accuracy: 0.8408203125\n",
      "Batch: 60, Loss: 0.4905754327774048, Accuracy: 0.8251953125\n",
      "Batch: 61, Loss: 0.4597218930721283, Accuracy: 0.8427734375\n",
      "Batch: 62, Loss: 0.46899178624153137, Accuracy: 0.84765625\n",
      "Batch: 63, Loss: 0.382467657327652, Accuracy: 0.8779296875\n",
      "Batch: 64, Loss: 0.47196242213249207, Accuracy: 0.8330078125\n",
      "Batch: 65, Loss: 0.42960280179977417, Accuracy: 0.8427734375\n",
      "Batch: 66, Loss: 0.40405339002609253, Accuracy: 0.86328125\n",
      "Batch: 67, Loss: 0.42188894748687744, Accuracy: 0.85546875\n",
      "Batch: 68, Loss: 0.4390519857406616, Accuracy: 0.8623046875\n",
      "Batch: 69, Loss: 0.3894561529159546, Accuracy: 0.873046875\n",
      "Batch: 70, Loss: 0.40199312567710876, Accuracy: 0.865234375\n",
      "Batch: 71, Loss: 0.4306914508342743, Accuracy: 0.845703125\n",
      "Batch: 72, Loss: 0.45522886514663696, Accuracy: 0.8505859375\n",
      "Batch: 73, Loss: 0.42609500885009766, Accuracy: 0.8525390625\n",
      "Batch: 74, Loss: 0.4261585474014282, Accuracy: 0.8583984375\n",
      "Batch: 75, Loss: 0.38076454401016235, Accuracy: 0.8671875\n",
      "Batch: 76, Loss: 0.3565298914909363, Accuracy: 0.875\n",
      "Batch: 77, Loss: 0.4605446457862854, Accuracy: 0.8525390625\n",
      "Batch: 78, Loss: 0.41513898968696594, Accuracy: 0.8583984375\n",
      "Batch: 79, Loss: 0.4374966323375702, Accuracy: 0.857421875\n",
      "Batch: 80, Loss: 0.44429150223731995, Accuracy: 0.8505859375\n",
      "Batch: 81, Loss: 0.4556838870048523, Accuracy: 0.84375\n",
      "Batch: 82, Loss: 0.4594777226448059, Accuracy: 0.845703125\n",
      "Batch: 83, Loss: 0.39203861355781555, Accuracy: 0.8720703125\n",
      "Batch: 84, Loss: 0.4233909249305725, Accuracy: 0.857421875\n",
      "Batch: 85, Loss: 0.44256553053855896, Accuracy: 0.85546875\n",
      "Batch: 86, Loss: 0.4095078706741333, Accuracy: 0.85546875\n",
      "Batch: 87, Loss: 0.3936004638671875, Accuracy: 0.87109375\n",
      "Batch: 88, Loss: 0.4496215879917145, Accuracy: 0.859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 89, Loss: 0.39765068888664246, Accuracy: 0.8720703125\n",
      "Batch: 90, Loss: 0.49370235204696655, Accuracy: 0.8388671875\n",
      "Batch: 91, Loss: 0.5322336554527283, Accuracy: 0.8232421875\n",
      "Batch: 92, Loss: 0.47693437337875366, Accuracy: 0.8388671875\n",
      "Batch: 93, Loss: 0.4633915424346924, Accuracy: 0.853515625\n",
      "Batch: 94, Loss: 0.48152869939804077, Accuracy: 0.83984375\n",
      "Batch: 95, Loss: 0.4720246195793152, Accuracy: 0.8505859375\n",
      "Batch: 96, Loss: 0.4267869293689728, Accuracy: 0.8603515625\n",
      "Batch: 97, Loss: 0.4216710031032562, Accuracy: 0.869140625\n",
      "Batch: 98, Loss: 0.4966588020324707, Accuracy: 0.8193359375\n",
      "Batch: 99, Loss: 0.42721420526504517, Accuracy: 0.8564453125\n",
      "Batch: 100, Loss: 0.44648364186286926, Accuracy: 0.84765625\n",
      "Batch: 101, Loss: 0.45677512884140015, Accuracy: 0.83984375\n",
      "Batch: 102, Loss: 0.452655553817749, Accuracy: 0.8515625\n",
      "Batch: 103, Loss: 0.48486849665641785, Accuracy: 0.837890625\n",
      "Batch: 104, Loss: 0.4438701868057251, Accuracy: 0.8525390625\n",
      "Batch: 105, Loss: 0.3812231719493866, Accuracy: 0.876953125\n",
      "Batch: 106, Loss: 0.449494868516922, Accuracy: 0.8466796875\n",
      "Batch: 107, Loss: 0.4070255160331726, Accuracy: 0.8681640625\n",
      "Batch: 108, Loss: 0.4420304596424103, Accuracy: 0.8603515625\n",
      "Batch: 109, Loss: 0.33976560831069946, Accuracy: 0.8837890625\n",
      "Batch: 110, Loss: 0.3783750534057617, Accuracy: 0.8828125\n",
      "Batch: 111, Loss: 0.4606379270553589, Accuracy: 0.853515625\n",
      "Batch: 112, Loss: 0.4372304081916809, Accuracy: 0.853515625\n",
      "Epoch 42/90\n",
      "Batch: 1, Loss: 0.5718317031860352, Accuracy: 0.8291015625\n",
      "Batch: 2, Loss: 0.4677688777446747, Accuracy: 0.841796875\n",
      "Batch: 3, Loss: 0.44129452109336853, Accuracy: 0.8603515625\n",
      "Batch: 4, Loss: 0.4164906144142151, Accuracy: 0.865234375\n",
      "Batch: 5, Loss: 0.37832123041152954, Accuracy: 0.8818359375\n",
      "Batch: 6, Loss: 0.42959603667259216, Accuracy: 0.86328125\n",
      "Batch: 7, Loss: 0.40246665477752686, Accuracy: 0.875\n",
      "Batch: 8, Loss: 0.39343833923339844, Accuracy: 0.8671875\n",
      "Batch: 9, Loss: 0.4273868799209595, Accuracy: 0.857421875\n",
      "Batch: 10, Loss: 0.4742897152900696, Accuracy: 0.8359375\n",
      "Batch: 11, Loss: 0.44742777943611145, Accuracy: 0.8447265625\n",
      "Batch: 12, Loss: 0.4038645029067993, Accuracy: 0.8564453125\n",
      "Batch: 13, Loss: 0.3857614994049072, Accuracy: 0.87890625\n",
      "Batch: 14, Loss: 0.440251886844635, Accuracy: 0.853515625\n",
      "Batch: 15, Loss: 0.42904895544052124, Accuracy: 0.865234375\n",
      "Batch: 16, Loss: 0.4515950679779053, Accuracy: 0.8447265625\n",
      "Batch: 17, Loss: 0.4519791603088379, Accuracy: 0.8505859375\n",
      "Batch: 18, Loss: 0.4233597218990326, Accuracy: 0.861328125\n",
      "Batch: 19, Loss: 0.4038185775279999, Accuracy: 0.8662109375\n",
      "Batch: 20, Loss: 0.4369209408760071, Accuracy: 0.84375\n",
      "Batch: 21, Loss: 0.4263242483139038, Accuracy: 0.84375\n",
      "Batch: 22, Loss: 0.4078543484210968, Accuracy: 0.8779296875\n",
      "Batch: 23, Loss: 0.4487859010696411, Accuracy: 0.87109375\n",
      "Batch: 24, Loss: 0.46618759632110596, Accuracy: 0.833984375\n",
      "Batch: 25, Loss: 0.49668142199516296, Accuracy: 0.830078125\n",
      "Batch: 26, Loss: 0.5029677152633667, Accuracy: 0.8427734375\n",
      "Batch: 27, Loss: 0.5085500478744507, Accuracy: 0.8408203125\n",
      "Batch: 28, Loss: 0.4537283778190613, Accuracy: 0.8486328125\n",
      "Batch: 29, Loss: 0.4857802391052246, Accuracy: 0.8388671875\n",
      "Batch: 30, Loss: 0.3980632424354553, Accuracy: 0.859375\n",
      "Batch: 31, Loss: 0.459958553314209, Accuracy: 0.845703125\n",
      "Batch: 32, Loss: 0.43265479803085327, Accuracy: 0.8623046875\n",
      "Batch: 33, Loss: 0.41813552379608154, Accuracy: 0.8544921875\n",
      "Batch: 34, Loss: 0.4007369875907898, Accuracy: 0.8642578125\n",
      "Batch: 35, Loss: 0.4143894612789154, Accuracy: 0.8583984375\n",
      "Batch: 36, Loss: 0.5009603500366211, Accuracy: 0.8427734375\n",
      "Batch: 37, Loss: 0.3980509042739868, Accuracy: 0.8671875\n",
      "Batch: 38, Loss: 0.4556635916233063, Accuracy: 0.8583984375\n",
      "Batch: 39, Loss: 0.43165111541748047, Accuracy: 0.857421875\n",
      "Batch: 40, Loss: 0.42658984661102295, Accuracy: 0.8544921875\n",
      "Batch: 41, Loss: 0.43416810035705566, Accuracy: 0.8486328125\n",
      "Batch: 42, Loss: 0.431455135345459, Accuracy: 0.8544921875\n",
      "Batch: 43, Loss: 0.46188944578170776, Accuracy: 0.8388671875\n",
      "Batch: 44, Loss: 0.4376506805419922, Accuracy: 0.8583984375\n",
      "Batch: 45, Loss: 0.4859796464443207, Accuracy: 0.8271484375\n",
      "Batch: 46, Loss: 0.40906256437301636, Accuracy: 0.86328125\n",
      "Batch: 47, Loss: 0.45371100306510925, Accuracy: 0.8408203125\n",
      "Batch: 48, Loss: 0.4733515977859497, Accuracy: 0.8486328125\n",
      "Batch: 49, Loss: 0.4881191849708557, Accuracy: 0.837890625\n",
      "Batch: 50, Loss: 0.3762369453907013, Accuracy: 0.8916015625\n",
      "Batch: 51, Loss: 0.4437342882156372, Accuracy: 0.8642578125\n",
      "Batch: 52, Loss: 0.4627324938774109, Accuracy: 0.8564453125\n",
      "Batch: 53, Loss: 0.5211951732635498, Accuracy: 0.8203125\n",
      "Batch: 54, Loss: 0.4505811929702759, Accuracy: 0.8623046875\n",
      "Batch: 55, Loss: 0.4866824150085449, Accuracy: 0.845703125\n",
      "Batch: 56, Loss: 0.43751221895217896, Accuracy: 0.861328125\n",
      "Batch: 57, Loss: 0.509610652923584, Accuracy: 0.82421875\n",
      "Batch: 58, Loss: 0.4976257383823395, Accuracy: 0.8427734375\n",
      "Batch: 59, Loss: 0.4515049457550049, Accuracy: 0.853515625\n",
      "Batch: 60, Loss: 0.461758017539978, Accuracy: 0.841796875\n",
      "Batch: 61, Loss: 0.4426983892917633, Accuracy: 0.8623046875\n",
      "Batch: 62, Loss: 0.46190476417541504, Accuracy: 0.8505859375\n",
      "Batch: 63, Loss: 0.3819023370742798, Accuracy: 0.869140625\n",
      "Batch: 64, Loss: 0.4335896074771881, Accuracy: 0.84765625\n",
      "Batch: 65, Loss: 0.3929094672203064, Accuracy: 0.859375\n",
      "Batch: 66, Loss: 0.41654324531555176, Accuracy: 0.8623046875\n",
      "Batch: 67, Loss: 0.4210653603076935, Accuracy: 0.85546875\n",
      "Batch: 68, Loss: 0.4338957667350769, Accuracy: 0.859375\n",
      "Batch: 69, Loss: 0.37961411476135254, Accuracy: 0.87109375\n",
      "Batch: 70, Loss: 0.41296207904815674, Accuracy: 0.865234375\n",
      "Batch: 71, Loss: 0.41103652119636536, Accuracy: 0.8671875\n",
      "Batch: 72, Loss: 0.45422273874282837, Accuracy: 0.84375\n",
      "Batch: 73, Loss: 0.42932751774787903, Accuracy: 0.8525390625\n",
      "Batch: 74, Loss: 0.4442814588546753, Accuracy: 0.865234375\n",
      "Batch: 75, Loss: 0.3955192565917969, Accuracy: 0.8515625\n",
      "Batch: 76, Loss: 0.37659376859664917, Accuracy: 0.876953125\n",
      "Batch: 77, Loss: 0.48015376925468445, Accuracy: 0.8447265625\n",
      "Batch: 78, Loss: 0.4351727366447449, Accuracy: 0.853515625\n",
      "Batch: 79, Loss: 0.4260983169078827, Accuracy: 0.85546875\n",
      "Batch: 80, Loss: 0.4094148278236389, Accuracy: 0.8564453125\n",
      "Batch: 81, Loss: 0.4506274461746216, Accuracy: 0.8505859375\n",
      "Batch: 82, Loss: 0.46234214305877686, Accuracy: 0.8388671875\n",
      "Batch: 83, Loss: 0.39375990629196167, Accuracy: 0.8759765625\n",
      "Batch: 84, Loss: 0.4387977123260498, Accuracy: 0.84765625\n",
      "Batch: 85, Loss: 0.4574771523475647, Accuracy: 0.84765625\n",
      "Batch: 86, Loss: 0.42949938774108887, Accuracy: 0.8515625\n",
      "Batch: 87, Loss: 0.39802172780036926, Accuracy: 0.865234375\n",
      "Batch: 88, Loss: 0.4396781325340271, Accuracy: 0.85546875\n",
      "Batch: 89, Loss: 0.40397489070892334, Accuracy: 0.8603515625\n",
      "Batch: 90, Loss: 0.5050102472305298, Accuracy: 0.8251953125\n",
      "Batch: 91, Loss: 0.5162855386734009, Accuracy: 0.8271484375\n",
      "Batch: 92, Loss: 0.4322415292263031, Accuracy: 0.8515625\n",
      "Batch: 93, Loss: 0.44094687700271606, Accuracy: 0.849609375\n",
      "Batch: 94, Loss: 0.47791942954063416, Accuracy: 0.8310546875\n",
      "Batch: 95, Loss: 0.465042382478714, Accuracy: 0.841796875\n",
      "Batch: 96, Loss: 0.4285787343978882, Accuracy: 0.8603515625\n",
      "Batch: 97, Loss: 0.4056287407875061, Accuracy: 0.8671875\n",
      "Batch: 98, Loss: 0.46563708782196045, Accuracy: 0.83984375\n",
      "Batch: 99, Loss: 0.4210095703601837, Accuracy: 0.857421875\n",
      "Batch: 100, Loss: 0.47806671261787415, Accuracy: 0.8369140625\n",
      "Batch: 101, Loss: 0.43962955474853516, Accuracy: 0.8447265625\n",
      "Batch: 102, Loss: 0.44756919145584106, Accuracy: 0.8505859375\n",
      "Batch: 103, Loss: 0.42281246185302734, Accuracy: 0.8623046875\n",
      "Batch: 104, Loss: 0.4472566843032837, Accuracy: 0.84765625\n",
      "Batch: 105, Loss: 0.3766579031944275, Accuracy: 0.8740234375\n",
      "Batch: 106, Loss: 0.45734649896621704, Accuracy: 0.8427734375\n",
      "Batch: 107, Loss: 0.4047875702381134, Accuracy: 0.865234375\n",
      "Batch: 108, Loss: 0.4000679850578308, Accuracy: 0.8720703125\n",
      "Batch: 109, Loss: 0.33654698729515076, Accuracy: 0.8857421875\n",
      "Batch: 110, Loss: 0.3610125780105591, Accuracy: 0.88671875\n",
      "Batch: 111, Loss: 0.43903306126594543, Accuracy: 0.8544921875\n",
      "Batch: 112, Loss: 0.42247816920280457, Accuracy: 0.869140625\n",
      "Epoch 43/90\n",
      "Batch: 1, Loss: 0.5738043785095215, Accuracy: 0.8310546875\n",
      "Batch: 2, Loss: 0.4742511510848999, Accuracy: 0.8544921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 3, Loss: 0.4393046498298645, Accuracy: 0.8701171875\n",
      "Batch: 4, Loss: 0.4193889796733856, Accuracy: 0.865234375\n",
      "Batch: 5, Loss: 0.37290412187576294, Accuracy: 0.888671875\n",
      "Batch: 6, Loss: 0.4513867199420929, Accuracy: 0.8505859375\n",
      "Batch: 7, Loss: 0.41601115465164185, Accuracy: 0.8671875\n",
      "Batch: 8, Loss: 0.35134512186050415, Accuracy: 0.8818359375\n",
      "Batch: 9, Loss: 0.4171040654182434, Accuracy: 0.865234375\n",
      "Batch: 10, Loss: 0.45533138513565063, Accuracy: 0.828125\n",
      "Batch: 11, Loss: 0.445143461227417, Accuracy: 0.84375\n",
      "Batch: 12, Loss: 0.386050283908844, Accuracy: 0.8662109375\n",
      "Batch: 13, Loss: 0.3604804277420044, Accuracy: 0.8798828125\n",
      "Batch: 14, Loss: 0.4353855848312378, Accuracy: 0.859375\n",
      "Batch: 15, Loss: 0.41993874311447144, Accuracy: 0.857421875\n",
      "Batch: 16, Loss: 0.4157056212425232, Accuracy: 0.8720703125\n",
      "Batch: 17, Loss: 0.43813249468803406, Accuracy: 0.8544921875\n",
      "Batch: 18, Loss: 0.3930211365222931, Accuracy: 0.8720703125\n",
      "Batch: 19, Loss: 0.40079542994499207, Accuracy: 0.8623046875\n",
      "Batch: 20, Loss: 0.44480836391448975, Accuracy: 0.8486328125\n",
      "Batch: 21, Loss: 0.4209209978580475, Accuracy: 0.8642578125\n",
      "Batch: 22, Loss: 0.3971613645553589, Accuracy: 0.876953125\n",
      "Batch: 23, Loss: 0.4469276964664459, Accuracy: 0.8505859375\n",
      "Batch: 24, Loss: 0.4462365508079529, Accuracy: 0.849609375\n",
      "Batch: 25, Loss: 0.5166589617729187, Accuracy: 0.8271484375\n",
      "Batch: 26, Loss: 0.4781225919723511, Accuracy: 0.8486328125\n",
      "Batch: 27, Loss: 0.5006394982337952, Accuracy: 0.8369140625\n",
      "Batch: 28, Loss: 0.4548238217830658, Accuracy: 0.853515625\n",
      "Batch: 29, Loss: 0.49188095331192017, Accuracy: 0.8369140625\n",
      "Batch: 30, Loss: 0.4042735695838928, Accuracy: 0.8603515625\n",
      "Batch: 31, Loss: 0.4604647159576416, Accuracy: 0.8427734375\n",
      "Batch: 32, Loss: 0.40094658732414246, Accuracy: 0.876953125\n",
      "Batch: 33, Loss: 0.40551674365997314, Accuracy: 0.8583984375\n",
      "Batch: 34, Loss: 0.4113796055316925, Accuracy: 0.8671875\n",
      "Batch: 35, Loss: 0.4130323529243469, Accuracy: 0.861328125\n",
      "Batch: 36, Loss: 0.5017759799957275, Accuracy: 0.84375\n",
      "Batch: 37, Loss: 0.3919369876384735, Accuracy: 0.8671875\n",
      "Batch: 38, Loss: 0.45581215620040894, Accuracy: 0.8447265625\n",
      "Batch: 39, Loss: 0.42459481954574585, Accuracy: 0.8564453125\n",
      "Batch: 40, Loss: 0.43589314818382263, Accuracy: 0.859375\n",
      "Batch: 41, Loss: 0.445236474275589, Accuracy: 0.8505859375\n",
      "Batch: 42, Loss: 0.4307745695114136, Accuracy: 0.85546875\n",
      "Batch: 43, Loss: 0.4113473892211914, Accuracy: 0.8662109375\n",
      "Batch: 44, Loss: 0.4412946105003357, Accuracy: 0.857421875\n",
      "Batch: 45, Loss: 0.49732857942581177, Accuracy: 0.8408203125\n",
      "Batch: 46, Loss: 0.43537187576293945, Accuracy: 0.8623046875\n",
      "Batch: 47, Loss: 0.4206256866455078, Accuracy: 0.8642578125\n",
      "Batch: 48, Loss: 0.44583117961883545, Accuracy: 0.84765625\n",
      "Batch: 49, Loss: 0.4860610067844391, Accuracy: 0.8388671875\n",
      "Batch: 50, Loss: 0.36190950870513916, Accuracy: 0.892578125\n",
      "Batch: 51, Loss: 0.43917030096054077, Accuracy: 0.853515625\n",
      "Batch: 52, Loss: 0.46870923042297363, Accuracy: 0.8447265625\n",
      "Batch: 53, Loss: 0.5155799984931946, Accuracy: 0.826171875\n",
      "Batch: 54, Loss: 0.4637618660926819, Accuracy: 0.8486328125\n",
      "Batch: 55, Loss: 0.4713532328605652, Accuracy: 0.8330078125\n",
      "Batch: 56, Loss: 0.4395044445991516, Accuracy: 0.8603515625\n",
      "Batch: 57, Loss: 0.49374163150787354, Accuracy: 0.837890625\n",
      "Batch: 58, Loss: 0.5084356069564819, Accuracy: 0.828125\n",
      "Batch: 59, Loss: 0.45926210284233093, Accuracy: 0.845703125\n",
      "Batch: 60, Loss: 0.4329797625541687, Accuracy: 0.8525390625\n",
      "Batch: 61, Loss: 0.4430789351463318, Accuracy: 0.859375\n",
      "Batch: 62, Loss: 0.4318985641002655, Accuracy: 0.8623046875\n",
      "Batch: 63, Loss: 0.35945838689804077, Accuracy: 0.8818359375\n",
      "Batch: 64, Loss: 0.4405500292778015, Accuracy: 0.853515625\n",
      "Batch: 65, Loss: 0.402678906917572, Accuracy: 0.8564453125\n",
      "Batch: 66, Loss: 0.3911930024623871, Accuracy: 0.8720703125\n",
      "Batch: 67, Loss: 0.4221119284629822, Accuracy: 0.861328125\n",
      "Batch: 68, Loss: 0.44761401414871216, Accuracy: 0.8564453125\n",
      "Batch: 69, Loss: 0.3723156154155731, Accuracy: 0.8828125\n",
      "Batch: 70, Loss: 0.41327375173568726, Accuracy: 0.859375\n",
      "Batch: 71, Loss: 0.4201867878437042, Accuracy: 0.8544921875\n",
      "Batch: 72, Loss: 0.44351112842559814, Accuracy: 0.853515625\n",
      "Batch: 73, Loss: 0.41032513976097107, Accuracy: 0.8623046875\n",
      "Batch: 74, Loss: 0.4215448200702667, Accuracy: 0.8701171875\n",
      "Batch: 75, Loss: 0.3513510227203369, Accuracy: 0.873046875\n",
      "Batch: 76, Loss: 0.37717005610466003, Accuracy: 0.8740234375\n",
      "Batch: 77, Loss: 0.4236108660697937, Accuracy: 0.86328125\n",
      "Batch: 78, Loss: 0.417164146900177, Accuracy: 0.859375\n",
      "Batch: 79, Loss: 0.41493821144104004, Accuracy: 0.869140625\n",
      "Batch: 80, Loss: 0.4051153063774109, Accuracy: 0.869140625\n",
      "Batch: 81, Loss: 0.40643036365509033, Accuracy: 0.8662109375\n",
      "Batch: 82, Loss: 0.4382826089859009, Accuracy: 0.8515625\n",
      "Batch: 83, Loss: 0.36499083042144775, Accuracy: 0.8759765625\n",
      "Batch: 84, Loss: 0.42887094616889954, Accuracy: 0.85546875\n",
      "Batch: 85, Loss: 0.4445645213127136, Accuracy: 0.8583984375\n",
      "Batch: 86, Loss: 0.4280085563659668, Accuracy: 0.853515625\n",
      "Batch: 87, Loss: 0.38482213020324707, Accuracy: 0.8740234375\n",
      "Batch: 88, Loss: 0.4173886477947235, Accuracy: 0.8564453125\n",
      "Batch: 89, Loss: 0.40399369597435, Accuracy: 0.86328125\n",
      "Batch: 90, Loss: 0.48654359579086304, Accuracy: 0.83984375\n",
      "Batch: 91, Loss: 0.48178550601005554, Accuracy: 0.8349609375\n",
      "Batch: 92, Loss: 0.46548742055892944, Accuracy: 0.83203125\n",
      "Batch: 93, Loss: 0.4603773355484009, Accuracy: 0.8466796875\n",
      "Batch: 94, Loss: 0.4727798402309418, Accuracy: 0.8408203125\n",
      "Batch: 95, Loss: 0.4653669595718384, Accuracy: 0.8427734375\n",
      "Batch: 96, Loss: 0.4245222210884094, Accuracy: 0.8564453125\n",
      "Batch: 97, Loss: 0.40303128957748413, Accuracy: 0.86328125\n",
      "Batch: 98, Loss: 0.4233700633049011, Accuracy: 0.8525390625\n",
      "Batch: 99, Loss: 0.38681748509407043, Accuracy: 0.865234375\n",
      "Batch: 100, Loss: 0.45980459451675415, Accuracy: 0.84375\n",
      "Batch: 101, Loss: 0.4348946213722229, Accuracy: 0.849609375\n",
      "Batch: 102, Loss: 0.42095494270324707, Accuracy: 0.85546875\n",
      "Batch: 103, Loss: 0.419970840215683, Accuracy: 0.85546875\n",
      "Batch: 104, Loss: 0.45437857508659363, Accuracy: 0.8408203125\n",
      "Batch: 105, Loss: 0.37503212690353394, Accuracy: 0.8681640625\n",
      "Batch: 106, Loss: 0.447546124458313, Accuracy: 0.8447265625\n",
      "Batch: 107, Loss: 0.382919579744339, Accuracy: 0.865234375\n",
      "Batch: 108, Loss: 0.3793836832046509, Accuracy: 0.8720703125\n",
      "Batch: 109, Loss: 0.35262101888656616, Accuracy: 0.880859375\n",
      "Batch: 110, Loss: 0.36301231384277344, Accuracy: 0.8857421875\n",
      "Batch: 111, Loss: 0.41845282912254333, Accuracy: 0.876953125\n",
      "Batch: 112, Loss: 0.4169807732105255, Accuracy: 0.8564453125\n",
      "Epoch 44/90\n",
      "Batch: 1, Loss: 0.5462676286697388, Accuracy: 0.84765625\n",
      "Batch: 2, Loss: 0.44378209114074707, Accuracy: 0.859375\n",
      "Batch: 3, Loss: 0.4253160357475281, Accuracy: 0.8681640625\n",
      "Batch: 4, Loss: 0.4023558497428894, Accuracy: 0.8740234375\n",
      "Batch: 5, Loss: 0.3716288208961487, Accuracy: 0.8740234375\n",
      "Batch: 6, Loss: 0.4180498719215393, Accuracy: 0.86328125\n",
      "Batch: 7, Loss: 0.3798827826976776, Accuracy: 0.869140625\n",
      "Batch: 8, Loss: 0.3717692494392395, Accuracy: 0.87109375\n",
      "Batch: 9, Loss: 0.40959957242012024, Accuracy: 0.85546875\n",
      "Batch: 10, Loss: 0.438906192779541, Accuracy: 0.8486328125\n",
      "Batch: 11, Loss: 0.4308847486972809, Accuracy: 0.8505859375\n",
      "Batch: 12, Loss: 0.36062538623809814, Accuracy: 0.8818359375\n",
      "Batch: 13, Loss: 0.3504389524459839, Accuracy: 0.892578125\n",
      "Batch: 14, Loss: 0.41572391986846924, Accuracy: 0.861328125\n",
      "Batch: 15, Loss: 0.4172554910182953, Accuracy: 0.8544921875\n",
      "Batch: 16, Loss: 0.41719383001327515, Accuracy: 0.8603515625\n",
      "Batch: 17, Loss: 0.4193822741508484, Accuracy: 0.8642578125\n",
      "Batch: 18, Loss: 0.3826462924480438, Accuracy: 0.865234375\n",
      "Batch: 19, Loss: 0.37955355644226074, Accuracy: 0.869140625\n",
      "Batch: 20, Loss: 0.4192940890789032, Accuracy: 0.8544921875\n",
      "Batch: 21, Loss: 0.4294885993003845, Accuracy: 0.857421875\n",
      "Batch: 22, Loss: 0.388386070728302, Accuracy: 0.8779296875\n",
      "Batch: 23, Loss: 0.44726458191871643, Accuracy: 0.8671875\n",
      "Batch: 24, Loss: 0.46729475259780884, Accuracy: 0.841796875\n",
      "Batch: 25, Loss: 0.4716816842556, Accuracy: 0.8359375\n",
      "Batch: 26, Loss: 0.5070750117301941, Accuracy: 0.8369140625\n",
      "Batch: 27, Loss: 0.474844753742218, Accuracy: 0.8349609375\n",
      "Batch: 28, Loss: 0.43613022565841675, Accuracy: 0.8505859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 29, Loss: 0.4492045044898987, Accuracy: 0.85546875\n",
      "Batch: 30, Loss: 0.36896735429763794, Accuracy: 0.8681640625\n",
      "Batch: 31, Loss: 0.4427914321422577, Accuracy: 0.8583984375\n",
      "Batch: 32, Loss: 0.41986411809921265, Accuracy: 0.8603515625\n",
      "Batch: 33, Loss: 0.40666598081588745, Accuracy: 0.8525390625\n",
      "Batch: 34, Loss: 0.38746970891952515, Accuracy: 0.865234375\n",
      "Batch: 35, Loss: 0.40288349986076355, Accuracy: 0.8603515625\n",
      "Batch: 36, Loss: 0.48525890707969666, Accuracy: 0.84765625\n",
      "Batch: 37, Loss: 0.3967916667461395, Accuracy: 0.865234375\n",
      "Batch: 38, Loss: 0.44317495822906494, Accuracy: 0.8369140625\n",
      "Batch: 39, Loss: 0.4009875953197479, Accuracy: 0.8671875\n",
      "Batch: 40, Loss: 0.41173747181892395, Accuracy: 0.8662109375\n",
      "Batch: 41, Loss: 0.4152149558067322, Accuracy: 0.8681640625\n",
      "Batch: 42, Loss: 0.43143796920776367, Accuracy: 0.8466796875\n",
      "Batch: 43, Loss: 0.4186287820339203, Accuracy: 0.8662109375\n",
      "Batch: 44, Loss: 0.4362204670906067, Accuracy: 0.8583984375\n",
      "Batch: 45, Loss: 0.47039172053337097, Accuracy: 0.84375\n",
      "Batch: 46, Loss: 0.4327620565891266, Accuracy: 0.849609375\n",
      "Batch: 47, Loss: 0.42233359813690186, Accuracy: 0.857421875\n",
      "Batch: 48, Loss: 0.4639042913913727, Accuracy: 0.845703125\n",
      "Batch: 49, Loss: 0.5020917057991028, Accuracy: 0.8408203125\n",
      "Batch: 50, Loss: 0.38679826259613037, Accuracy: 0.8935546875\n",
      "Batch: 51, Loss: 0.4347400367259979, Accuracy: 0.849609375\n",
      "Batch: 52, Loss: 0.43012070655822754, Accuracy: 0.8544921875\n",
      "Batch: 53, Loss: 0.5000731945037842, Accuracy: 0.841796875\n",
      "Batch: 54, Loss: 0.4375075101852417, Accuracy: 0.8662109375\n",
      "Batch: 55, Loss: 0.43926119804382324, Accuracy: 0.859375\n",
      "Batch: 56, Loss: 0.39048144221305847, Accuracy: 0.8671875\n",
      "Batch: 57, Loss: 0.490156352519989, Accuracy: 0.826171875\n",
      "Batch: 58, Loss: 0.48504510521888733, Accuracy: 0.8330078125\n",
      "Batch: 59, Loss: 0.45150962471961975, Accuracy: 0.8505859375\n",
      "Batch: 60, Loss: 0.4538799822330475, Accuracy: 0.8447265625\n",
      "Batch: 61, Loss: 0.4082833230495453, Accuracy: 0.8681640625\n",
      "Batch: 62, Loss: 0.4161239564418793, Accuracy: 0.87109375\n",
      "Batch: 63, Loss: 0.37750476598739624, Accuracy: 0.8603515625\n",
      "Batch: 64, Loss: 0.4505223333835602, Accuracy: 0.841796875\n",
      "Batch: 65, Loss: 0.4253005087375641, Accuracy: 0.8623046875\n",
      "Batch: 66, Loss: 0.3964388966560364, Accuracy: 0.87890625\n",
      "Batch: 67, Loss: 0.41304564476013184, Accuracy: 0.8623046875\n",
      "Batch: 68, Loss: 0.4077858328819275, Accuracy: 0.8623046875\n",
      "Batch: 69, Loss: 0.3873266577720642, Accuracy: 0.8681640625\n",
      "Batch: 70, Loss: 0.41227787733078003, Accuracy: 0.861328125\n",
      "Batch: 71, Loss: 0.38873404264450073, Accuracy: 0.859375\n",
      "Batch: 72, Loss: 0.4505632519721985, Accuracy: 0.861328125\n",
      "Batch: 73, Loss: 0.39060285687446594, Accuracy: 0.876953125\n",
      "Batch: 74, Loss: 0.4125838279724121, Accuracy: 0.8583984375\n",
      "Batch: 75, Loss: 0.3654896914958954, Accuracy: 0.8759765625\n",
      "Batch: 76, Loss: 0.3563492000102997, Accuracy: 0.8837890625\n",
      "Batch: 77, Loss: 0.4204205870628357, Accuracy: 0.8623046875\n",
      "Batch: 78, Loss: 0.4177561402320862, Accuracy: 0.8642578125\n",
      "Batch: 79, Loss: 0.39312487840652466, Accuracy: 0.8798828125\n",
      "Batch: 80, Loss: 0.4076066017150879, Accuracy: 0.8603515625\n",
      "Batch: 81, Loss: 0.45978981256484985, Accuracy: 0.845703125\n",
      "Batch: 82, Loss: 0.4253799319267273, Accuracy: 0.845703125\n",
      "Batch: 83, Loss: 0.3973316550254822, Accuracy: 0.87109375\n",
      "Batch: 84, Loss: 0.41454312205314636, Accuracy: 0.8662109375\n",
      "Batch: 85, Loss: 0.41940122842788696, Accuracy: 0.865234375\n",
      "Batch: 86, Loss: 0.39778921008110046, Accuracy: 0.8486328125\n",
      "Batch: 87, Loss: 0.3588793873786926, Accuracy: 0.87109375\n",
      "Batch: 88, Loss: 0.4217483401298523, Accuracy: 0.8564453125\n",
      "Batch: 89, Loss: 0.40734153985977173, Accuracy: 0.8779296875\n",
      "Batch: 90, Loss: 0.4484032392501831, Accuracy: 0.8427734375\n",
      "Batch: 91, Loss: 0.4799353778362274, Accuracy: 0.8486328125\n",
      "Batch: 92, Loss: 0.4333060383796692, Accuracy: 0.845703125\n",
      "Batch: 93, Loss: 0.44633156061172485, Accuracy: 0.853515625\n",
      "Batch: 94, Loss: 0.4431958496570587, Accuracy: 0.853515625\n",
      "Batch: 95, Loss: 0.44725412130355835, Accuracy: 0.841796875\n",
      "Batch: 96, Loss: 0.42494529485702515, Accuracy: 0.8583984375\n",
      "Batch: 97, Loss: 0.38545769453048706, Accuracy: 0.8779296875\n",
      "Batch: 98, Loss: 0.4496731758117676, Accuracy: 0.8486328125\n",
      "Batch: 99, Loss: 0.4196782112121582, Accuracy: 0.8544921875\n",
      "Batch: 100, Loss: 0.41925573348999023, Accuracy: 0.853515625\n",
      "Batch: 101, Loss: 0.4444355368614197, Accuracy: 0.8505859375\n",
      "Batch: 102, Loss: 0.40255075693130493, Accuracy: 0.8701171875\n",
      "Batch: 103, Loss: 0.4225870370864868, Accuracy: 0.861328125\n",
      "Batch: 104, Loss: 0.4378993511199951, Accuracy: 0.8544921875\n",
      "Batch: 105, Loss: 0.3524552881717682, Accuracy: 0.880859375\n",
      "Batch: 106, Loss: 0.44398534297943115, Accuracy: 0.8544921875\n",
      "Batch: 107, Loss: 0.3996604382991791, Accuracy: 0.8642578125\n",
      "Batch: 108, Loss: 0.41818729043006897, Accuracy: 0.8544921875\n",
      "Batch: 109, Loss: 0.3417550325393677, Accuracy: 0.888671875\n",
      "Batch: 110, Loss: 0.35066238045692444, Accuracy: 0.890625\n",
      "Batch: 111, Loss: 0.40501201152801514, Accuracy: 0.857421875\n",
      "Batch: 112, Loss: 0.40264979004859924, Accuracy: 0.861328125\n",
      "Epoch 45/90\n",
      "Batch: 1, Loss: 0.5409203767776489, Accuracy: 0.84375\n",
      "Batch: 2, Loss: 0.44525426626205444, Accuracy: 0.8583984375\n",
      "Batch: 3, Loss: 0.43269070982933044, Accuracy: 0.849609375\n",
      "Batch: 4, Loss: 0.4036771059036255, Accuracy: 0.873046875\n",
      "Batch: 5, Loss: 0.3403303027153015, Accuracy: 0.900390625\n",
      "Batch: 6, Loss: 0.40960943698883057, Accuracy: 0.869140625\n",
      "Batch: 7, Loss: 0.39422446489334106, Accuracy: 0.875\n",
      "Batch: 8, Loss: 0.36268818378448486, Accuracy: 0.8876953125\n",
      "Batch: 9, Loss: 0.43508368730545044, Accuracy: 0.8505859375\n",
      "Batch: 10, Loss: 0.46370142698287964, Accuracy: 0.837890625\n",
      "Batch: 11, Loss: 0.4179318845272064, Accuracy: 0.8515625\n",
      "Batch: 12, Loss: 0.40173959732055664, Accuracy: 0.8623046875\n",
      "Batch: 13, Loss: 0.36963486671447754, Accuracy: 0.890625\n",
      "Batch: 14, Loss: 0.41022831201553345, Accuracy: 0.8701171875\n",
      "Batch: 15, Loss: 0.39662227034568787, Accuracy: 0.8779296875\n",
      "Batch: 16, Loss: 0.43263527750968933, Accuracy: 0.8583984375\n",
      "Batch: 17, Loss: 0.44349682331085205, Accuracy: 0.857421875\n",
      "Batch: 18, Loss: 0.37285250425338745, Accuracy: 0.8798828125\n",
      "Batch: 19, Loss: 0.37547045946121216, Accuracy: 0.876953125\n",
      "Batch: 20, Loss: 0.4377208352088928, Accuracy: 0.8544921875\n",
      "Batch: 21, Loss: 0.4234318435192108, Accuracy: 0.8525390625\n",
      "Batch: 22, Loss: 0.3912736773490906, Accuracy: 0.8671875\n",
      "Batch: 23, Loss: 0.45233798027038574, Accuracy: 0.841796875\n",
      "Batch: 24, Loss: 0.464518278837204, Accuracy: 0.84765625\n",
      "Batch: 25, Loss: 0.4810011684894562, Accuracy: 0.8408203125\n",
      "Batch: 26, Loss: 0.4773961901664734, Accuracy: 0.857421875\n",
      "Batch: 27, Loss: 0.46480321884155273, Accuracy: 0.8515625\n",
      "Batch: 28, Loss: 0.4644363224506378, Accuracy: 0.84765625\n",
      "Batch: 29, Loss: 0.46564629673957825, Accuracy: 0.84765625\n",
      "Batch: 30, Loss: 0.3757666349411011, Accuracy: 0.8740234375\n",
      "Batch: 31, Loss: 0.4275110960006714, Accuracy: 0.8623046875\n",
      "Batch: 32, Loss: 0.39455321431159973, Accuracy: 0.861328125\n",
      "Batch: 33, Loss: 0.3879813551902771, Accuracy: 0.8583984375\n",
      "Batch: 34, Loss: 0.3657603859901428, Accuracy: 0.880859375\n",
      "Batch: 35, Loss: 0.388482928276062, Accuracy: 0.8623046875\n",
      "Batch: 36, Loss: 0.4630907475948334, Accuracy: 0.849609375\n",
      "Batch: 37, Loss: 0.3830838203430176, Accuracy: 0.86328125\n",
      "Batch: 38, Loss: 0.41571736335754395, Accuracy: 0.8662109375\n",
      "Batch: 39, Loss: 0.40583691000938416, Accuracy: 0.8642578125\n",
      "Batch: 40, Loss: 0.38975077867507935, Accuracy: 0.8818359375\n",
      "Batch: 41, Loss: 0.43152719736099243, Accuracy: 0.845703125\n",
      "Batch: 42, Loss: 0.4332159161567688, Accuracy: 0.849609375\n",
      "Batch: 43, Loss: 0.42069101333618164, Accuracy: 0.8623046875\n",
      "Batch: 44, Loss: 0.436002254486084, Accuracy: 0.86328125\n",
      "Batch: 45, Loss: 0.45308610796928406, Accuracy: 0.8623046875\n",
      "Batch: 46, Loss: 0.423672616481781, Accuracy: 0.8583984375\n",
      "Batch: 47, Loss: 0.42092442512512207, Accuracy: 0.8623046875\n",
      "Batch: 48, Loss: 0.4589458703994751, Accuracy: 0.8544921875\n",
      "Batch: 49, Loss: 0.46907466650009155, Accuracy: 0.8427734375\n",
      "Batch: 50, Loss: 0.3632528781890869, Accuracy: 0.884765625\n",
      "Batch: 51, Loss: 0.43165963888168335, Accuracy: 0.861328125\n",
      "Batch: 52, Loss: 0.4320194125175476, Accuracy: 0.87109375\n",
      "Batch: 53, Loss: 0.49103087186813354, Accuracy: 0.837890625\n",
      "Batch: 54, Loss: 0.4414779841899872, Accuracy: 0.857421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 55, Loss: 0.44700831174850464, Accuracy: 0.8505859375\n",
      "Batch: 56, Loss: 0.3977073132991791, Accuracy: 0.8740234375\n",
      "Batch: 57, Loss: 0.4686580002307892, Accuracy: 0.8427734375\n",
      "Batch: 58, Loss: 0.47166162729263306, Accuracy: 0.859375\n",
      "Batch: 59, Loss: 0.46342891454696655, Accuracy: 0.8515625\n",
      "Batch: 60, Loss: 0.3851461410522461, Accuracy: 0.8701171875\n",
      "Batch: 61, Loss: 0.40406060218811035, Accuracy: 0.8896484375\n",
      "Batch: 62, Loss: 0.4340132474899292, Accuracy: 0.85546875\n",
      "Batch: 63, Loss: 0.361964613199234, Accuracy: 0.880859375\n",
      "Batch: 64, Loss: 0.4649636745452881, Accuracy: 0.849609375\n",
      "Batch: 65, Loss: 0.4182435870170593, Accuracy: 0.85546875\n",
      "Batch: 66, Loss: 0.37157776951789856, Accuracy: 0.875\n",
      "Batch: 67, Loss: 0.40781959891319275, Accuracy: 0.865234375\n",
      "Batch: 68, Loss: 0.41027137637138367, Accuracy: 0.87109375\n",
      "Batch: 69, Loss: 0.36316031217575073, Accuracy: 0.8818359375\n",
      "Batch: 70, Loss: 0.37255918979644775, Accuracy: 0.875\n",
      "Batch: 71, Loss: 0.3797885477542877, Accuracy: 0.87109375\n",
      "Batch: 72, Loss: 0.44654417037963867, Accuracy: 0.8525390625\n",
      "Batch: 73, Loss: 0.4148285984992981, Accuracy: 0.8642578125\n",
      "Batch: 74, Loss: 0.4085884690284729, Accuracy: 0.86328125\n",
      "Batch: 75, Loss: 0.36079809069633484, Accuracy: 0.876953125\n",
      "Batch: 76, Loss: 0.3307665288448334, Accuracy: 0.8955078125\n",
      "Batch: 77, Loss: 0.4358071982860565, Accuracy: 0.85546875\n",
      "Batch: 78, Loss: 0.41034525632858276, Accuracy: 0.8662109375\n",
      "Batch: 79, Loss: 0.395293265581131, Accuracy: 0.88671875\n",
      "Batch: 80, Loss: 0.3784599006175995, Accuracy: 0.8671875\n",
      "Batch: 81, Loss: 0.42398250102996826, Accuracy: 0.8466796875\n",
      "Batch: 82, Loss: 0.4075321555137634, Accuracy: 0.8564453125\n",
      "Batch: 83, Loss: 0.35284894704818726, Accuracy: 0.8857421875\n",
      "Batch: 84, Loss: 0.38473451137542725, Accuracy: 0.865234375\n",
      "Batch: 85, Loss: 0.4331546723842621, Accuracy: 0.857421875\n",
      "Batch: 86, Loss: 0.400519996881485, Accuracy: 0.8583984375\n",
      "Batch: 87, Loss: 0.380304753780365, Accuracy: 0.880859375\n",
      "Batch: 88, Loss: 0.3864671587944031, Accuracy: 0.865234375\n",
      "Batch: 89, Loss: 0.3817015290260315, Accuracy: 0.875\n",
      "Batch: 90, Loss: 0.4493138790130615, Accuracy: 0.8408203125\n",
      "Batch: 91, Loss: 0.49531853199005127, Accuracy: 0.8310546875\n",
      "Batch: 92, Loss: 0.4125892221927643, Accuracy: 0.857421875\n",
      "Batch: 93, Loss: 0.44317927956581116, Accuracy: 0.857421875\n",
      "Batch: 94, Loss: 0.4607504606246948, Accuracy: 0.8408203125\n",
      "Batch: 95, Loss: 0.43128013610839844, Accuracy: 0.849609375\n",
      "Batch: 96, Loss: 0.4195016622543335, Accuracy: 0.8544921875\n",
      "Batch: 97, Loss: 0.38557547330856323, Accuracy: 0.873046875\n",
      "Batch: 98, Loss: 0.4041261672973633, Accuracy: 0.865234375\n",
      "Batch: 99, Loss: 0.38311508297920227, Accuracy: 0.876953125\n",
      "Batch: 100, Loss: 0.4238543212413788, Accuracy: 0.8564453125\n",
      "Batch: 101, Loss: 0.4415992796421051, Accuracy: 0.837890625\n",
      "Batch: 102, Loss: 0.41122502088546753, Accuracy: 0.8642578125\n",
      "Batch: 103, Loss: 0.4273814857006073, Accuracy: 0.8642578125\n",
      "Batch: 104, Loss: 0.4122515916824341, Accuracy: 0.8603515625\n",
      "Batch: 105, Loss: 0.3217526972293854, Accuracy: 0.8896484375\n",
      "Batch: 106, Loss: 0.41050493717193604, Accuracy: 0.865234375\n",
      "Batch: 107, Loss: 0.3762526512145996, Accuracy: 0.8779296875\n",
      "Batch: 108, Loss: 0.37669432163238525, Accuracy: 0.8759765625\n",
      "Batch: 109, Loss: 0.3075302839279175, Accuracy: 0.8994140625\n",
      "Batch: 110, Loss: 0.32926249504089355, Accuracy: 0.9013671875\n",
      "Batch: 111, Loss: 0.4006926715373993, Accuracy: 0.869140625\n",
      "Batch: 112, Loss: 0.39568886160850525, Accuracy: 0.876953125\n",
      "Epoch 46/90\n",
      "Batch: 1, Loss: 0.5303365588188171, Accuracy: 0.84765625\n",
      "Batch: 2, Loss: 0.408573180437088, Accuracy: 0.8759765625\n",
      "Batch: 3, Loss: 0.4182746410369873, Accuracy: 0.8701171875\n",
      "Batch: 4, Loss: 0.37882956862449646, Accuracy: 0.884765625\n",
      "Batch: 5, Loss: 0.3275490999221802, Accuracy: 0.884765625\n",
      "Batch: 6, Loss: 0.4276506304740906, Accuracy: 0.861328125\n",
      "Batch: 7, Loss: 0.37365320324897766, Accuracy: 0.873046875\n",
      "Batch: 8, Loss: 0.3747199773788452, Accuracy: 0.8818359375\n",
      "Batch: 9, Loss: 0.4132005572319031, Accuracy: 0.8623046875\n",
      "Batch: 10, Loss: 0.45218968391418457, Accuracy: 0.845703125\n",
      "Batch: 11, Loss: 0.408387154340744, Accuracy: 0.861328125\n",
      "Batch: 12, Loss: 0.3726918697357178, Accuracy: 0.87109375\n",
      "Batch: 13, Loss: 0.3560185134410858, Accuracy: 0.86328125\n",
      "Batch: 14, Loss: 0.4499428868293762, Accuracy: 0.8427734375\n",
      "Batch: 15, Loss: 0.40606042742729187, Accuracy: 0.861328125\n",
      "Batch: 16, Loss: 0.4082481265068054, Accuracy: 0.8701171875\n",
      "Batch: 17, Loss: 0.41471588611602783, Accuracy: 0.8623046875\n",
      "Batch: 18, Loss: 0.3596048951148987, Accuracy: 0.8798828125\n",
      "Batch: 19, Loss: 0.3772764801979065, Accuracy: 0.8837890625\n",
      "Batch: 20, Loss: 0.4101940989494324, Accuracy: 0.8642578125\n",
      "Batch: 21, Loss: 0.4037652015686035, Accuracy: 0.8642578125\n",
      "Batch: 22, Loss: 0.37584060430526733, Accuracy: 0.875\n",
      "Batch: 23, Loss: 0.4329759478569031, Accuracy: 0.87109375\n",
      "Batch: 24, Loss: 0.45487073063850403, Accuracy: 0.8486328125\n",
      "Batch: 25, Loss: 0.46021875739097595, Accuracy: 0.83984375\n",
      "Batch: 26, Loss: 0.4788793921470642, Accuracy: 0.8466796875\n",
      "Batch: 27, Loss: 0.4466237425804138, Accuracy: 0.8642578125\n",
      "Batch: 28, Loss: 0.4213468134403229, Accuracy: 0.865234375\n",
      "Batch: 29, Loss: 0.48888084292411804, Accuracy: 0.845703125\n",
      "Batch: 30, Loss: 0.358938992023468, Accuracy: 0.875\n",
      "Batch: 31, Loss: 0.40778759121894836, Accuracy: 0.87109375\n",
      "Batch: 32, Loss: 0.41366046667099, Accuracy: 0.8583984375\n",
      "Batch: 33, Loss: 0.4154190719127655, Accuracy: 0.8486328125\n",
      "Batch: 34, Loss: 0.384755402803421, Accuracy: 0.8759765625\n",
      "Batch: 35, Loss: 0.3887011408805847, Accuracy: 0.8681640625\n",
      "Batch: 36, Loss: 0.4540867507457733, Accuracy: 0.8583984375\n",
      "Batch: 37, Loss: 0.37730857729911804, Accuracy: 0.87109375\n",
      "Batch: 38, Loss: 0.4443246126174927, Accuracy: 0.83984375\n",
      "Batch: 39, Loss: 0.3874281048774719, Accuracy: 0.87109375\n",
      "Batch: 40, Loss: 0.3872358798980713, Accuracy: 0.8662109375\n",
      "Batch: 41, Loss: 0.40006712079048157, Accuracy: 0.859375\n",
      "Batch: 42, Loss: 0.4242073893547058, Accuracy: 0.849609375\n",
      "Batch: 43, Loss: 0.3997594714164734, Accuracy: 0.8623046875\n",
      "Batch: 44, Loss: 0.41142937541007996, Accuracy: 0.873046875\n",
      "Batch: 45, Loss: 0.4348893463611603, Accuracy: 0.8583984375\n",
      "Batch: 46, Loss: 0.4040887951850891, Accuracy: 0.8623046875\n",
      "Batch: 47, Loss: 0.412841260433197, Accuracy: 0.853515625\n",
      "Batch: 48, Loss: 0.441670298576355, Accuracy: 0.86328125\n",
      "Batch: 49, Loss: 0.45326128602027893, Accuracy: 0.859375\n",
      "Batch: 50, Loss: 0.347079336643219, Accuracy: 0.8974609375\n",
      "Batch: 51, Loss: 0.37683290243148804, Accuracy: 0.87890625\n",
      "Batch: 52, Loss: 0.404010146856308, Accuracy: 0.876953125\n",
      "Batch: 53, Loss: 0.4966210722923279, Accuracy: 0.8359375\n",
      "Batch: 54, Loss: 0.43848273158073425, Accuracy: 0.8583984375\n",
      "Batch: 55, Loss: 0.42554983496665955, Accuracy: 0.85546875\n",
      "Batch: 56, Loss: 0.38021427392959595, Accuracy: 0.875\n",
      "Batch: 57, Loss: 0.4314807057380676, Accuracy: 0.8583984375\n",
      "Batch: 58, Loss: 0.4395512342453003, Accuracy: 0.86328125\n",
      "Batch: 59, Loss: 0.4544902443885803, Accuracy: 0.845703125\n",
      "Batch: 60, Loss: 0.4117257595062256, Accuracy: 0.8720703125\n",
      "Batch: 61, Loss: 0.4313107132911682, Accuracy: 0.8525390625\n",
      "Batch: 62, Loss: 0.43175017833709717, Accuracy: 0.853515625\n",
      "Batch: 63, Loss: 0.3517087399959564, Accuracy: 0.880859375\n",
      "Batch: 64, Loss: 0.4404642581939697, Accuracy: 0.859375\n",
      "Batch: 65, Loss: 0.42353811860084534, Accuracy: 0.8447265625\n",
      "Batch: 66, Loss: 0.3572726547718048, Accuracy: 0.8798828125\n",
      "Batch: 67, Loss: 0.39046138525009155, Accuracy: 0.8671875\n",
      "Batch: 68, Loss: 0.3914237916469574, Accuracy: 0.8720703125\n",
      "Batch: 69, Loss: 0.3389710783958435, Accuracy: 0.8935546875\n",
      "Batch: 70, Loss: 0.3683164119720459, Accuracy: 0.873046875\n",
      "Batch: 71, Loss: 0.3913804292678833, Accuracy: 0.8642578125\n",
      "Batch: 72, Loss: 0.419217050075531, Accuracy: 0.8583984375\n",
      "Batch: 73, Loss: 0.38598328828811646, Accuracy: 0.8828125\n",
      "Batch: 74, Loss: 0.4041537642478943, Accuracy: 0.8642578125\n",
      "Batch: 75, Loss: 0.34998297691345215, Accuracy: 0.8828125\n",
      "Batch: 76, Loss: 0.36008137464523315, Accuracy: 0.8759765625\n",
      "Batch: 77, Loss: 0.4057449698448181, Accuracy: 0.8779296875\n",
      "Batch: 78, Loss: 0.3938905894756317, Accuracy: 0.8623046875\n",
      "Batch: 79, Loss: 0.3774813413619995, Accuracy: 0.8701171875\n",
      "Batch: 80, Loss: 0.3774554133415222, Accuracy: 0.8701171875\n",
      "Batch: 81, Loss: 0.41939809918403625, Accuracy: 0.8603515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 82, Loss: 0.38487377762794495, Accuracy: 0.86328125\n",
      "Batch: 83, Loss: 0.3443739414215088, Accuracy: 0.884765625\n",
      "Batch: 84, Loss: 0.37308382987976074, Accuracy: 0.8720703125\n",
      "Batch: 85, Loss: 0.4172152280807495, Accuracy: 0.8642578125\n",
      "Batch: 86, Loss: 0.38989418745040894, Accuracy: 0.8603515625\n",
      "Batch: 87, Loss: 0.38561540842056274, Accuracy: 0.87109375\n",
      "Batch: 88, Loss: 0.39814072847366333, Accuracy: 0.8671875\n",
      "Batch: 89, Loss: 0.3742177486419678, Accuracy: 0.87890625\n",
      "Batch: 90, Loss: 0.44697117805480957, Accuracy: 0.8505859375\n",
      "Batch: 91, Loss: 0.462909996509552, Accuracy: 0.8466796875\n",
      "Batch: 92, Loss: 0.40623730421066284, Accuracy: 0.865234375\n",
      "Batch: 93, Loss: 0.4556933045387268, Accuracy: 0.8486328125\n",
      "Batch: 94, Loss: 0.4545748233795166, Accuracy: 0.8466796875\n",
      "Batch: 95, Loss: 0.44659584760665894, Accuracy: 0.8525390625\n",
      "Batch: 96, Loss: 0.4028294086456299, Accuracy: 0.87109375\n",
      "Batch: 97, Loss: 0.35393741726875305, Accuracy: 0.88671875\n",
      "Batch: 98, Loss: 0.4140707850456238, Accuracy: 0.86328125\n",
      "Batch: 99, Loss: 0.3785881996154785, Accuracy: 0.8671875\n",
      "Batch: 100, Loss: 0.40861839056015015, Accuracy: 0.865234375\n",
      "Batch: 101, Loss: 0.4151822626590729, Accuracy: 0.859375\n",
      "Batch: 102, Loss: 0.40638938546180725, Accuracy: 0.873046875\n",
      "Batch: 103, Loss: 0.40096819400787354, Accuracy: 0.869140625\n",
      "Batch: 104, Loss: 0.4141417145729065, Accuracy: 0.8662109375\n",
      "Batch: 105, Loss: 0.32320186495780945, Accuracy: 0.892578125\n",
      "Batch: 106, Loss: 0.41736847162246704, Accuracy: 0.8671875\n",
      "Batch: 107, Loss: 0.3618922531604767, Accuracy: 0.875\n",
      "Batch: 108, Loss: 0.3505735695362091, Accuracy: 0.8818359375\n",
      "Batch: 109, Loss: 0.3039616346359253, Accuracy: 0.8984375\n",
      "Batch: 110, Loss: 0.3204214572906494, Accuracy: 0.904296875\n",
      "Batch: 111, Loss: 0.3989187777042389, Accuracy: 0.8662109375\n",
      "Batch: 112, Loss: 0.41457733511924744, Accuracy: 0.8525390625\n",
      "Epoch 47/90\n",
      "Batch: 1, Loss: 0.4901835322380066, Accuracy: 0.8544921875\n",
      "Batch: 2, Loss: 0.41423192620277405, Accuracy: 0.8662109375\n",
      "Batch: 3, Loss: 0.4235152006149292, Accuracy: 0.8623046875\n",
      "Batch: 4, Loss: 0.380113422870636, Accuracy: 0.8720703125\n",
      "Batch: 5, Loss: 0.35802850127220154, Accuracy: 0.8837890625\n",
      "Batch: 6, Loss: 0.40159374475479126, Accuracy: 0.87890625\n",
      "Batch: 7, Loss: 0.38107383251190186, Accuracy: 0.875\n",
      "Batch: 8, Loss: 0.34632936120033264, Accuracy: 0.8955078125\n",
      "Batch: 9, Loss: 0.4137462079524994, Accuracy: 0.86328125\n",
      "Batch: 10, Loss: 0.42808201909065247, Accuracy: 0.85546875\n",
      "Batch: 11, Loss: 0.3990747034549713, Accuracy: 0.8681640625\n",
      "Batch: 12, Loss: 0.35063573718070984, Accuracy: 0.880859375\n",
      "Batch: 13, Loss: 0.33517277240753174, Accuracy: 0.888671875\n",
      "Batch: 14, Loss: 0.3919367790222168, Accuracy: 0.8740234375\n",
      "Batch: 15, Loss: 0.37098515033721924, Accuracy: 0.876953125\n",
      "Batch: 16, Loss: 0.3864489793777466, Accuracy: 0.8828125\n",
      "Batch: 17, Loss: 0.4122510850429535, Accuracy: 0.8642578125\n",
      "Batch: 18, Loss: 0.34895437955856323, Accuracy: 0.8896484375\n",
      "Batch: 19, Loss: 0.3495612144470215, Accuracy: 0.8837890625\n",
      "Batch: 20, Loss: 0.39697152376174927, Accuracy: 0.861328125\n",
      "Batch: 21, Loss: 0.43157151341438293, Accuracy: 0.849609375\n",
      "Batch: 22, Loss: 0.3475283086299896, Accuracy: 0.8916015625\n",
      "Batch: 23, Loss: 0.433149129152298, Accuracy: 0.865234375\n",
      "Batch: 24, Loss: 0.4243101477622986, Accuracy: 0.8466796875\n",
      "Batch: 25, Loss: 0.4543010890483856, Accuracy: 0.8486328125\n",
      "Batch: 26, Loss: 0.4508984386920929, Accuracy: 0.8525390625\n",
      "Batch: 27, Loss: 0.4543672204017639, Accuracy: 0.853515625\n",
      "Batch: 28, Loss: 0.4191867709159851, Accuracy: 0.8525390625\n",
      "Batch: 29, Loss: 0.45845168828964233, Accuracy: 0.859375\n",
      "Batch: 30, Loss: 0.376799076795578, Accuracy: 0.8779296875\n",
      "Batch: 31, Loss: 0.40979522466659546, Accuracy: 0.857421875\n",
      "Batch: 32, Loss: 0.3815821409225464, Accuracy: 0.8642578125\n",
      "Batch: 33, Loss: 0.3717450201511383, Accuracy: 0.87109375\n",
      "Batch: 34, Loss: 0.3662421405315399, Accuracy: 0.88671875\n",
      "Batch: 35, Loss: 0.3976142406463623, Accuracy: 0.8564453125\n",
      "Batch: 36, Loss: 0.45648229122161865, Accuracy: 0.8525390625\n",
      "Batch: 37, Loss: 0.3606017827987671, Accuracy: 0.8701171875\n",
      "Batch: 38, Loss: 0.40594708919525146, Accuracy: 0.86328125\n",
      "Batch: 39, Loss: 0.38428354263305664, Accuracy: 0.8642578125\n",
      "Batch: 40, Loss: 0.3881247341632843, Accuracy: 0.8662109375\n",
      "Batch: 41, Loss: 0.45732173323631287, Accuracy: 0.8427734375\n",
      "Batch: 42, Loss: 0.40774741768836975, Accuracy: 0.8564453125\n",
      "Batch: 43, Loss: 0.3597055971622467, Accuracy: 0.8740234375\n",
      "Batch: 44, Loss: 0.3757482171058655, Accuracy: 0.876953125\n",
      "Batch: 45, Loss: 0.39989542961120605, Accuracy: 0.865234375\n",
      "Batch: 46, Loss: 0.4210536777973175, Accuracy: 0.853515625\n",
      "Batch: 47, Loss: 0.41084402799606323, Accuracy: 0.8603515625\n",
      "Batch: 48, Loss: 0.4382312297821045, Accuracy: 0.8603515625\n",
      "Batch: 49, Loss: 0.4383668303489685, Accuracy: 0.8564453125\n",
      "Batch: 50, Loss: 0.34479764103889465, Accuracy: 0.8857421875\n",
      "Batch: 51, Loss: 0.39196860790252686, Accuracy: 0.8779296875\n",
      "Batch: 52, Loss: 0.4063279628753662, Accuracy: 0.8818359375\n",
      "Batch: 53, Loss: 0.4773721694946289, Accuracy: 0.8388671875\n",
      "Batch: 54, Loss: 0.4239438474178314, Accuracy: 0.861328125\n",
      "Batch: 55, Loss: 0.4239844083786011, Accuracy: 0.8642578125\n",
      "Batch: 56, Loss: 0.3698061406612396, Accuracy: 0.869140625\n",
      "Batch: 57, Loss: 0.4048580527305603, Accuracy: 0.8642578125\n",
      "Batch: 58, Loss: 0.44600534439086914, Accuracy: 0.859375\n",
      "Batch: 59, Loss: 0.4115961790084839, Accuracy: 0.8564453125\n",
      "Batch: 60, Loss: 0.3948841392993927, Accuracy: 0.8642578125\n",
      "Batch: 61, Loss: 0.3871462941169739, Accuracy: 0.8681640625\n",
      "Batch: 62, Loss: 0.40568315982818604, Accuracy: 0.876953125\n",
      "Batch: 63, Loss: 0.3405359387397766, Accuracy: 0.8896484375\n",
      "Batch: 64, Loss: 0.41554197669029236, Accuracy: 0.8662109375\n",
      "Batch: 65, Loss: 0.3681158125400543, Accuracy: 0.869140625\n",
      "Batch: 66, Loss: 0.35524120926856995, Accuracy: 0.8857421875\n",
      "Batch: 67, Loss: 0.3519863784313202, Accuracy: 0.8857421875\n",
      "Batch: 68, Loss: 0.37817591428756714, Accuracy: 0.8671875\n",
      "Batch: 69, Loss: 0.34976089000701904, Accuracy: 0.884765625\n",
      "Batch: 70, Loss: 0.35693222284317017, Accuracy: 0.8876953125\n",
      "Batch: 71, Loss: 0.38944682478904724, Accuracy: 0.875\n",
      "Batch: 72, Loss: 0.41298964619636536, Accuracy: 0.865234375\n",
      "Batch: 73, Loss: 0.4006534218788147, Accuracy: 0.859375\n",
      "Batch: 74, Loss: 0.38513192534446716, Accuracy: 0.876953125\n",
      "Batch: 75, Loss: 0.3422347903251648, Accuracy: 0.8759765625\n",
      "Batch: 76, Loss: 0.3388444185256958, Accuracy: 0.8828125\n",
      "Batch: 77, Loss: 0.39666199684143066, Accuracy: 0.8818359375\n",
      "Batch: 78, Loss: 0.4101819396018982, Accuracy: 0.8642578125\n",
      "Batch: 79, Loss: 0.38317668437957764, Accuracy: 0.88671875\n",
      "Batch: 80, Loss: 0.3381020128726959, Accuracy: 0.88671875\n",
      "Batch: 81, Loss: 0.3756988048553467, Accuracy: 0.8720703125\n",
      "Batch: 82, Loss: 0.3951343297958374, Accuracy: 0.8623046875\n",
      "Batch: 83, Loss: 0.33099597692489624, Accuracy: 0.876953125\n",
      "Batch: 84, Loss: 0.3917447328567505, Accuracy: 0.8740234375\n",
      "Batch: 85, Loss: 0.4120188057422638, Accuracy: 0.8671875\n",
      "Batch: 86, Loss: 0.37743276357650757, Accuracy: 0.8779296875\n",
      "Batch: 87, Loss: 0.3602510094642639, Accuracy: 0.873046875\n",
      "Batch: 88, Loss: 0.38335132598876953, Accuracy: 0.8681640625\n",
      "Batch: 89, Loss: 0.36805057525634766, Accuracy: 0.869140625\n",
      "Batch: 90, Loss: 0.4608412981033325, Accuracy: 0.841796875\n",
      "Batch: 91, Loss: 0.43366384506225586, Accuracy: 0.8515625\n",
      "Batch: 92, Loss: 0.39957869052886963, Accuracy: 0.857421875\n",
      "Batch: 93, Loss: 0.44305726885795593, Accuracy: 0.8564453125\n",
      "Batch: 94, Loss: 0.45244482159614563, Accuracy: 0.8505859375\n",
      "Batch: 95, Loss: 0.4295860528945923, Accuracy: 0.8505859375\n",
      "Batch: 96, Loss: 0.3727080821990967, Accuracy: 0.873046875\n",
      "Batch: 97, Loss: 0.37252023816108704, Accuracy: 0.875\n",
      "Batch: 98, Loss: 0.41408127546310425, Accuracy: 0.859375\n",
      "Batch: 99, Loss: 0.3558005094528198, Accuracy: 0.865234375\n",
      "Batch: 100, Loss: 0.39643946290016174, Accuracy: 0.86328125\n",
      "Batch: 101, Loss: 0.4030178487300873, Accuracy: 0.861328125\n",
      "Batch: 102, Loss: 0.3666834831237793, Accuracy: 0.87890625\n",
      "Batch: 103, Loss: 0.3844118118286133, Accuracy: 0.88671875\n",
      "Batch: 104, Loss: 0.41254526376724243, Accuracy: 0.869140625\n",
      "Batch: 105, Loss: 0.33684515953063965, Accuracy: 0.8876953125\n",
      "Batch: 106, Loss: 0.4226950407028198, Accuracy: 0.8564453125\n",
      "Batch: 107, Loss: 0.38432320952415466, Accuracy: 0.873046875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 108, Loss: 0.36422544717788696, Accuracy: 0.892578125\n",
      "Batch: 109, Loss: 0.29929834604263306, Accuracy: 0.9072265625\n",
      "Batch: 110, Loss: 0.33345359563827515, Accuracy: 0.8955078125\n",
      "Batch: 111, Loss: 0.37791693210601807, Accuracy: 0.884765625\n",
      "Batch: 112, Loss: 0.3679593503475189, Accuracy: 0.87890625\n",
      "Epoch 48/90\n",
      "Batch: 1, Loss: 0.5166316032409668, Accuracy: 0.8466796875\n",
      "Batch: 2, Loss: 0.39777594804763794, Accuracy: 0.876953125\n",
      "Batch: 3, Loss: 0.3978733420372009, Accuracy: 0.8564453125\n",
      "Batch: 4, Loss: 0.36726975440979004, Accuracy: 0.880859375\n",
      "Batch: 5, Loss: 0.3340652585029602, Accuracy: 0.8857421875\n",
      "Batch: 6, Loss: 0.4023350477218628, Accuracy: 0.8779296875\n",
      "Batch: 7, Loss: 0.367903470993042, Accuracy: 0.884765625\n",
      "Batch: 8, Loss: 0.3346068263053894, Accuracy: 0.88671875\n",
      "Batch: 9, Loss: 0.40820950269699097, Accuracy: 0.87109375\n",
      "Batch: 10, Loss: 0.39076924324035645, Accuracy: 0.859375\n",
      "Batch: 11, Loss: 0.3762325644493103, Accuracy: 0.880859375\n",
      "Batch: 12, Loss: 0.3369019031524658, Accuracy: 0.8876953125\n",
      "Batch: 13, Loss: 0.3403548300266266, Accuracy: 0.888671875\n",
      "Batch: 14, Loss: 0.37859463691711426, Accuracy: 0.87890625\n",
      "Batch: 15, Loss: 0.3790234923362732, Accuracy: 0.873046875\n",
      "Batch: 16, Loss: 0.39014583826065063, Accuracy: 0.869140625\n",
      "Batch: 17, Loss: 0.39110738039016724, Accuracy: 0.8681640625\n",
      "Batch: 18, Loss: 0.33685699105262756, Accuracy: 0.892578125\n",
      "Batch: 19, Loss: 0.35228776931762695, Accuracy: 0.8876953125\n",
      "Batch: 20, Loss: 0.38531458377838135, Accuracy: 0.86328125\n",
      "Batch: 21, Loss: 0.3821086287498474, Accuracy: 0.8681640625\n",
      "Batch: 22, Loss: 0.36373645067214966, Accuracy: 0.884765625\n",
      "Batch: 23, Loss: 0.43700599670410156, Accuracy: 0.8525390625\n",
      "Batch: 24, Loss: 0.40361613035202026, Accuracy: 0.861328125\n",
      "Batch: 25, Loss: 0.44634392857551575, Accuracy: 0.8427734375\n",
      "Batch: 26, Loss: 0.43929362297058105, Accuracy: 0.859375\n",
      "Batch: 27, Loss: 0.43204471468925476, Accuracy: 0.8642578125\n",
      "Batch: 28, Loss: 0.3947429358959198, Accuracy: 0.869140625\n",
      "Batch: 29, Loss: 0.41903942823410034, Accuracy: 0.8662109375\n",
      "Batch: 30, Loss: 0.32389816641807556, Accuracy: 0.8994140625\n",
      "Batch: 31, Loss: 0.4255734086036682, Accuracy: 0.8564453125\n",
      "Batch: 32, Loss: 0.3696831166744232, Accuracy: 0.8671875\n",
      "Batch: 33, Loss: 0.3751095235347748, Accuracy: 0.8720703125\n",
      "Batch: 34, Loss: 0.3439655303955078, Accuracy: 0.880859375\n",
      "Batch: 35, Loss: 0.39023131132125854, Accuracy: 0.873046875\n",
      "Batch: 36, Loss: 0.4475768208503723, Accuracy: 0.8505859375\n",
      "Batch: 37, Loss: 0.357585608959198, Accuracy: 0.876953125\n",
      "Batch: 38, Loss: 0.41357481479644775, Accuracy: 0.8583984375\n",
      "Batch: 39, Loss: 0.37495553493499756, Accuracy: 0.8828125\n",
      "Batch: 40, Loss: 0.3704884350299835, Accuracy: 0.876953125\n",
      "Batch: 41, Loss: 0.40824106335639954, Accuracy: 0.86328125\n",
      "Batch: 42, Loss: 0.42104241251945496, Accuracy: 0.853515625\n",
      "Batch: 43, Loss: 0.3911694288253784, Accuracy: 0.87109375\n",
      "Batch: 44, Loss: 0.40832409262657166, Accuracy: 0.8642578125\n",
      "Batch: 45, Loss: 0.40836378931999207, Accuracy: 0.8642578125\n",
      "Batch: 46, Loss: 0.377968966960907, Accuracy: 0.869140625\n",
      "Batch: 47, Loss: 0.37511593103408813, Accuracy: 0.8740234375\n",
      "Batch: 48, Loss: 0.3982864022254944, Accuracy: 0.8720703125\n",
      "Batch: 49, Loss: 0.4357106685638428, Accuracy: 0.8603515625\n",
      "Batch: 50, Loss: 0.3245626389980316, Accuracy: 0.900390625\n",
      "Batch: 51, Loss: 0.3942028880119324, Accuracy: 0.8759765625\n",
      "Batch: 52, Loss: 0.395723819732666, Accuracy: 0.87109375\n",
      "Batch: 53, Loss: 0.46426135301589966, Accuracy: 0.84765625\n",
      "Batch: 54, Loss: 0.3972429633140564, Accuracy: 0.876953125\n",
      "Batch: 55, Loss: 0.41999292373657227, Accuracy: 0.857421875\n",
      "Batch: 56, Loss: 0.3823394477367401, Accuracy: 0.86328125\n",
      "Batch: 57, Loss: 0.4305564761161804, Accuracy: 0.85546875\n",
      "Batch: 58, Loss: 0.46923959255218506, Accuracy: 0.8408203125\n",
      "Batch: 59, Loss: 0.41559457778930664, Accuracy: 0.8515625\n",
      "Batch: 60, Loss: 0.40622442960739136, Accuracy: 0.86328125\n",
      "Batch: 61, Loss: 0.3726347088813782, Accuracy: 0.884765625\n",
      "Batch: 62, Loss: 0.40122637152671814, Accuracy: 0.8740234375\n",
      "Batch: 63, Loss: 0.3250022530555725, Accuracy: 0.896484375\n",
      "Batch: 64, Loss: 0.4220086336135864, Accuracy: 0.8486328125\n",
      "Batch: 65, Loss: 0.3696151077747345, Accuracy: 0.875\n",
      "Batch: 66, Loss: 0.3344670236110687, Accuracy: 0.8955078125\n",
      "Batch: 67, Loss: 0.3484829068183899, Accuracy: 0.8798828125\n",
      "Batch: 68, Loss: 0.3868412375450134, Accuracy: 0.8818359375\n",
      "Batch: 69, Loss: 0.3229057788848877, Accuracy: 0.8935546875\n",
      "Batch: 70, Loss: 0.3683686852455139, Accuracy: 0.869140625\n",
      "Batch: 71, Loss: 0.3636019229888916, Accuracy: 0.8779296875\n",
      "Batch: 72, Loss: 0.41113731265068054, Accuracy: 0.8681640625\n",
      "Batch: 73, Loss: 0.3957275450229645, Accuracy: 0.8720703125\n",
      "Batch: 74, Loss: 0.390211284160614, Accuracy: 0.8671875\n",
      "Batch: 75, Loss: 0.34307020902633667, Accuracy: 0.8740234375\n",
      "Batch: 76, Loss: 0.34351468086242676, Accuracy: 0.8818359375\n",
      "Batch: 77, Loss: 0.3767443001270294, Accuracy: 0.875\n",
      "Batch: 78, Loss: 0.3775355815887451, Accuracy: 0.87890625\n",
      "Batch: 79, Loss: 0.36316898465156555, Accuracy: 0.8837890625\n",
      "Batch: 80, Loss: 0.3396971523761749, Accuracy: 0.890625\n",
      "Batch: 81, Loss: 0.40189555287361145, Accuracy: 0.8671875\n",
      "Batch: 82, Loss: 0.3885411024093628, Accuracy: 0.869140625\n",
      "Batch: 83, Loss: 0.33007314801216125, Accuracy: 0.8935546875\n",
      "Batch: 84, Loss: 0.3610066771507263, Accuracy: 0.873046875\n",
      "Batch: 85, Loss: 0.4017106592655182, Accuracy: 0.8740234375\n",
      "Batch: 86, Loss: 0.3722129464149475, Accuracy: 0.8720703125\n",
      "Batch: 87, Loss: 0.3689817786216736, Accuracy: 0.87890625\n",
      "Batch: 88, Loss: 0.3868258595466614, Accuracy: 0.8720703125\n",
      "Batch: 89, Loss: 0.35854071378707886, Accuracy: 0.87890625\n",
      "Batch: 90, Loss: 0.43147534132003784, Accuracy: 0.8623046875\n",
      "Batch: 91, Loss: 0.45105159282684326, Accuracy: 0.845703125\n",
      "Batch: 92, Loss: 0.42399895191192627, Accuracy: 0.853515625\n",
      "Batch: 93, Loss: 0.42345958948135376, Accuracy: 0.8623046875\n",
      "Batch: 94, Loss: 0.4189755320549011, Accuracy: 0.8515625\n",
      "Batch: 95, Loss: 0.42439955472946167, Accuracy: 0.845703125\n",
      "Batch: 96, Loss: 0.376801073551178, Accuracy: 0.876953125\n",
      "Batch: 97, Loss: 0.36941131949424744, Accuracy: 0.865234375\n",
      "Batch: 98, Loss: 0.41482746601104736, Accuracy: 0.8544921875\n",
      "Batch: 99, Loss: 0.3402060568332672, Accuracy: 0.8779296875\n",
      "Batch: 100, Loss: 0.37467581033706665, Accuracy: 0.865234375\n",
      "Batch: 101, Loss: 0.3904497027397156, Accuracy: 0.8623046875\n",
      "Batch: 102, Loss: 0.3895604610443115, Accuracy: 0.869140625\n",
      "Batch: 103, Loss: 0.3924208879470825, Accuracy: 0.880859375\n",
      "Batch: 104, Loss: 0.38037383556365967, Accuracy: 0.8759765625\n",
      "Batch: 105, Loss: 0.31757375597953796, Accuracy: 0.8896484375\n",
      "Batch: 106, Loss: 0.39197659492492676, Accuracy: 0.8740234375\n",
      "Batch: 107, Loss: 0.36995768547058105, Accuracy: 0.8701171875\n",
      "Batch: 108, Loss: 0.3702705502510071, Accuracy: 0.869140625\n",
      "Batch: 109, Loss: 0.3017420172691345, Accuracy: 0.9013671875\n",
      "Batch: 110, Loss: 0.33916014432907104, Accuracy: 0.8984375\n",
      "Batch: 111, Loss: 0.40235698223114014, Accuracy: 0.875\n",
      "Batch: 112, Loss: 0.3721691370010376, Accuracy: 0.87109375\n",
      "Epoch 49/90\n",
      "Batch: 1, Loss: 0.5131039619445801, Accuracy: 0.8486328125\n",
      "Batch: 2, Loss: 0.42307913303375244, Accuracy: 0.8623046875\n",
      "Batch: 3, Loss: 0.38693517446517944, Accuracy: 0.876953125\n",
      "Batch: 4, Loss: 0.3685786724090576, Accuracy: 0.8798828125\n",
      "Batch: 5, Loss: 0.32081538438796997, Accuracy: 0.892578125\n",
      "Batch: 6, Loss: 0.39589864015579224, Accuracy: 0.8642578125\n",
      "Batch: 7, Loss: 0.3631506860256195, Accuracy: 0.87109375\n",
      "Batch: 8, Loss: 0.3615696132183075, Accuracy: 0.890625\n",
      "Batch: 9, Loss: 0.3637109398841858, Accuracy: 0.8818359375\n",
      "Batch: 10, Loss: 0.3925163447856903, Accuracy: 0.8662109375\n",
      "Batch: 11, Loss: 0.37599456310272217, Accuracy: 0.875\n",
      "Batch: 12, Loss: 0.3368748426437378, Accuracy: 0.8837890625\n",
      "Batch: 13, Loss: 0.32595789432525635, Accuracy: 0.8935546875\n",
      "Batch: 14, Loss: 0.3797512948513031, Accuracy: 0.8779296875\n",
      "Batch: 15, Loss: 0.37013208866119385, Accuracy: 0.8740234375\n",
      "Batch: 16, Loss: 0.40145355463027954, Accuracy: 0.8818359375\n",
      "Batch: 17, Loss: 0.38917025923728943, Accuracy: 0.8671875\n",
      "Batch: 18, Loss: 0.3526071608066559, Accuracy: 0.8720703125\n",
      "Batch: 19, Loss: 0.34290167689323425, Accuracy: 0.892578125\n",
      "Batch: 20, Loss: 0.3934522867202759, Accuracy: 0.8544921875\n",
      "Batch: 21, Loss: 0.3893982768058777, Accuracy: 0.87890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 22, Loss: 0.35830649733543396, Accuracy: 0.8837890625\n",
      "Batch: 23, Loss: 0.41873544454574585, Accuracy: 0.8583984375\n",
      "Batch: 24, Loss: 0.4263066053390503, Accuracy: 0.8544921875\n",
      "Batch: 25, Loss: 0.41307926177978516, Accuracy: 0.8505859375\n",
      "Batch: 26, Loss: 0.4159144163131714, Accuracy: 0.87109375\n",
      "Batch: 27, Loss: 0.4353172183036804, Accuracy: 0.8486328125\n",
      "Batch: 28, Loss: 0.394193172454834, Accuracy: 0.87109375\n",
      "Batch: 29, Loss: 0.4163879156112671, Accuracy: 0.87109375\n",
      "Batch: 30, Loss: 0.3589223027229309, Accuracy: 0.8857421875\n",
      "Batch: 31, Loss: 0.3907884955406189, Accuracy: 0.8759765625\n",
      "Batch: 32, Loss: 0.37146878242492676, Accuracy: 0.8701171875\n",
      "Batch: 33, Loss: 0.38693568110466003, Accuracy: 0.8603515625\n",
      "Batch: 34, Loss: 0.3481579124927521, Accuracy: 0.8837890625\n",
      "Batch: 35, Loss: 0.36099952459335327, Accuracy: 0.8759765625\n",
      "Batch: 36, Loss: 0.4262702465057373, Accuracy: 0.86328125\n",
      "Batch: 37, Loss: 0.34175795316696167, Accuracy: 0.87890625\n",
      "Batch: 38, Loss: 0.387673020362854, Accuracy: 0.8564453125\n",
      "Batch: 39, Loss: 0.36446017026901245, Accuracy: 0.884765625\n",
      "Batch: 40, Loss: 0.35801318287849426, Accuracy: 0.8818359375\n",
      "Batch: 41, Loss: 0.425922155380249, Accuracy: 0.8515625\n",
      "Batch: 42, Loss: 0.39449983835220337, Accuracy: 0.86328125\n",
      "Batch: 43, Loss: 0.3779553771018982, Accuracy: 0.869140625\n",
      "Batch: 44, Loss: 0.38260263204574585, Accuracy: 0.8759765625\n",
      "Batch: 45, Loss: 0.44933170080184937, Accuracy: 0.845703125\n",
      "Batch: 46, Loss: 0.35314980149269104, Accuracy: 0.8837890625\n",
      "Batch: 47, Loss: 0.3819153904914856, Accuracy: 0.8623046875\n",
      "Batch: 48, Loss: 0.39874619245529175, Accuracy: 0.87109375\n",
      "Batch: 49, Loss: 0.41107383370399475, Accuracy: 0.8671875\n",
      "Batch: 50, Loss: 0.32560551166534424, Accuracy: 0.890625\n",
      "Batch: 51, Loss: 0.3652160167694092, Accuracy: 0.8759765625\n",
      "Batch: 52, Loss: 0.36765938997268677, Accuracy: 0.8779296875\n",
      "Batch: 53, Loss: 0.45382159948349, Accuracy: 0.8408203125\n",
      "Batch: 54, Loss: 0.40832188725471497, Accuracy: 0.8671875\n",
      "Batch: 55, Loss: 0.4047047793865204, Accuracy: 0.8623046875\n",
      "Batch: 56, Loss: 0.3664700984954834, Accuracy: 0.876953125\n",
      "Batch: 57, Loss: 0.40051817893981934, Accuracy: 0.8671875\n",
      "Batch: 58, Loss: 0.4393203556537628, Accuracy: 0.8515625\n",
      "Batch: 59, Loss: 0.43126410245895386, Accuracy: 0.85546875\n",
      "Batch: 60, Loss: 0.3949868083000183, Accuracy: 0.861328125\n",
      "Batch: 61, Loss: 0.38776373863220215, Accuracy: 0.8681640625\n",
      "Batch: 62, Loss: 0.3961004614830017, Accuracy: 0.869140625\n",
      "Batch: 63, Loss: 0.3334125578403473, Accuracy: 0.880859375\n",
      "Batch: 64, Loss: 0.4117102324962616, Accuracy: 0.8564453125\n",
      "Batch: 65, Loss: 0.3866810202598572, Accuracy: 0.865234375\n",
      "Batch: 66, Loss: 0.3322213888168335, Accuracy: 0.8984375\n",
      "Batch: 67, Loss: 0.3664981722831726, Accuracy: 0.8857421875\n",
      "Batch: 68, Loss: 0.37785762548446655, Accuracy: 0.873046875\n",
      "Batch: 69, Loss: 0.32938605546951294, Accuracy: 0.888671875\n",
      "Batch: 70, Loss: 0.33707159757614136, Accuracy: 0.8935546875\n",
      "Batch: 71, Loss: 0.32552245259284973, Accuracy: 0.896484375\n",
      "Batch: 72, Loss: 0.3910682201385498, Accuracy: 0.869140625\n",
      "Batch: 73, Loss: 0.33441516757011414, Accuracy: 0.8896484375\n",
      "Batch: 74, Loss: 0.35468101501464844, Accuracy: 0.8828125\n",
      "Batch: 75, Loss: 0.34112513065338135, Accuracy: 0.8935546875\n",
      "Batch: 76, Loss: 0.29441380500793457, Accuracy: 0.900390625\n",
      "Batch: 77, Loss: 0.36954396963119507, Accuracy: 0.88671875\n",
      "Batch: 78, Loss: 0.3609864115715027, Accuracy: 0.8857421875\n",
      "Batch: 79, Loss: 0.3640008270740509, Accuracy: 0.896484375\n",
      "Batch: 80, Loss: 0.3552471399307251, Accuracy: 0.8740234375\n",
      "Batch: 81, Loss: 0.4156142473220825, Accuracy: 0.8642578125\n",
      "Batch: 82, Loss: 0.38053250312805176, Accuracy: 0.8681640625\n",
      "Batch: 83, Loss: 0.3211015462875366, Accuracy: 0.890625\n",
      "Batch: 84, Loss: 0.37577229738235474, Accuracy: 0.8681640625\n",
      "Batch: 85, Loss: 0.40518027544021606, Accuracy: 0.8779296875\n",
      "Batch: 86, Loss: 0.35990211367607117, Accuracy: 0.87109375\n",
      "Batch: 87, Loss: 0.34014347195625305, Accuracy: 0.88671875\n",
      "Batch: 88, Loss: 0.41168761253356934, Accuracy: 0.8671875\n",
      "Batch: 89, Loss: 0.3682735860347748, Accuracy: 0.88671875\n",
      "Batch: 90, Loss: 0.4263618588447571, Accuracy: 0.85546875\n",
      "Batch: 91, Loss: 0.40823429822921753, Accuracy: 0.8623046875\n",
      "Batch: 92, Loss: 0.4077787399291992, Accuracy: 0.8603515625\n",
      "Batch: 93, Loss: 0.41001200675964355, Accuracy: 0.8603515625\n",
      "Batch: 94, Loss: 0.38055452704429626, Accuracy: 0.87109375\n",
      "Batch: 95, Loss: 0.4110966920852661, Accuracy: 0.8623046875\n",
      "Batch: 96, Loss: 0.33192306756973267, Accuracy: 0.90234375\n",
      "Batch: 97, Loss: 0.3422115445137024, Accuracy: 0.884765625\n",
      "Batch: 98, Loss: 0.3754305839538574, Accuracy: 0.8759765625\n",
      "Batch: 99, Loss: 0.32998088002204895, Accuracy: 0.88671875\n",
      "Batch: 100, Loss: 0.3684656620025635, Accuracy: 0.8837890625\n",
      "Batch: 101, Loss: 0.3814970850944519, Accuracy: 0.8642578125\n",
      "Batch: 102, Loss: 0.34338319301605225, Accuracy: 0.8876953125\n",
      "Batch: 103, Loss: 0.3620264530181885, Accuracy: 0.892578125\n",
      "Batch: 104, Loss: 0.386690616607666, Accuracy: 0.8779296875\n",
      "Batch: 105, Loss: 0.32704615592956543, Accuracy: 0.8828125\n",
      "Batch: 106, Loss: 0.3963181972503662, Accuracy: 0.8564453125\n",
      "Batch: 107, Loss: 0.34123605489730835, Accuracy: 0.8828125\n",
      "Batch: 108, Loss: 0.35501906275749207, Accuracy: 0.888671875\n",
      "Batch: 109, Loss: 0.3047274351119995, Accuracy: 0.896484375\n",
      "Batch: 110, Loss: 0.3207084536552429, Accuracy: 0.890625\n",
      "Batch: 111, Loss: 0.39039236307144165, Accuracy: 0.873046875\n",
      "Batch: 112, Loss: 0.3554638922214508, Accuracy: 0.8662109375\n",
      "Epoch 50/90\n",
      "Batch: 1, Loss: 0.44405311346054077, Accuracy: 0.869140625\n",
      "Batch: 2, Loss: 0.36342576146125793, Accuracy: 0.8935546875\n",
      "Batch: 3, Loss: 0.38987356424331665, Accuracy: 0.884765625\n",
      "Batch: 4, Loss: 0.32857561111450195, Accuracy: 0.8916015625\n",
      "Batch: 5, Loss: 0.31938934326171875, Accuracy: 0.8994140625\n",
      "Batch: 6, Loss: 0.3830321133136749, Accuracy: 0.880859375\n",
      "Batch: 7, Loss: 0.3507543206214905, Accuracy: 0.888671875\n",
      "Batch: 8, Loss: 0.29892975091934204, Accuracy: 0.9013671875\n",
      "Batch: 9, Loss: 0.34669339656829834, Accuracy: 0.8876953125\n",
      "Batch: 10, Loss: 0.37728944420814514, Accuracy: 0.8798828125\n",
      "Batch: 11, Loss: 0.3673863112926483, Accuracy: 0.8837890625\n",
      "Batch: 12, Loss: 0.31790250539779663, Accuracy: 0.89453125\n",
      "Batch: 13, Loss: 0.3063667416572571, Accuracy: 0.8984375\n",
      "Batch: 14, Loss: 0.36305034160614014, Accuracy: 0.87109375\n",
      "Batch: 15, Loss: 0.3501456379890442, Accuracy: 0.8837890625\n",
      "Batch: 16, Loss: 0.36419302225112915, Accuracy: 0.8828125\n",
      "Batch: 17, Loss: 0.3568241596221924, Accuracy: 0.875\n",
      "Batch: 18, Loss: 0.3389270603656769, Accuracy: 0.8837890625\n",
      "Batch: 19, Loss: 0.35194826126098633, Accuracy: 0.8837890625\n",
      "Batch: 20, Loss: 0.37772199511528015, Accuracy: 0.8671875\n",
      "Batch: 21, Loss: 0.3766593635082245, Accuracy: 0.87890625\n",
      "Batch: 22, Loss: 0.3317035436630249, Accuracy: 0.896484375\n",
      "Batch: 23, Loss: 0.39257872104644775, Accuracy: 0.873046875\n",
      "Batch: 24, Loss: 0.40491288900375366, Accuracy: 0.865234375\n",
      "Batch: 25, Loss: 0.41057735681533813, Accuracy: 0.8740234375\n",
      "Batch: 26, Loss: 0.41217750310897827, Accuracy: 0.8662109375\n",
      "Batch: 27, Loss: 0.42291274666786194, Accuracy: 0.865234375\n",
      "Batch: 28, Loss: 0.382434606552124, Accuracy: 0.8662109375\n",
      "Batch: 29, Loss: 0.3977826237678528, Accuracy: 0.8671875\n",
      "Batch: 30, Loss: 0.34332793951034546, Accuracy: 0.8828125\n",
      "Batch: 31, Loss: 0.3771318793296814, Accuracy: 0.8818359375\n",
      "Batch: 32, Loss: 0.3364425003528595, Accuracy: 0.892578125\n",
      "Batch: 33, Loss: 0.33966028690338135, Accuracy: 0.8818359375\n",
      "Batch: 34, Loss: 0.3538886308670044, Accuracy: 0.890625\n",
      "Batch: 35, Loss: 0.3549077808856964, Accuracy: 0.8798828125\n",
      "Batch: 36, Loss: 0.4135287404060364, Accuracy: 0.8671875\n",
      "Batch: 37, Loss: 0.32303357124328613, Accuracy: 0.8837890625\n",
      "Batch: 38, Loss: 0.3565381169319153, Accuracy: 0.8818359375\n",
      "Batch: 39, Loss: 0.36306557059288025, Accuracy: 0.873046875\n",
      "Batch: 40, Loss: 0.3609811067581177, Accuracy: 0.8818359375\n",
      "Batch: 41, Loss: 0.38201504945755005, Accuracy: 0.8720703125\n",
      "Batch: 42, Loss: 0.389504998922348, Accuracy: 0.865234375\n",
      "Batch: 43, Loss: 0.3837093114852905, Accuracy: 0.8740234375\n",
      "Batch: 44, Loss: 0.3716893196105957, Accuracy: 0.875\n",
      "Batch: 45, Loss: 0.4242996573448181, Accuracy: 0.8544921875\n",
      "Batch: 46, Loss: 0.378203809261322, Accuracy: 0.8681640625\n",
      "Batch: 47, Loss: 0.3466638922691345, Accuracy: 0.8857421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 48, Loss: 0.3772027790546417, Accuracy: 0.8740234375\n",
      "Batch: 49, Loss: 0.38928738236427307, Accuracy: 0.8671875\n",
      "Batch: 50, Loss: 0.32033318281173706, Accuracy: 0.8994140625\n",
      "Batch: 51, Loss: 0.33926719427108765, Accuracy: 0.88671875\n",
      "Batch: 52, Loss: 0.37568771839141846, Accuracy: 0.876953125\n",
      "Batch: 53, Loss: 0.4224550724029541, Accuracy: 0.8662109375\n",
      "Batch: 54, Loss: 0.36190536618232727, Accuracy: 0.888671875\n",
      "Batch: 55, Loss: 0.4034939110279083, Accuracy: 0.8583984375\n",
      "Batch: 56, Loss: 0.3670555353164673, Accuracy: 0.880859375\n",
      "Batch: 57, Loss: 0.41457855701446533, Accuracy: 0.859375\n",
      "Batch: 58, Loss: 0.4253857433795929, Accuracy: 0.8701171875\n",
      "Batch: 59, Loss: 0.38553914427757263, Accuracy: 0.8662109375\n",
      "Batch: 60, Loss: 0.3570652902126312, Accuracy: 0.87109375\n",
      "Batch: 61, Loss: 0.3458806872367859, Accuracy: 0.880859375\n",
      "Batch: 62, Loss: 0.37457793951034546, Accuracy: 0.87890625\n",
      "Batch: 63, Loss: 0.336372047662735, Accuracy: 0.8935546875\n",
      "Batch: 64, Loss: 0.38103175163269043, Accuracy: 0.873046875\n",
      "Batch: 65, Loss: 0.3912195563316345, Accuracy: 0.8544921875\n",
      "Batch: 66, Loss: 0.3300841450691223, Accuracy: 0.890625\n",
      "Batch: 67, Loss: 0.3440549373626709, Accuracy: 0.8935546875\n",
      "Batch: 68, Loss: 0.37299713492393494, Accuracy: 0.8779296875\n",
      "Batch: 69, Loss: 0.32622963190078735, Accuracy: 0.8974609375\n",
      "Batch: 70, Loss: 0.32793426513671875, Accuracy: 0.8935546875\n",
      "Batch: 71, Loss: 0.308921754360199, Accuracy: 0.90234375\n",
      "Batch: 72, Loss: 0.3864031732082367, Accuracy: 0.8740234375\n",
      "Batch: 73, Loss: 0.3577856421470642, Accuracy: 0.87890625\n",
      "Batch: 74, Loss: 0.3821687698364258, Accuracy: 0.8671875\n",
      "Batch: 75, Loss: 0.3263719081878662, Accuracy: 0.90234375\n",
      "Batch: 76, Loss: 0.31816017627716064, Accuracy: 0.8974609375\n",
      "Batch: 77, Loss: 0.35707002878189087, Accuracy: 0.884765625\n",
      "Batch: 78, Loss: 0.37209367752075195, Accuracy: 0.876953125\n",
      "Batch: 79, Loss: 0.3779183626174927, Accuracy: 0.88671875\n",
      "Batch: 80, Loss: 0.33534014225006104, Accuracy: 0.876953125\n",
      "Batch: 81, Loss: 0.3761512041091919, Accuracy: 0.87890625\n",
      "Batch: 82, Loss: 0.3612115979194641, Accuracy: 0.875\n",
      "Batch: 83, Loss: 0.3133939504623413, Accuracy: 0.8955078125\n",
      "Batch: 84, Loss: 0.35306793451309204, Accuracy: 0.8837890625\n",
      "Batch: 85, Loss: 0.37912559509277344, Accuracy: 0.875\n",
      "Batch: 86, Loss: 0.36124008893966675, Accuracy: 0.8681640625\n",
      "Batch: 87, Loss: 0.352743536233902, Accuracy: 0.8759765625\n",
      "Batch: 88, Loss: 0.365530788898468, Accuracy: 0.87109375\n",
      "Batch: 89, Loss: 0.36018797755241394, Accuracy: 0.8896484375\n",
      "Batch: 90, Loss: 0.4062865972518921, Accuracy: 0.8564453125\n",
      "Batch: 91, Loss: 0.4277219772338867, Accuracy: 0.85546875\n",
      "Batch: 92, Loss: 0.4112384021282196, Accuracy: 0.857421875\n",
      "Batch: 93, Loss: 0.3920208513736725, Accuracy: 0.8720703125\n",
      "Batch: 94, Loss: 0.39226531982421875, Accuracy: 0.8740234375\n",
      "Batch: 95, Loss: 0.376600980758667, Accuracy: 0.8701171875\n",
      "Batch: 96, Loss: 0.3335036635398865, Accuracy: 0.888671875\n",
      "Batch: 97, Loss: 0.3446755111217499, Accuracy: 0.8876953125\n",
      "Batch: 98, Loss: 0.36513224244117737, Accuracy: 0.8779296875\n",
      "Batch: 99, Loss: 0.33155596256256104, Accuracy: 0.8916015625\n",
      "Batch: 100, Loss: 0.366170734167099, Accuracy: 0.8662109375\n",
      "Batch: 101, Loss: 0.35489779710769653, Accuracy: 0.8798828125\n",
      "Batch: 102, Loss: 0.3526811897754669, Accuracy: 0.8837890625\n",
      "Batch: 103, Loss: 0.38163161277770996, Accuracy: 0.8564453125\n",
      "Batch: 104, Loss: 0.3682325482368469, Accuracy: 0.8857421875\n",
      "Batch: 105, Loss: 0.2935798764228821, Accuracy: 0.9033203125\n",
      "Batch: 106, Loss: 0.35954830050468445, Accuracy: 0.8701171875\n",
      "Batch: 107, Loss: 0.3134232759475708, Accuracy: 0.8916015625\n",
      "Batch: 108, Loss: 0.3339877128601074, Accuracy: 0.8857421875\n",
      "Batch: 109, Loss: 0.29238444566726685, Accuracy: 0.8984375\n",
      "Batch: 110, Loss: 0.3262571692466736, Accuracy: 0.896484375\n",
      "Batch: 111, Loss: 0.35285601019859314, Accuracy: 0.88671875\n",
      "Batch: 112, Loss: 0.35440653562545776, Accuracy: 0.875\n",
      "Saved Weights at epoch 50 to file Weights_50.h5\n",
      "Epoch 51/90\n",
      "Batch: 1, Loss: 0.4248354732990265, Accuracy: 0.8701171875\n",
      "Batch: 2, Loss: 0.359835147857666, Accuracy: 0.88671875\n",
      "Batch: 3, Loss: 0.349817156791687, Accuracy: 0.8896484375\n",
      "Batch: 4, Loss: 0.35241687297821045, Accuracy: 0.88671875\n",
      "Batch: 5, Loss: 0.30352094769477844, Accuracy: 0.89453125\n",
      "Batch: 6, Loss: 0.3527907729148865, Accuracy: 0.8837890625\n",
      "Batch: 7, Loss: 0.33687824010849, Accuracy: 0.8896484375\n",
      "Batch: 8, Loss: 0.30660247802734375, Accuracy: 0.9033203125\n",
      "Batch: 9, Loss: 0.36413416266441345, Accuracy: 0.87890625\n",
      "Batch: 10, Loss: 0.3648093342781067, Accuracy: 0.8720703125\n",
      "Batch: 11, Loss: 0.38089656829833984, Accuracy: 0.8701171875\n",
      "Batch: 12, Loss: 0.31525135040283203, Accuracy: 0.8994140625\n",
      "Batch: 13, Loss: 0.31408295035362244, Accuracy: 0.890625\n",
      "Batch: 14, Loss: 0.33805474638938904, Accuracy: 0.8896484375\n",
      "Batch: 15, Loss: 0.3494891822338104, Accuracy: 0.87890625\n",
      "Batch: 16, Loss: 0.3491228222846985, Accuracy: 0.876953125\n",
      "Batch: 17, Loss: 0.3533334732055664, Accuracy: 0.8779296875\n",
      "Batch: 18, Loss: 0.3397983908653259, Accuracy: 0.8857421875\n",
      "Batch: 19, Loss: 0.3540736436843872, Accuracy: 0.875\n",
      "Batch: 20, Loss: 0.3691727817058563, Accuracy: 0.8779296875\n",
      "Batch: 21, Loss: 0.35103508830070496, Accuracy: 0.87109375\n",
      "Batch: 22, Loss: 0.33659401535987854, Accuracy: 0.890625\n",
      "Batch: 23, Loss: 0.42650270462036133, Accuracy: 0.8681640625\n",
      "Batch: 24, Loss: 0.3852352797985077, Accuracy: 0.87109375\n",
      "Batch: 25, Loss: 0.38203343749046326, Accuracy: 0.861328125\n",
      "Batch: 26, Loss: 0.40529197454452515, Accuracy: 0.861328125\n",
      "Batch: 27, Loss: 0.415946364402771, Accuracy: 0.8720703125\n",
      "Batch: 28, Loss: 0.38223138451576233, Accuracy: 0.869140625\n",
      "Batch: 29, Loss: 0.39074793457984924, Accuracy: 0.8837890625\n",
      "Batch: 30, Loss: 0.31603944301605225, Accuracy: 0.890625\n",
      "Batch: 31, Loss: 0.38313454389572144, Accuracy: 0.8759765625\n",
      "Batch: 32, Loss: 0.3356660306453705, Accuracy: 0.8876953125\n",
      "Batch: 33, Loss: 0.3505137264728546, Accuracy: 0.8779296875\n",
      "Batch: 34, Loss: 0.3350996971130371, Accuracy: 0.8876953125\n",
      "Batch: 35, Loss: 0.3386423587799072, Accuracy: 0.88671875\n",
      "Batch: 36, Loss: 0.4016473591327667, Accuracy: 0.8740234375\n",
      "Batch: 37, Loss: 0.3249262571334839, Accuracy: 0.8857421875\n",
      "Batch: 38, Loss: 0.391379177570343, Accuracy: 0.869140625\n",
      "Batch: 39, Loss: 0.36928847432136536, Accuracy: 0.8837890625\n",
      "Batch: 40, Loss: 0.3752254843711853, Accuracy: 0.8740234375\n",
      "Batch: 41, Loss: 0.36397355794906616, Accuracy: 0.8779296875\n",
      "Batch: 42, Loss: 0.3659808933734894, Accuracy: 0.875\n",
      "Batch: 43, Loss: 0.3598264753818512, Accuracy: 0.880859375\n",
      "Batch: 44, Loss: 0.3484281301498413, Accuracy: 0.8857421875\n",
      "Batch: 45, Loss: 0.38405242562294006, Accuracy: 0.86328125\n",
      "Batch: 46, Loss: 0.3662615418434143, Accuracy: 0.8740234375\n",
      "Batch: 47, Loss: 0.34203284978866577, Accuracy: 0.8828125\n",
      "Batch: 48, Loss: 0.3651314079761505, Accuracy: 0.884765625\n",
      "Batch: 49, Loss: 0.3675154447555542, Accuracy: 0.8720703125\n",
      "Batch: 50, Loss: 0.2994154691696167, Accuracy: 0.904296875\n",
      "Batch: 51, Loss: 0.3265213966369629, Accuracy: 0.8984375\n",
      "Batch: 52, Loss: 0.38148099184036255, Accuracy: 0.8720703125\n",
      "Batch: 53, Loss: 0.41431647539138794, Accuracy: 0.86328125\n",
      "Batch: 54, Loss: 0.37330523133277893, Accuracy: 0.8740234375\n",
      "Batch: 55, Loss: 0.382700651884079, Accuracy: 0.8798828125\n",
      "Batch: 56, Loss: 0.3119054436683655, Accuracy: 0.9013671875\n",
      "Batch: 57, Loss: 0.36076515913009644, Accuracy: 0.8828125\n",
      "Batch: 58, Loss: 0.4393077790737152, Accuracy: 0.859375\n",
      "Batch: 59, Loss: 0.36975425481796265, Accuracy: 0.875\n",
      "Batch: 60, Loss: 0.3642624616622925, Accuracy: 0.8720703125\n",
      "Batch: 61, Loss: 0.36026903986930847, Accuracy: 0.8779296875\n",
      "Batch: 62, Loss: 0.3589191436767578, Accuracy: 0.8857421875\n",
      "Batch: 63, Loss: 0.2989463210105896, Accuracy: 0.8955078125\n",
      "Batch: 64, Loss: 0.3798387050628662, Accuracy: 0.87890625\n",
      "Batch: 65, Loss: 0.33583229780197144, Accuracy: 0.888671875\n",
      "Batch: 66, Loss: 0.28724557161331177, Accuracy: 0.8994140625\n",
      "Batch: 67, Loss: 0.3473677337169647, Accuracy: 0.8837890625\n",
      "Batch: 68, Loss: 0.3250415623188019, Accuracy: 0.8974609375\n",
      "Batch: 69, Loss: 0.30356818437576294, Accuracy: 0.904296875\n",
      "Batch: 70, Loss: 0.36651837825775146, Accuracy: 0.8837890625\n",
      "Batch: 71, Loss: 0.3323030471801758, Accuracy: 0.89453125\n",
      "Batch: 72, Loss: 0.3661186397075653, Accuracy: 0.87890625\n",
      "Batch: 73, Loss: 0.33568015694618225, Accuracy: 0.8935546875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 74, Loss: 0.34803080558776855, Accuracy: 0.87109375\n",
      "Batch: 75, Loss: 0.32083678245544434, Accuracy: 0.8857421875\n",
      "Batch: 76, Loss: 0.3288147747516632, Accuracy: 0.888671875\n",
      "Batch: 77, Loss: 0.3272418975830078, Accuracy: 0.896484375\n",
      "Batch: 78, Loss: 0.3346196413040161, Accuracy: 0.896484375\n",
      "Batch: 79, Loss: 0.3490724563598633, Accuracy: 0.8896484375\n",
      "Batch: 80, Loss: 0.33453816175460815, Accuracy: 0.888671875\n",
      "Batch: 81, Loss: 0.37511563301086426, Accuracy: 0.8740234375\n",
      "Batch: 82, Loss: 0.3603021502494812, Accuracy: 0.87890625\n",
      "Batch: 83, Loss: 0.30366581678390503, Accuracy: 0.8974609375\n",
      "Batch: 84, Loss: 0.3491261899471283, Accuracy: 0.8818359375\n",
      "Batch: 85, Loss: 0.37636131048202515, Accuracy: 0.87890625\n",
      "Batch: 86, Loss: 0.3464937210083008, Accuracy: 0.8818359375\n",
      "Batch: 87, Loss: 0.3300325274467468, Accuracy: 0.8779296875\n",
      "Batch: 88, Loss: 0.32878464460372925, Accuracy: 0.8896484375\n",
      "Batch: 89, Loss: 0.35092583298683167, Accuracy: 0.888671875\n",
      "Batch: 90, Loss: 0.3967564105987549, Accuracy: 0.8642578125\n",
      "Batch: 91, Loss: 0.39773768186569214, Accuracy: 0.86328125\n",
      "Batch: 92, Loss: 0.38862344622612, Accuracy: 0.8779296875\n",
      "Batch: 93, Loss: 0.42602092027664185, Accuracy: 0.8583984375\n",
      "Batch: 94, Loss: 0.38311371207237244, Accuracy: 0.8671875\n",
      "Batch: 95, Loss: 0.379417359828949, Accuracy: 0.8603515625\n",
      "Batch: 96, Loss: 0.32635408639907837, Accuracy: 0.900390625\n",
      "Batch: 97, Loss: 0.3256199359893799, Accuracy: 0.8857421875\n",
      "Batch: 98, Loss: 0.38279175758361816, Accuracy: 0.873046875\n",
      "Batch: 99, Loss: 0.32344743609428406, Accuracy: 0.8857421875\n",
      "Batch: 100, Loss: 0.34418785572052, Accuracy: 0.875\n",
      "Batch: 101, Loss: 0.37016862630844116, Accuracy: 0.8662109375\n",
      "Batch: 102, Loss: 0.3479974567890167, Accuracy: 0.8857421875\n",
      "Batch: 103, Loss: 0.34403663873672485, Accuracy: 0.8837890625\n",
      "Batch: 104, Loss: 0.3593568205833435, Accuracy: 0.8740234375\n",
      "Batch: 105, Loss: 0.3123396635055542, Accuracy: 0.87890625\n",
      "Batch: 106, Loss: 0.3588072657585144, Accuracy: 0.8828125\n",
      "Batch: 107, Loss: 0.32841742038726807, Accuracy: 0.8837890625\n",
      "Batch: 108, Loss: 0.3077612817287445, Accuracy: 0.9033203125\n",
      "Batch: 109, Loss: 0.2598649561405182, Accuracy: 0.9150390625\n",
      "Batch: 110, Loss: 0.31277263164520264, Accuracy: 0.89453125\n",
      "Batch: 111, Loss: 0.346088171005249, Accuracy: 0.884765625\n",
      "Batch: 112, Loss: 0.36302733421325684, Accuracy: 0.8740234375\n",
      "Epoch 52/90\n",
      "Batch: 1, Loss: 0.44912832975387573, Accuracy: 0.876953125\n",
      "Batch: 2, Loss: 0.3372015953063965, Accuracy: 0.88671875\n",
      "Batch: 3, Loss: 0.36842912435531616, Accuracy: 0.8828125\n",
      "Batch: 4, Loss: 0.3367183208465576, Accuracy: 0.892578125\n",
      "Batch: 5, Loss: 0.29910463094711304, Accuracy: 0.91015625\n",
      "Batch: 6, Loss: 0.3412708342075348, Accuracy: 0.890625\n",
      "Batch: 7, Loss: 0.3118031919002533, Accuracy: 0.9013671875\n",
      "Batch: 8, Loss: 0.31045472621917725, Accuracy: 0.8916015625\n",
      "Batch: 9, Loss: 0.352087140083313, Accuracy: 0.87890625\n",
      "Batch: 10, Loss: 0.40067288279533386, Accuracy: 0.8681640625\n",
      "Batch: 11, Loss: 0.37918955087661743, Accuracy: 0.8681640625\n",
      "Batch: 12, Loss: 0.323397159576416, Accuracy: 0.8798828125\n",
      "Batch: 13, Loss: 0.3045969307422638, Accuracy: 0.9052734375\n",
      "Batch: 14, Loss: 0.3542610704898834, Accuracy: 0.8837890625\n",
      "Batch: 15, Loss: 0.34296125173568726, Accuracy: 0.8857421875\n",
      "Batch: 16, Loss: 0.3253943920135498, Accuracy: 0.892578125\n",
      "Batch: 17, Loss: 0.3369443416595459, Accuracy: 0.890625\n",
      "Batch: 18, Loss: 0.3214643895626068, Accuracy: 0.89453125\n",
      "Batch: 19, Loss: 0.3129289746284485, Accuracy: 0.896484375\n",
      "Batch: 20, Loss: 0.38740891218185425, Accuracy: 0.861328125\n",
      "Batch: 21, Loss: 0.35602718591690063, Accuracy: 0.884765625\n",
      "Batch: 22, Loss: 0.33429163694381714, Accuracy: 0.8896484375\n",
      "Batch: 23, Loss: 0.3887975215911865, Accuracy: 0.873046875\n",
      "Batch: 24, Loss: 0.39275774359703064, Accuracy: 0.861328125\n",
      "Batch: 25, Loss: 0.3712320923805237, Accuracy: 0.8759765625\n",
      "Batch: 26, Loss: 0.4087032675743103, Accuracy: 0.8642578125\n",
      "Batch: 27, Loss: 0.43900203704833984, Accuracy: 0.857421875\n",
      "Batch: 28, Loss: 0.34994494915008545, Accuracy: 0.876953125\n",
      "Batch: 29, Loss: 0.3947804570198059, Accuracy: 0.875\n",
      "Batch: 30, Loss: 0.3409457802772522, Accuracy: 0.888671875\n",
      "Batch: 31, Loss: 0.3761080503463745, Accuracy: 0.8759765625\n",
      "Batch: 32, Loss: 0.32359519600868225, Accuracy: 0.8935546875\n",
      "Batch: 33, Loss: 0.3511959910392761, Accuracy: 0.8818359375\n",
      "Batch: 34, Loss: 0.3186552822589874, Accuracy: 0.892578125\n",
      "Batch: 35, Loss: 0.34688717126846313, Accuracy: 0.8916015625\n",
      "Batch: 36, Loss: 0.4047316014766693, Accuracy: 0.875\n",
      "Batch: 37, Loss: 0.31779199838638306, Accuracy: 0.904296875\n",
      "Batch: 38, Loss: 0.3449356257915497, Accuracy: 0.8798828125\n",
      "Batch: 39, Loss: 0.3392125964164734, Accuracy: 0.875\n",
      "Batch: 40, Loss: 0.3223281800746918, Accuracy: 0.8955078125\n",
      "Batch: 41, Loss: 0.363872766494751, Accuracy: 0.876953125\n",
      "Batch: 42, Loss: 0.3939517140388489, Accuracy: 0.861328125\n",
      "Batch: 43, Loss: 0.34665513038635254, Accuracy: 0.8876953125\n",
      "Batch: 44, Loss: 0.35149574279785156, Accuracy: 0.8857421875\n",
      "Batch: 45, Loss: 0.36363786458969116, Accuracy: 0.8720703125\n",
      "Batch: 46, Loss: 0.3439607620239258, Accuracy: 0.888671875\n",
      "Batch: 47, Loss: 0.3503163158893585, Accuracy: 0.88671875\n",
      "Batch: 48, Loss: 0.35353589057922363, Accuracy: 0.8837890625\n",
      "Batch: 49, Loss: 0.38315731287002563, Accuracy: 0.875\n",
      "Batch: 50, Loss: 0.3275810480117798, Accuracy: 0.8935546875\n",
      "Batch: 51, Loss: 0.3603552579879761, Accuracy: 0.88671875\n",
      "Batch: 52, Loss: 0.36047786474227905, Accuracy: 0.8740234375\n",
      "Batch: 53, Loss: 0.41846176981925964, Accuracy: 0.8681640625\n",
      "Batch: 54, Loss: 0.3924720585346222, Accuracy: 0.8701171875\n",
      "Batch: 55, Loss: 0.38231492042541504, Accuracy: 0.87890625\n",
      "Batch: 56, Loss: 0.31051933765411377, Accuracy: 0.890625\n",
      "Batch: 57, Loss: 0.38021576404571533, Accuracy: 0.8701171875\n",
      "Batch: 58, Loss: 0.42045849561691284, Accuracy: 0.8564453125\n",
      "Batch: 59, Loss: 0.39506906270980835, Accuracy: 0.857421875\n",
      "Batch: 60, Loss: 0.37964802980422974, Accuracy: 0.8701171875\n",
      "Batch: 61, Loss: 0.3479943871498108, Accuracy: 0.8759765625\n",
      "Batch: 62, Loss: 0.36010879278182983, Accuracy: 0.8759765625\n",
      "Batch: 63, Loss: 0.30742502212524414, Accuracy: 0.8984375\n",
      "Batch: 64, Loss: 0.3617568612098694, Accuracy: 0.8779296875\n",
      "Batch: 65, Loss: 0.33512675762176514, Accuracy: 0.8818359375\n",
      "Batch: 66, Loss: 0.31666114926338196, Accuracy: 0.896484375\n",
      "Batch: 67, Loss: 0.33359798789024353, Accuracy: 0.8857421875\n",
      "Batch: 68, Loss: 0.3246813416481018, Accuracy: 0.900390625\n",
      "Batch: 69, Loss: 0.3182138204574585, Accuracy: 0.9013671875\n",
      "Batch: 70, Loss: 0.3076092004776001, Accuracy: 0.9072265625\n",
      "Batch: 71, Loss: 0.3071852922439575, Accuracy: 0.8955078125\n",
      "Batch: 72, Loss: 0.3734494149684906, Accuracy: 0.880859375\n",
      "Batch: 73, Loss: 0.33644700050354004, Accuracy: 0.880859375\n",
      "Batch: 74, Loss: 0.33151671290397644, Accuracy: 0.88671875\n",
      "Batch: 75, Loss: 0.32560065388679504, Accuracy: 0.8896484375\n",
      "Batch: 76, Loss: 0.29233479499816895, Accuracy: 0.8916015625\n",
      "Batch: 77, Loss: 0.35603174567222595, Accuracy: 0.8798828125\n",
      "Batch: 78, Loss: 0.3410130739212036, Accuracy: 0.8837890625\n",
      "Batch: 79, Loss: 0.3246077597141266, Accuracy: 0.8974609375\n",
      "Batch: 80, Loss: 0.318629652261734, Accuracy: 0.8876953125\n",
      "Batch: 81, Loss: 0.348740816116333, Accuracy: 0.8798828125\n",
      "Batch: 82, Loss: 0.3263050317764282, Accuracy: 0.880859375\n",
      "Batch: 83, Loss: 0.30439674854278564, Accuracy: 0.90234375\n",
      "Batch: 84, Loss: 0.3392752408981323, Accuracy: 0.8818359375\n",
      "Batch: 85, Loss: 0.3389722406864166, Accuracy: 0.8837890625\n",
      "Batch: 86, Loss: 0.33740904927253723, Accuracy: 0.876953125\n",
      "Batch: 87, Loss: 0.3277168869972229, Accuracy: 0.8994140625\n",
      "Batch: 88, Loss: 0.3583557605743408, Accuracy: 0.8671875\n",
      "Batch: 89, Loss: 0.3219645619392395, Accuracy: 0.8857421875\n",
      "Batch: 90, Loss: 0.40500199794769287, Accuracy: 0.865234375\n",
      "Batch: 91, Loss: 0.3940291404724121, Accuracy: 0.8623046875\n",
      "Batch: 92, Loss: 0.3869549334049225, Accuracy: 0.869140625\n",
      "Batch: 93, Loss: 0.3719547390937805, Accuracy: 0.861328125\n",
      "Batch: 94, Loss: 0.37079736590385437, Accuracy: 0.8740234375\n",
      "Batch: 95, Loss: 0.38124901056289673, Accuracy: 0.865234375\n",
      "Batch: 96, Loss: 0.3681349754333496, Accuracy: 0.8720703125\n",
      "Batch: 97, Loss: 0.329240620136261, Accuracy: 0.8828125\n",
      "Batch: 98, Loss: 0.3654276132583618, Accuracy: 0.8759765625\n",
      "Batch: 99, Loss: 0.32318031787872314, Accuracy: 0.87890625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 100, Loss: 0.35865092277526855, Accuracy: 0.8740234375\n",
      "Batch: 101, Loss: 0.3563363254070282, Accuracy: 0.87890625\n",
      "Batch: 102, Loss: 0.3498399257659912, Accuracy: 0.890625\n",
      "Batch: 103, Loss: 0.37120577692985535, Accuracy: 0.876953125\n",
      "Batch: 104, Loss: 0.3587179481983185, Accuracy: 0.8818359375\n",
      "Batch: 105, Loss: 0.30013251304626465, Accuracy: 0.8974609375\n",
      "Batch: 106, Loss: 0.35834968090057373, Accuracy: 0.87890625\n",
      "Batch: 107, Loss: 0.3182508945465088, Accuracy: 0.8896484375\n",
      "Batch: 108, Loss: 0.33936789631843567, Accuracy: 0.8857421875\n",
      "Batch: 109, Loss: 0.2684180736541748, Accuracy: 0.9091796875\n",
      "Batch: 110, Loss: 0.30035436153411865, Accuracy: 0.900390625\n",
      "Batch: 111, Loss: 0.3687499165534973, Accuracy: 0.880859375\n",
      "Batch: 112, Loss: 0.35579362511634827, Accuracy: 0.880859375\n",
      "Epoch 53/90\n",
      "Batch: 1, Loss: 0.4323365390300751, Accuracy: 0.8779296875\n",
      "Batch: 2, Loss: 0.3698105812072754, Accuracy: 0.880859375\n",
      "Batch: 3, Loss: 0.3318904638290405, Accuracy: 0.8955078125\n",
      "Batch: 4, Loss: 0.3273734152317047, Accuracy: 0.8955078125\n",
      "Batch: 5, Loss: 0.29711952805519104, Accuracy: 0.908203125\n",
      "Batch: 6, Loss: 0.3522627055644989, Accuracy: 0.9013671875\n",
      "Batch: 7, Loss: 0.3402758240699768, Accuracy: 0.88671875\n",
      "Batch: 8, Loss: 0.30323708057403564, Accuracy: 0.9052734375\n",
      "Batch: 9, Loss: 0.3153301477432251, Accuracy: 0.8984375\n",
      "Batch: 10, Loss: 0.38794323801994324, Accuracy: 0.861328125\n",
      "Batch: 11, Loss: 0.3387666344642639, Accuracy: 0.890625\n",
      "Batch: 12, Loss: 0.32202398777008057, Accuracy: 0.8935546875\n",
      "Batch: 13, Loss: 0.28296515345573425, Accuracy: 0.900390625\n",
      "Batch: 14, Loss: 0.3550042510032654, Accuracy: 0.884765625\n",
      "Batch: 15, Loss: 0.35841286182403564, Accuracy: 0.8759765625\n",
      "Batch: 16, Loss: 0.35461974143981934, Accuracy: 0.888671875\n",
      "Batch: 17, Loss: 0.357962965965271, Accuracy: 0.88671875\n",
      "Batch: 18, Loss: 0.3311479389667511, Accuracy: 0.8818359375\n",
      "Batch: 19, Loss: 0.3191383481025696, Accuracy: 0.8837890625\n",
      "Batch: 20, Loss: 0.3420861065387726, Accuracy: 0.8818359375\n",
      "Batch: 21, Loss: 0.3547983765602112, Accuracy: 0.8759765625\n",
      "Batch: 22, Loss: 0.3378525376319885, Accuracy: 0.8955078125\n",
      "Batch: 23, Loss: 0.3843424320220947, Accuracy: 0.87890625\n",
      "Batch: 24, Loss: 0.34829533100128174, Accuracy: 0.8798828125\n",
      "Batch: 25, Loss: 0.400005578994751, Accuracy: 0.85546875\n",
      "Batch: 26, Loss: 0.38630107045173645, Accuracy: 0.865234375\n",
      "Batch: 27, Loss: 0.4103110134601593, Accuracy: 0.859375\n",
      "Batch: 28, Loss: 0.3927081227302551, Accuracy: 0.873046875\n",
      "Batch: 29, Loss: 0.4082273840904236, Accuracy: 0.8720703125\n",
      "Batch: 30, Loss: 0.32097190618515015, Accuracy: 0.8916015625\n",
      "Batch: 31, Loss: 0.3498404622077942, Accuracy: 0.8857421875\n",
      "Batch: 32, Loss: 0.32768961787223816, Accuracy: 0.89453125\n",
      "Batch: 33, Loss: 0.3300930857658386, Accuracy: 0.892578125\n",
      "Batch: 34, Loss: 0.30962300300598145, Accuracy: 0.8955078125\n",
      "Batch: 35, Loss: 0.35709714889526367, Accuracy: 0.8779296875\n",
      "Batch: 36, Loss: 0.39042627811431885, Accuracy: 0.8681640625\n",
      "Batch: 37, Loss: 0.29141998291015625, Accuracy: 0.8974609375\n",
      "Batch: 38, Loss: 0.3632354736328125, Accuracy: 0.8779296875\n",
      "Batch: 39, Loss: 0.3487696051597595, Accuracy: 0.8779296875\n",
      "Batch: 40, Loss: 0.3382921516895294, Accuracy: 0.888671875\n",
      "Batch: 41, Loss: 0.33837127685546875, Accuracy: 0.88671875\n",
      "Batch: 42, Loss: 0.35482022166252136, Accuracy: 0.8828125\n",
      "Batch: 43, Loss: 0.3436652421951294, Accuracy: 0.876953125\n",
      "Batch: 44, Loss: 0.3473799228668213, Accuracy: 0.884765625\n",
      "Batch: 45, Loss: 0.3667503595352173, Accuracy: 0.876953125\n",
      "Batch: 46, Loss: 0.33977246284484863, Accuracy: 0.892578125\n",
      "Batch: 47, Loss: 0.3496145009994507, Accuracy: 0.8818359375\n",
      "Batch: 48, Loss: 0.37867289781570435, Accuracy: 0.8759765625\n",
      "Batch: 49, Loss: 0.3966748118400574, Accuracy: 0.87890625\n",
      "Batch: 50, Loss: 0.2880452275276184, Accuracy: 0.91796875\n",
      "Batch: 51, Loss: 0.32638663053512573, Accuracy: 0.8994140625\n",
      "Batch: 52, Loss: 0.3561254143714905, Accuracy: 0.890625\n",
      "Batch: 53, Loss: 0.39098334312438965, Accuracy: 0.8662109375\n",
      "Batch: 54, Loss: 0.37325263023376465, Accuracy: 0.876953125\n",
      "Batch: 55, Loss: 0.38218802213668823, Accuracy: 0.880859375\n",
      "Batch: 56, Loss: 0.3453187942504883, Accuracy: 0.8857421875\n",
      "Batch: 57, Loss: 0.366879940032959, Accuracy: 0.8818359375\n",
      "Batch: 58, Loss: 0.4036431312561035, Accuracy: 0.8671875\n",
      "Batch: 59, Loss: 0.38892555236816406, Accuracy: 0.8671875\n",
      "Batch: 60, Loss: 0.3375953137874603, Accuracy: 0.8935546875\n",
      "Batch: 61, Loss: 0.32497745752334595, Accuracy: 0.8876953125\n",
      "Batch: 62, Loss: 0.3287178575992584, Accuracy: 0.904296875\n",
      "Batch: 63, Loss: 0.3019171357154846, Accuracy: 0.904296875\n",
      "Batch: 64, Loss: 0.33858615159988403, Accuracy: 0.88671875\n",
      "Batch: 65, Loss: 0.3392780125141144, Accuracy: 0.8818359375\n",
      "Batch: 66, Loss: 0.3055434823036194, Accuracy: 0.896484375\n",
      "Batch: 67, Loss: 0.3327748775482178, Accuracy: 0.884765625\n",
      "Batch: 68, Loss: 0.3330821394920349, Accuracy: 0.890625\n",
      "Batch: 69, Loss: 0.27812454104423523, Accuracy: 0.9072265625\n",
      "Batch: 70, Loss: 0.311883807182312, Accuracy: 0.8994140625\n",
      "Batch: 71, Loss: 0.32840192317962646, Accuracy: 0.8818359375\n",
      "Batch: 72, Loss: 0.3535141944885254, Accuracy: 0.888671875\n",
      "Batch: 73, Loss: 0.32919740676879883, Accuracy: 0.888671875\n",
      "Batch: 74, Loss: 0.33550381660461426, Accuracy: 0.8974609375\n",
      "Batch: 75, Loss: 0.3290165662765503, Accuracy: 0.8876953125\n",
      "Batch: 76, Loss: 0.28756892681121826, Accuracy: 0.9052734375\n",
      "Batch: 77, Loss: 0.31465545296669006, Accuracy: 0.8994140625\n",
      "Batch: 78, Loss: 0.34234029054641724, Accuracy: 0.890625\n",
      "Batch: 79, Loss: 0.3199922442436218, Accuracy: 0.892578125\n",
      "Batch: 80, Loss: 0.318281888961792, Accuracy: 0.8935546875\n",
      "Batch: 81, Loss: 0.3372865319252014, Accuracy: 0.88671875\n",
      "Batch: 82, Loss: 0.36371466517448425, Accuracy: 0.875\n",
      "Batch: 83, Loss: 0.281394362449646, Accuracy: 0.90625\n",
      "Batch: 84, Loss: 0.2999219000339508, Accuracy: 0.8955078125\n",
      "Batch: 85, Loss: 0.3560790419578552, Accuracy: 0.8876953125\n",
      "Batch: 86, Loss: 0.32486075162887573, Accuracy: 0.8916015625\n",
      "Batch: 87, Loss: 0.322432279586792, Accuracy: 0.8935546875\n",
      "Batch: 88, Loss: 0.37731218338012695, Accuracy: 0.8759765625\n",
      "Batch: 89, Loss: 0.3335973620414734, Accuracy: 0.890625\n",
      "Batch: 90, Loss: 0.37278398871421814, Accuracy: 0.8837890625\n",
      "Batch: 91, Loss: 0.37461841106414795, Accuracy: 0.869140625\n",
      "Batch: 92, Loss: 0.34866219758987427, Accuracy: 0.8837890625\n",
      "Batch: 93, Loss: 0.3609876036643982, Accuracy: 0.8798828125\n",
      "Batch: 94, Loss: 0.3693391680717468, Accuracy: 0.8740234375\n",
      "Batch: 95, Loss: 0.33736035227775574, Accuracy: 0.89453125\n",
      "Batch: 96, Loss: 0.3328932821750641, Accuracy: 0.888671875\n",
      "Batch: 97, Loss: 0.33230382204055786, Accuracy: 0.880859375\n",
      "Batch: 98, Loss: 0.37013643980026245, Accuracy: 0.8720703125\n",
      "Batch: 99, Loss: 0.3027697801589966, Accuracy: 0.896484375\n",
      "Batch: 100, Loss: 0.35600990056991577, Accuracy: 0.8779296875\n",
      "Batch: 101, Loss: 0.3868454694747925, Accuracy: 0.87109375\n",
      "Batch: 102, Loss: 0.34550002217292786, Accuracy: 0.8955078125\n",
      "Batch: 103, Loss: 0.36384317278862, Accuracy: 0.87890625\n",
      "Batch: 104, Loss: 0.3430931568145752, Accuracy: 0.8818359375\n",
      "Batch: 105, Loss: 0.27847641706466675, Accuracy: 0.90234375\n",
      "Batch: 106, Loss: 0.33852410316467285, Accuracy: 0.880859375\n",
      "Batch: 107, Loss: 0.310599684715271, Accuracy: 0.8974609375\n",
      "Batch: 108, Loss: 0.3209473490715027, Accuracy: 0.8974609375\n",
      "Batch: 109, Loss: 0.251637727022171, Accuracy: 0.9150390625\n",
      "Batch: 110, Loss: 0.31101879477500916, Accuracy: 0.904296875\n",
      "Batch: 111, Loss: 0.34816867113113403, Accuracy: 0.8798828125\n",
      "Batch: 112, Loss: 0.3243982195854187, Accuracy: 0.8857421875\n",
      "Epoch 54/90\n",
      "Batch: 1, Loss: 0.431593656539917, Accuracy: 0.8798828125\n",
      "Batch: 2, Loss: 0.354625940322876, Accuracy: 0.8857421875\n",
      "Batch: 3, Loss: 0.32121336460113525, Accuracy: 0.8974609375\n",
      "Batch: 4, Loss: 0.3093779683113098, Accuracy: 0.9072265625\n",
      "Batch: 5, Loss: 0.2770390808582306, Accuracy: 0.91015625\n",
      "Batch: 6, Loss: 0.32582440972328186, Accuracy: 0.8955078125\n",
      "Batch: 7, Loss: 0.32755112648010254, Accuracy: 0.896484375\n",
      "Batch: 8, Loss: 0.27210235595703125, Accuracy: 0.912109375\n",
      "Batch: 9, Loss: 0.3405986428260803, Accuracy: 0.8876953125\n",
      "Batch: 10, Loss: 0.396229088306427, Accuracy: 0.8671875\n",
      "Batch: 11, Loss: 0.3636021018028259, Accuracy: 0.8779296875\n",
      "Batch: 12, Loss: 0.29556843638420105, Accuracy: 0.90234375\n",
      "Batch: 13, Loss: 0.2974774241447449, Accuracy: 0.900390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 14, Loss: 0.3581240177154541, Accuracy: 0.876953125\n",
      "Batch: 15, Loss: 0.32060229778289795, Accuracy: 0.8818359375\n",
      "Batch: 16, Loss: 0.31280890107154846, Accuracy: 0.896484375\n",
      "Batch: 17, Loss: 0.3534533381462097, Accuracy: 0.8720703125\n",
      "Batch: 18, Loss: 0.3374682068824768, Accuracy: 0.890625\n",
      "Batch: 19, Loss: 0.335429847240448, Accuracy: 0.892578125\n",
      "Batch: 20, Loss: 0.347415566444397, Accuracy: 0.87890625\n",
      "Batch: 21, Loss: 0.34816232323646545, Accuracy: 0.8857421875\n",
      "Batch: 22, Loss: 0.32633063197135925, Accuracy: 0.8955078125\n",
      "Batch: 23, Loss: 0.35596758127212524, Accuracy: 0.8720703125\n",
      "Batch: 24, Loss: 0.37388694286346436, Accuracy: 0.8779296875\n",
      "Batch: 25, Loss: 0.3735223412513733, Accuracy: 0.875\n",
      "Batch: 26, Loss: 0.35885506868362427, Accuracy: 0.880859375\n",
      "Batch: 27, Loss: 0.39855653047561646, Accuracy: 0.8662109375\n",
      "Batch: 28, Loss: 0.3618336319923401, Accuracy: 0.8779296875\n",
      "Batch: 29, Loss: 0.3804537355899811, Accuracy: 0.869140625\n",
      "Batch: 30, Loss: 0.32203078269958496, Accuracy: 0.8837890625\n",
      "Batch: 31, Loss: 0.3432988226413727, Accuracy: 0.8857421875\n",
      "Batch: 32, Loss: 0.29580235481262207, Accuracy: 0.900390625\n",
      "Batch: 33, Loss: 0.36185961961746216, Accuracy: 0.8798828125\n",
      "Batch: 34, Loss: 0.3143739700317383, Accuracy: 0.9013671875\n",
      "Batch: 35, Loss: 0.3086303472518921, Accuracy: 0.892578125\n",
      "Batch: 36, Loss: 0.3525772988796234, Accuracy: 0.892578125\n",
      "Batch: 37, Loss: 0.3059745132923126, Accuracy: 0.89453125\n",
      "Batch: 38, Loss: 0.32956427335739136, Accuracy: 0.89453125\n",
      "Batch: 39, Loss: 0.31391429901123047, Accuracy: 0.88671875\n",
      "Batch: 40, Loss: 0.31781262159347534, Accuracy: 0.9013671875\n",
      "Batch: 41, Loss: 0.3356005847454071, Accuracy: 0.8876953125\n",
      "Batch: 42, Loss: 0.36215436458587646, Accuracy: 0.8662109375\n",
      "Batch: 43, Loss: 0.3268452286720276, Accuracy: 0.892578125\n",
      "Batch: 44, Loss: 0.32872113585472107, Accuracy: 0.8955078125\n",
      "Batch: 45, Loss: 0.3761409521102905, Accuracy: 0.8818359375\n",
      "Batch: 46, Loss: 0.3642255663871765, Accuracy: 0.8779296875\n",
      "Batch: 47, Loss: 0.3220032751560211, Accuracy: 0.8896484375\n",
      "Batch: 48, Loss: 0.34080052375793457, Accuracy: 0.88671875\n",
      "Batch: 49, Loss: 0.36870473623275757, Accuracy: 0.8798828125\n",
      "Batch: 50, Loss: 0.29465535283088684, Accuracy: 0.90625\n",
      "Batch: 51, Loss: 0.3338102102279663, Accuracy: 0.890625\n",
      "Batch: 52, Loss: 0.3267320394515991, Accuracy: 0.8935546875\n",
      "Batch: 53, Loss: 0.3831510841846466, Accuracy: 0.87109375\n",
      "Batch: 54, Loss: 0.33014971017837524, Accuracy: 0.9013671875\n",
      "Batch: 55, Loss: 0.39391034841537476, Accuracy: 0.8779296875\n",
      "Batch: 56, Loss: 0.32316309213638306, Accuracy: 0.875\n",
      "Batch: 57, Loss: 0.37133359909057617, Accuracy: 0.87109375\n",
      "Batch: 58, Loss: 0.38123780488967896, Accuracy: 0.875\n",
      "Batch: 59, Loss: 0.3654797077178955, Accuracy: 0.8828125\n",
      "Batch: 60, Loss: 0.3332373797893524, Accuracy: 0.8798828125\n",
      "Batch: 61, Loss: 0.32768428325653076, Accuracy: 0.8916015625\n",
      "Batch: 62, Loss: 0.37356695532798767, Accuracy: 0.875\n",
      "Batch: 63, Loss: 0.2946465015411377, Accuracy: 0.8984375\n",
      "Batch: 64, Loss: 0.3507678508758545, Accuracy: 0.8896484375\n",
      "Batch: 65, Loss: 0.31777894496917725, Accuracy: 0.888671875\n",
      "Batch: 66, Loss: 0.27618828415870667, Accuracy: 0.9150390625\n",
      "Batch: 67, Loss: 0.2944366931915283, Accuracy: 0.90234375\n",
      "Batch: 68, Loss: 0.31256523728370667, Accuracy: 0.912109375\n",
      "Batch: 69, Loss: 0.2919864058494568, Accuracy: 0.9052734375\n",
      "Batch: 70, Loss: 0.3172415494918823, Accuracy: 0.9013671875\n",
      "Batch: 71, Loss: 0.3212350904941559, Accuracy: 0.8896484375\n",
      "Batch: 72, Loss: 0.34010517597198486, Accuracy: 0.8984375\n",
      "Batch: 73, Loss: 0.3375278115272522, Accuracy: 0.888671875\n",
      "Batch: 74, Loss: 0.332711786031723, Accuracy: 0.875\n",
      "Batch: 75, Loss: 0.2956055998802185, Accuracy: 0.9072265625\n",
      "Batch: 76, Loss: 0.2715834677219391, Accuracy: 0.916015625\n",
      "Batch: 77, Loss: 0.3450462818145752, Accuracy: 0.884765625\n",
      "Batch: 78, Loss: 0.3319363296031952, Accuracy: 0.8857421875\n",
      "Batch: 79, Loss: 0.33256494998931885, Accuracy: 0.8837890625\n",
      "Batch: 80, Loss: 0.3223663568496704, Accuracy: 0.8974609375\n",
      "Batch: 81, Loss: 0.358265221118927, Accuracy: 0.8876953125\n",
      "Batch: 82, Loss: 0.3205950856208801, Accuracy: 0.8798828125\n",
      "Batch: 83, Loss: 0.2890847325325012, Accuracy: 0.91015625\n",
      "Batch: 84, Loss: 0.3211713135242462, Accuracy: 0.8935546875\n",
      "Batch: 85, Loss: 0.35609638690948486, Accuracy: 0.884765625\n",
      "Batch: 86, Loss: 0.30557721853256226, Accuracy: 0.89453125\n",
      "Batch: 87, Loss: 0.3102930784225464, Accuracy: 0.8984375\n",
      "Batch: 88, Loss: 0.33417490124702454, Accuracy: 0.88671875\n",
      "Batch: 89, Loss: 0.34150582551956177, Accuracy: 0.880859375\n",
      "Batch: 90, Loss: 0.37295442819595337, Accuracy: 0.8701171875\n",
      "Batch: 91, Loss: 0.37431600689888, Accuracy: 0.875\n",
      "Batch: 92, Loss: 0.3661502003669739, Accuracy: 0.87109375\n",
      "Batch: 93, Loss: 0.3626159429550171, Accuracy: 0.8740234375\n",
      "Batch: 94, Loss: 0.36938542127609253, Accuracy: 0.8857421875\n",
      "Batch: 95, Loss: 0.373865008354187, Accuracy: 0.8701171875\n",
      "Batch: 96, Loss: 0.3375172019004822, Accuracy: 0.8857421875\n",
      "Batch: 97, Loss: 0.2784339189529419, Accuracy: 0.8974609375\n",
      "Batch: 98, Loss: 0.3487088084220886, Accuracy: 0.880859375\n",
      "Batch: 99, Loss: 0.29434576630592346, Accuracy: 0.9033203125\n",
      "Batch: 100, Loss: 0.3460107445716858, Accuracy: 0.87890625\n",
      "Batch: 101, Loss: 0.3360292911529541, Accuracy: 0.888671875\n",
      "Batch: 102, Loss: 0.3300955891609192, Accuracy: 0.88671875\n",
      "Batch: 103, Loss: 0.3227043151855469, Accuracy: 0.892578125\n",
      "Batch: 104, Loss: 0.3324918746948242, Accuracy: 0.8828125\n",
      "Batch: 105, Loss: 0.28478899598121643, Accuracy: 0.9013671875\n",
      "Batch: 106, Loss: 0.3655623197555542, Accuracy: 0.8759765625\n",
      "Batch: 107, Loss: 0.3177959620952606, Accuracy: 0.8984375\n",
      "Batch: 108, Loss: 0.32128244638442993, Accuracy: 0.8994140625\n",
      "Batch: 109, Loss: 0.2753012180328369, Accuracy: 0.90234375\n",
      "Batch: 110, Loss: 0.3057557940483093, Accuracy: 0.8994140625\n",
      "Batch: 111, Loss: 0.3521665036678314, Accuracy: 0.8896484375\n",
      "Batch: 112, Loss: 0.2991176247596741, Accuracy: 0.904296875\n",
      "Epoch 55/90\n",
      "Batch: 1, Loss: 0.4115539789199829, Accuracy: 0.8828125\n",
      "Batch: 2, Loss: 0.34043264389038086, Accuracy: 0.88671875\n",
      "Batch: 3, Loss: 0.34458139538764954, Accuracy: 0.890625\n",
      "Batch: 4, Loss: 0.29405057430267334, Accuracy: 0.908203125\n",
      "Batch: 5, Loss: 0.28566646575927734, Accuracy: 0.908203125\n",
      "Batch: 6, Loss: 0.3053906559944153, Accuracy: 0.9033203125\n",
      "Batch: 7, Loss: 0.2995208501815796, Accuracy: 0.9013671875\n",
      "Batch: 8, Loss: 0.28214192390441895, Accuracy: 0.9052734375\n",
      "Batch: 9, Loss: 0.31794267892837524, Accuracy: 0.88671875\n",
      "Batch: 10, Loss: 0.3689698576927185, Accuracy: 0.8759765625\n",
      "Batch: 11, Loss: 0.3797077536582947, Accuracy: 0.876953125\n",
      "Batch: 12, Loss: 0.30665862560272217, Accuracy: 0.892578125\n",
      "Batch: 13, Loss: 0.2979385256767273, Accuracy: 0.9033203125\n",
      "Batch: 14, Loss: 0.32108402252197266, Accuracy: 0.8876953125\n",
      "Batch: 15, Loss: 0.3255666494369507, Accuracy: 0.8828125\n",
      "Batch: 16, Loss: 0.3437281847000122, Accuracy: 0.8896484375\n",
      "Batch: 17, Loss: 0.3177573084831238, Accuracy: 0.890625\n",
      "Batch: 18, Loss: 0.30840861797332764, Accuracy: 0.8994140625\n",
      "Batch: 19, Loss: 0.2907567620277405, Accuracy: 0.90625\n",
      "Batch: 20, Loss: 0.3206292390823364, Accuracy: 0.88671875\n",
      "Batch: 21, Loss: 0.325522243976593, Accuracy: 0.888671875\n",
      "Batch: 22, Loss: 0.3146694600582123, Accuracy: 0.89453125\n",
      "Batch: 23, Loss: 0.36242640018463135, Accuracy: 0.8828125\n",
      "Batch: 24, Loss: 0.3687472939491272, Accuracy: 0.86328125\n",
      "Batch: 25, Loss: 0.4105972647666931, Accuracy: 0.849609375\n",
      "Batch: 26, Loss: 0.38290494680404663, Accuracy: 0.875\n",
      "Batch: 27, Loss: 0.3987421989440918, Accuracy: 0.865234375\n",
      "Batch: 28, Loss: 0.3460485637187958, Accuracy: 0.8818359375\n",
      "Batch: 29, Loss: 0.40714675188064575, Accuracy: 0.8740234375\n",
      "Batch: 30, Loss: 0.28970810770988464, Accuracy: 0.8974609375\n",
      "Batch: 31, Loss: 0.32665976881980896, Accuracy: 0.8837890625\n",
      "Batch: 32, Loss: 0.3309870958328247, Accuracy: 0.8935546875\n",
      "Batch: 33, Loss: 0.3338778018951416, Accuracy: 0.884765625\n",
      "Batch: 34, Loss: 0.30721962451934814, Accuracy: 0.8974609375\n",
      "Batch: 35, Loss: 0.32709014415740967, Accuracy: 0.892578125\n",
      "Batch: 36, Loss: 0.3768610954284668, Accuracy: 0.8818359375\n",
      "Batch: 37, Loss: 0.296789288520813, Accuracy: 0.8896484375\n",
      "Batch: 38, Loss: 0.3178418278694153, Accuracy: 0.8984375\n",
      "Batch: 39, Loss: 0.31425726413726807, Accuracy: 0.8857421875\n",
      "Batch: 40, Loss: 0.3215070962905884, Accuracy: 0.9013671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 41, Loss: 0.35555005073547363, Accuracy: 0.8837890625\n",
      "Batch: 42, Loss: 0.3442312479019165, Accuracy: 0.8857421875\n",
      "Batch: 43, Loss: 0.35577449202537537, Accuracy: 0.876953125\n",
      "Batch: 44, Loss: 0.33876264095306396, Accuracy: 0.8876953125\n",
      "Batch: 45, Loss: 0.384340763092041, Accuracy: 0.8740234375\n",
      "Batch: 46, Loss: 0.34537482261657715, Accuracy: 0.8798828125\n",
      "Batch: 47, Loss: 0.2975870668888092, Accuracy: 0.8935546875\n",
      "Batch: 48, Loss: 0.3530672788619995, Accuracy: 0.87890625\n",
      "Batch: 49, Loss: 0.36724966764450073, Accuracy: 0.876953125\n",
      "Batch: 50, Loss: 0.2963429093360901, Accuracy: 0.9091796875\n",
      "Batch: 51, Loss: 0.3437022268772125, Accuracy: 0.8955078125\n",
      "Batch: 52, Loss: 0.33485931158065796, Accuracy: 0.8955078125\n",
      "Batch: 53, Loss: 0.4135710597038269, Accuracy: 0.8623046875\n",
      "Batch: 54, Loss: 0.3545953631401062, Accuracy: 0.8876953125\n",
      "Batch: 55, Loss: 0.33091941475868225, Accuracy: 0.8876953125\n",
      "Batch: 56, Loss: 0.3189730942249298, Accuracy: 0.890625\n",
      "Batch: 57, Loss: 0.3740817904472351, Accuracy: 0.869140625\n",
      "Batch: 58, Loss: 0.33849912881851196, Accuracy: 0.888671875\n",
      "Batch: 59, Loss: 0.36566871404647827, Accuracy: 0.8798828125\n",
      "Batch: 60, Loss: 0.3843478560447693, Accuracy: 0.8759765625\n",
      "Batch: 61, Loss: 0.33338144421577454, Accuracy: 0.8896484375\n",
      "Batch: 62, Loss: 0.3466314673423767, Accuracy: 0.8955078125\n",
      "Batch: 63, Loss: 0.2889208495616913, Accuracy: 0.904296875\n",
      "Batch: 64, Loss: 0.3406792879104614, Accuracy: 0.88671875\n",
      "Batch: 65, Loss: 0.32153868675231934, Accuracy: 0.8818359375\n",
      "Batch: 66, Loss: 0.29037564992904663, Accuracy: 0.9072265625\n",
      "Batch: 67, Loss: 0.32556837797164917, Accuracy: 0.8837890625\n",
      "Batch: 68, Loss: 0.3209482431411743, Accuracy: 0.904296875\n",
      "Batch: 69, Loss: 0.2793387174606323, Accuracy: 0.908203125\n",
      "Batch: 70, Loss: 0.28394854068756104, Accuracy: 0.9072265625\n",
      "Batch: 71, Loss: 0.29362159967422485, Accuracy: 0.8974609375\n",
      "Batch: 72, Loss: 0.3583788573741913, Accuracy: 0.8896484375\n",
      "Batch: 73, Loss: 0.3130751848220825, Accuracy: 0.8896484375\n",
      "Batch: 74, Loss: 0.2836991250514984, Accuracy: 0.9052734375\n",
      "Batch: 75, Loss: 0.3107341527938843, Accuracy: 0.896484375\n",
      "Batch: 76, Loss: 0.265531063079834, Accuracy: 0.9111328125\n",
      "Batch: 77, Loss: 0.325421541929245, Accuracy: 0.89453125\n",
      "Batch: 78, Loss: 0.34126612544059753, Accuracy: 0.888671875\n",
      "Batch: 79, Loss: 0.32396477460861206, Accuracy: 0.8984375\n",
      "Batch: 80, Loss: 0.3045102059841156, Accuracy: 0.8955078125\n",
      "Batch: 81, Loss: 0.3736293315887451, Accuracy: 0.876953125\n",
      "Batch: 82, Loss: 0.3162243962287903, Accuracy: 0.888671875\n",
      "Batch: 83, Loss: 0.28641682863235474, Accuracy: 0.900390625\n",
      "Batch: 84, Loss: 0.32406917214393616, Accuracy: 0.8857421875\n",
      "Batch: 85, Loss: 0.3323668837547302, Accuracy: 0.888671875\n",
      "Batch: 86, Loss: 0.3169586658477783, Accuracy: 0.88671875\n",
      "Batch: 87, Loss: 0.27764931321144104, Accuracy: 0.91015625\n",
      "Batch: 88, Loss: 0.34146618843078613, Accuracy: 0.8896484375\n",
      "Batch: 89, Loss: 0.3261467218399048, Accuracy: 0.8828125\n",
      "Batch: 90, Loss: 0.36371344327926636, Accuracy: 0.8681640625\n",
      "Batch: 91, Loss: 0.3607810139656067, Accuracy: 0.869140625\n",
      "Batch: 92, Loss: 0.34713760018348694, Accuracy: 0.873046875\n",
      "Batch: 93, Loss: 0.3674992620944977, Accuracy: 0.8779296875\n",
      "Batch: 94, Loss: 0.3573111295700073, Accuracy: 0.8779296875\n",
      "Batch: 95, Loss: 0.34949809312820435, Accuracy: 0.8759765625\n",
      "Batch: 96, Loss: 0.3368400037288666, Accuracy: 0.8876953125\n",
      "Batch: 97, Loss: 0.3233361840248108, Accuracy: 0.890625\n",
      "Batch: 98, Loss: 0.3569599986076355, Accuracy: 0.873046875\n",
      "Batch: 99, Loss: 0.30170464515686035, Accuracy: 0.89453125\n",
      "Batch: 100, Loss: 0.3369104862213135, Accuracy: 0.875\n",
      "Batch: 101, Loss: 0.3316235840320587, Accuracy: 0.890625\n",
      "Batch: 102, Loss: 0.3306352496147156, Accuracy: 0.89453125\n",
      "Batch: 103, Loss: 0.3296428918838501, Accuracy: 0.88671875\n",
      "Batch: 104, Loss: 0.33197396993637085, Accuracy: 0.890625\n",
      "Batch: 105, Loss: 0.25949716567993164, Accuracy: 0.90625\n",
      "Batch: 106, Loss: 0.33470189571380615, Accuracy: 0.8828125\n",
      "Batch: 107, Loss: 0.32402148842811584, Accuracy: 0.88671875\n",
      "Batch: 108, Loss: 0.2993784546852112, Accuracy: 0.892578125\n",
      "Batch: 109, Loss: 0.2540808320045471, Accuracy: 0.9208984375\n",
      "Batch: 110, Loss: 0.2558785080909729, Accuracy: 0.919921875\n",
      "Batch: 111, Loss: 0.3178747892379761, Accuracy: 0.8974609375\n",
      "Batch: 112, Loss: 0.31860288977622986, Accuracy: 0.8955078125\n",
      "Epoch 56/90\n",
      "Batch: 1, Loss: 0.43705588579177856, Accuracy: 0.8701171875\n",
      "Batch: 2, Loss: 0.33960631489753723, Accuracy: 0.890625\n",
      "Batch: 3, Loss: 0.3350831866264343, Accuracy: 0.8974609375\n",
      "Batch: 4, Loss: 0.30598074197769165, Accuracy: 0.8984375\n",
      "Batch: 5, Loss: 0.2947959303855896, Accuracy: 0.8984375\n",
      "Batch: 6, Loss: 0.32852885127067566, Accuracy: 0.8984375\n",
      "Batch: 7, Loss: 0.3136266767978668, Accuracy: 0.8984375\n",
      "Batch: 8, Loss: 0.2818708121776581, Accuracy: 0.904296875\n",
      "Batch: 9, Loss: 0.30877238512039185, Accuracy: 0.89453125\n",
      "Batch: 10, Loss: 0.37927645444869995, Accuracy: 0.865234375\n",
      "Batch: 11, Loss: 0.3365964889526367, Accuracy: 0.8818359375\n",
      "Batch: 12, Loss: 0.2952726185321808, Accuracy: 0.9013671875\n",
      "Batch: 13, Loss: 0.2747393846511841, Accuracy: 0.9091796875\n",
      "Batch: 14, Loss: 0.3329736590385437, Accuracy: 0.8828125\n",
      "Batch: 15, Loss: 0.3080829977989197, Accuracy: 0.890625\n",
      "Batch: 16, Loss: 0.2997182309627533, Accuracy: 0.91015625\n",
      "Batch: 17, Loss: 0.3110389709472656, Accuracy: 0.8935546875\n",
      "Batch: 18, Loss: 0.29021304845809937, Accuracy: 0.90625\n",
      "Batch: 19, Loss: 0.29726874828338623, Accuracy: 0.900390625\n",
      "Batch: 20, Loss: 0.3192731738090515, Accuracy: 0.8798828125\n",
      "Batch: 21, Loss: 0.35204190015792847, Accuracy: 0.8876953125\n",
      "Batch: 22, Loss: 0.33030736446380615, Accuracy: 0.888671875\n",
      "Batch: 23, Loss: 0.341996967792511, Accuracy: 0.8896484375\n",
      "Batch: 24, Loss: 0.36870527267456055, Accuracy: 0.875\n",
      "Batch: 25, Loss: 0.36645323038101196, Accuracy: 0.8759765625\n",
      "Batch: 26, Loss: 0.35222792625427246, Accuracy: 0.87890625\n",
      "Batch: 27, Loss: 0.3852907121181488, Accuracy: 0.875\n",
      "Batch: 28, Loss: 0.33731937408447266, Accuracy: 0.88671875\n",
      "Batch: 29, Loss: 0.3343461751937866, Accuracy: 0.8984375\n",
      "Batch: 30, Loss: 0.2783912122249603, Accuracy: 0.908203125\n",
      "Batch: 31, Loss: 0.3617820739746094, Accuracy: 0.876953125\n",
      "Batch: 32, Loss: 0.28996872901916504, Accuracy: 0.9033203125\n",
      "Batch: 33, Loss: 0.30022162199020386, Accuracy: 0.8896484375\n",
      "Batch: 34, Loss: 0.28138962388038635, Accuracy: 0.8984375\n",
      "Batch: 35, Loss: 0.3138648271560669, Accuracy: 0.9013671875\n",
      "Batch: 36, Loss: 0.3604706823825836, Accuracy: 0.8896484375\n",
      "Batch: 37, Loss: 0.27248021960258484, Accuracy: 0.9052734375\n",
      "Batch: 38, Loss: 0.30913037061691284, Accuracy: 0.8955078125\n",
      "Batch: 39, Loss: 0.34462970495224, Accuracy: 0.88671875\n",
      "Batch: 40, Loss: 0.3005104660987854, Accuracy: 0.9033203125\n",
      "Batch: 41, Loss: 0.3294849395751953, Accuracy: 0.8896484375\n",
      "Batch: 42, Loss: 0.33153194189071655, Accuracy: 0.890625\n",
      "Batch: 43, Loss: 0.3180508017539978, Accuracy: 0.892578125\n",
      "Batch: 44, Loss: 0.337027907371521, Accuracy: 0.8857421875\n",
      "Batch: 45, Loss: 0.3405987024307251, Accuracy: 0.8857421875\n",
      "Batch: 46, Loss: 0.3149126172065735, Accuracy: 0.9033203125\n",
      "Batch: 47, Loss: 0.3185431659221649, Accuracy: 0.888671875\n",
      "Batch: 48, Loss: 0.3322828710079193, Accuracy: 0.8837890625\n",
      "Batch: 49, Loss: 0.32628771662712097, Accuracy: 0.8994140625\n",
      "Batch: 50, Loss: 0.2843666672706604, Accuracy: 0.91796875\n",
      "Batch: 51, Loss: 0.3225458264350891, Accuracy: 0.9013671875\n",
      "Batch: 52, Loss: 0.32075539231300354, Accuracy: 0.8896484375\n",
      "Batch: 53, Loss: 0.3862147927284241, Accuracy: 0.87109375\n",
      "Batch: 54, Loss: 0.35062849521636963, Accuracy: 0.884765625\n",
      "Batch: 55, Loss: 0.3346034288406372, Accuracy: 0.8798828125\n",
      "Batch: 56, Loss: 0.28315478563308716, Accuracy: 0.8994140625\n",
      "Batch: 57, Loss: 0.35329875349998474, Accuracy: 0.873046875\n",
      "Batch: 58, Loss: 0.37101486325263977, Accuracy: 0.8779296875\n",
      "Batch: 59, Loss: 0.3584463894367218, Accuracy: 0.8828125\n",
      "Batch: 60, Loss: 0.3271501362323761, Accuracy: 0.8828125\n",
      "Batch: 61, Loss: 0.3135087192058563, Accuracy: 0.9013671875\n",
      "Batch: 62, Loss: 0.33877143263816833, Accuracy: 0.8955078125\n",
      "Batch: 63, Loss: 0.2614609897136688, Accuracy: 0.916015625\n",
      "Batch: 64, Loss: 0.35093820095062256, Accuracy: 0.8828125\n",
      "Batch: 65, Loss: 0.32099494338035583, Accuracy: 0.8974609375\n",
      "Batch: 66, Loss: 0.29752159118652344, Accuracy: 0.904296875\n",
      "Batch: 67, Loss: 0.2995539903640747, Accuracy: 0.8955078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 68, Loss: 0.31661099195480347, Accuracy: 0.9013671875\n",
      "Batch: 69, Loss: 0.30753928422927856, Accuracy: 0.8974609375\n",
      "Batch: 70, Loss: 0.3001742362976074, Accuracy: 0.8955078125\n",
      "Batch: 71, Loss: 0.2778467535972595, Accuracy: 0.9072265625\n",
      "Batch: 72, Loss: 0.334499716758728, Accuracy: 0.890625\n",
      "Batch: 73, Loss: 0.3437727689743042, Accuracy: 0.8818359375\n",
      "Batch: 74, Loss: 0.3202643394470215, Accuracy: 0.890625\n",
      "Batch: 75, Loss: 0.27494633197784424, Accuracy: 0.9013671875\n",
      "Batch: 76, Loss: 0.2725523114204407, Accuracy: 0.9052734375\n",
      "Batch: 77, Loss: 0.32587930560112, Accuracy: 0.8779296875\n",
      "Batch: 78, Loss: 0.32768237590789795, Accuracy: 0.892578125\n",
      "Batch: 79, Loss: 0.3358679413795471, Accuracy: 0.880859375\n",
      "Batch: 80, Loss: 0.3122803568840027, Accuracy: 0.8896484375\n",
      "Batch: 81, Loss: 0.3424782156944275, Accuracy: 0.8857421875\n",
      "Batch: 82, Loss: 0.3448472321033478, Accuracy: 0.876953125\n",
      "Batch: 83, Loss: 0.28084224462509155, Accuracy: 0.9111328125\n",
      "Batch: 84, Loss: 0.3202778995037079, Accuracy: 0.9013671875\n",
      "Batch: 85, Loss: 0.3549257218837738, Accuracy: 0.888671875\n",
      "Batch: 86, Loss: 0.3376670777797699, Accuracy: 0.888671875\n",
      "Batch: 87, Loss: 0.32012468576431274, Accuracy: 0.8955078125\n",
      "Batch: 88, Loss: 0.327701210975647, Accuracy: 0.8857421875\n",
      "Batch: 89, Loss: 0.3085363507270813, Accuracy: 0.896484375\n",
      "Batch: 90, Loss: 0.36127084493637085, Accuracy: 0.876953125\n",
      "Batch: 91, Loss: 0.35723257064819336, Accuracy: 0.8857421875\n",
      "Batch: 92, Loss: 0.3086353838443756, Accuracy: 0.8828125\n",
      "Batch: 93, Loss: 0.3775368928909302, Accuracy: 0.8671875\n",
      "Batch: 94, Loss: 0.33354634046554565, Accuracy: 0.8828125\n",
      "Batch: 95, Loss: 0.3551936149597168, Accuracy: 0.8759765625\n",
      "Batch: 96, Loss: 0.31459319591522217, Accuracy: 0.896484375\n",
      "Batch: 97, Loss: 0.28671708703041077, Accuracy: 0.9072265625\n",
      "Batch: 98, Loss: 0.3567430377006531, Accuracy: 0.87890625\n",
      "Batch: 99, Loss: 0.28358224034309387, Accuracy: 0.9052734375\n",
      "Batch: 100, Loss: 0.33676427602767944, Accuracy: 0.8916015625\n",
      "Batch: 101, Loss: 0.3303378224372864, Accuracy: 0.8876953125\n",
      "Batch: 102, Loss: 0.32554757595062256, Accuracy: 0.88671875\n",
      "Batch: 103, Loss: 0.3017106354236603, Accuracy: 0.8955078125\n",
      "Batch: 104, Loss: 0.3424055576324463, Accuracy: 0.8876953125\n",
      "Batch: 105, Loss: 0.2760595679283142, Accuracy: 0.9052734375\n",
      "Batch: 106, Loss: 0.3240278959274292, Accuracy: 0.8818359375\n",
      "Batch: 107, Loss: 0.31287452578544617, Accuracy: 0.9052734375\n",
      "Batch: 108, Loss: 0.3024791479110718, Accuracy: 0.8974609375\n",
      "Batch: 109, Loss: 0.2429710328578949, Accuracy: 0.9189453125\n",
      "Batch: 110, Loss: 0.26967641711235046, Accuracy: 0.9033203125\n",
      "Batch: 111, Loss: 0.3198651671409607, Accuracy: 0.890625\n",
      "Batch: 112, Loss: 0.32168784737586975, Accuracy: 0.88671875\n",
      "Epoch 57/90\n",
      "Batch: 1, Loss: 0.4063027501106262, Accuracy: 0.8642578125\n",
      "Batch: 2, Loss: 0.32767245173454285, Accuracy: 0.8974609375\n",
      "Batch: 3, Loss: 0.321277916431427, Accuracy: 0.8984375\n",
      "Batch: 4, Loss: 0.3025849163532257, Accuracy: 0.900390625\n",
      "Batch: 5, Loss: 0.2846648693084717, Accuracy: 0.9091796875\n",
      "Batch: 6, Loss: 0.3037908673286438, Accuracy: 0.904296875\n",
      "Batch: 7, Loss: 0.30582571029663086, Accuracy: 0.9033203125\n",
      "Batch: 8, Loss: 0.3134691119194031, Accuracy: 0.89453125\n",
      "Batch: 9, Loss: 0.3235636353492737, Accuracy: 0.890625\n",
      "Batch: 10, Loss: 0.3288039565086365, Accuracy: 0.89453125\n",
      "Batch: 11, Loss: 0.34086835384368896, Accuracy: 0.8935546875\n",
      "Batch: 12, Loss: 0.2751956880092621, Accuracy: 0.9111328125\n",
      "Batch: 13, Loss: 0.2822360396385193, Accuracy: 0.9111328125\n",
      "Batch: 14, Loss: 0.3036815822124481, Accuracy: 0.8955078125\n",
      "Batch: 15, Loss: 0.32053855061531067, Accuracy: 0.90234375\n",
      "Batch: 16, Loss: 0.32992181181907654, Accuracy: 0.8876953125\n",
      "Batch: 17, Loss: 0.3339434266090393, Accuracy: 0.892578125\n",
      "Batch: 18, Loss: 0.294908732175827, Accuracy: 0.8955078125\n",
      "Batch: 19, Loss: 0.28725218772888184, Accuracy: 0.9033203125\n",
      "Batch: 20, Loss: 0.3308018743991852, Accuracy: 0.89453125\n",
      "Batch: 21, Loss: 0.33095434308052063, Accuracy: 0.8876953125\n",
      "Batch: 22, Loss: 0.29935508966445923, Accuracy: 0.89453125\n",
      "Batch: 23, Loss: 0.34880581498146057, Accuracy: 0.8837890625\n",
      "Batch: 24, Loss: 0.3374307453632355, Accuracy: 0.8984375\n",
      "Batch: 25, Loss: 0.39180606603622437, Accuracy: 0.86328125\n",
      "Batch: 26, Loss: 0.3725784420967102, Accuracy: 0.8720703125\n",
      "Batch: 27, Loss: 0.34662139415740967, Accuracy: 0.8994140625\n",
      "Batch: 28, Loss: 0.3347582519054413, Accuracy: 0.8916015625\n",
      "Batch: 29, Loss: 0.36747175455093384, Accuracy: 0.884765625\n",
      "Batch: 30, Loss: 0.2644652724266052, Accuracy: 0.916015625\n",
      "Batch: 31, Loss: 0.323943555355072, Accuracy: 0.8935546875\n",
      "Batch: 32, Loss: 0.3075416088104248, Accuracy: 0.8984375\n",
      "Batch: 33, Loss: 0.2983311712741852, Accuracy: 0.884765625\n",
      "Batch: 34, Loss: 0.2874206006526947, Accuracy: 0.9091796875\n",
      "Batch: 35, Loss: 0.29193419218063354, Accuracy: 0.9072265625\n",
      "Batch: 36, Loss: 0.38335222005844116, Accuracy: 0.8759765625\n",
      "Batch: 37, Loss: 0.3004562556743622, Accuracy: 0.8935546875\n",
      "Batch: 38, Loss: 0.31668388843536377, Accuracy: 0.8955078125\n",
      "Batch: 39, Loss: 0.3155275583267212, Accuracy: 0.8876953125\n",
      "Batch: 40, Loss: 0.30332469940185547, Accuracy: 0.892578125\n",
      "Batch: 41, Loss: 0.323745995759964, Accuracy: 0.88671875\n",
      "Batch: 42, Loss: 0.3382723033428192, Accuracy: 0.876953125\n",
      "Batch: 43, Loss: 0.28510475158691406, Accuracy: 0.908203125\n",
      "Batch: 44, Loss: 0.29420650005340576, Accuracy: 0.90625\n",
      "Batch: 45, Loss: 0.3489798307418823, Accuracy: 0.8798828125\n",
      "Batch: 46, Loss: 0.3283984661102295, Accuracy: 0.8798828125\n",
      "Batch: 47, Loss: 0.27824193239212036, Accuracy: 0.908203125\n",
      "Batch: 48, Loss: 0.3215535879135132, Accuracy: 0.8896484375\n",
      "Batch: 49, Loss: 0.3401014506816864, Accuracy: 0.8896484375\n",
      "Batch: 50, Loss: 0.3074035942554474, Accuracy: 0.904296875\n",
      "Batch: 51, Loss: 0.3157706558704376, Accuracy: 0.8984375\n",
      "Batch: 52, Loss: 0.3155261278152466, Accuracy: 0.8935546875\n",
      "Batch: 53, Loss: 0.4006608724594116, Accuracy: 0.876953125\n",
      "Batch: 54, Loss: 0.3296349048614502, Accuracy: 0.892578125\n",
      "Batch: 55, Loss: 0.34650129079818726, Accuracy: 0.8798828125\n",
      "Batch: 56, Loss: 0.28412121534347534, Accuracy: 0.8984375\n",
      "Batch: 57, Loss: 0.356044739484787, Accuracy: 0.8837890625\n",
      "Batch: 58, Loss: 0.3634968101978302, Accuracy: 0.875\n",
      "Batch: 59, Loss: 0.3387942910194397, Accuracy: 0.8876953125\n",
      "Batch: 60, Loss: 0.32346633076667786, Accuracy: 0.8837890625\n",
      "Batch: 61, Loss: 0.33267730474472046, Accuracy: 0.89453125\n",
      "Batch: 62, Loss: 0.3298228979110718, Accuracy: 0.8876953125\n",
      "Batch: 63, Loss: 0.2883749008178711, Accuracy: 0.8916015625\n",
      "Batch: 64, Loss: 0.3256460428237915, Accuracy: 0.9033203125\n",
      "Batch: 65, Loss: 0.2952272593975067, Accuracy: 0.8916015625\n",
      "Batch: 66, Loss: 0.26242971420288086, Accuracy: 0.908203125\n",
      "Batch: 67, Loss: 0.29754287004470825, Accuracy: 0.9013671875\n",
      "Batch: 68, Loss: 0.2907566726207733, Accuracy: 0.9052734375\n",
      "Batch: 69, Loss: 0.3034508228302002, Accuracy: 0.8935546875\n",
      "Batch: 70, Loss: 0.30234450101852417, Accuracy: 0.9091796875\n",
      "Batch: 71, Loss: 0.2801979184150696, Accuracy: 0.90625\n",
      "Batch: 72, Loss: 0.2996370196342468, Accuracy: 0.8984375\n",
      "Batch: 73, Loss: 0.3125969171524048, Accuracy: 0.8974609375\n",
      "Batch: 74, Loss: 0.3347117304801941, Accuracy: 0.869140625\n",
      "Batch: 75, Loss: 0.27806299924850464, Accuracy: 0.8974609375\n",
      "Batch: 76, Loss: 0.2596980333328247, Accuracy: 0.90625\n",
      "Batch: 77, Loss: 0.2993987500667572, Accuracy: 0.9052734375\n",
      "Batch: 78, Loss: 0.3128460943698883, Accuracy: 0.892578125\n",
      "Batch: 79, Loss: 0.29992425441741943, Accuracy: 0.8935546875\n",
      "Batch: 80, Loss: 0.2846050262451172, Accuracy: 0.904296875\n",
      "Batch: 81, Loss: 0.3248904347419739, Accuracy: 0.892578125\n",
      "Batch: 82, Loss: 0.3276207149028778, Accuracy: 0.884765625\n",
      "Batch: 83, Loss: 0.26227378845214844, Accuracy: 0.9140625\n",
      "Batch: 84, Loss: 0.32850658893585205, Accuracy: 0.8896484375\n",
      "Batch: 85, Loss: 0.33117812871932983, Accuracy: 0.892578125\n",
      "Batch: 86, Loss: 0.31537336111068726, Accuracy: 0.8974609375\n",
      "Batch: 87, Loss: 0.2909121513366699, Accuracy: 0.8984375\n",
      "Batch: 88, Loss: 0.32610586285591125, Accuracy: 0.8857421875\n",
      "Batch: 89, Loss: 0.31570136547088623, Accuracy: 0.8955078125\n",
      "Batch: 90, Loss: 0.36217302083969116, Accuracy: 0.8759765625\n",
      "Batch: 91, Loss: 0.36006036400794983, Accuracy: 0.8837890625\n",
      "Batch: 92, Loss: 0.36228638887405396, Accuracy: 0.876953125\n",
      "Batch: 93, Loss: 0.33425623178482056, Accuracy: 0.88671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 94, Loss: 0.3331925868988037, Accuracy: 0.8837890625\n",
      "Batch: 95, Loss: 0.35309508442878723, Accuracy: 0.876953125\n",
      "Batch: 96, Loss: 0.3260939121246338, Accuracy: 0.8876953125\n",
      "Batch: 97, Loss: 0.30818605422973633, Accuracy: 0.88671875\n",
      "Batch: 98, Loss: 0.32961755990982056, Accuracy: 0.884765625\n",
      "Batch: 99, Loss: 0.2935755252838135, Accuracy: 0.896484375\n",
      "Batch: 100, Loss: 0.3067505955696106, Accuracy: 0.8916015625\n",
      "Batch: 101, Loss: 0.31234633922576904, Accuracy: 0.88671875\n",
      "Batch: 102, Loss: 0.3323305547237396, Accuracy: 0.88671875\n",
      "Batch: 103, Loss: 0.30985158681869507, Accuracy: 0.9052734375\n",
      "Batch: 104, Loss: 0.31790271401405334, Accuracy: 0.8994140625\n",
      "Batch: 105, Loss: 0.2731429934501648, Accuracy: 0.90625\n",
      "Batch: 106, Loss: 0.3507426381111145, Accuracy: 0.8828125\n",
      "Batch: 107, Loss: 0.2865954339504242, Accuracy: 0.90625\n",
      "Batch: 108, Loss: 0.3062090277671814, Accuracy: 0.896484375\n",
      "Batch: 109, Loss: 0.24124741554260254, Accuracy: 0.9208984375\n",
      "Batch: 110, Loss: 0.3172976076602936, Accuracy: 0.8916015625\n",
      "Batch: 111, Loss: 0.3173753023147583, Accuracy: 0.892578125\n",
      "Batch: 112, Loss: 0.32931065559387207, Accuracy: 0.900390625\n",
      "Epoch 58/90\n",
      "Batch: 1, Loss: 0.3788014352321625, Accuracy: 0.890625\n",
      "Batch: 2, Loss: 0.331845223903656, Accuracy: 0.89453125\n",
      "Batch: 3, Loss: 0.3146776258945465, Accuracy: 0.9052734375\n",
      "Batch: 4, Loss: 0.314813494682312, Accuracy: 0.8935546875\n",
      "Batch: 5, Loss: 0.26687830686569214, Accuracy: 0.9150390625\n",
      "Batch: 6, Loss: 0.31661927700042725, Accuracy: 0.896484375\n",
      "Batch: 7, Loss: 0.29551589488983154, Accuracy: 0.912109375\n",
      "Batch: 8, Loss: 0.26677656173706055, Accuracy: 0.91796875\n",
      "Batch: 9, Loss: 0.29700925946235657, Accuracy: 0.9072265625\n",
      "Batch: 10, Loss: 0.3306751251220703, Accuracy: 0.884765625\n",
      "Batch: 11, Loss: 0.3000240623950958, Accuracy: 0.90625\n",
      "Batch: 12, Loss: 0.2846461534500122, Accuracy: 0.8955078125\n",
      "Batch: 13, Loss: 0.25209668278694153, Accuracy: 0.9189453125\n",
      "Batch: 14, Loss: 0.31144237518310547, Accuracy: 0.888671875\n",
      "Batch: 15, Loss: 0.2987161874771118, Accuracy: 0.8935546875\n",
      "Batch: 16, Loss: 0.31985563039779663, Accuracy: 0.8984375\n",
      "Batch: 17, Loss: 0.3292369246482849, Accuracy: 0.900390625\n",
      "Batch: 18, Loss: 0.3199848532676697, Accuracy: 0.900390625\n",
      "Batch: 19, Loss: 0.274472177028656, Accuracy: 0.9111328125\n",
      "Batch: 20, Loss: 0.2944772243499756, Accuracy: 0.900390625\n",
      "Batch: 21, Loss: 0.3265452980995178, Accuracy: 0.8984375\n",
      "Batch: 22, Loss: 0.3147762715816498, Accuracy: 0.8876953125\n",
      "Batch: 23, Loss: 0.3555328845977783, Accuracy: 0.8857421875\n",
      "Batch: 24, Loss: 0.3569270968437195, Accuracy: 0.87890625\n",
      "Batch: 25, Loss: 0.3561015725135803, Accuracy: 0.876953125\n",
      "Batch: 26, Loss: 0.36852264404296875, Accuracy: 0.8740234375\n",
      "Batch: 27, Loss: 0.34812089800834656, Accuracy: 0.8857421875\n",
      "Batch: 28, Loss: 0.3413126468658447, Accuracy: 0.8798828125\n",
      "Batch: 29, Loss: 0.3623470962047577, Accuracy: 0.8798828125\n",
      "Batch: 30, Loss: 0.2837836742401123, Accuracy: 0.9111328125\n",
      "Batch: 31, Loss: 0.3422500491142273, Accuracy: 0.8896484375\n",
      "Batch: 32, Loss: 0.30997660756111145, Accuracy: 0.8876953125\n",
      "Batch: 33, Loss: 0.3341403901576996, Accuracy: 0.8837890625\n",
      "Batch: 34, Loss: 0.27427321672439575, Accuracy: 0.90625\n",
      "Batch: 35, Loss: 0.2969774901866913, Accuracy: 0.89453125\n",
      "Batch: 36, Loss: 0.3534493148326874, Accuracy: 0.89453125\n",
      "Batch: 37, Loss: 0.3111003637313843, Accuracy: 0.89453125\n",
      "Batch: 38, Loss: 0.312688946723938, Accuracy: 0.8896484375\n",
      "Batch: 39, Loss: 0.3159196376800537, Accuracy: 0.8857421875\n",
      "Batch: 40, Loss: 0.3016156256198883, Accuracy: 0.9033203125\n",
      "Batch: 41, Loss: 0.34417903423309326, Accuracy: 0.888671875\n",
      "Batch: 42, Loss: 0.32402950525283813, Accuracy: 0.880859375\n",
      "Batch: 43, Loss: 0.3303360342979431, Accuracy: 0.8798828125\n",
      "Batch: 44, Loss: 0.32066529989242554, Accuracy: 0.8896484375\n",
      "Batch: 45, Loss: 0.34501945972442627, Accuracy: 0.87890625\n",
      "Batch: 46, Loss: 0.34589269757270813, Accuracy: 0.8828125\n",
      "Batch: 47, Loss: 0.303266316652298, Accuracy: 0.904296875\n",
      "Batch: 48, Loss: 0.3198494613170624, Accuracy: 0.888671875\n",
      "Batch: 49, Loss: 0.3527349829673767, Accuracy: 0.88671875\n",
      "Batch: 50, Loss: 0.29056861996650696, Accuracy: 0.90625\n",
      "Batch: 51, Loss: 0.35897815227508545, Accuracy: 0.88671875\n",
      "Batch: 52, Loss: 0.3424103260040283, Accuracy: 0.876953125\n",
      "Batch: 53, Loss: 0.378686785697937, Accuracy: 0.8720703125\n",
      "Batch: 54, Loss: 0.3396030068397522, Accuracy: 0.875\n",
      "Batch: 55, Loss: 0.36525505781173706, Accuracy: 0.8740234375\n",
      "Batch: 56, Loss: 0.30012261867523193, Accuracy: 0.892578125\n",
      "Batch: 57, Loss: 0.3118046820163727, Accuracy: 0.8916015625\n",
      "Batch: 58, Loss: 0.3504227101802826, Accuracy: 0.888671875\n",
      "Batch: 59, Loss: 0.3404443860054016, Accuracy: 0.8916015625\n",
      "Batch: 60, Loss: 0.31226998567581177, Accuracy: 0.8935546875\n",
      "Batch: 61, Loss: 0.2990962564945221, Accuracy: 0.8955078125\n",
      "Batch: 62, Loss: 0.3122361898422241, Accuracy: 0.9033203125\n",
      "Batch: 63, Loss: 0.2695024609565735, Accuracy: 0.9140625\n",
      "Batch: 64, Loss: 0.3172304332256317, Accuracy: 0.8916015625\n",
      "Batch: 65, Loss: 0.31211036443710327, Accuracy: 0.89453125\n",
      "Batch: 66, Loss: 0.2623019218444824, Accuracy: 0.9130859375\n",
      "Batch: 67, Loss: 0.27690988779067993, Accuracy: 0.9130859375\n",
      "Batch: 68, Loss: 0.2923871874809265, Accuracy: 0.90234375\n",
      "Batch: 69, Loss: 0.29013359546661377, Accuracy: 0.9013671875\n",
      "Batch: 70, Loss: 0.2936629056930542, Accuracy: 0.900390625\n",
      "Batch: 71, Loss: 0.2653619647026062, Accuracy: 0.9072265625\n",
      "Batch: 72, Loss: 0.33754071593284607, Accuracy: 0.890625\n",
      "Batch: 73, Loss: 0.3217271566390991, Accuracy: 0.896484375\n",
      "Batch: 74, Loss: 0.3145145773887634, Accuracy: 0.900390625\n",
      "Batch: 75, Loss: 0.2775175869464874, Accuracy: 0.9033203125\n",
      "Batch: 76, Loss: 0.24053677916526794, Accuracy: 0.9150390625\n",
      "Batch: 77, Loss: 0.3105754256248474, Accuracy: 0.8916015625\n",
      "Batch: 78, Loss: 0.29755181074142456, Accuracy: 0.8984375\n",
      "Batch: 79, Loss: 0.2873475253582001, Accuracy: 0.912109375\n",
      "Batch: 80, Loss: 0.3014625310897827, Accuracy: 0.892578125\n",
      "Batch: 81, Loss: 0.34261226654052734, Accuracy: 0.8916015625\n",
      "Batch: 82, Loss: 0.31868797540664673, Accuracy: 0.8876953125\n",
      "Batch: 83, Loss: 0.28706204891204834, Accuracy: 0.904296875\n",
      "Batch: 84, Loss: 0.3067260980606079, Accuracy: 0.89453125\n",
      "Batch: 85, Loss: 0.31071382761001587, Accuracy: 0.900390625\n",
      "Batch: 86, Loss: 0.30948135256767273, Accuracy: 0.8896484375\n",
      "Batch: 87, Loss: 0.3039790987968445, Accuracy: 0.890625\n",
      "Batch: 88, Loss: 0.3274790644645691, Accuracy: 0.8935546875\n",
      "Batch: 89, Loss: 0.32150691747665405, Accuracy: 0.8896484375\n",
      "Batch: 90, Loss: 0.3689185380935669, Accuracy: 0.8662109375\n",
      "Batch: 91, Loss: 0.360474169254303, Accuracy: 0.8779296875\n",
      "Batch: 92, Loss: 0.3547578454017639, Accuracy: 0.8720703125\n",
      "Batch: 93, Loss: 0.34032127261161804, Accuracy: 0.8916015625\n",
      "Batch: 94, Loss: 0.33199983835220337, Accuracy: 0.8896484375\n",
      "Batch: 95, Loss: 0.33685538172721863, Accuracy: 0.8857421875\n",
      "Batch: 96, Loss: 0.3230494260787964, Accuracy: 0.8896484375\n",
      "Batch: 97, Loss: 0.292492151260376, Accuracy: 0.896484375\n",
      "Batch: 98, Loss: 0.3564976453781128, Accuracy: 0.880859375\n",
      "Batch: 99, Loss: 0.27863243222236633, Accuracy: 0.9033203125\n",
      "Batch: 100, Loss: 0.3181335926055908, Accuracy: 0.8857421875\n",
      "Batch: 101, Loss: 0.3093217611312866, Accuracy: 0.8876953125\n",
      "Batch: 102, Loss: 0.29870015382766724, Accuracy: 0.89453125\n",
      "Batch: 103, Loss: 0.33100008964538574, Accuracy: 0.89453125\n",
      "Batch: 104, Loss: 0.2929787039756775, Accuracy: 0.90234375\n",
      "Batch: 105, Loss: 0.25617852807044983, Accuracy: 0.904296875\n",
      "Batch: 106, Loss: 0.3300486207008362, Accuracy: 0.8759765625\n",
      "Batch: 107, Loss: 0.2852131128311157, Accuracy: 0.904296875\n",
      "Batch: 108, Loss: 0.29461392760276794, Accuracy: 0.900390625\n",
      "Batch: 109, Loss: 0.24203439056873322, Accuracy: 0.916015625\n",
      "Batch: 110, Loss: 0.2792564034461975, Accuracy: 0.9189453125\n",
      "Batch: 111, Loss: 0.3230215311050415, Accuracy: 0.8984375\n",
      "Batch: 112, Loss: 0.30581164360046387, Accuracy: 0.896484375\n",
      "Epoch 59/90\n",
      "Batch: 1, Loss: 0.3761841654777527, Accuracy: 0.890625\n",
      "Batch: 2, Loss: 0.32615160942077637, Accuracy: 0.896484375\n",
      "Batch: 3, Loss: 0.30694639682769775, Accuracy: 0.8994140625\n",
      "Batch: 4, Loss: 0.2894037067890167, Accuracy: 0.904296875\n",
      "Batch: 5, Loss: 0.24753336608409882, Accuracy: 0.9228515625\n",
      "Batch: 6, Loss: 0.30492928624153137, Accuracy: 0.9033203125\n",
      "Batch: 7, Loss: 0.2957722544670105, Accuracy: 0.9033203125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 8, Loss: 0.27357420325279236, Accuracy: 0.904296875\n",
      "Batch: 9, Loss: 0.3067992925643921, Accuracy: 0.89453125\n",
      "Batch: 10, Loss: 0.31200721859931946, Accuracy: 0.8916015625\n",
      "Batch: 11, Loss: 0.3059312701225281, Accuracy: 0.8935546875\n",
      "Batch: 12, Loss: 0.27617472410202026, Accuracy: 0.9111328125\n",
      "Batch: 13, Loss: 0.24523088335990906, Accuracy: 0.921875\n",
      "Batch: 14, Loss: 0.3075828552246094, Accuracy: 0.8935546875\n",
      "Batch: 15, Loss: 0.3140178620815277, Accuracy: 0.8916015625\n",
      "Batch: 16, Loss: 0.28493285179138184, Accuracy: 0.9091796875\n",
      "Batch: 17, Loss: 0.29926419258117676, Accuracy: 0.8955078125\n",
      "Batch: 18, Loss: 0.2736995816230774, Accuracy: 0.9140625\n",
      "Batch: 19, Loss: 0.28976115584373474, Accuracy: 0.90234375\n",
      "Batch: 20, Loss: 0.3196067214012146, Accuracy: 0.8974609375\n",
      "Batch: 21, Loss: 0.3253032863140106, Accuracy: 0.8935546875\n",
      "Batch: 22, Loss: 0.2738323211669922, Accuracy: 0.90625\n",
      "Batch: 23, Loss: 0.3184611201286316, Accuracy: 0.888671875\n",
      "Batch: 24, Loss: 0.35235488414764404, Accuracy: 0.8759765625\n",
      "Batch: 25, Loss: 0.36131054162979126, Accuracy: 0.8798828125\n",
      "Batch: 26, Loss: 0.34129875898361206, Accuracy: 0.8837890625\n",
      "Batch: 27, Loss: 0.36896926164627075, Accuracy: 0.8779296875\n",
      "Batch: 28, Loss: 0.3217686712741852, Accuracy: 0.892578125\n",
      "Batch: 29, Loss: 0.33087921142578125, Accuracy: 0.896484375\n",
      "Batch: 30, Loss: 0.29534220695495605, Accuracy: 0.9033203125\n",
      "Batch: 31, Loss: 0.33024150133132935, Accuracy: 0.89453125\n",
      "Batch: 32, Loss: 0.30353668332099915, Accuracy: 0.8955078125\n",
      "Batch: 33, Loss: 0.3009189963340759, Accuracy: 0.892578125\n",
      "Batch: 34, Loss: 0.2693171203136444, Accuracy: 0.908203125\n",
      "Batch: 35, Loss: 0.30554383993148804, Accuracy: 0.8984375\n",
      "Batch: 36, Loss: 0.33100008964538574, Accuracy: 0.8818359375\n",
      "Batch: 37, Loss: 0.28807348012924194, Accuracy: 0.900390625\n",
      "Batch: 38, Loss: 0.3184639811515808, Accuracy: 0.8896484375\n",
      "Batch: 39, Loss: 0.3166050612926483, Accuracy: 0.8974609375\n",
      "Batch: 40, Loss: 0.3028583228588104, Accuracy: 0.8974609375\n",
      "Batch: 41, Loss: 0.33343207836151123, Accuracy: 0.892578125\n",
      "Batch: 42, Loss: 0.32574892044067383, Accuracy: 0.8779296875\n",
      "Batch: 43, Loss: 0.2925894856452942, Accuracy: 0.9111328125\n",
      "Batch: 44, Loss: 0.3075183033943176, Accuracy: 0.8984375\n",
      "Batch: 45, Loss: 0.3203638195991516, Accuracy: 0.8974609375\n",
      "Batch: 46, Loss: 0.3024343252182007, Accuracy: 0.890625\n",
      "Batch: 47, Loss: 0.2807273268699646, Accuracy: 0.8994140625\n",
      "Batch: 48, Loss: 0.33163830637931824, Accuracy: 0.884765625\n",
      "Batch: 49, Loss: 0.31949296593666077, Accuracy: 0.8994140625\n",
      "Batch: 50, Loss: 0.2543370723724365, Accuracy: 0.923828125\n",
      "Batch: 51, Loss: 0.3085199296474457, Accuracy: 0.8974609375\n",
      "Batch: 52, Loss: 0.3398056626319885, Accuracy: 0.8779296875\n",
      "Batch: 53, Loss: 0.37781140208244324, Accuracy: 0.869140625\n",
      "Batch: 54, Loss: 0.3280835747718811, Accuracy: 0.8935546875\n",
      "Batch: 55, Loss: 0.3562505841255188, Accuracy: 0.873046875\n",
      "Batch: 56, Loss: 0.28287559747695923, Accuracy: 0.904296875\n",
      "Batch: 57, Loss: 0.3546973466873169, Accuracy: 0.8779296875\n",
      "Batch: 58, Loss: 0.34823644161224365, Accuracy: 0.8994140625\n",
      "Batch: 59, Loss: 0.3391055464744568, Accuracy: 0.8818359375\n",
      "Batch: 60, Loss: 0.3385305404663086, Accuracy: 0.8896484375\n",
      "Batch: 61, Loss: 0.28976970911026, Accuracy: 0.900390625\n",
      "Batch: 62, Loss: 0.30323225259780884, Accuracy: 0.9052734375\n",
      "Batch: 63, Loss: 0.2514325678348541, Accuracy: 0.9130859375\n",
      "Batch: 64, Loss: 0.3349759876728058, Accuracy: 0.88671875\n",
      "Batch: 65, Loss: 0.29650598764419556, Accuracy: 0.904296875\n",
      "Batch: 66, Loss: 0.29374921321868896, Accuracy: 0.9052734375\n",
      "Batch: 67, Loss: 0.2839886546134949, Accuracy: 0.8955078125\n",
      "Batch: 68, Loss: 0.2969897389411926, Accuracy: 0.8994140625\n",
      "Batch: 69, Loss: 0.25455617904663086, Accuracy: 0.9150390625\n",
      "Batch: 70, Loss: 0.2982262074947357, Accuracy: 0.88671875\n",
      "Batch: 71, Loss: 0.3058944046497345, Accuracy: 0.89453125\n",
      "Batch: 72, Loss: 0.3114703297615051, Accuracy: 0.900390625\n",
      "Batch: 73, Loss: 0.3049658536911011, Accuracy: 0.888671875\n",
      "Batch: 74, Loss: 0.3207371234893799, Accuracy: 0.8876953125\n",
      "Batch: 75, Loss: 0.2589655816555023, Accuracy: 0.9072265625\n",
      "Batch: 76, Loss: 0.2580172121524811, Accuracy: 0.9169921875\n",
      "Batch: 77, Loss: 0.3157571852207184, Accuracy: 0.900390625\n",
      "Batch: 78, Loss: 0.30726200342178345, Accuracy: 0.8984375\n",
      "Batch: 79, Loss: 0.30558010935783386, Accuracy: 0.9013671875\n",
      "Batch: 80, Loss: 0.2769409120082855, Accuracy: 0.9072265625\n",
      "Batch: 81, Loss: 0.32784706354141235, Accuracy: 0.8837890625\n",
      "Batch: 82, Loss: 0.2980925738811493, Accuracy: 0.904296875\n",
      "Batch: 83, Loss: 0.2808471620082855, Accuracy: 0.90234375\n",
      "Batch: 84, Loss: 0.3105286657810211, Accuracy: 0.8876953125\n",
      "Batch: 85, Loss: 0.2965977191925049, Accuracy: 0.900390625\n",
      "Batch: 86, Loss: 0.310486376285553, Accuracy: 0.8974609375\n",
      "Batch: 87, Loss: 0.29126548767089844, Accuracy: 0.8994140625\n",
      "Batch: 88, Loss: 0.30260246992111206, Accuracy: 0.8955078125\n",
      "Batch: 89, Loss: 0.28985631465911865, Accuracy: 0.8984375\n",
      "Batch: 90, Loss: 0.3368752896785736, Accuracy: 0.888671875\n",
      "Batch: 91, Loss: 0.32575151324272156, Accuracy: 0.892578125\n",
      "Batch: 92, Loss: 0.3367350399494171, Accuracy: 0.8828125\n",
      "Batch: 93, Loss: 0.3235146105289459, Accuracy: 0.8837890625\n",
      "Batch: 94, Loss: 0.3156685531139374, Accuracy: 0.8916015625\n",
      "Batch: 95, Loss: 0.33908069133758545, Accuracy: 0.88671875\n",
      "Batch: 96, Loss: 0.32982760667800903, Accuracy: 0.89453125\n",
      "Batch: 97, Loss: 0.2747669219970703, Accuracy: 0.9130859375\n",
      "Batch: 98, Loss: 0.3356907367706299, Accuracy: 0.8857421875\n",
      "Batch: 99, Loss: 0.2740299105644226, Accuracy: 0.904296875\n",
      "Batch: 100, Loss: 0.287447452545166, Accuracy: 0.8974609375\n",
      "Batch: 101, Loss: 0.2760030925273895, Accuracy: 0.8955078125\n",
      "Batch: 102, Loss: 0.29703786969184875, Accuracy: 0.90234375\n",
      "Batch: 103, Loss: 0.302785724401474, Accuracy: 0.8974609375\n",
      "Batch: 104, Loss: 0.32321760058403015, Accuracy: 0.88671875\n",
      "Batch: 105, Loss: 0.25312185287475586, Accuracy: 0.912109375\n",
      "Batch: 106, Loss: 0.2954257130622864, Accuracy: 0.8955078125\n",
      "Batch: 107, Loss: 0.28024232387542725, Accuracy: 0.9052734375\n",
      "Batch: 108, Loss: 0.29163017868995667, Accuracy: 0.900390625\n",
      "Batch: 109, Loss: 0.22127237915992737, Accuracy: 0.9287109375\n",
      "Batch: 110, Loss: 0.2581194043159485, Accuracy: 0.916015625\n",
      "Batch: 111, Loss: 0.2868763208389282, Accuracy: 0.9072265625\n",
      "Batch: 112, Loss: 0.316673219203949, Accuracy: 0.884765625\n",
      "Epoch 60/90\n",
      "Batch: 1, Loss: 0.3575025200843811, Accuracy: 0.8857421875\n",
      "Batch: 2, Loss: 0.3270409107208252, Accuracy: 0.9033203125\n",
      "Batch: 3, Loss: 0.3045133948326111, Accuracy: 0.9111328125\n",
      "Batch: 4, Loss: 0.2685821056365967, Accuracy: 0.9130859375\n",
      "Batch: 5, Loss: 0.26602205634117126, Accuracy: 0.9072265625\n",
      "Batch: 6, Loss: 0.30952662229537964, Accuracy: 0.900390625\n",
      "Batch: 7, Loss: 0.2879760265350342, Accuracy: 0.8994140625\n",
      "Batch: 8, Loss: 0.27837517857551575, Accuracy: 0.91015625\n",
      "Batch: 9, Loss: 0.280740886926651, Accuracy: 0.908203125\n",
      "Batch: 10, Loss: 0.33608171343803406, Accuracy: 0.8916015625\n",
      "Batch: 11, Loss: 0.3110244870185852, Accuracy: 0.90625\n",
      "Batch: 12, Loss: 0.28751882910728455, Accuracy: 0.9033203125\n",
      "Batch: 13, Loss: 0.25464296340942383, Accuracy: 0.9052734375\n",
      "Batch: 14, Loss: 0.3023068606853485, Accuracy: 0.900390625\n",
      "Batch: 15, Loss: 0.30698060989379883, Accuracy: 0.8955078125\n",
      "Batch: 16, Loss: 0.29921290278434753, Accuracy: 0.8984375\n",
      "Batch: 17, Loss: 0.31507426500320435, Accuracy: 0.896484375\n",
      "Batch: 18, Loss: 0.28798171877861023, Accuracy: 0.900390625\n",
      "Batch: 19, Loss: 0.27413952350616455, Accuracy: 0.9130859375\n",
      "Batch: 20, Loss: 0.3092091977596283, Accuracy: 0.89453125\n",
      "Batch: 21, Loss: 0.3189104199409485, Accuracy: 0.8935546875\n",
      "Batch: 22, Loss: 0.31443968415260315, Accuracy: 0.908203125\n",
      "Batch: 23, Loss: 0.3421201705932617, Accuracy: 0.875\n",
      "Batch: 24, Loss: 0.33854740858078003, Accuracy: 0.8876953125\n",
      "Batch: 25, Loss: 0.3268198072910309, Accuracy: 0.8896484375\n",
      "Batch: 26, Loss: 0.341994047164917, Accuracy: 0.8896484375\n",
      "Batch: 27, Loss: 0.35357797145843506, Accuracy: 0.8955078125\n",
      "Batch: 28, Loss: 0.3374733328819275, Accuracy: 0.8798828125\n",
      "Batch: 29, Loss: 0.368638277053833, Accuracy: 0.8779296875\n",
      "Batch: 30, Loss: 0.2924599051475525, Accuracy: 0.9033203125\n",
      "Batch: 31, Loss: 0.3311845660209656, Accuracy: 0.8896484375\n",
      "Batch: 32, Loss: 0.2890050709247589, Accuracy: 0.8974609375\n",
      "Batch: 33, Loss: 0.3269161880016327, Accuracy: 0.89453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 34, Loss: 0.2657034993171692, Accuracy: 0.9169921875\n",
      "Batch: 35, Loss: 0.30342864990234375, Accuracy: 0.8955078125\n",
      "Batch: 36, Loss: 0.33046573400497437, Accuracy: 0.900390625\n",
      "Batch: 37, Loss: 0.2760118842124939, Accuracy: 0.904296875\n",
      "Batch: 38, Loss: 0.3274723291397095, Accuracy: 0.88671875\n",
      "Batch: 39, Loss: 0.27540847659111023, Accuracy: 0.896484375\n",
      "Batch: 40, Loss: 0.2931770384311676, Accuracy: 0.8955078125\n",
      "Batch: 41, Loss: 0.310055673122406, Accuracy: 0.8896484375\n",
      "Batch: 42, Loss: 0.31993070244789124, Accuracy: 0.87109375\n",
      "Batch: 43, Loss: 0.3229411244392395, Accuracy: 0.8818359375\n",
      "Batch: 44, Loss: 0.2866708040237427, Accuracy: 0.912109375\n",
      "Batch: 45, Loss: 0.30870693922042847, Accuracy: 0.896484375\n",
      "Batch: 46, Loss: 0.30465734004974365, Accuracy: 0.900390625\n",
      "Batch: 47, Loss: 0.28866058588027954, Accuracy: 0.8974609375\n",
      "Batch: 48, Loss: 0.30866116285324097, Accuracy: 0.8994140625\n",
      "Batch: 49, Loss: 0.3169599771499634, Accuracy: 0.8935546875\n",
      "Batch: 50, Loss: 0.25257185101509094, Accuracy: 0.91015625\n",
      "Batch: 51, Loss: 0.2893327474594116, Accuracy: 0.8974609375\n",
      "Batch: 52, Loss: 0.3088761568069458, Accuracy: 0.90234375\n",
      "Batch: 53, Loss: 0.34260207414627075, Accuracy: 0.88671875\n",
      "Batch: 54, Loss: 0.2900189757347107, Accuracy: 0.9072265625\n",
      "Batch: 55, Loss: 0.3277464509010315, Accuracy: 0.8935546875\n",
      "Batch: 56, Loss: 0.2905128002166748, Accuracy: 0.900390625\n",
      "Batch: 57, Loss: 0.31629905104637146, Accuracy: 0.8955078125\n",
      "Batch: 58, Loss: 0.3366274833679199, Accuracy: 0.8916015625\n",
      "Batch: 59, Loss: 0.32596588134765625, Accuracy: 0.888671875\n",
      "Batch: 60, Loss: 0.28870904445648193, Accuracy: 0.89453125\n",
      "Batch: 61, Loss: 0.29718685150146484, Accuracy: 0.900390625\n",
      "Batch: 62, Loss: 0.30211585760116577, Accuracy: 0.904296875\n",
      "Batch: 63, Loss: 0.2794764041900635, Accuracy: 0.9072265625\n",
      "Batch: 64, Loss: 0.3238838016986847, Accuracy: 0.8935546875\n",
      "Batch: 65, Loss: 0.28240785002708435, Accuracy: 0.9072265625\n",
      "Batch: 66, Loss: 0.2681932747364044, Accuracy: 0.912109375\n",
      "Batch: 67, Loss: 0.25208890438079834, Accuracy: 0.9248046875\n",
      "Batch: 68, Loss: 0.30080121755599976, Accuracy: 0.9033203125\n",
      "Batch: 69, Loss: 0.27252545952796936, Accuracy: 0.9111328125\n",
      "Batch: 70, Loss: 0.286544531583786, Accuracy: 0.9072265625\n",
      "Batch: 71, Loss: 0.28437286615371704, Accuracy: 0.8984375\n",
      "Batch: 72, Loss: 0.30364924669265747, Accuracy: 0.900390625\n",
      "Batch: 73, Loss: 0.2903539836406708, Accuracy: 0.90234375\n",
      "Batch: 74, Loss: 0.29877740144729614, Accuracy: 0.9052734375\n",
      "Batch: 75, Loss: 0.2464727908372879, Accuracy: 0.9189453125\n",
      "Batch: 76, Loss: 0.2298319786787033, Accuracy: 0.9296875\n",
      "Batch: 77, Loss: 0.28665590286254883, Accuracy: 0.9140625\n",
      "Batch: 78, Loss: 0.28497955203056335, Accuracy: 0.90234375\n",
      "Batch: 79, Loss: 0.2958706021308899, Accuracy: 0.9033203125\n",
      "Batch: 80, Loss: 0.2814602255821228, Accuracy: 0.904296875\n",
      "Batch: 81, Loss: 0.320970356464386, Accuracy: 0.8916015625\n",
      "Batch: 82, Loss: 0.2978397607803345, Accuracy: 0.8984375\n",
      "Batch: 83, Loss: 0.2768544554710388, Accuracy: 0.91015625\n",
      "Batch: 84, Loss: 0.2837092876434326, Accuracy: 0.8994140625\n",
      "Batch: 85, Loss: 0.32399487495422363, Accuracy: 0.8935546875\n",
      "Batch: 86, Loss: 0.33436882495880127, Accuracy: 0.890625\n",
      "Batch: 87, Loss: 0.2878977060317993, Accuracy: 0.9140625\n",
      "Batch: 88, Loss: 0.30128294229507446, Accuracy: 0.8984375\n",
      "Batch: 89, Loss: 0.28759926557540894, Accuracy: 0.8994140625\n",
      "Batch: 90, Loss: 0.354907751083374, Accuracy: 0.87890625\n",
      "Batch: 91, Loss: 0.34245485067367554, Accuracy: 0.876953125\n",
      "Batch: 92, Loss: 0.31444546580314636, Accuracy: 0.890625\n",
      "Batch: 93, Loss: 0.34319204092025757, Accuracy: 0.8818359375\n",
      "Batch: 94, Loss: 0.30274373292922974, Accuracy: 0.8994140625\n",
      "Batch: 95, Loss: 0.32211214303970337, Accuracy: 0.8857421875\n",
      "Batch: 96, Loss: 0.3158688545227051, Accuracy: 0.8984375\n",
      "Batch: 97, Loss: 0.26174092292785645, Accuracy: 0.912109375\n",
      "Batch: 98, Loss: 0.29295438528060913, Accuracy: 0.904296875\n",
      "Batch: 99, Loss: 0.249442458152771, Accuracy: 0.9033203125\n",
      "Batch: 100, Loss: 0.2836586833000183, Accuracy: 0.90625\n",
      "Batch: 101, Loss: 0.2945467233657837, Accuracy: 0.908203125\n",
      "Batch: 102, Loss: 0.2986617982387543, Accuracy: 0.8955078125\n",
      "Batch: 103, Loss: 0.3112698793411255, Accuracy: 0.896484375\n",
      "Batch: 104, Loss: 0.31816744804382324, Accuracy: 0.888671875\n",
      "Batch: 105, Loss: 0.24319113790988922, Accuracy: 0.9228515625\n",
      "Batch: 106, Loss: 0.31886252760887146, Accuracy: 0.8935546875\n",
      "Batch: 107, Loss: 0.27801382541656494, Accuracy: 0.9091796875\n",
      "Batch: 108, Loss: 0.28381866216659546, Accuracy: 0.9130859375\n",
      "Batch: 109, Loss: 0.23215046525001526, Accuracy: 0.9208984375\n",
      "Batch: 110, Loss: 0.24104468524456024, Accuracy: 0.923828125\n",
      "Batch: 111, Loss: 0.2776477634906769, Accuracy: 0.904296875\n",
      "Batch: 112, Loss: 0.3286362886428833, Accuracy: 0.8828125\n",
      "Saved Weights at epoch 60 to file Weights_60.h5\n",
      "Epoch 61/90\n",
      "Batch: 1, Loss: 0.3767372965812683, Accuracy: 0.8779296875\n",
      "Batch: 2, Loss: 0.30020493268966675, Accuracy: 0.9091796875\n",
      "Batch: 3, Loss: 0.3247791826725006, Accuracy: 0.892578125\n",
      "Batch: 4, Loss: 0.2756246030330658, Accuracy: 0.91015625\n",
      "Batch: 5, Loss: 0.24347051978111267, Accuracy: 0.9130859375\n",
      "Batch: 6, Loss: 0.30417490005493164, Accuracy: 0.9013671875\n",
      "Batch: 7, Loss: 0.2766302525997162, Accuracy: 0.9130859375\n",
      "Batch: 8, Loss: 0.2484847605228424, Accuracy: 0.916015625\n",
      "Batch: 9, Loss: 0.3079823851585388, Accuracy: 0.892578125\n",
      "Batch: 10, Loss: 0.34632018208503723, Accuracy: 0.876953125\n",
      "Batch: 11, Loss: 0.2937769889831543, Accuracy: 0.9072265625\n",
      "Batch: 12, Loss: 0.26200371980667114, Accuracy: 0.9111328125\n",
      "Batch: 13, Loss: 0.2677205204963684, Accuracy: 0.908203125\n",
      "Batch: 14, Loss: 0.30480635166168213, Accuracy: 0.9033203125\n",
      "Batch: 15, Loss: 0.3136311173439026, Accuracy: 0.896484375\n",
      "Batch: 16, Loss: 0.32144200801849365, Accuracy: 0.900390625\n",
      "Batch: 17, Loss: 0.2886822819709778, Accuracy: 0.8994140625\n",
      "Batch: 18, Loss: 0.25122272968292236, Accuracy: 0.9130859375\n",
      "Batch: 19, Loss: 0.27413344383239746, Accuracy: 0.9091796875\n",
      "Batch: 20, Loss: 0.2839823365211487, Accuracy: 0.9052734375\n",
      "Batch: 21, Loss: 0.3237679600715637, Accuracy: 0.896484375\n",
      "Batch: 22, Loss: 0.2872592806816101, Accuracy: 0.90625\n",
      "Batch: 23, Loss: 0.3259192705154419, Accuracy: 0.8837890625\n",
      "Batch: 24, Loss: 0.3246910572052002, Accuracy: 0.8896484375\n",
      "Batch: 25, Loss: 0.30630797147750854, Accuracy: 0.8984375\n",
      "Batch: 26, Loss: 0.3200019598007202, Accuracy: 0.89453125\n",
      "Batch: 27, Loss: 0.3615694046020508, Accuracy: 0.873046875\n",
      "Batch: 28, Loss: 0.29735010862350464, Accuracy: 0.8974609375\n",
      "Batch: 29, Loss: 0.3018885850906372, Accuracy: 0.90234375\n",
      "Batch: 30, Loss: 0.3143227994441986, Accuracy: 0.88671875\n",
      "Batch: 31, Loss: 0.28906333446502686, Accuracy: 0.9013671875\n",
      "Batch: 32, Loss: 0.2859269976615906, Accuracy: 0.9013671875\n",
      "Batch: 33, Loss: 0.2836689352989197, Accuracy: 0.904296875\n",
      "Batch: 34, Loss: 0.2736530303955078, Accuracy: 0.9091796875\n",
      "Batch: 35, Loss: 0.2959081530570984, Accuracy: 0.890625\n",
      "Batch: 36, Loss: 0.3600284159183502, Accuracy: 0.888671875\n",
      "Batch: 37, Loss: 0.23795080184936523, Accuracy: 0.916015625\n",
      "Batch: 38, Loss: 0.32554662227630615, Accuracy: 0.892578125\n",
      "Batch: 39, Loss: 0.29454946517944336, Accuracy: 0.900390625\n",
      "Batch: 40, Loss: 0.26560288667678833, Accuracy: 0.9150390625\n",
      "Batch: 41, Loss: 0.30208566784858704, Accuracy: 0.89453125\n",
      "Batch: 42, Loss: 0.2833777666091919, Accuracy: 0.90234375\n",
      "Batch: 43, Loss: 0.3079209327697754, Accuracy: 0.89453125\n",
      "Batch: 44, Loss: 0.2861327528953552, Accuracy: 0.8916015625\n",
      "Batch: 45, Loss: 0.29040879011154175, Accuracy: 0.9111328125\n",
      "Batch: 46, Loss: 0.29764771461486816, Accuracy: 0.904296875\n",
      "Batch: 47, Loss: 0.30771613121032715, Accuracy: 0.8935546875\n",
      "Batch: 48, Loss: 0.3224945664405823, Accuracy: 0.8876953125\n",
      "Batch: 49, Loss: 0.33881473541259766, Accuracy: 0.88671875\n",
      "Batch: 50, Loss: 0.2605709135532379, Accuracy: 0.9169921875\n",
      "Batch: 51, Loss: 0.26611125469207764, Accuracy: 0.9150390625\n",
      "Batch: 52, Loss: 0.29965704679489136, Accuracy: 0.900390625\n",
      "Batch: 53, Loss: 0.33302897214889526, Accuracy: 0.88671875\n",
      "Batch: 54, Loss: 0.31057465076446533, Accuracy: 0.892578125\n",
      "Batch: 55, Loss: 0.31396400928497314, Accuracy: 0.9052734375\n",
      "Batch: 56, Loss: 0.26786139607429504, Accuracy: 0.90625\n",
      "Batch: 57, Loss: 0.3152012825012207, Accuracy: 0.8974609375\n",
      "Batch: 58, Loss: 0.33032098412513733, Accuracy: 0.880859375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 59, Loss: 0.33156418800354004, Accuracy: 0.88671875\n",
      "Batch: 60, Loss: 0.29845741391181946, Accuracy: 0.88671875\n",
      "Batch: 61, Loss: 0.29098427295684814, Accuracy: 0.8974609375\n",
      "Batch: 62, Loss: 0.3199617564678192, Accuracy: 0.8994140625\n",
      "Batch: 63, Loss: 0.28756460547447205, Accuracy: 0.8974609375\n",
      "Batch: 64, Loss: 0.35117900371551514, Accuracy: 0.8955078125\n",
      "Batch: 65, Loss: 0.30601924657821655, Accuracy: 0.900390625\n",
      "Batch: 66, Loss: 0.27911168336868286, Accuracy: 0.9013671875\n",
      "Batch: 67, Loss: 0.3046817183494568, Accuracy: 0.892578125\n",
      "Batch: 68, Loss: 0.3123217821121216, Accuracy: 0.9033203125\n",
      "Batch: 69, Loss: 0.2839232087135315, Accuracy: 0.8984375\n",
      "Batch: 70, Loss: 0.27070629596710205, Accuracy: 0.9130859375\n",
      "Batch: 71, Loss: 0.29100698232650757, Accuracy: 0.8994140625\n",
      "Batch: 72, Loss: 0.3134433329105377, Accuracy: 0.896484375\n",
      "Batch: 73, Loss: 0.28641077876091003, Accuracy: 0.900390625\n",
      "Batch: 74, Loss: 0.28251680731773376, Accuracy: 0.8955078125\n",
      "Batch: 75, Loss: 0.2599540054798126, Accuracy: 0.916015625\n",
      "Batch: 76, Loss: 0.22135135531425476, Accuracy: 0.9189453125\n",
      "Batch: 77, Loss: 0.29204061627388, Accuracy: 0.8955078125\n",
      "Batch: 78, Loss: 0.2979746460914612, Accuracy: 0.89453125\n",
      "Batch: 79, Loss: 0.2752784490585327, Accuracy: 0.9033203125\n",
      "Batch: 80, Loss: 0.27449142932891846, Accuracy: 0.91015625\n",
      "Batch: 81, Loss: 0.29575589299201965, Accuracy: 0.9033203125\n",
      "Batch: 82, Loss: 0.28843849897384644, Accuracy: 0.8984375\n",
      "Batch: 83, Loss: 0.2672117054462433, Accuracy: 0.9052734375\n",
      "Batch: 84, Loss: 0.2838963270187378, Accuracy: 0.904296875\n",
      "Batch: 85, Loss: 0.31721624732017517, Accuracy: 0.8896484375\n",
      "Batch: 86, Loss: 0.3296528458595276, Accuracy: 0.8828125\n",
      "Batch: 87, Loss: 0.2824341952800751, Accuracy: 0.9033203125\n",
      "Batch: 88, Loss: 0.3229237198829651, Accuracy: 0.888671875\n",
      "Batch: 89, Loss: 0.28329911828041077, Accuracy: 0.9033203125\n",
      "Batch: 90, Loss: 0.35097816586494446, Accuracy: 0.8798828125\n",
      "Batch: 91, Loss: 0.33160609006881714, Accuracy: 0.8779296875\n",
      "Batch: 92, Loss: 0.3387849032878876, Accuracy: 0.888671875\n",
      "Batch: 93, Loss: 0.35251715779304504, Accuracy: 0.8779296875\n",
      "Batch: 94, Loss: 0.32180190086364746, Accuracy: 0.8955078125\n",
      "Batch: 95, Loss: 0.3209112584590912, Accuracy: 0.8955078125\n",
      "Batch: 96, Loss: 0.3197630047798157, Accuracy: 0.9033203125\n",
      "Batch: 97, Loss: 0.25090885162353516, Accuracy: 0.916015625\n",
      "Batch: 98, Loss: 0.3181394934654236, Accuracy: 0.892578125\n",
      "Batch: 99, Loss: 0.2502392828464508, Accuracy: 0.9111328125\n",
      "Batch: 100, Loss: 0.2974505126476288, Accuracy: 0.8974609375\n",
      "Batch: 101, Loss: 0.30514538288116455, Accuracy: 0.892578125\n",
      "Batch: 102, Loss: 0.2813733220100403, Accuracy: 0.9033203125\n",
      "Batch: 103, Loss: 0.31070855259895325, Accuracy: 0.90625\n",
      "Batch: 104, Loss: 0.2909965515136719, Accuracy: 0.8984375\n",
      "Batch: 105, Loss: 0.26312270760536194, Accuracy: 0.908203125\n",
      "Batch: 106, Loss: 0.29373759031295776, Accuracy: 0.896484375\n",
      "Batch: 107, Loss: 0.27371811866760254, Accuracy: 0.908203125\n",
      "Batch: 108, Loss: 0.28825196623802185, Accuracy: 0.9033203125\n",
      "Batch: 109, Loss: 0.21665218472480774, Accuracy: 0.9267578125\n",
      "Batch: 110, Loss: 0.2544972896575928, Accuracy: 0.923828125\n",
      "Batch: 111, Loss: 0.31531822681427, Accuracy: 0.8984375\n",
      "Batch: 112, Loss: 0.2885879874229431, Accuracy: 0.904296875\n",
      "Epoch 62/90\n",
      "Batch: 1, Loss: 0.35645705461502075, Accuracy: 0.890625\n",
      "Batch: 2, Loss: 0.3046274781227112, Accuracy: 0.900390625\n",
      "Batch: 3, Loss: 0.31891143321990967, Accuracy: 0.89453125\n",
      "Batch: 4, Loss: 0.26065725088119507, Accuracy: 0.9150390625\n",
      "Batch: 5, Loss: 0.24758872389793396, Accuracy: 0.9150390625\n",
      "Batch: 6, Loss: 0.2781056761741638, Accuracy: 0.9072265625\n",
      "Batch: 7, Loss: 0.24423962831497192, Accuracy: 0.9169921875\n",
      "Batch: 8, Loss: 0.26742783188819885, Accuracy: 0.908203125\n",
      "Batch: 9, Loss: 0.2914603352546692, Accuracy: 0.8955078125\n",
      "Batch: 10, Loss: 0.2932629883289337, Accuracy: 0.9072265625\n",
      "Batch: 11, Loss: 0.31069427728652954, Accuracy: 0.9013671875\n",
      "Batch: 12, Loss: 0.24665391445159912, Accuracy: 0.912109375\n",
      "Batch: 13, Loss: 0.23660066723823547, Accuracy: 0.919921875\n",
      "Batch: 14, Loss: 0.3195641040802002, Accuracy: 0.88671875\n",
      "Batch: 15, Loss: 0.29082709550857544, Accuracy: 0.9013671875\n",
      "Batch: 16, Loss: 0.28996992111206055, Accuracy: 0.9052734375\n",
      "Batch: 17, Loss: 0.2888643145561218, Accuracy: 0.9052734375\n",
      "Batch: 18, Loss: 0.24144455790519714, Accuracy: 0.92578125\n",
      "Batch: 19, Loss: 0.2635565996170044, Accuracy: 0.9169921875\n",
      "Batch: 20, Loss: 0.2720021605491638, Accuracy: 0.90234375\n",
      "Batch: 21, Loss: 0.3016021251678467, Accuracy: 0.9150390625\n",
      "Batch: 22, Loss: 0.26780784130096436, Accuracy: 0.904296875\n",
      "Batch: 23, Loss: 0.31428009271621704, Accuracy: 0.8916015625\n",
      "Batch: 24, Loss: 0.3413006663322449, Accuracy: 0.8837890625\n",
      "Batch: 25, Loss: 0.31205904483795166, Accuracy: 0.89453125\n",
      "Batch: 26, Loss: 0.32538166642189026, Accuracy: 0.8984375\n",
      "Batch: 27, Loss: 0.3309601843357086, Accuracy: 0.890625\n",
      "Batch: 28, Loss: 0.3169366419315338, Accuracy: 0.8828125\n",
      "Batch: 29, Loss: 0.35501912236213684, Accuracy: 0.88671875\n",
      "Batch: 30, Loss: 0.28622373938560486, Accuracy: 0.8935546875\n",
      "Batch: 31, Loss: 0.3269988000392914, Accuracy: 0.89453125\n",
      "Batch: 32, Loss: 0.2786349356174469, Accuracy: 0.904296875\n",
      "Batch: 33, Loss: 0.2832013964653015, Accuracy: 0.9033203125\n",
      "Batch: 34, Loss: 0.2846371531486511, Accuracy: 0.90234375\n",
      "Batch: 35, Loss: 0.28860586881637573, Accuracy: 0.90234375\n",
      "Batch: 36, Loss: 0.3460218608379364, Accuracy: 0.8896484375\n",
      "Batch: 37, Loss: 0.2644905149936676, Accuracy: 0.908203125\n",
      "Batch: 38, Loss: 0.32349544763565063, Accuracy: 0.8935546875\n",
      "Batch: 39, Loss: 0.27739864587783813, Accuracy: 0.8955078125\n",
      "Batch: 40, Loss: 0.2880476415157318, Accuracy: 0.90234375\n",
      "Batch: 41, Loss: 0.2801009714603424, Accuracy: 0.9072265625\n",
      "Batch: 42, Loss: 0.28103357553482056, Accuracy: 0.908203125\n",
      "Batch: 43, Loss: 0.2916455864906311, Accuracy: 0.90234375\n",
      "Batch: 44, Loss: 0.246225044131279, Accuracy: 0.919921875\n",
      "Batch: 45, Loss: 0.325284481048584, Accuracy: 0.8935546875\n",
      "Batch: 46, Loss: 0.271089106798172, Accuracy: 0.8994140625\n",
      "Batch: 47, Loss: 0.28313136100769043, Accuracy: 0.900390625\n",
      "Batch: 48, Loss: 0.26797670125961304, Accuracy: 0.91796875\n",
      "Batch: 49, Loss: 0.30035513639450073, Accuracy: 0.90234375\n",
      "Batch: 50, Loss: 0.2618214786052704, Accuracy: 0.9189453125\n",
      "Batch: 51, Loss: 0.27132871747016907, Accuracy: 0.9140625\n",
      "Batch: 52, Loss: 0.2724824547767639, Accuracy: 0.91015625\n",
      "Batch: 53, Loss: 0.3427871763706207, Accuracy: 0.8857421875\n",
      "Batch: 54, Loss: 0.3329237103462219, Accuracy: 0.8828125\n",
      "Batch: 55, Loss: 0.3268338441848755, Accuracy: 0.888671875\n",
      "Batch: 56, Loss: 0.2532755732536316, Accuracy: 0.9228515625\n",
      "Batch: 57, Loss: 0.3118603825569153, Accuracy: 0.896484375\n",
      "Batch: 58, Loss: 0.3163730502128601, Accuracy: 0.8896484375\n",
      "Batch: 59, Loss: 0.32612425088882446, Accuracy: 0.876953125\n",
      "Batch: 60, Loss: 0.3166182041168213, Accuracy: 0.892578125\n",
      "Batch: 61, Loss: 0.27137598395347595, Accuracy: 0.9189453125\n",
      "Batch: 62, Loss: 0.29569804668426514, Accuracy: 0.90234375\n",
      "Batch: 63, Loss: 0.24466902017593384, Accuracy: 0.9150390625\n",
      "Batch: 64, Loss: 0.3266542851924896, Accuracy: 0.8896484375\n",
      "Batch: 65, Loss: 0.2656242251396179, Accuracy: 0.9111328125\n",
      "Batch: 66, Loss: 0.24282240867614746, Accuracy: 0.923828125\n",
      "Batch: 67, Loss: 0.2624385952949524, Accuracy: 0.908203125\n",
      "Batch: 68, Loss: 0.266426682472229, Accuracy: 0.9091796875\n",
      "Batch: 69, Loss: 0.24386262893676758, Accuracy: 0.90625\n",
      "Batch: 70, Loss: 0.23659367859363556, Accuracy: 0.921875\n",
      "Batch: 71, Loss: 0.26442041993141174, Accuracy: 0.9169921875\n",
      "Batch: 72, Loss: 0.32199811935424805, Accuracy: 0.8876953125\n",
      "Batch: 73, Loss: 0.2827495336532593, Accuracy: 0.9013671875\n",
      "Batch: 74, Loss: 0.27744972705841064, Accuracy: 0.904296875\n",
      "Batch: 75, Loss: 0.2516672611236572, Accuracy: 0.921875\n",
      "Batch: 76, Loss: 0.22682476043701172, Accuracy: 0.9228515625\n",
      "Batch: 77, Loss: 0.26490920782089233, Accuracy: 0.912109375\n",
      "Batch: 78, Loss: 0.2794122099876404, Accuracy: 0.9072265625\n",
      "Batch: 79, Loss: 0.2731475830078125, Accuracy: 0.9150390625\n",
      "Batch: 80, Loss: 0.2500985264778137, Accuracy: 0.9091796875\n",
      "Batch: 81, Loss: 0.31429523229599, Accuracy: 0.892578125\n",
      "Batch: 82, Loss: 0.29756975173950195, Accuracy: 0.9013671875\n",
      "Batch: 83, Loss: 0.26491406559944153, Accuracy: 0.9140625\n",
      "Batch: 84, Loss: 0.2701573371887207, Accuracy: 0.9150390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 85, Loss: 0.2915913462638855, Accuracy: 0.8994140625\n",
      "Batch: 86, Loss: 0.3129998445510864, Accuracy: 0.8984375\n",
      "Batch: 87, Loss: 0.26213014125823975, Accuracy: 0.90625\n",
      "Batch: 88, Loss: 0.2982076406478882, Accuracy: 0.8955078125\n",
      "Batch: 89, Loss: 0.27744394540786743, Accuracy: 0.9072265625\n",
      "Batch: 90, Loss: 0.34321823716163635, Accuracy: 0.8828125\n",
      "Batch: 91, Loss: 0.34383225440979004, Accuracy: 0.8779296875\n",
      "Batch: 92, Loss: 0.30517494678497314, Accuracy: 0.89453125\n",
      "Batch: 93, Loss: 0.33053693175315857, Accuracy: 0.880859375\n",
      "Batch: 94, Loss: 0.31355971097946167, Accuracy: 0.89453125\n",
      "Batch: 95, Loss: 0.30231785774230957, Accuracy: 0.91015625\n",
      "Batch: 96, Loss: 0.2875499725341797, Accuracy: 0.90234375\n",
      "Batch: 97, Loss: 0.2685658037662506, Accuracy: 0.908203125\n",
      "Batch: 98, Loss: 0.30821239948272705, Accuracy: 0.8955078125\n",
      "Batch: 99, Loss: 0.25406360626220703, Accuracy: 0.912109375\n",
      "Batch: 100, Loss: 0.2928289771080017, Accuracy: 0.8984375\n",
      "Batch: 101, Loss: 0.28257662057876587, Accuracy: 0.89453125\n",
      "Batch: 102, Loss: 0.2909809947013855, Accuracy: 0.91015625\n",
      "Batch: 103, Loss: 0.30122989416122437, Accuracy: 0.908203125\n",
      "Batch: 104, Loss: 0.28088653087615967, Accuracy: 0.904296875\n",
      "Batch: 105, Loss: 0.24862635135650635, Accuracy: 0.9169921875\n",
      "Batch: 106, Loss: 0.2872718870639801, Accuracy: 0.9013671875\n",
      "Batch: 107, Loss: 0.256795197725296, Accuracy: 0.91015625\n",
      "Batch: 108, Loss: 0.28735458850860596, Accuracy: 0.9091796875\n",
      "Batch: 109, Loss: 0.2446584701538086, Accuracy: 0.91015625\n",
      "Batch: 110, Loss: 0.262088418006897, Accuracy: 0.9228515625\n",
      "Batch: 111, Loss: 0.296531617641449, Accuracy: 0.8994140625\n",
      "Batch: 112, Loss: 0.28182750940322876, Accuracy: 0.8984375\n",
      "Epoch 63/90\n",
      "Batch: 1, Loss: 0.35391563177108765, Accuracy: 0.896484375\n",
      "Batch: 2, Loss: 0.3107938766479492, Accuracy: 0.892578125\n",
      "Batch: 3, Loss: 0.2936423122882843, Accuracy: 0.8974609375\n",
      "Batch: 4, Loss: 0.29248082637786865, Accuracy: 0.9033203125\n",
      "Batch: 5, Loss: 0.25009965896606445, Accuracy: 0.9169921875\n",
      "Batch: 6, Loss: 0.28275588154792786, Accuracy: 0.9130859375\n",
      "Batch: 7, Loss: 0.24668362736701965, Accuracy: 0.91796875\n",
      "Batch: 8, Loss: 0.2665843963623047, Accuracy: 0.8984375\n",
      "Batch: 9, Loss: 0.28671106696128845, Accuracy: 0.8984375\n",
      "Batch: 10, Loss: 0.31470203399658203, Accuracy: 0.8896484375\n",
      "Batch: 11, Loss: 0.31029289960861206, Accuracy: 0.89453125\n",
      "Batch: 12, Loss: 0.2385849803686142, Accuracy: 0.916015625\n",
      "Batch: 13, Loss: 0.2395831197500229, Accuracy: 0.919921875\n",
      "Batch: 14, Loss: 0.282443642616272, Accuracy: 0.9033203125\n",
      "Batch: 15, Loss: 0.2771519124507904, Accuracy: 0.9072265625\n",
      "Batch: 16, Loss: 0.2743681073188782, Accuracy: 0.9140625\n",
      "Batch: 17, Loss: 0.2980111837387085, Accuracy: 0.888671875\n",
      "Batch: 18, Loss: 0.26202136278152466, Accuracy: 0.91796875\n",
      "Batch: 19, Loss: 0.26864680647850037, Accuracy: 0.908203125\n",
      "Batch: 20, Loss: 0.28531622886657715, Accuracy: 0.9013671875\n",
      "Batch: 21, Loss: 0.25949347019195557, Accuracy: 0.912109375\n",
      "Batch: 22, Loss: 0.2715650498867035, Accuracy: 0.908203125\n",
      "Batch: 23, Loss: 0.3261924386024475, Accuracy: 0.8896484375\n",
      "Batch: 24, Loss: 0.3170974850654602, Accuracy: 0.8935546875\n",
      "Batch: 25, Loss: 0.3291264772415161, Accuracy: 0.8828125\n",
      "Batch: 26, Loss: 0.33078593015670776, Accuracy: 0.890625\n",
      "Batch: 27, Loss: 0.3407524824142456, Accuracy: 0.892578125\n",
      "Batch: 28, Loss: 0.31380748748779297, Accuracy: 0.884765625\n",
      "Batch: 29, Loss: 0.3172902464866638, Accuracy: 0.888671875\n",
      "Batch: 30, Loss: 0.2842666804790497, Accuracy: 0.9052734375\n",
      "Batch: 31, Loss: 0.29341185092926025, Accuracy: 0.9072265625\n",
      "Batch: 32, Loss: 0.28051573038101196, Accuracy: 0.90625\n",
      "Batch: 33, Loss: 0.28878286480903625, Accuracy: 0.89453125\n",
      "Batch: 34, Loss: 0.26205673813819885, Accuracy: 0.9169921875\n",
      "Batch: 35, Loss: 0.29968899488449097, Accuracy: 0.8935546875\n",
      "Batch: 36, Loss: 0.3346988260746002, Accuracy: 0.8837890625\n",
      "Batch: 37, Loss: 0.27234870195388794, Accuracy: 0.9091796875\n",
      "Batch: 38, Loss: 0.2994268536567688, Accuracy: 0.904296875\n",
      "Batch: 39, Loss: 0.28805917501449585, Accuracy: 0.8974609375\n",
      "Batch: 40, Loss: 0.3138667643070221, Accuracy: 0.8916015625\n",
      "Batch: 41, Loss: 0.3051473796367645, Accuracy: 0.8896484375\n",
      "Batch: 42, Loss: 0.295970618724823, Accuracy: 0.8994140625\n",
      "Batch: 43, Loss: 0.3023971915245056, Accuracy: 0.8876953125\n",
      "Batch: 44, Loss: 0.27880871295928955, Accuracy: 0.9130859375\n",
      "Batch: 45, Loss: 0.2835581600666046, Accuracy: 0.9013671875\n",
      "Batch: 46, Loss: 0.295369029045105, Accuracy: 0.8974609375\n",
      "Batch: 47, Loss: 0.28787872195243835, Accuracy: 0.900390625\n",
      "Batch: 48, Loss: 0.29212048649787903, Accuracy: 0.8984375\n",
      "Batch: 49, Loss: 0.3132011890411377, Accuracy: 0.9072265625\n",
      "Batch: 50, Loss: 0.2517865300178528, Accuracy: 0.9150390625\n",
      "Batch: 51, Loss: 0.2851642370223999, Accuracy: 0.9072265625\n",
      "Batch: 52, Loss: 0.2808372676372528, Accuracy: 0.9033203125\n",
      "Batch: 53, Loss: 0.342390239238739, Accuracy: 0.888671875\n",
      "Batch: 54, Loss: 0.31855538487434387, Accuracy: 0.888671875\n",
      "Batch: 55, Loss: 0.3264840245246887, Accuracy: 0.896484375\n",
      "Batch: 56, Loss: 0.24209877848625183, Accuracy: 0.9208984375\n",
      "Batch: 57, Loss: 0.32686570286750793, Accuracy: 0.890625\n",
      "Batch: 58, Loss: 0.3225296139717102, Accuracy: 0.8984375\n",
      "Batch: 59, Loss: 0.3502899408340454, Accuracy: 0.884765625\n",
      "Batch: 60, Loss: 0.3131977915763855, Accuracy: 0.892578125\n",
      "Batch: 61, Loss: 0.3076620101928711, Accuracy: 0.89453125\n",
      "Batch: 62, Loss: 0.2953253388404846, Accuracy: 0.890625\n",
      "Batch: 63, Loss: 0.2563634216785431, Accuracy: 0.9150390625\n",
      "Batch: 64, Loss: 0.28301945328712463, Accuracy: 0.900390625\n",
      "Batch: 65, Loss: 0.2835627496242523, Accuracy: 0.8984375\n",
      "Batch: 66, Loss: 0.24419555068016052, Accuracy: 0.9189453125\n",
      "Batch: 67, Loss: 0.27393579483032227, Accuracy: 0.90234375\n",
      "Batch: 68, Loss: 0.30413955450057983, Accuracy: 0.8974609375\n",
      "Batch: 69, Loss: 0.24420925974845886, Accuracy: 0.921875\n",
      "Batch: 70, Loss: 0.2548118531703949, Accuracy: 0.9248046875\n",
      "Batch: 71, Loss: 0.2773171663284302, Accuracy: 0.90234375\n",
      "Batch: 72, Loss: 0.30030807852745056, Accuracy: 0.90625\n",
      "Batch: 73, Loss: 0.2905997037887573, Accuracy: 0.8955078125\n",
      "Batch: 74, Loss: 0.2945247292518616, Accuracy: 0.8974609375\n",
      "Batch: 75, Loss: 0.23280733823776245, Accuracy: 0.923828125\n",
      "Batch: 76, Loss: 0.23266012966632843, Accuracy: 0.91796875\n",
      "Batch: 77, Loss: 0.2912883460521698, Accuracy: 0.9052734375\n",
      "Batch: 78, Loss: 0.3068104088306427, Accuracy: 0.8974609375\n",
      "Batch: 79, Loss: 0.29090607166290283, Accuracy: 0.900390625\n",
      "Batch: 80, Loss: 0.26310452818870544, Accuracy: 0.9052734375\n",
      "Batch: 81, Loss: 0.3317195773124695, Accuracy: 0.8828125\n",
      "Batch: 82, Loss: 0.3167368471622467, Accuracy: 0.8896484375\n",
      "Batch: 83, Loss: 0.2620614171028137, Accuracy: 0.916015625\n",
      "Batch: 84, Loss: 0.28413358330726624, Accuracy: 0.8994140625\n",
      "Batch: 85, Loss: 0.26458293199539185, Accuracy: 0.9091796875\n",
      "Batch: 86, Loss: 0.29503655433654785, Accuracy: 0.9033203125\n",
      "Batch: 87, Loss: 0.2665320336818695, Accuracy: 0.9091796875\n",
      "Batch: 88, Loss: 0.27465569972991943, Accuracy: 0.9130859375\n",
      "Batch: 89, Loss: 0.280572772026062, Accuracy: 0.896484375\n",
      "Batch: 90, Loss: 0.33934035897254944, Accuracy: 0.88671875\n",
      "Batch: 91, Loss: 0.32869893312454224, Accuracy: 0.8798828125\n",
      "Batch: 92, Loss: 0.33897796273231506, Accuracy: 0.8798828125\n",
      "Batch: 93, Loss: 0.30663418769836426, Accuracy: 0.888671875\n",
      "Batch: 94, Loss: 0.3096770644187927, Accuracy: 0.900390625\n",
      "Batch: 95, Loss: 0.32101601362228394, Accuracy: 0.8916015625\n",
      "Batch: 96, Loss: 0.3090512752532959, Accuracy: 0.9052734375\n",
      "Batch: 97, Loss: 0.2639043629169464, Accuracy: 0.908203125\n",
      "Batch: 98, Loss: 0.3001308739185333, Accuracy: 0.8935546875\n",
      "Batch: 99, Loss: 0.2736058235168457, Accuracy: 0.9111328125\n",
      "Batch: 100, Loss: 0.27886325120925903, Accuracy: 0.896484375\n",
      "Batch: 101, Loss: 0.2804523706436157, Accuracy: 0.8994140625\n",
      "Batch: 102, Loss: 0.2949299216270447, Accuracy: 0.8955078125\n",
      "Batch: 103, Loss: 0.2629305124282837, Accuracy: 0.9150390625\n",
      "Batch: 104, Loss: 0.3023570775985718, Accuracy: 0.904296875\n",
      "Batch: 105, Loss: 0.2534647285938263, Accuracy: 0.9111328125\n",
      "Batch: 106, Loss: 0.29346030950546265, Accuracy: 0.900390625\n",
      "Batch: 107, Loss: 0.24903789162635803, Accuracy: 0.9150390625\n",
      "Batch: 108, Loss: 0.25649553537368774, Accuracy: 0.91015625\n",
      "Batch: 109, Loss: 0.2132337987422943, Accuracy: 0.931640625\n",
      "Batch: 110, Loss: 0.23735949397087097, Accuracy: 0.9267578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 111, Loss: 0.3029385209083557, Accuracy: 0.8955078125\n",
      "Batch: 112, Loss: 0.31227222084999084, Accuracy: 0.8896484375\n",
      "Epoch 64/90\n",
      "Batch: 1, Loss: 0.39357131719589233, Accuracy: 0.8837890625\n",
      "Batch: 2, Loss: 0.3083934187889099, Accuracy: 0.9111328125\n",
      "Batch: 3, Loss: 0.32466042041778564, Accuracy: 0.90234375\n",
      "Batch: 4, Loss: 0.26444709300994873, Accuracy: 0.916015625\n",
      "Batch: 5, Loss: 0.25503039360046387, Accuracy: 0.9130859375\n",
      "Batch: 6, Loss: 0.26573485136032104, Accuracy: 0.9140625\n",
      "Batch: 7, Loss: 0.2354273647069931, Accuracy: 0.923828125\n",
      "Batch: 8, Loss: 0.25863710045814514, Accuracy: 0.9189453125\n",
      "Batch: 9, Loss: 0.2798975706100464, Accuracy: 0.90625\n",
      "Batch: 10, Loss: 0.3139016032218933, Accuracy: 0.8974609375\n",
      "Batch: 11, Loss: 0.30226635932922363, Accuracy: 0.9013671875\n",
      "Batch: 12, Loss: 0.27257370948791504, Accuracy: 0.9111328125\n",
      "Batch: 13, Loss: 0.24905449151992798, Accuracy: 0.9140625\n",
      "Batch: 14, Loss: 0.28347575664520264, Accuracy: 0.904296875\n",
      "Batch: 15, Loss: 0.29965198040008545, Accuracy: 0.904296875\n",
      "Batch: 16, Loss: 0.2733989357948303, Accuracy: 0.9169921875\n",
      "Batch: 17, Loss: 0.29664912819862366, Accuracy: 0.89453125\n",
      "Batch: 18, Loss: 0.23532089591026306, Accuracy: 0.921875\n",
      "Batch: 19, Loss: 0.2800518274307251, Accuracy: 0.90234375\n",
      "Batch: 20, Loss: 0.2942957282066345, Accuracy: 0.896484375\n",
      "Batch: 21, Loss: 0.2789234519004822, Accuracy: 0.8955078125\n",
      "Batch: 22, Loss: 0.26365259289741516, Accuracy: 0.9130859375\n",
      "Batch: 23, Loss: 0.31842634081840515, Accuracy: 0.8955078125\n",
      "Batch: 24, Loss: 0.34083855152130127, Accuracy: 0.880859375\n",
      "Batch: 25, Loss: 0.3401944935321808, Accuracy: 0.87890625\n",
      "Batch: 26, Loss: 0.31653469800949097, Accuracy: 0.8857421875\n",
      "Batch: 27, Loss: 0.34257856011390686, Accuracy: 0.8798828125\n",
      "Batch: 28, Loss: 0.33011114597320557, Accuracy: 0.8857421875\n",
      "Batch: 29, Loss: 0.3047626316547394, Accuracy: 0.9111328125\n",
      "Batch: 30, Loss: 0.2608085870742798, Accuracy: 0.919921875\n",
      "Batch: 31, Loss: 0.29831913113594055, Accuracy: 0.9033203125\n",
      "Batch: 32, Loss: 0.2612000107765198, Accuracy: 0.904296875\n",
      "Batch: 33, Loss: 0.2374124825000763, Accuracy: 0.923828125\n",
      "Batch: 34, Loss: 0.2781546115875244, Accuracy: 0.8994140625\n",
      "Batch: 35, Loss: 0.2852095365524292, Accuracy: 0.9013671875\n",
      "Batch: 36, Loss: 0.34451553225517273, Accuracy: 0.88671875\n",
      "Batch: 37, Loss: 0.23028212785720825, Accuracy: 0.9140625\n",
      "Batch: 38, Loss: 0.31363481283187866, Accuracy: 0.8935546875\n",
      "Batch: 39, Loss: 0.2783747911453247, Accuracy: 0.9111328125\n",
      "Batch: 40, Loss: 0.26066911220550537, Accuracy: 0.916015625\n",
      "Batch: 41, Loss: 0.29855769872665405, Accuracy: 0.8876953125\n",
      "Batch: 42, Loss: 0.2714502513408661, Accuracy: 0.9052734375\n",
      "Batch: 43, Loss: 0.28727421164512634, Accuracy: 0.9052734375\n",
      "Batch: 44, Loss: 0.26339906454086304, Accuracy: 0.9150390625\n",
      "Batch: 45, Loss: 0.29912933707237244, Accuracy: 0.90234375\n",
      "Batch: 46, Loss: 0.31549158692359924, Accuracy: 0.904296875\n",
      "Batch: 47, Loss: 0.22118952870368958, Accuracy: 0.9189453125\n",
      "Batch: 48, Loss: 0.27697527408599854, Accuracy: 0.904296875\n",
      "Batch: 49, Loss: 0.27299314737319946, Accuracy: 0.9111328125\n",
      "Batch: 50, Loss: 0.21991491317749023, Accuracy: 0.92578125\n",
      "Batch: 51, Loss: 0.27195125818252563, Accuracy: 0.9130859375\n",
      "Batch: 52, Loss: 0.27582693099975586, Accuracy: 0.90625\n",
      "Batch: 53, Loss: 0.3389180898666382, Accuracy: 0.8837890625\n",
      "Batch: 54, Loss: 0.2772483825683594, Accuracy: 0.91796875\n",
      "Batch: 55, Loss: 0.2881317436695099, Accuracy: 0.90625\n",
      "Batch: 56, Loss: 0.2768389582633972, Accuracy: 0.9091796875\n",
      "Batch: 57, Loss: 0.2959349453449249, Accuracy: 0.89453125\n",
      "Batch: 58, Loss: 0.30603140592575073, Accuracy: 0.9013671875\n",
      "Batch: 59, Loss: 0.32854002714157104, Accuracy: 0.89453125\n",
      "Batch: 60, Loss: 0.27203232049942017, Accuracy: 0.8994140625\n",
      "Batch: 61, Loss: 0.2922103703022003, Accuracy: 0.904296875\n",
      "Batch: 62, Loss: 0.27818939089775085, Accuracy: 0.90625\n",
      "Batch: 63, Loss: 0.24588818848133087, Accuracy: 0.9150390625\n",
      "Batch: 64, Loss: 0.32847702503204346, Accuracy: 0.8876953125\n",
      "Batch: 65, Loss: 0.27775049209594727, Accuracy: 0.9111328125\n",
      "Batch: 66, Loss: 0.258651465177536, Accuracy: 0.9150390625\n",
      "Batch: 67, Loss: 0.28056660294532776, Accuracy: 0.9072265625\n",
      "Batch: 68, Loss: 0.3004816770553589, Accuracy: 0.8974609375\n",
      "Batch: 69, Loss: 0.22179260849952698, Accuracy: 0.9326171875\n",
      "Batch: 70, Loss: 0.2529754042625427, Accuracy: 0.919921875\n",
      "Batch: 71, Loss: 0.279236763715744, Accuracy: 0.89453125\n",
      "Batch: 72, Loss: 0.29316943883895874, Accuracy: 0.8974609375\n",
      "Batch: 73, Loss: 0.2304011434316635, Accuracy: 0.9267578125\n",
      "Batch: 74, Loss: 0.27268627285957336, Accuracy: 0.90234375\n",
      "Batch: 75, Loss: 0.2366572618484497, Accuracy: 0.919921875\n",
      "Batch: 76, Loss: 0.22541451454162598, Accuracy: 0.9287109375\n",
      "Batch: 77, Loss: 0.2800760865211487, Accuracy: 0.9150390625\n",
      "Batch: 78, Loss: 0.28066596388816833, Accuracy: 0.908203125\n",
      "Batch: 79, Loss: 0.28180965781211853, Accuracy: 0.91015625\n",
      "Batch: 80, Loss: 0.27097582817077637, Accuracy: 0.916015625\n",
      "Batch: 81, Loss: 0.30483561754226685, Accuracy: 0.896484375\n",
      "Batch: 82, Loss: 0.2680736780166626, Accuracy: 0.91015625\n",
      "Batch: 83, Loss: 0.24857792258262634, Accuracy: 0.912109375\n",
      "Batch: 84, Loss: 0.271025687456131, Accuracy: 0.9091796875\n",
      "Batch: 85, Loss: 0.2936219573020935, Accuracy: 0.904296875\n",
      "Batch: 86, Loss: 0.29779499769210815, Accuracy: 0.904296875\n",
      "Batch: 87, Loss: 0.2647705674171448, Accuracy: 0.912109375\n",
      "Batch: 88, Loss: 0.2659754753112793, Accuracy: 0.908203125\n",
      "Batch: 89, Loss: 0.2839880883693695, Accuracy: 0.90625\n",
      "Batch: 90, Loss: 0.3392983675003052, Accuracy: 0.87890625\n",
      "Batch: 91, Loss: 0.31885001063346863, Accuracy: 0.888671875\n",
      "Batch: 92, Loss: 0.32835379242897034, Accuracy: 0.880859375\n",
      "Batch: 93, Loss: 0.3038598895072937, Accuracy: 0.896484375\n",
      "Batch: 94, Loss: 0.2669718265533447, Accuracy: 0.919921875\n",
      "Batch: 95, Loss: 0.2949907183647156, Accuracy: 0.8984375\n",
      "Batch: 96, Loss: 0.2570832073688507, Accuracy: 0.9130859375\n",
      "Batch: 97, Loss: 0.2882736921310425, Accuracy: 0.892578125\n",
      "Batch: 98, Loss: 0.29648515582084656, Accuracy: 0.8994140625\n",
      "Batch: 99, Loss: 0.23634591698646545, Accuracy: 0.9189453125\n",
      "Batch: 100, Loss: 0.26417332887649536, Accuracy: 0.908203125\n",
      "Batch: 101, Loss: 0.28979599475860596, Accuracy: 0.904296875\n",
      "Batch: 102, Loss: 0.27580904960632324, Accuracy: 0.9033203125\n",
      "Batch: 103, Loss: 0.28638774156570435, Accuracy: 0.9033203125\n",
      "Batch: 104, Loss: 0.2815380096435547, Accuracy: 0.9072265625\n",
      "Batch: 105, Loss: 0.23360483348369598, Accuracy: 0.9228515625\n",
      "Batch: 106, Loss: 0.26584726572036743, Accuracy: 0.9091796875\n",
      "Batch: 107, Loss: 0.2618124485015869, Accuracy: 0.90625\n",
      "Batch: 108, Loss: 0.3003859519958496, Accuracy: 0.9013671875\n",
      "Batch: 109, Loss: 0.21924012899398804, Accuracy: 0.927734375\n",
      "Batch: 110, Loss: 0.24393720924854279, Accuracy: 0.921875\n",
      "Batch: 111, Loss: 0.2763328552246094, Accuracy: 0.900390625\n",
      "Batch: 112, Loss: 0.2856644093990326, Accuracy: 0.9072265625\n",
      "Epoch 65/90\n",
      "Batch: 1, Loss: 0.35388123989105225, Accuracy: 0.8935546875\n",
      "Batch: 2, Loss: 0.30349230766296387, Accuracy: 0.900390625\n",
      "Batch: 3, Loss: 0.30653563141822815, Accuracy: 0.8984375\n",
      "Batch: 4, Loss: 0.23838025331497192, Accuracy: 0.9296875\n",
      "Batch: 5, Loss: 0.22923247516155243, Accuracy: 0.9169921875\n",
      "Batch: 6, Loss: 0.29594671726226807, Accuracy: 0.896484375\n",
      "Batch: 7, Loss: 0.25339260697364807, Accuracy: 0.912109375\n",
      "Batch: 8, Loss: 0.2544912099838257, Accuracy: 0.919921875\n",
      "Batch: 9, Loss: 0.2742312550544739, Accuracy: 0.90234375\n",
      "Batch: 10, Loss: 0.3099726140499115, Accuracy: 0.896484375\n",
      "Batch: 11, Loss: 0.25197499990463257, Accuracy: 0.912109375\n",
      "Batch: 12, Loss: 0.2719786763191223, Accuracy: 0.90625\n",
      "Batch: 13, Loss: 0.2445117086172104, Accuracy: 0.91796875\n",
      "Batch: 14, Loss: 0.2702895998954773, Accuracy: 0.9052734375\n",
      "Batch: 15, Loss: 0.290820837020874, Accuracy: 0.9013671875\n",
      "Batch: 16, Loss: 0.2609316110610962, Accuracy: 0.9150390625\n",
      "Batch: 17, Loss: 0.28869253396987915, Accuracy: 0.9140625\n",
      "Batch: 18, Loss: 0.2565465569496155, Accuracy: 0.9130859375\n",
      "Batch: 19, Loss: 0.2732916474342346, Accuracy: 0.9091796875\n",
      "Batch: 20, Loss: 0.2819417119026184, Accuracy: 0.89453125\n",
      "Batch: 21, Loss: 0.2771134376525879, Accuracy: 0.9091796875\n",
      "Batch: 22, Loss: 0.2636891007423401, Accuracy: 0.904296875\n",
      "Batch: 23, Loss: 0.3057795763015747, Accuracy: 0.912109375\n",
      "Batch: 24, Loss: 0.3051263391971588, Accuracy: 0.8974609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 25, Loss: 0.3130612373352051, Accuracy: 0.8837890625\n",
      "Batch: 26, Loss: 0.3054320216178894, Accuracy: 0.90234375\n",
      "Batch: 27, Loss: 0.32722634077072144, Accuracy: 0.88671875\n",
      "Batch: 28, Loss: 0.2921749949455261, Accuracy: 0.9033203125\n",
      "Batch: 29, Loss: 0.3113512694835663, Accuracy: 0.896484375\n",
      "Batch: 30, Loss: 0.2670131325721741, Accuracy: 0.9130859375\n",
      "Batch: 31, Loss: 0.310086727142334, Accuracy: 0.8935546875\n",
      "Batch: 32, Loss: 0.27704912424087524, Accuracy: 0.9013671875\n",
      "Batch: 33, Loss: 0.27612733840942383, Accuracy: 0.912109375\n",
      "Batch: 34, Loss: 0.24394041299819946, Accuracy: 0.9169921875\n",
      "Batch: 35, Loss: 0.24922266602516174, Accuracy: 0.9189453125\n",
      "Batch: 36, Loss: 0.3191526234149933, Accuracy: 0.8974609375\n",
      "Batch: 37, Loss: 0.2352129966020584, Accuracy: 0.9169921875\n",
      "Batch: 38, Loss: 0.2610630691051483, Accuracy: 0.900390625\n",
      "Batch: 39, Loss: 0.26946237683296204, Accuracy: 0.90625\n",
      "Batch: 40, Loss: 0.2642897665500641, Accuracy: 0.9072265625\n",
      "Batch: 41, Loss: 0.277851939201355, Accuracy: 0.8994140625\n",
      "Batch: 42, Loss: 0.25938910245895386, Accuracy: 0.9072265625\n",
      "Batch: 43, Loss: 0.2572857439517975, Accuracy: 0.9072265625\n",
      "Batch: 44, Loss: 0.2771357595920563, Accuracy: 0.91015625\n",
      "Batch: 45, Loss: 0.29253125190734863, Accuracy: 0.9052734375\n",
      "Batch: 46, Loss: 0.26579204201698303, Accuracy: 0.904296875\n",
      "Batch: 47, Loss: 0.24893614649772644, Accuracy: 0.9140625\n",
      "Batch: 48, Loss: 0.24509257078170776, Accuracy: 0.9140625\n",
      "Batch: 49, Loss: 0.2974611520767212, Accuracy: 0.908203125\n",
      "Batch: 50, Loss: 0.24495896697044373, Accuracy: 0.9189453125\n",
      "Batch: 51, Loss: 0.289887934923172, Accuracy: 0.90234375\n",
      "Batch: 52, Loss: 0.27814698219299316, Accuracy: 0.908203125\n",
      "Batch: 53, Loss: 0.34997737407684326, Accuracy: 0.8935546875\n",
      "Batch: 54, Loss: 0.29360973834991455, Accuracy: 0.908203125\n",
      "Batch: 55, Loss: 0.30130788683891296, Accuracy: 0.8974609375\n",
      "Batch: 56, Loss: 0.23608267307281494, Accuracy: 0.919921875\n",
      "Batch: 57, Loss: 0.31392818689346313, Accuracy: 0.892578125\n",
      "Batch: 58, Loss: 0.30201730132102966, Accuracy: 0.90234375\n",
      "Batch: 59, Loss: 0.2988419532775879, Accuracy: 0.9033203125\n",
      "Batch: 60, Loss: 0.28018173575401306, Accuracy: 0.8974609375\n",
      "Batch: 61, Loss: 0.2758982181549072, Accuracy: 0.9052734375\n",
      "Batch: 62, Loss: 0.2871527075767517, Accuracy: 0.8916015625\n",
      "Batch: 63, Loss: 0.23573176562786102, Accuracy: 0.919921875\n",
      "Batch: 64, Loss: 0.27585768699645996, Accuracy: 0.9052734375\n",
      "Batch: 65, Loss: 0.26765871047973633, Accuracy: 0.9072265625\n",
      "Batch: 66, Loss: 0.24953538179397583, Accuracy: 0.9140625\n",
      "Batch: 67, Loss: 0.2574108839035034, Accuracy: 0.91796875\n",
      "Batch: 68, Loss: 0.309492290019989, Accuracy: 0.89453125\n",
      "Batch: 69, Loss: 0.22982563078403473, Accuracy: 0.921875\n",
      "Batch: 70, Loss: 0.2751131057739258, Accuracy: 0.91796875\n",
      "Batch: 71, Loss: 0.27747124433517456, Accuracy: 0.9072265625\n",
      "Batch: 72, Loss: 0.2836679220199585, Accuracy: 0.9052734375\n",
      "Batch: 73, Loss: 0.26100218296051025, Accuracy: 0.91015625\n",
      "Batch: 74, Loss: 0.28879064321517944, Accuracy: 0.8955078125\n",
      "Batch: 75, Loss: 0.23236083984375, Accuracy: 0.9189453125\n",
      "Batch: 76, Loss: 0.22091753780841827, Accuracy: 0.9169921875\n",
      "Batch: 77, Loss: 0.26139718294143677, Accuracy: 0.916015625\n",
      "Batch: 78, Loss: 0.282016396522522, Accuracy: 0.91015625\n",
      "Batch: 79, Loss: 0.29563289880752563, Accuracy: 0.9140625\n",
      "Batch: 80, Loss: 0.24177736043930054, Accuracy: 0.9189453125\n",
      "Batch: 81, Loss: 0.2883411943912506, Accuracy: 0.9052734375\n",
      "Batch: 82, Loss: 0.27014732360839844, Accuracy: 0.90625\n",
      "Batch: 83, Loss: 0.2344854474067688, Accuracy: 0.9150390625\n",
      "Batch: 84, Loss: 0.27373820543289185, Accuracy: 0.9150390625\n",
      "Batch: 85, Loss: 0.26989272236824036, Accuracy: 0.912109375\n",
      "Batch: 86, Loss: 0.27601438760757446, Accuracy: 0.91796875\n",
      "Batch: 87, Loss: 0.24314793944358826, Accuracy: 0.919921875\n",
      "Batch: 88, Loss: 0.31905120611190796, Accuracy: 0.89453125\n",
      "Batch: 89, Loss: 0.24840565025806427, Accuracy: 0.916015625\n",
      "Batch: 90, Loss: 0.3328668475151062, Accuracy: 0.884765625\n",
      "Batch: 91, Loss: 0.3135678768157959, Accuracy: 0.8935546875\n",
      "Batch: 92, Loss: 0.30142074823379517, Accuracy: 0.890625\n",
      "Batch: 93, Loss: 0.2857842445373535, Accuracy: 0.9052734375\n",
      "Batch: 94, Loss: 0.2815965414047241, Accuracy: 0.9013671875\n",
      "Batch: 95, Loss: 0.2742280960083008, Accuracy: 0.8984375\n",
      "Batch: 96, Loss: 0.271148145198822, Accuracy: 0.9111328125\n",
      "Batch: 97, Loss: 0.23375484347343445, Accuracy: 0.923828125\n",
      "Batch: 98, Loss: 0.299842894077301, Accuracy: 0.8974609375\n",
      "Batch: 99, Loss: 0.2528100609779358, Accuracy: 0.9130859375\n",
      "Batch: 100, Loss: 0.2821691632270813, Accuracy: 0.896484375\n",
      "Batch: 101, Loss: 0.291232168674469, Accuracy: 0.8994140625\n",
      "Batch: 102, Loss: 0.28035497665405273, Accuracy: 0.9111328125\n",
      "Batch: 103, Loss: 0.29484692215919495, Accuracy: 0.9052734375\n",
      "Batch: 104, Loss: 0.2933335304260254, Accuracy: 0.8935546875\n",
      "Batch: 105, Loss: 0.21846431493759155, Accuracy: 0.919921875\n",
      "Batch: 106, Loss: 0.264394074678421, Accuracy: 0.90234375\n",
      "Batch: 107, Loss: 0.24914336204528809, Accuracy: 0.919921875\n",
      "Batch: 108, Loss: 0.25988519191741943, Accuracy: 0.9189453125\n",
      "Batch: 109, Loss: 0.2312742918729782, Accuracy: 0.9169921875\n",
      "Batch: 110, Loss: 0.24658964574337006, Accuracy: 0.92578125\n",
      "Batch: 111, Loss: 0.2791094183921814, Accuracy: 0.9140625\n",
      "Batch: 112, Loss: 0.27480947971343994, Accuracy: 0.90234375\n",
      "Epoch 66/90\n",
      "Batch: 1, Loss: 0.3568840026855469, Accuracy: 0.8984375\n",
      "Batch: 2, Loss: 0.26582711935043335, Accuracy: 0.9169921875\n",
      "Batch: 3, Loss: 0.2579249143600464, Accuracy: 0.9091796875\n",
      "Batch: 4, Loss: 0.24904891848564148, Accuracy: 0.90625\n",
      "Batch: 5, Loss: 0.22951877117156982, Accuracy: 0.9208984375\n",
      "Batch: 6, Loss: 0.2885245084762573, Accuracy: 0.90234375\n",
      "Batch: 7, Loss: 0.24166876077651978, Accuracy: 0.921875\n",
      "Batch: 8, Loss: 0.252261757850647, Accuracy: 0.9189453125\n",
      "Batch: 9, Loss: 0.2640419006347656, Accuracy: 0.912109375\n",
      "Batch: 10, Loss: 0.33532702922821045, Accuracy: 0.890625\n",
      "Batch: 11, Loss: 0.26593250036239624, Accuracy: 0.916015625\n",
      "Batch: 12, Loss: 0.2513398230075836, Accuracy: 0.91796875\n",
      "Batch: 13, Loss: 0.23778030276298523, Accuracy: 0.9111328125\n",
      "Batch: 14, Loss: 0.2695596218109131, Accuracy: 0.908203125\n",
      "Batch: 15, Loss: 0.2924690842628479, Accuracy: 0.90234375\n",
      "Batch: 16, Loss: 0.2861449122428894, Accuracy: 0.90234375\n",
      "Batch: 17, Loss: 0.26021111011505127, Accuracy: 0.9150390625\n",
      "Batch: 18, Loss: 0.24795818328857422, Accuracy: 0.916015625\n",
      "Batch: 19, Loss: 0.2603457570075989, Accuracy: 0.912109375\n",
      "Batch: 20, Loss: 0.27355068922042847, Accuracy: 0.9033203125\n",
      "Batch: 21, Loss: 0.29737091064453125, Accuracy: 0.90625\n",
      "Batch: 22, Loss: 0.2605571746826172, Accuracy: 0.90625\n",
      "Batch: 23, Loss: 0.2816314101219177, Accuracy: 0.91015625\n",
      "Batch: 24, Loss: 0.3423245847225189, Accuracy: 0.8837890625\n",
      "Batch: 25, Loss: 0.2934894263744354, Accuracy: 0.8974609375\n",
      "Batch: 26, Loss: 0.2927004098892212, Accuracy: 0.90234375\n",
      "Batch: 27, Loss: 0.29979249835014343, Accuracy: 0.9013671875\n",
      "Batch: 28, Loss: 0.2800785303115845, Accuracy: 0.900390625\n",
      "Batch: 29, Loss: 0.3045271635055542, Accuracy: 0.9091796875\n",
      "Batch: 30, Loss: 0.25570303201675415, Accuracy: 0.9150390625\n",
      "Batch: 31, Loss: 0.29725539684295654, Accuracy: 0.8984375\n",
      "Batch: 32, Loss: 0.2452610433101654, Accuracy: 0.9140625\n",
      "Batch: 33, Loss: 0.24802076816558838, Accuracy: 0.908203125\n",
      "Batch: 34, Loss: 0.2661747336387634, Accuracy: 0.9111328125\n",
      "Batch: 35, Loss: 0.2445264756679535, Accuracy: 0.91796875\n",
      "Batch: 36, Loss: 0.2882809042930603, Accuracy: 0.904296875\n",
      "Batch: 37, Loss: 0.2861410975456238, Accuracy: 0.9033203125\n",
      "Batch: 38, Loss: 0.28601139783859253, Accuracy: 0.900390625\n",
      "Batch: 39, Loss: 0.2576996088027954, Accuracy: 0.9150390625\n",
      "Batch: 40, Loss: 0.3127211034297943, Accuracy: 0.89453125\n",
      "Batch: 41, Loss: 0.2693747282028198, Accuracy: 0.9150390625\n",
      "Batch: 42, Loss: 0.2725285291671753, Accuracy: 0.904296875\n",
      "Batch: 43, Loss: 0.259820818901062, Accuracy: 0.91015625\n",
      "Batch: 44, Loss: 0.2565189301967621, Accuracy: 0.908203125\n",
      "Batch: 45, Loss: 0.30325835943222046, Accuracy: 0.90234375\n",
      "Batch: 46, Loss: 0.29920488595962524, Accuracy: 0.9013671875\n",
      "Batch: 47, Loss: 0.24691003561019897, Accuracy: 0.9140625\n",
      "Batch: 48, Loss: 0.25096869468688965, Accuracy: 0.9150390625\n",
      "Batch: 49, Loss: 0.3115658462047577, Accuracy: 0.896484375\n",
      "Batch: 50, Loss: 0.23149055242538452, Accuracy: 0.9267578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 51, Loss: 0.26055872440338135, Accuracy: 0.912109375\n",
      "Batch: 52, Loss: 0.2749243378639221, Accuracy: 0.90625\n",
      "Batch: 53, Loss: 0.28384172916412354, Accuracy: 0.904296875\n",
      "Batch: 54, Loss: 0.282266765832901, Accuracy: 0.908203125\n",
      "Batch: 55, Loss: 0.28148597478866577, Accuracy: 0.9033203125\n",
      "Batch: 56, Loss: 0.24183201789855957, Accuracy: 0.9150390625\n",
      "Batch: 57, Loss: 0.3112128973007202, Accuracy: 0.90234375\n",
      "Batch: 58, Loss: 0.28351032733917236, Accuracy: 0.9013671875\n",
      "Batch: 59, Loss: 0.3094791769981384, Accuracy: 0.89453125\n",
      "Batch: 60, Loss: 0.2898036539554596, Accuracy: 0.9072265625\n",
      "Batch: 61, Loss: 0.25044485926628113, Accuracy: 0.91015625\n",
      "Batch: 62, Loss: 0.2472190260887146, Accuracy: 0.9091796875\n",
      "Batch: 63, Loss: 0.24052275717258453, Accuracy: 0.919921875\n",
      "Batch: 64, Loss: 0.2859351336956024, Accuracy: 0.904296875\n",
      "Batch: 65, Loss: 0.24948790669441223, Accuracy: 0.91796875\n",
      "Batch: 66, Loss: 0.2725462019443512, Accuracy: 0.908203125\n",
      "Batch: 67, Loss: 0.2440570592880249, Accuracy: 0.9091796875\n",
      "Batch: 68, Loss: 0.26161378622055054, Accuracy: 0.9091796875\n",
      "Batch: 69, Loss: 0.251767098903656, Accuracy: 0.9150390625\n",
      "Batch: 70, Loss: 0.24254140257835388, Accuracy: 0.92578125\n",
      "Batch: 71, Loss: 0.24736948311328888, Accuracy: 0.9150390625\n",
      "Batch: 72, Loss: 0.287045955657959, Accuracy: 0.8974609375\n",
      "Batch: 73, Loss: 0.25271713733673096, Accuracy: 0.916015625\n",
      "Batch: 74, Loss: 0.26503753662109375, Accuracy: 0.90234375\n",
      "Batch: 75, Loss: 0.24200396239757538, Accuracy: 0.9287109375\n",
      "Batch: 76, Loss: 0.20880267024040222, Accuracy: 0.9267578125\n",
      "Batch: 77, Loss: 0.2528800964355469, Accuracy: 0.9150390625\n",
      "Batch: 78, Loss: 0.28241124749183655, Accuracy: 0.896484375\n",
      "Batch: 79, Loss: 0.26475757360458374, Accuracy: 0.91015625\n",
      "Batch: 80, Loss: 0.24920088052749634, Accuracy: 0.9169921875\n",
      "Batch: 81, Loss: 0.2964543104171753, Accuracy: 0.896484375\n",
      "Batch: 82, Loss: 0.29076719284057617, Accuracy: 0.900390625\n",
      "Batch: 83, Loss: 0.22913479804992676, Accuracy: 0.9169921875\n",
      "Batch: 84, Loss: 0.25647932291030884, Accuracy: 0.916015625\n",
      "Batch: 85, Loss: 0.27979594469070435, Accuracy: 0.9033203125\n",
      "Batch: 86, Loss: 0.28780481219291687, Accuracy: 0.90625\n",
      "Batch: 87, Loss: 0.2692297697067261, Accuracy: 0.90625\n",
      "Batch: 88, Loss: 0.3223792016506195, Accuracy: 0.890625\n",
      "Batch: 89, Loss: 0.28648096323013306, Accuracy: 0.904296875\n",
      "Batch: 90, Loss: 0.33650732040405273, Accuracy: 0.8837890625\n",
      "Batch: 91, Loss: 0.30726420879364014, Accuracy: 0.8896484375\n",
      "Batch: 92, Loss: 0.292552649974823, Accuracy: 0.9052734375\n",
      "Batch: 93, Loss: 0.31419694423675537, Accuracy: 0.88671875\n",
      "Batch: 94, Loss: 0.30282777547836304, Accuracy: 0.896484375\n",
      "Batch: 95, Loss: 0.2861137390136719, Accuracy: 0.896484375\n",
      "Batch: 96, Loss: 0.27887606620788574, Accuracy: 0.90625\n",
      "Batch: 97, Loss: 0.26423025131225586, Accuracy: 0.90625\n",
      "Batch: 98, Loss: 0.28176993131637573, Accuracy: 0.900390625\n",
      "Batch: 99, Loss: 0.2626171410083771, Accuracy: 0.9091796875\n",
      "Batch: 100, Loss: 0.2628827691078186, Accuracy: 0.90625\n",
      "Batch: 101, Loss: 0.2725757360458374, Accuracy: 0.9033203125\n",
      "Batch: 102, Loss: 0.28303730487823486, Accuracy: 0.908203125\n",
      "Batch: 103, Loss: 0.27775663137435913, Accuracy: 0.8955078125\n",
      "Batch: 104, Loss: 0.28716397285461426, Accuracy: 0.90625\n",
      "Batch: 105, Loss: 0.24038159847259521, Accuracy: 0.9091796875\n",
      "Batch: 106, Loss: 0.26595187187194824, Accuracy: 0.9091796875\n",
      "Batch: 107, Loss: 0.25326770544052124, Accuracy: 0.91015625\n",
      "Batch: 108, Loss: 0.23870518803596497, Accuracy: 0.9248046875\n",
      "Batch: 109, Loss: 0.23590916395187378, Accuracy: 0.9150390625\n",
      "Batch: 110, Loss: 0.24314308166503906, Accuracy: 0.9208984375\n",
      "Batch: 111, Loss: 0.30388426780700684, Accuracy: 0.8974609375\n",
      "Batch: 112, Loss: 0.27506905794143677, Accuracy: 0.90625\n",
      "Epoch 67/90\n",
      "Batch: 1, Loss: 0.32562416791915894, Accuracy: 0.912109375\n",
      "Batch: 2, Loss: 0.279163658618927, Accuracy: 0.9013671875\n",
      "Batch: 3, Loss: 0.3057079315185547, Accuracy: 0.8984375\n",
      "Batch: 4, Loss: 0.24288222193717957, Accuracy: 0.9248046875\n",
      "Batch: 5, Loss: 0.22894249856472015, Accuracy: 0.9296875\n",
      "Batch: 6, Loss: 0.2752476632595062, Accuracy: 0.9189453125\n",
      "Batch: 7, Loss: 0.24986135959625244, Accuracy: 0.916015625\n",
      "Batch: 8, Loss: 0.2255304455757141, Accuracy: 0.9208984375\n",
      "Batch: 9, Loss: 0.25265708565711975, Accuracy: 0.9150390625\n",
      "Batch: 10, Loss: 0.28445589542388916, Accuracy: 0.9111328125\n",
      "Batch: 11, Loss: 0.306308776140213, Accuracy: 0.896484375\n",
      "Batch: 12, Loss: 0.2462766021490097, Accuracy: 0.90625\n",
      "Batch: 13, Loss: 0.23647217452526093, Accuracy: 0.916015625\n",
      "Batch: 14, Loss: 0.2927483916282654, Accuracy: 0.9072265625\n",
      "Batch: 15, Loss: 0.2601009011268616, Accuracy: 0.9189453125\n",
      "Batch: 16, Loss: 0.2586362957954407, Accuracy: 0.9169921875\n",
      "Batch: 17, Loss: 0.28582239151000977, Accuracy: 0.9072265625\n",
      "Batch: 18, Loss: 0.23238053917884827, Accuracy: 0.916015625\n",
      "Batch: 19, Loss: 0.2624620795249939, Accuracy: 0.91015625\n",
      "Batch: 20, Loss: 0.2900170683860779, Accuracy: 0.888671875\n",
      "Batch: 21, Loss: 0.27468788623809814, Accuracy: 0.9091796875\n",
      "Batch: 22, Loss: 0.25145649909973145, Accuracy: 0.91015625\n",
      "Batch: 23, Loss: 0.27359187602996826, Accuracy: 0.90625\n",
      "Batch: 24, Loss: 0.32689130306243896, Accuracy: 0.890625\n",
      "Batch: 25, Loss: 0.31557050347328186, Accuracy: 0.8974609375\n",
      "Batch: 26, Loss: 0.2989952564239502, Accuracy: 0.908203125\n",
      "Batch: 27, Loss: 0.30381643772125244, Accuracy: 0.8974609375\n",
      "Batch: 28, Loss: 0.2766036093235016, Accuracy: 0.91015625\n",
      "Batch: 29, Loss: 0.29922112822532654, Accuracy: 0.90625\n",
      "Batch: 30, Loss: 0.23753690719604492, Accuracy: 0.9208984375\n",
      "Batch: 31, Loss: 0.29209330677986145, Accuracy: 0.89453125\n",
      "Batch: 32, Loss: 0.2528366446495056, Accuracy: 0.9111328125\n",
      "Batch: 33, Loss: 0.2747059464454651, Accuracy: 0.90234375\n",
      "Batch: 34, Loss: 0.23040230572223663, Accuracy: 0.923828125\n",
      "Batch: 35, Loss: 0.25372445583343506, Accuracy: 0.9150390625\n",
      "Batch: 36, Loss: 0.2850308418273926, Accuracy: 0.8994140625\n",
      "Batch: 37, Loss: 0.25122320652008057, Accuracy: 0.9169921875\n",
      "Batch: 38, Loss: 0.2809593081474304, Accuracy: 0.9072265625\n",
      "Batch: 39, Loss: 0.25498026609420776, Accuracy: 0.9072265625\n",
      "Batch: 40, Loss: 0.2478073090314865, Accuracy: 0.9111328125\n",
      "Batch: 41, Loss: 0.2821018099784851, Accuracy: 0.9052734375\n",
      "Batch: 42, Loss: 0.2871147692203522, Accuracy: 0.900390625\n",
      "Batch: 43, Loss: 0.2556733191013336, Accuracy: 0.91015625\n",
      "Batch: 44, Loss: 0.2532532215118408, Accuracy: 0.923828125\n",
      "Batch: 45, Loss: 0.2566482126712799, Accuracy: 0.9150390625\n",
      "Batch: 46, Loss: 0.29450979828834534, Accuracy: 0.890625\n",
      "Batch: 47, Loss: 0.24917611479759216, Accuracy: 0.9140625\n",
      "Batch: 48, Loss: 0.2651273012161255, Accuracy: 0.9130859375\n",
      "Batch: 49, Loss: 0.2457524687051773, Accuracy: 0.9267578125\n",
      "Batch: 50, Loss: 0.22442148625850677, Accuracy: 0.9267578125\n",
      "Batch: 51, Loss: 0.24944715201854706, Accuracy: 0.9130859375\n",
      "Batch: 52, Loss: 0.2941543757915497, Accuracy: 0.896484375\n",
      "Batch: 53, Loss: 0.3302944302558899, Accuracy: 0.8876953125\n",
      "Batch: 54, Loss: 0.305574893951416, Accuracy: 0.9052734375\n",
      "Batch: 55, Loss: 0.2891848087310791, Accuracy: 0.912109375\n",
      "Batch: 56, Loss: 0.2271120548248291, Accuracy: 0.9228515625\n",
      "Batch: 57, Loss: 0.32602107524871826, Accuracy: 0.900390625\n",
      "Batch: 58, Loss: 0.30375614762306213, Accuracy: 0.90234375\n",
      "Batch: 59, Loss: 0.3141406178474426, Accuracy: 0.8896484375\n",
      "Batch: 60, Loss: 0.2507087290287018, Accuracy: 0.90234375\n",
      "Batch: 61, Loss: 0.24928933382034302, Accuracy: 0.9140625\n",
      "Batch: 62, Loss: 0.27193838357925415, Accuracy: 0.9130859375\n",
      "Batch: 63, Loss: 0.23984932899475098, Accuracy: 0.919921875\n",
      "Batch: 64, Loss: 0.2748839855194092, Accuracy: 0.90625\n",
      "Batch: 65, Loss: 0.25198987126350403, Accuracy: 0.9150390625\n",
      "Batch: 66, Loss: 0.2214173674583435, Accuracy: 0.931640625\n",
      "Batch: 67, Loss: 0.2869120240211487, Accuracy: 0.8974609375\n",
      "Batch: 68, Loss: 0.27244922518730164, Accuracy: 0.9169921875\n",
      "Batch: 69, Loss: 0.2336145043373108, Accuracy: 0.9189453125\n",
      "Batch: 70, Loss: 0.23619957268238068, Accuracy: 0.916015625\n",
      "Batch: 71, Loss: 0.24229437112808228, Accuracy: 0.921875\n",
      "Batch: 72, Loss: 0.2698606550693512, Accuracy: 0.90234375\n",
      "Batch: 73, Loss: 0.2591635584831238, Accuracy: 0.91796875\n",
      "Batch: 74, Loss: 0.2619097828865051, Accuracy: 0.90625\n",
      "Batch: 75, Loss: 0.2550343871116638, Accuracy: 0.9052734375\n",
      "Batch: 76, Loss: 0.21561862528324127, Accuracy: 0.9208984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 77, Loss: 0.25940394401550293, Accuracy: 0.91796875\n",
      "Batch: 78, Loss: 0.26325517892837524, Accuracy: 0.9111328125\n",
      "Batch: 79, Loss: 0.2572714686393738, Accuracy: 0.9208984375\n",
      "Batch: 80, Loss: 0.25935906171798706, Accuracy: 0.9111328125\n",
      "Batch: 81, Loss: 0.2947966158390045, Accuracy: 0.900390625\n",
      "Batch: 82, Loss: 0.25821343064308167, Accuracy: 0.9111328125\n",
      "Batch: 83, Loss: 0.25010058283805847, Accuracy: 0.9150390625\n",
      "Batch: 84, Loss: 0.22772163152694702, Accuracy: 0.919921875\n",
      "Batch: 85, Loss: 0.27261799573898315, Accuracy: 0.908203125\n",
      "Batch: 86, Loss: 0.27296537160873413, Accuracy: 0.9033203125\n",
      "Batch: 87, Loss: 0.258121132850647, Accuracy: 0.9169921875\n",
      "Batch: 88, Loss: 0.26094910502433777, Accuracy: 0.9091796875\n",
      "Batch: 89, Loss: 0.25373491644859314, Accuracy: 0.912109375\n",
      "Batch: 90, Loss: 0.31776633858680725, Accuracy: 0.8935546875\n",
      "Batch: 91, Loss: 0.3102455139160156, Accuracy: 0.904296875\n",
      "Batch: 92, Loss: 0.2907450199127197, Accuracy: 0.9052734375\n",
      "Batch: 93, Loss: 0.3182705044746399, Accuracy: 0.89453125\n",
      "Batch: 94, Loss: 0.28037095069885254, Accuracy: 0.90625\n",
      "Batch: 95, Loss: 0.29776185750961304, Accuracy: 0.8974609375\n",
      "Batch: 96, Loss: 0.28282368183135986, Accuracy: 0.9033203125\n",
      "Batch: 97, Loss: 0.23866796493530273, Accuracy: 0.9208984375\n",
      "Batch: 98, Loss: 0.28520405292510986, Accuracy: 0.9091796875\n",
      "Batch: 99, Loss: 0.24014639854431152, Accuracy: 0.9150390625\n",
      "Batch: 100, Loss: 0.24346759915351868, Accuracy: 0.9169921875\n",
      "Batch: 101, Loss: 0.2821178436279297, Accuracy: 0.8984375\n",
      "Batch: 102, Loss: 0.26754486560821533, Accuracy: 0.908203125\n",
      "Batch: 103, Loss: 0.27881157398223877, Accuracy: 0.9111328125\n",
      "Batch: 104, Loss: 0.2636893689632416, Accuracy: 0.91015625\n",
      "Batch: 105, Loss: 0.23512548208236694, Accuracy: 0.9150390625\n",
      "Batch: 106, Loss: 0.2728992700576782, Accuracy: 0.9052734375\n",
      "Batch: 107, Loss: 0.2640642821788788, Accuracy: 0.9091796875\n",
      "Batch: 108, Loss: 0.26988059282302856, Accuracy: 0.9150390625\n",
      "Batch: 109, Loss: 0.21581679582595825, Accuracy: 0.9228515625\n",
      "Batch: 110, Loss: 0.22146590054035187, Accuracy: 0.9326171875\n",
      "Batch: 111, Loss: 0.2876565754413605, Accuracy: 0.9052734375\n",
      "Batch: 112, Loss: 0.27490872144699097, Accuracy: 0.9091796875\n",
      "Epoch 68/90\n",
      "Batch: 1, Loss: 0.3247162699699402, Accuracy: 0.91015625\n",
      "Batch: 2, Loss: 0.2681669592857361, Accuracy: 0.9189453125\n",
      "Batch: 3, Loss: 0.2784714698791504, Accuracy: 0.9111328125\n",
      "Batch: 4, Loss: 0.24711263179779053, Accuracy: 0.9169921875\n",
      "Batch: 5, Loss: 0.22039735317230225, Accuracy: 0.927734375\n",
      "Batch: 6, Loss: 0.2868098020553589, Accuracy: 0.9140625\n",
      "Batch: 7, Loss: 0.23265500366687775, Accuracy: 0.923828125\n",
      "Batch: 8, Loss: 0.23564404249191284, Accuracy: 0.927734375\n",
      "Batch: 9, Loss: 0.258595734834671, Accuracy: 0.9169921875\n",
      "Batch: 10, Loss: 0.28207826614379883, Accuracy: 0.890625\n",
      "Batch: 11, Loss: 0.3048478960990906, Accuracy: 0.90234375\n",
      "Batch: 12, Loss: 0.24189206957817078, Accuracy: 0.9150390625\n",
      "Batch: 13, Loss: 0.21377527713775635, Accuracy: 0.923828125\n",
      "Batch: 14, Loss: 0.25031957030296326, Accuracy: 0.912109375\n",
      "Batch: 15, Loss: 0.2618325352668762, Accuracy: 0.91796875\n",
      "Batch: 16, Loss: 0.2707003653049469, Accuracy: 0.9150390625\n",
      "Batch: 17, Loss: 0.23949569463729858, Accuracy: 0.9208984375\n",
      "Batch: 18, Loss: 0.25112754106521606, Accuracy: 0.9140625\n",
      "Batch: 19, Loss: 0.2675741910934448, Accuracy: 0.921875\n",
      "Batch: 20, Loss: 0.25002267956733704, Accuracy: 0.9140625\n",
      "Batch: 21, Loss: 0.28242433071136475, Accuracy: 0.9013671875\n",
      "Batch: 22, Loss: 0.2558346390724182, Accuracy: 0.9072265625\n",
      "Batch: 23, Loss: 0.29261091351509094, Accuracy: 0.90625\n",
      "Batch: 24, Loss: 0.2770750820636749, Accuracy: 0.8955078125\n",
      "Batch: 25, Loss: 0.3069682717323303, Accuracy: 0.8974609375\n",
      "Batch: 26, Loss: 0.2866901755332947, Accuracy: 0.900390625\n",
      "Batch: 27, Loss: 0.3241780400276184, Accuracy: 0.8974609375\n",
      "Batch: 28, Loss: 0.26985466480255127, Accuracy: 0.9111328125\n",
      "Batch: 29, Loss: 0.2956100106239319, Accuracy: 0.90625\n",
      "Batch: 30, Loss: 0.23882341384887695, Accuracy: 0.9228515625\n",
      "Batch: 31, Loss: 0.29553234577178955, Accuracy: 0.9033203125\n",
      "Batch: 32, Loss: 0.2752891182899475, Accuracy: 0.900390625\n",
      "Batch: 33, Loss: 0.24880579113960266, Accuracy: 0.90625\n",
      "Batch: 34, Loss: 0.2610260248184204, Accuracy: 0.91015625\n",
      "Batch: 35, Loss: 0.2775607705116272, Accuracy: 0.8974609375\n",
      "Batch: 36, Loss: 0.29420047998428345, Accuracy: 0.9091796875\n",
      "Batch: 37, Loss: 0.238398015499115, Accuracy: 0.919921875\n",
      "Batch: 38, Loss: 0.2928357422351837, Accuracy: 0.8916015625\n",
      "Batch: 39, Loss: 0.25505250692367554, Accuracy: 0.904296875\n",
      "Batch: 40, Loss: 0.2524581253528595, Accuracy: 0.9169921875\n",
      "Batch: 41, Loss: 0.2571350932121277, Accuracy: 0.91796875\n",
      "Batch: 42, Loss: 0.25831836462020874, Accuracy: 0.9208984375\n",
      "Batch: 43, Loss: 0.2621552348136902, Accuracy: 0.908203125\n",
      "Batch: 44, Loss: 0.2550725042819977, Accuracy: 0.9013671875\n",
      "Batch: 45, Loss: 0.26345908641815186, Accuracy: 0.9111328125\n",
      "Batch: 46, Loss: 0.23824524879455566, Accuracy: 0.912109375\n",
      "Batch: 47, Loss: 0.26623404026031494, Accuracy: 0.9150390625\n",
      "Batch: 48, Loss: 0.2491835653781891, Accuracy: 0.916015625\n",
      "Batch: 49, Loss: 0.267201691865921, Accuracy: 0.9130859375\n",
      "Batch: 50, Loss: 0.23053531348705292, Accuracy: 0.919921875\n",
      "Batch: 51, Loss: 0.26551103591918945, Accuracy: 0.91015625\n",
      "Batch: 52, Loss: 0.24209055304527283, Accuracy: 0.91796875\n",
      "Batch: 53, Loss: 0.3119118809700012, Accuracy: 0.892578125\n",
      "Batch: 54, Loss: 0.2565702199935913, Accuracy: 0.9140625\n",
      "Batch: 55, Loss: 0.2664673924446106, Accuracy: 0.912109375\n",
      "Batch: 56, Loss: 0.2209385633468628, Accuracy: 0.9267578125\n",
      "Batch: 57, Loss: 0.30799707770347595, Accuracy: 0.890625\n",
      "Batch: 58, Loss: 0.3060842454433441, Accuracy: 0.9013671875\n",
      "Batch: 59, Loss: 0.29401087760925293, Accuracy: 0.9013671875\n",
      "Batch: 60, Loss: 0.25962939858436584, Accuracy: 0.912109375\n",
      "Batch: 61, Loss: 0.2660328447818756, Accuracy: 0.8994140625\n",
      "Batch: 62, Loss: 0.27614110708236694, Accuracy: 0.9091796875\n",
      "Batch: 63, Loss: 0.2228279858827591, Accuracy: 0.9326171875\n",
      "Batch: 64, Loss: 0.30240947008132935, Accuracy: 0.896484375\n",
      "Batch: 65, Loss: 0.2665366530418396, Accuracy: 0.9091796875\n",
      "Batch: 66, Loss: 0.25338014960289, Accuracy: 0.9248046875\n",
      "Batch: 67, Loss: 0.23948541283607483, Accuracy: 0.9169921875\n",
      "Batch: 68, Loss: 0.2665140628814697, Accuracy: 0.9228515625\n",
      "Batch: 69, Loss: 0.25841230154037476, Accuracy: 0.908203125\n",
      "Batch: 70, Loss: 0.25019553303718567, Accuracy: 0.9208984375\n",
      "Batch: 71, Loss: 0.24704807996749878, Accuracy: 0.9130859375\n",
      "Batch: 72, Loss: 0.26047515869140625, Accuracy: 0.9189453125\n",
      "Batch: 73, Loss: 0.26429325342178345, Accuracy: 0.921875\n",
      "Batch: 74, Loss: 0.28940385580062866, Accuracy: 0.9013671875\n",
      "Batch: 75, Loss: 0.22814875841140747, Accuracy: 0.9189453125\n",
      "Batch: 76, Loss: 0.22662967443466187, Accuracy: 0.9248046875\n",
      "Batch: 77, Loss: 0.26145970821380615, Accuracy: 0.916015625\n",
      "Batch: 78, Loss: 0.2610914409160614, Accuracy: 0.908203125\n",
      "Batch: 79, Loss: 0.2643281817436218, Accuracy: 0.919921875\n",
      "Batch: 80, Loss: 0.2612881660461426, Accuracy: 0.90625\n",
      "Batch: 81, Loss: 0.3106532096862793, Accuracy: 0.892578125\n",
      "Batch: 82, Loss: 0.2807644009590149, Accuracy: 0.9052734375\n",
      "Batch: 83, Loss: 0.2469654083251953, Accuracy: 0.919921875\n",
      "Batch: 84, Loss: 0.27139076590538025, Accuracy: 0.9130859375\n",
      "Batch: 85, Loss: 0.24479882419109344, Accuracy: 0.921875\n",
      "Batch: 86, Loss: 0.2846176028251648, Accuracy: 0.900390625\n",
      "Batch: 87, Loss: 0.2530865967273712, Accuracy: 0.9130859375\n",
      "Batch: 88, Loss: 0.24969512224197388, Accuracy: 0.9150390625\n",
      "Batch: 89, Loss: 0.2716423571109772, Accuracy: 0.9111328125\n",
      "Batch: 90, Loss: 0.3157506585121155, Accuracy: 0.8916015625\n",
      "Batch: 91, Loss: 0.3171721398830414, Accuracy: 0.888671875\n",
      "Batch: 92, Loss: 0.2918369770050049, Accuracy: 0.90234375\n",
      "Batch: 93, Loss: 0.28519412875175476, Accuracy: 0.900390625\n",
      "Batch: 94, Loss: 0.27387547492980957, Accuracy: 0.9033203125\n",
      "Batch: 95, Loss: 0.2862153649330139, Accuracy: 0.904296875\n",
      "Batch: 96, Loss: 0.26012253761291504, Accuracy: 0.9111328125\n",
      "Batch: 97, Loss: 0.2293253242969513, Accuracy: 0.9228515625\n",
      "Batch: 98, Loss: 0.2560114860534668, Accuracy: 0.9169921875\n",
      "Batch: 99, Loss: 0.23005163669586182, Accuracy: 0.9150390625\n",
      "Batch: 100, Loss: 0.2810002565383911, Accuracy: 0.900390625\n",
      "Batch: 101, Loss: 0.26216334104537964, Accuracy: 0.9013671875\n",
      "Batch: 102, Loss: 0.24303513765335083, Accuracy: 0.916015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 103, Loss: 0.2920985817909241, Accuracy: 0.9013671875\n",
      "Batch: 104, Loss: 0.2827485203742981, Accuracy: 0.900390625\n",
      "Batch: 105, Loss: 0.20974835753440857, Accuracy: 0.9306640625\n",
      "Batch: 106, Loss: 0.28035804629325867, Accuracy: 0.8974609375\n",
      "Batch: 107, Loss: 0.24782761931419373, Accuracy: 0.9189453125\n",
      "Batch: 108, Loss: 0.22621403634548187, Accuracy: 0.923828125\n",
      "Batch: 109, Loss: 0.18480706214904785, Accuracy: 0.9306640625\n",
      "Batch: 110, Loss: 0.2364530712366104, Accuracy: 0.919921875\n",
      "Batch: 111, Loss: 0.2805882692337036, Accuracy: 0.9013671875\n",
      "Batch: 112, Loss: 0.2767811715602875, Accuracy: 0.8994140625\n",
      "Epoch 69/90\n",
      "Batch: 1, Loss: 0.33651936054229736, Accuracy: 0.896484375\n",
      "Batch: 2, Loss: 0.261981338262558, Accuracy: 0.9150390625\n",
      "Batch: 3, Loss: 0.2629934549331665, Accuracy: 0.908203125\n",
      "Batch: 4, Loss: 0.23197118937969208, Accuracy: 0.9150390625\n",
      "Batch: 5, Loss: 0.22268472611904144, Accuracy: 0.9248046875\n",
      "Batch: 6, Loss: 0.24918228387832642, Accuracy: 0.919921875\n",
      "Batch: 7, Loss: 0.22806468605995178, Accuracy: 0.9228515625\n",
      "Batch: 8, Loss: 0.2616315484046936, Accuracy: 0.9169921875\n",
      "Batch: 9, Loss: 0.24948002398014069, Accuracy: 0.921875\n",
      "Batch: 10, Loss: 0.27640777826309204, Accuracy: 0.9072265625\n",
      "Batch: 11, Loss: 0.2904329299926758, Accuracy: 0.90234375\n",
      "Batch: 12, Loss: 0.2131606638431549, Accuracy: 0.91796875\n",
      "Batch: 13, Loss: 0.20028620958328247, Accuracy: 0.93359375\n",
      "Batch: 14, Loss: 0.26461467146873474, Accuracy: 0.9013671875\n",
      "Batch: 15, Loss: 0.2400740683078766, Accuracy: 0.9189453125\n",
      "Batch: 16, Loss: 0.2516278028488159, Accuracy: 0.9169921875\n",
      "Batch: 17, Loss: 0.2588813006877899, Accuracy: 0.9150390625\n",
      "Batch: 18, Loss: 0.23517940938472748, Accuracy: 0.916015625\n",
      "Batch: 19, Loss: 0.24294760823249817, Accuracy: 0.9208984375\n",
      "Batch: 20, Loss: 0.26151666045188904, Accuracy: 0.91015625\n",
      "Batch: 21, Loss: 0.2830736041069031, Accuracy: 0.9150390625\n",
      "Batch: 22, Loss: 0.2262960523366928, Accuracy: 0.923828125\n",
      "Batch: 23, Loss: 0.27673304080963135, Accuracy: 0.90234375\n",
      "Batch: 24, Loss: 0.30051177740097046, Accuracy: 0.9091796875\n",
      "Batch: 25, Loss: 0.2876194715499878, Accuracy: 0.9013671875\n",
      "Batch: 26, Loss: 0.28057047724723816, Accuracy: 0.908203125\n",
      "Batch: 27, Loss: 0.3138028681278229, Accuracy: 0.890625\n",
      "Batch: 28, Loss: 0.2979128956794739, Accuracy: 0.8994140625\n",
      "Batch: 29, Loss: 0.31795942783355713, Accuracy: 0.896484375\n",
      "Batch: 30, Loss: 0.22839969396591187, Accuracy: 0.9326171875\n",
      "Batch: 31, Loss: 0.25242501497268677, Accuracy: 0.9111328125\n",
      "Batch: 32, Loss: 0.22457730770111084, Accuracy: 0.9296875\n",
      "Batch: 33, Loss: 0.23704266548156738, Accuracy: 0.9248046875\n",
      "Batch: 34, Loss: 0.2357676923274994, Accuracy: 0.9306640625\n",
      "Batch: 35, Loss: 0.2838118374347687, Accuracy: 0.91015625\n",
      "Batch: 36, Loss: 0.30214935541152954, Accuracy: 0.8955078125\n",
      "Batch: 37, Loss: 0.22528767585754395, Accuracy: 0.9189453125\n",
      "Batch: 38, Loss: 0.25907063484191895, Accuracy: 0.9052734375\n",
      "Batch: 39, Loss: 0.25352051854133606, Accuracy: 0.9130859375\n",
      "Batch: 40, Loss: 0.24511507153511047, Accuracy: 0.916015625\n",
      "Batch: 41, Loss: 0.2882828712463379, Accuracy: 0.9033203125\n",
      "Batch: 42, Loss: 0.28712230920791626, Accuracy: 0.900390625\n",
      "Batch: 43, Loss: 0.2377704530954361, Accuracy: 0.9169921875\n",
      "Batch: 44, Loss: 0.2536979019641876, Accuracy: 0.9140625\n",
      "Batch: 45, Loss: 0.2805631160736084, Accuracy: 0.9130859375\n",
      "Batch: 46, Loss: 0.2749418020248413, Accuracy: 0.8974609375\n",
      "Batch: 47, Loss: 0.2501426339149475, Accuracy: 0.9033203125\n",
      "Batch: 48, Loss: 0.24690210819244385, Accuracy: 0.9248046875\n",
      "Batch: 49, Loss: 0.27478933334350586, Accuracy: 0.9072265625\n",
      "Batch: 50, Loss: 0.21094000339508057, Accuracy: 0.9287109375\n",
      "Batch: 51, Loss: 0.2521826922893524, Accuracy: 0.9130859375\n",
      "Batch: 52, Loss: 0.2584746778011322, Accuracy: 0.91015625\n",
      "Batch: 53, Loss: 0.32493871450424194, Accuracy: 0.890625\n",
      "Batch: 54, Loss: 0.2768859565258026, Accuracy: 0.912109375\n",
      "Batch: 55, Loss: 0.28672781586647034, Accuracy: 0.892578125\n",
      "Batch: 56, Loss: 0.25086045265197754, Accuracy: 0.9208984375\n",
      "Batch: 57, Loss: 0.25972944498062134, Accuracy: 0.91015625\n",
      "Batch: 58, Loss: 0.3129867613315582, Accuracy: 0.8955078125\n",
      "Batch: 59, Loss: 0.2662290036678314, Accuracy: 0.9150390625\n",
      "Batch: 60, Loss: 0.2656882405281067, Accuracy: 0.90234375\n",
      "Batch: 61, Loss: 0.2523026764392853, Accuracy: 0.9150390625\n",
      "Batch: 62, Loss: 0.2540472149848938, Accuracy: 0.919921875\n",
      "Batch: 63, Loss: 0.2130950391292572, Accuracy: 0.9248046875\n",
      "Batch: 64, Loss: 0.27852532267570496, Accuracy: 0.900390625\n",
      "Batch: 65, Loss: 0.2561468780040741, Accuracy: 0.919921875\n",
      "Batch: 66, Loss: 0.24057750403881073, Accuracy: 0.9228515625\n",
      "Batch: 67, Loss: 0.24118033051490784, Accuracy: 0.9150390625\n",
      "Batch: 68, Loss: 0.25882619619369507, Accuracy: 0.9169921875\n",
      "Batch: 69, Loss: 0.23038606345653534, Accuracy: 0.923828125\n",
      "Batch: 70, Loss: 0.2179526686668396, Accuracy: 0.9326171875\n",
      "Batch: 71, Loss: 0.28579089045524597, Accuracy: 0.8896484375\n",
      "Batch: 72, Loss: 0.2684364318847656, Accuracy: 0.904296875\n",
      "Batch: 73, Loss: 0.23443636298179626, Accuracy: 0.9248046875\n",
      "Batch: 74, Loss: 0.24944111704826355, Accuracy: 0.916015625\n",
      "Batch: 75, Loss: 0.24453620612621307, Accuracy: 0.9140625\n",
      "Batch: 76, Loss: 0.22070640325546265, Accuracy: 0.931640625\n",
      "Batch: 77, Loss: 0.2794368863105774, Accuracy: 0.9072265625\n",
      "Batch: 78, Loss: 0.2769223153591156, Accuracy: 0.9111328125\n",
      "Batch: 79, Loss: 0.24981078505516052, Accuracy: 0.919921875\n",
      "Batch: 80, Loss: 0.25167542695999146, Accuracy: 0.91796875\n",
      "Batch: 81, Loss: 0.30035609006881714, Accuracy: 0.896484375\n",
      "Batch: 82, Loss: 0.2453058362007141, Accuracy: 0.91015625\n",
      "Batch: 83, Loss: 0.23662540316581726, Accuracy: 0.91796875\n",
      "Batch: 84, Loss: 0.24264875054359436, Accuracy: 0.9248046875\n",
      "Batch: 85, Loss: 0.24054916203022003, Accuracy: 0.91796875\n",
      "Batch: 86, Loss: 0.24995744228363037, Accuracy: 0.90625\n",
      "Batch: 87, Loss: 0.2540700137615204, Accuracy: 0.9140625\n",
      "Batch: 88, Loss: 0.2680550217628479, Accuracy: 0.89453125\n",
      "Batch: 89, Loss: 0.2464657872915268, Accuracy: 0.919921875\n",
      "Batch: 90, Loss: 0.30836039781570435, Accuracy: 0.884765625\n",
      "Batch: 91, Loss: 0.2850417494773865, Accuracy: 0.8935546875\n",
      "Batch: 92, Loss: 0.2849617302417755, Accuracy: 0.9052734375\n",
      "Batch: 93, Loss: 0.29356276988983154, Accuracy: 0.8984375\n",
      "Batch: 94, Loss: 0.29136115312576294, Accuracy: 0.900390625\n",
      "Batch: 95, Loss: 0.26191413402557373, Accuracy: 0.912109375\n",
      "Batch: 96, Loss: 0.26749187707901, Accuracy: 0.9111328125\n",
      "Batch: 97, Loss: 0.2502504587173462, Accuracy: 0.91796875\n",
      "Batch: 98, Loss: 0.27849215269088745, Accuracy: 0.8955078125\n",
      "Batch: 99, Loss: 0.2521059811115265, Accuracy: 0.916015625\n",
      "Batch: 100, Loss: 0.27068889141082764, Accuracy: 0.90234375\n",
      "Batch: 101, Loss: 0.256519615650177, Accuracy: 0.908203125\n",
      "Batch: 102, Loss: 0.25660014152526855, Accuracy: 0.9208984375\n",
      "Batch: 103, Loss: 0.26823559403419495, Accuracy: 0.91796875\n",
      "Batch: 104, Loss: 0.27112695574760437, Accuracy: 0.9130859375\n",
      "Batch: 105, Loss: 0.20741233229637146, Accuracy: 0.9287109375\n",
      "Batch: 106, Loss: 0.2838789224624634, Accuracy: 0.8935546875\n",
      "Batch: 107, Loss: 0.21979422867298126, Accuracy: 0.9248046875\n",
      "Batch: 108, Loss: 0.24829086661338806, Accuracy: 0.9140625\n",
      "Batch: 109, Loss: 0.2418501079082489, Accuracy: 0.9130859375\n",
      "Batch: 110, Loss: 0.2378314882516861, Accuracy: 0.9169921875\n",
      "Batch: 111, Loss: 0.25749579071998596, Accuracy: 0.91796875\n",
      "Batch: 112, Loss: 0.27842748165130615, Accuracy: 0.8984375\n",
      "Epoch 70/90\n",
      "Batch: 1, Loss: 0.3299204707145691, Accuracy: 0.90625\n",
      "Batch: 2, Loss: 0.26559221744537354, Accuracy: 0.91796875\n",
      "Batch: 3, Loss: 0.24535956978797913, Accuracy: 0.9189453125\n",
      "Batch: 4, Loss: 0.23613853752613068, Accuracy: 0.9208984375\n",
      "Batch: 5, Loss: 0.20806282758712769, Accuracy: 0.931640625\n",
      "Batch: 6, Loss: 0.2745581269264221, Accuracy: 0.9072265625\n",
      "Batch: 7, Loss: 0.23268017172813416, Accuracy: 0.919921875\n",
      "Batch: 8, Loss: 0.1857946515083313, Accuracy: 0.9375\n",
      "Batch: 9, Loss: 0.25505414605140686, Accuracy: 0.9072265625\n",
      "Batch: 10, Loss: 0.27726730704307556, Accuracy: 0.9013671875\n",
      "Batch: 11, Loss: 0.28063324093818665, Accuracy: 0.9013671875\n",
      "Batch: 12, Loss: 0.2681959271430969, Accuracy: 0.9013671875\n",
      "Batch: 13, Loss: 0.22468018531799316, Accuracy: 0.9326171875\n",
      "Batch: 14, Loss: 0.23688849806785583, Accuracy: 0.9228515625\n",
      "Batch: 15, Loss: 0.24179911613464355, Accuracy: 0.9296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 16, Loss: 0.24968823790550232, Accuracy: 0.9267578125\n",
      "Batch: 17, Loss: 0.24887239933013916, Accuracy: 0.9169921875\n",
      "Batch: 18, Loss: 0.23098640143871307, Accuracy: 0.9267578125\n",
      "Batch: 19, Loss: 0.24789007008075714, Accuracy: 0.9169921875\n",
      "Batch: 20, Loss: 0.24899911880493164, Accuracy: 0.9150390625\n",
      "Batch: 21, Loss: 0.2864997386932373, Accuracy: 0.90625\n",
      "Batch: 22, Loss: 0.22153955698013306, Accuracy: 0.9228515625\n",
      "Batch: 23, Loss: 0.30557769536972046, Accuracy: 0.8974609375\n",
      "Batch: 24, Loss: 0.3139951825141907, Accuracy: 0.892578125\n",
      "Batch: 25, Loss: 0.2977041006088257, Accuracy: 0.89453125\n",
      "Batch: 26, Loss: 0.2792871296405792, Accuracy: 0.8955078125\n",
      "Batch: 27, Loss: 0.2965625524520874, Accuracy: 0.9052734375\n",
      "Batch: 28, Loss: 0.280586302280426, Accuracy: 0.9140625\n",
      "Batch: 29, Loss: 0.296809583902359, Accuracy: 0.9052734375\n",
      "Batch: 30, Loss: 0.23830342292785645, Accuracy: 0.91796875\n",
      "Batch: 31, Loss: 0.30841851234436035, Accuracy: 0.9052734375\n",
      "Batch: 32, Loss: 0.2556350529193878, Accuracy: 0.9072265625\n",
      "Batch: 33, Loss: 0.25806501507759094, Accuracy: 0.91796875\n",
      "Batch: 34, Loss: 0.22823674976825714, Accuracy: 0.9150390625\n",
      "Batch: 35, Loss: 0.23890390992164612, Accuracy: 0.9150390625\n",
      "Batch: 36, Loss: 0.2917047142982483, Accuracy: 0.8974609375\n",
      "Batch: 37, Loss: 0.24460908770561218, Accuracy: 0.919921875\n",
      "Batch: 38, Loss: 0.27019935846328735, Accuracy: 0.90234375\n",
      "Batch: 39, Loss: 0.23633748292922974, Accuracy: 0.9072265625\n",
      "Batch: 40, Loss: 0.28182435035705566, Accuracy: 0.896484375\n",
      "Batch: 41, Loss: 0.2626381516456604, Accuracy: 0.9091796875\n",
      "Batch: 42, Loss: 0.27048057317733765, Accuracy: 0.9052734375\n",
      "Batch: 43, Loss: 0.24081462621688843, Accuracy: 0.9150390625\n",
      "Batch: 44, Loss: 0.2538774013519287, Accuracy: 0.91015625\n",
      "Batch: 45, Loss: 0.2808087170124054, Accuracy: 0.90625\n",
      "Batch: 46, Loss: 0.2780693471431732, Accuracy: 0.8984375\n",
      "Batch: 47, Loss: 0.21740566194057465, Accuracy: 0.9267578125\n",
      "Batch: 48, Loss: 0.2635594308376312, Accuracy: 0.91015625\n",
      "Batch: 49, Loss: 0.2763809263706207, Accuracy: 0.9150390625\n",
      "Batch: 50, Loss: 0.222104012966156, Accuracy: 0.9306640625\n",
      "Batch: 51, Loss: 0.21231596171855927, Accuracy: 0.935546875\n",
      "Batch: 52, Loss: 0.24774588644504547, Accuracy: 0.9150390625\n",
      "Batch: 53, Loss: 0.2948836088180542, Accuracy: 0.90234375\n",
      "Batch: 54, Loss: 0.2518119215965271, Accuracy: 0.919921875\n",
      "Batch: 55, Loss: 0.2534836530685425, Accuracy: 0.921875\n",
      "Batch: 56, Loss: 0.21797023713588715, Accuracy: 0.919921875\n",
      "Batch: 57, Loss: 0.29491734504699707, Accuracy: 0.904296875\n",
      "Batch: 58, Loss: 0.29809001088142395, Accuracy: 0.8935546875\n",
      "Batch: 59, Loss: 0.2959308624267578, Accuracy: 0.890625\n",
      "Batch: 60, Loss: 0.2885235548019409, Accuracy: 0.9033203125\n",
      "Batch: 61, Loss: 0.2385595142841339, Accuracy: 0.9169921875\n",
      "Batch: 62, Loss: 0.2534208297729492, Accuracy: 0.9130859375\n",
      "Batch: 63, Loss: 0.21921013295650482, Accuracy: 0.9228515625\n",
      "Batch: 64, Loss: 0.2974123954772949, Accuracy: 0.89453125\n",
      "Batch: 65, Loss: 0.2443574219942093, Accuracy: 0.912109375\n",
      "Batch: 66, Loss: 0.2245488464832306, Accuracy: 0.9228515625\n",
      "Batch: 67, Loss: 0.24934396147727966, Accuracy: 0.9072265625\n",
      "Batch: 68, Loss: 0.2816099524497986, Accuracy: 0.90234375\n",
      "Batch: 69, Loss: 0.23936721682548523, Accuracy: 0.9169921875\n",
      "Batch: 70, Loss: 0.26216697692871094, Accuracy: 0.91015625\n",
      "Batch: 71, Loss: 0.2550518810749054, Accuracy: 0.90625\n",
      "Batch: 72, Loss: 0.30555322766304016, Accuracy: 0.8994140625\n",
      "Batch: 73, Loss: 0.2515262961387634, Accuracy: 0.916015625\n",
      "Batch: 74, Loss: 0.25211095809936523, Accuracy: 0.9169921875\n",
      "Batch: 75, Loss: 0.24057674407958984, Accuracy: 0.9169921875\n",
      "Batch: 76, Loss: 0.21937642991542816, Accuracy: 0.921875\n",
      "Batch: 77, Loss: 0.23839057981967926, Accuracy: 0.923828125\n",
      "Batch: 78, Loss: 0.2512783706188202, Accuracy: 0.9130859375\n",
      "Batch: 79, Loss: 0.23142679035663605, Accuracy: 0.92578125\n",
      "Batch: 80, Loss: 0.25206539034843445, Accuracy: 0.9150390625\n",
      "Batch: 81, Loss: 0.28510671854019165, Accuracy: 0.90234375\n",
      "Batch: 82, Loss: 0.2339746654033661, Accuracy: 0.9208984375\n",
      "Batch: 83, Loss: 0.25145596265792847, Accuracy: 0.916015625\n",
      "Batch: 84, Loss: 0.24124065041542053, Accuracy: 0.919921875\n",
      "Batch: 85, Loss: 0.26202282309532166, Accuracy: 0.91796875\n",
      "Batch: 86, Loss: 0.27697378396987915, Accuracy: 0.8994140625\n",
      "Batch: 87, Loss: 0.23464453220367432, Accuracy: 0.9208984375\n",
      "Batch: 88, Loss: 0.24464240670204163, Accuracy: 0.9208984375\n",
      "Batch: 89, Loss: 0.25479090213775635, Accuracy: 0.91015625\n",
      "Batch: 90, Loss: 0.2917797267436981, Accuracy: 0.8935546875\n",
      "Batch: 91, Loss: 0.29180988669395447, Accuracy: 0.9013671875\n",
      "Batch: 92, Loss: 0.2916504144668579, Accuracy: 0.9013671875\n",
      "Batch: 93, Loss: 0.2692943215370178, Accuracy: 0.9150390625\n",
      "Batch: 94, Loss: 0.2758004069328308, Accuracy: 0.900390625\n",
      "Batch: 95, Loss: 0.26003938913345337, Accuracy: 0.9091796875\n",
      "Batch: 96, Loss: 0.25390326976776123, Accuracy: 0.9140625\n",
      "Batch: 97, Loss: 0.23273159563541412, Accuracy: 0.908203125\n",
      "Batch: 98, Loss: 0.23316577076911926, Accuracy: 0.9189453125\n",
      "Batch: 99, Loss: 0.20319248735904694, Accuracy: 0.9267578125\n",
      "Batch: 100, Loss: 0.23368343710899353, Accuracy: 0.916015625\n",
      "Batch: 101, Loss: 0.24579638242721558, Accuracy: 0.9208984375\n",
      "Batch: 102, Loss: 0.30051738023757935, Accuracy: 0.892578125\n",
      "Batch: 103, Loss: 0.2785469591617584, Accuracy: 0.9052734375\n",
      "Batch: 104, Loss: 0.25306379795074463, Accuracy: 0.912109375\n",
      "Batch: 105, Loss: 0.1995648741722107, Accuracy: 0.9326171875\n",
      "Batch: 106, Loss: 0.2725822925567627, Accuracy: 0.9111328125\n",
      "Batch: 107, Loss: 0.231938898563385, Accuracy: 0.9189453125\n",
      "Batch: 108, Loss: 0.24495887756347656, Accuracy: 0.9150390625\n",
      "Batch: 109, Loss: 0.19558903574943542, Accuracy: 0.943359375\n",
      "Batch: 110, Loss: 0.21358785033226013, Accuracy: 0.9208984375\n",
      "Batch: 111, Loss: 0.2474009096622467, Accuracy: 0.9130859375\n",
      "Batch: 112, Loss: 0.26532459259033203, Accuracy: 0.91796875\n",
      "Saved Weights at epoch 70 to file Weights_70.h5\n",
      "Epoch 71/90\n",
      "Batch: 1, Loss: 0.3096197247505188, Accuracy: 0.9091796875\n",
      "Batch: 2, Loss: 0.23741306364536285, Accuracy: 0.921875\n",
      "Batch: 3, Loss: 0.25704535841941833, Accuracy: 0.9208984375\n",
      "Batch: 4, Loss: 0.21373501420021057, Accuracy: 0.927734375\n",
      "Batch: 5, Loss: 0.20038042962551117, Accuracy: 0.9345703125\n",
      "Batch: 6, Loss: 0.2423231154680252, Accuracy: 0.9150390625\n",
      "Batch: 7, Loss: 0.24481752514839172, Accuracy: 0.9228515625\n",
      "Batch: 8, Loss: 0.20927631855010986, Accuracy: 0.9267578125\n",
      "Batch: 9, Loss: 0.25315919518470764, Accuracy: 0.912109375\n",
      "Batch: 10, Loss: 0.25891101360321045, Accuracy: 0.9052734375\n",
      "Batch: 11, Loss: 0.2620455026626587, Accuracy: 0.916015625\n",
      "Batch: 12, Loss: 0.24163773655891418, Accuracy: 0.9208984375\n",
      "Batch: 13, Loss: 0.23990824818611145, Accuracy: 0.916015625\n",
      "Batch: 14, Loss: 0.2577182650566101, Accuracy: 0.916015625\n",
      "Batch: 15, Loss: 0.2319948375225067, Accuracy: 0.9189453125\n",
      "Batch: 16, Loss: 0.2769193649291992, Accuracy: 0.9091796875\n",
      "Batch: 17, Loss: 0.2588111162185669, Accuracy: 0.9111328125\n",
      "Batch: 18, Loss: 0.23981556296348572, Accuracy: 0.91796875\n",
      "Batch: 19, Loss: 0.2125430703163147, Accuracy: 0.93359375\n",
      "Batch: 20, Loss: 0.25232499837875366, Accuracy: 0.90625\n",
      "Batch: 21, Loss: 0.2772707939147949, Accuracy: 0.91015625\n",
      "Batch: 22, Loss: 0.24804575741291046, Accuracy: 0.91015625\n",
      "Batch: 23, Loss: 0.29067739844322205, Accuracy: 0.90234375\n",
      "Batch: 24, Loss: 0.30712926387786865, Accuracy: 0.8984375\n",
      "Batch: 25, Loss: 0.2839476764202118, Accuracy: 0.8974609375\n",
      "Batch: 26, Loss: 0.27326545119285583, Accuracy: 0.9072265625\n",
      "Batch: 27, Loss: 0.28694596886634827, Accuracy: 0.9033203125\n",
      "Batch: 28, Loss: 0.2913910150527954, Accuracy: 0.9033203125\n",
      "Batch: 29, Loss: 0.2960243225097656, Accuracy: 0.90234375\n",
      "Batch: 30, Loss: 0.22795042395591736, Accuracy: 0.921875\n",
      "Batch: 31, Loss: 0.2924203872680664, Accuracy: 0.9033203125\n",
      "Batch: 32, Loss: 0.24608434736728668, Accuracy: 0.91015625\n",
      "Batch: 33, Loss: 0.25400325655937195, Accuracy: 0.91796875\n",
      "Batch: 34, Loss: 0.19320790469646454, Accuracy: 0.9443359375\n",
      "Batch: 35, Loss: 0.2314033806324005, Accuracy: 0.9248046875\n",
      "Batch: 36, Loss: 0.27692484855651855, Accuracy: 0.904296875\n",
      "Batch: 37, Loss: 0.21482355892658234, Accuracy: 0.93359375\n",
      "Batch: 38, Loss: 0.28217238187789917, Accuracy: 0.904296875\n",
      "Batch: 39, Loss: 0.22998031973838806, Accuracy: 0.91015625\n",
      "Batch: 40, Loss: 0.23528188467025757, Accuracy: 0.9228515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 41, Loss: 0.2805304229259491, Accuracy: 0.904296875\n",
      "Batch: 42, Loss: 0.2644481062889099, Accuracy: 0.9140625\n",
      "Batch: 43, Loss: 0.25362449884414673, Accuracy: 0.91796875\n",
      "Batch: 44, Loss: 0.24756604433059692, Accuracy: 0.9169921875\n",
      "Batch: 45, Loss: 0.2707383334636688, Accuracy: 0.9111328125\n",
      "Batch: 46, Loss: 0.25057387351989746, Accuracy: 0.9052734375\n",
      "Batch: 47, Loss: 0.25133436918258667, Accuracy: 0.9169921875\n",
      "Batch: 48, Loss: 0.24120140075683594, Accuracy: 0.9130859375\n",
      "Batch: 49, Loss: 0.27497225999832153, Accuracy: 0.908203125\n",
      "Batch: 50, Loss: 0.22383178770542145, Accuracy: 0.9326171875\n",
      "Batch: 51, Loss: 0.27905184030532837, Accuracy: 0.9091796875\n",
      "Batch: 52, Loss: 0.23070234060287476, Accuracy: 0.9248046875\n",
      "Batch: 53, Loss: 0.3057873249053955, Accuracy: 0.8896484375\n",
      "Batch: 54, Loss: 0.2808796465396881, Accuracy: 0.9091796875\n",
      "Batch: 55, Loss: 0.26679056882858276, Accuracy: 0.908203125\n",
      "Batch: 56, Loss: 0.21140296757221222, Accuracy: 0.9267578125\n",
      "Batch: 57, Loss: 0.28170254826545715, Accuracy: 0.91015625\n",
      "Batch: 58, Loss: 0.2984318137168884, Accuracy: 0.900390625\n",
      "Batch: 59, Loss: 0.2875472903251648, Accuracy: 0.9033203125\n",
      "Batch: 60, Loss: 0.24755878746509552, Accuracy: 0.912109375\n",
      "Batch: 61, Loss: 0.24428585171699524, Accuracy: 0.9150390625\n",
      "Batch: 62, Loss: 0.24608857929706573, Accuracy: 0.923828125\n",
      "Batch: 63, Loss: 0.21070235967636108, Accuracy: 0.935546875\n",
      "Batch: 64, Loss: 0.25612324476242065, Accuracy: 0.9208984375\n",
      "Batch: 65, Loss: 0.23239251971244812, Accuracy: 0.919921875\n",
      "Batch: 66, Loss: 0.2231108546257019, Accuracy: 0.9306640625\n",
      "Batch: 67, Loss: 0.2581028938293457, Accuracy: 0.916015625\n",
      "Batch: 68, Loss: 0.2609441578388214, Accuracy: 0.9140625\n",
      "Batch: 69, Loss: 0.21652159094810486, Accuracy: 0.9287109375\n",
      "Batch: 70, Loss: 0.22513547539710999, Accuracy: 0.92578125\n",
      "Batch: 71, Loss: 0.2638547122478485, Accuracy: 0.9140625\n",
      "Batch: 72, Loss: 0.25441408157348633, Accuracy: 0.9033203125\n",
      "Batch: 73, Loss: 0.2363947033882141, Accuracy: 0.916015625\n",
      "Batch: 74, Loss: 0.25187623500823975, Accuracy: 0.9140625\n",
      "Batch: 75, Loss: 0.21510571241378784, Accuracy: 0.9189453125\n",
      "Batch: 76, Loss: 0.206697016954422, Accuracy: 0.9365234375\n",
      "Batch: 77, Loss: 0.2598288953304291, Accuracy: 0.9150390625\n",
      "Batch: 78, Loss: 0.24153825640678406, Accuracy: 0.91796875\n",
      "Batch: 79, Loss: 0.2604261636734009, Accuracy: 0.916015625\n",
      "Batch: 80, Loss: 0.23329833149909973, Accuracy: 0.9189453125\n",
      "Batch: 81, Loss: 0.26423734426498413, Accuracy: 0.912109375\n",
      "Batch: 82, Loss: 0.249222993850708, Accuracy: 0.90234375\n",
      "Batch: 83, Loss: 0.2109908163547516, Accuracy: 0.9345703125\n",
      "Batch: 84, Loss: 0.2560007870197296, Accuracy: 0.908203125\n",
      "Batch: 85, Loss: 0.24394962191581726, Accuracy: 0.9208984375\n",
      "Batch: 86, Loss: 0.2780023217201233, Accuracy: 0.90234375\n",
      "Batch: 87, Loss: 0.2258472740650177, Accuracy: 0.9228515625\n",
      "Batch: 88, Loss: 0.24954839050769806, Accuracy: 0.9130859375\n",
      "Batch: 89, Loss: 0.2426120936870575, Accuracy: 0.9150390625\n",
      "Batch: 90, Loss: 0.2964455485343933, Accuracy: 0.904296875\n",
      "Batch: 91, Loss: 0.2922600507736206, Accuracy: 0.8984375\n",
      "Batch: 92, Loss: 0.27049973607063293, Accuracy: 0.9140625\n",
      "Batch: 93, Loss: 0.3107838034629822, Accuracy: 0.8994140625\n",
      "Batch: 94, Loss: 0.29889822006225586, Accuracy: 0.904296875\n",
      "Batch: 95, Loss: 0.2866511940956116, Accuracy: 0.8994140625\n",
      "Batch: 96, Loss: 0.2316562533378601, Accuracy: 0.9267578125\n",
      "Batch: 97, Loss: 0.2262350171804428, Accuracy: 0.9208984375\n",
      "Batch: 98, Loss: 0.2721049189567566, Accuracy: 0.89453125\n",
      "Batch: 99, Loss: 0.218019038438797, Accuracy: 0.9130859375\n",
      "Batch: 100, Loss: 0.2641659379005432, Accuracy: 0.9150390625\n",
      "Batch: 101, Loss: 0.23948948085308075, Accuracy: 0.9208984375\n",
      "Batch: 102, Loss: 0.2824661433696747, Accuracy: 0.9033203125\n",
      "Batch: 103, Loss: 0.26366734504699707, Accuracy: 0.9169921875\n",
      "Batch: 104, Loss: 0.2429995834827423, Accuracy: 0.9150390625\n",
      "Batch: 105, Loss: 0.2075408697128296, Accuracy: 0.9287109375\n",
      "Batch: 106, Loss: 0.24231934547424316, Accuracy: 0.916015625\n",
      "Batch: 107, Loss: 0.23615601658821106, Accuracy: 0.923828125\n",
      "Batch: 108, Loss: 0.22061745822429657, Accuracy: 0.9267578125\n",
      "Batch: 109, Loss: 0.19104140996932983, Accuracy: 0.939453125\n",
      "Batch: 110, Loss: 0.21970294415950775, Accuracy: 0.9287109375\n",
      "Batch: 111, Loss: 0.27216461300849915, Accuracy: 0.9013671875\n",
      "Batch: 112, Loss: 0.2583678960800171, Accuracy: 0.916015625\n",
      "Epoch 72/90\n",
      "Batch: 1, Loss: 0.29613155126571655, Accuracy: 0.91015625\n",
      "Batch: 2, Loss: 0.2218557596206665, Accuracy: 0.9296875\n",
      "Batch: 3, Loss: 0.2634020745754242, Accuracy: 0.904296875\n",
      "Batch: 4, Loss: 0.24808716773986816, Accuracy: 0.9150390625\n",
      "Batch: 5, Loss: 0.20465880632400513, Accuracy: 0.931640625\n",
      "Batch: 6, Loss: 0.2388656884431839, Accuracy: 0.9267578125\n",
      "Batch: 7, Loss: 0.2237645536661148, Accuracy: 0.927734375\n",
      "Batch: 8, Loss: 0.18774184584617615, Accuracy: 0.94140625\n",
      "Batch: 9, Loss: 0.24466463923454285, Accuracy: 0.919921875\n",
      "Batch: 10, Loss: 0.24854928255081177, Accuracy: 0.9189453125\n",
      "Batch: 11, Loss: 0.2800098657608032, Accuracy: 0.8994140625\n",
      "Batch: 12, Loss: 0.22539697587490082, Accuracy: 0.9267578125\n",
      "Batch: 13, Loss: 0.1817169189453125, Accuracy: 0.9375\n",
      "Batch: 14, Loss: 0.23288513720035553, Accuracy: 0.9111328125\n",
      "Batch: 15, Loss: 0.23319494724273682, Accuracy: 0.9228515625\n",
      "Batch: 16, Loss: 0.2570549249649048, Accuracy: 0.923828125\n",
      "Batch: 17, Loss: 0.22615782916545868, Accuracy: 0.927734375\n",
      "Batch: 18, Loss: 0.23984888195991516, Accuracy: 0.916015625\n",
      "Batch: 19, Loss: 0.2249421626329422, Accuracy: 0.9248046875\n",
      "Batch: 20, Loss: 0.2477937638759613, Accuracy: 0.908203125\n",
      "Batch: 21, Loss: 0.28881606459617615, Accuracy: 0.8974609375\n",
      "Batch: 22, Loss: 0.2497725635766983, Accuracy: 0.916015625\n",
      "Batch: 23, Loss: 0.2638038098812103, Accuracy: 0.908203125\n",
      "Batch: 24, Loss: 0.2734929919242859, Accuracy: 0.9091796875\n",
      "Batch: 25, Loss: 0.2661062777042389, Accuracy: 0.9150390625\n",
      "Batch: 26, Loss: 0.2666967511177063, Accuracy: 0.9130859375\n",
      "Batch: 27, Loss: 0.28088292479515076, Accuracy: 0.91015625\n",
      "Batch: 28, Loss: 0.2542093098163605, Accuracy: 0.9169921875\n",
      "Batch: 29, Loss: 0.30365699529647827, Accuracy: 0.90625\n",
      "Batch: 30, Loss: 0.23727375268936157, Accuracy: 0.9228515625\n",
      "Batch: 31, Loss: 0.28339749574661255, Accuracy: 0.900390625\n",
      "Batch: 32, Loss: 0.24259993433952332, Accuracy: 0.9130859375\n",
      "Batch: 33, Loss: 0.2318134903907776, Accuracy: 0.9130859375\n",
      "Batch: 34, Loss: 0.22642004489898682, Accuracy: 0.921875\n",
      "Batch: 35, Loss: 0.23343461751937866, Accuracy: 0.9140625\n",
      "Batch: 36, Loss: 0.30666041374206543, Accuracy: 0.890625\n",
      "Batch: 37, Loss: 0.22937454283237457, Accuracy: 0.919921875\n",
      "Batch: 38, Loss: 0.2503765821456909, Accuracy: 0.9091796875\n",
      "Batch: 39, Loss: 0.23896928131580353, Accuracy: 0.91796875\n",
      "Batch: 40, Loss: 0.24977213144302368, Accuracy: 0.9130859375\n",
      "Batch: 41, Loss: 0.27982255816459656, Accuracy: 0.9013671875\n",
      "Batch: 42, Loss: 0.22384609282016754, Accuracy: 0.9296875\n",
      "Batch: 43, Loss: 0.26206308603286743, Accuracy: 0.912109375\n",
      "Batch: 44, Loss: 0.23115205764770508, Accuracy: 0.919921875\n",
      "Batch: 45, Loss: 0.26055583357810974, Accuracy: 0.916015625\n",
      "Batch: 46, Loss: 0.23976364731788635, Accuracy: 0.9130859375\n",
      "Batch: 47, Loss: 0.23146629333496094, Accuracy: 0.923828125\n",
      "Batch: 48, Loss: 0.2253616601228714, Accuracy: 0.9189453125\n",
      "Batch: 49, Loss: 0.26656574010849, Accuracy: 0.912109375\n",
      "Batch: 50, Loss: 0.21475549042224884, Accuracy: 0.931640625\n",
      "Batch: 51, Loss: 0.242460235953331, Accuracy: 0.9130859375\n",
      "Batch: 52, Loss: 0.21856525540351868, Accuracy: 0.927734375\n",
      "Batch: 53, Loss: 0.28159427642822266, Accuracy: 0.9013671875\n",
      "Batch: 54, Loss: 0.2644530236721039, Accuracy: 0.9130859375\n",
      "Batch: 55, Loss: 0.2796652317047119, Accuracy: 0.8984375\n",
      "Batch: 56, Loss: 0.20594626665115356, Accuracy: 0.93359375\n",
      "Batch: 57, Loss: 0.26735013723373413, Accuracy: 0.9052734375\n",
      "Batch: 58, Loss: 0.286973237991333, Accuracy: 0.919921875\n",
      "Batch: 59, Loss: 0.24432989954948425, Accuracy: 0.919921875\n",
      "Batch: 60, Loss: 0.25479280948638916, Accuracy: 0.908203125\n",
      "Batch: 61, Loss: 0.283847451210022, Accuracy: 0.8974609375\n",
      "Batch: 62, Loss: 0.24371622502803802, Accuracy: 0.91796875\n",
      "Batch: 63, Loss: 0.21231529116630554, Accuracy: 0.92578125\n",
      "Batch: 64, Loss: 0.2702817916870117, Accuracy: 0.904296875\n",
      "Batch: 65, Loss: 0.2440291941165924, Accuracy: 0.9130859375\n",
      "Batch: 66, Loss: 0.2054491937160492, Accuracy: 0.9267578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 67, Loss: 0.2607814073562622, Accuracy: 0.9111328125\n",
      "Batch: 68, Loss: 0.2475181519985199, Accuracy: 0.9150390625\n",
      "Batch: 69, Loss: 0.23189671337604523, Accuracy: 0.921875\n",
      "Batch: 70, Loss: 0.21210025250911713, Accuracy: 0.931640625\n",
      "Batch: 71, Loss: 0.24388152360916138, Accuracy: 0.9169921875\n",
      "Batch: 72, Loss: 0.298905611038208, Accuracy: 0.904296875\n",
      "Batch: 73, Loss: 0.22461025416851044, Accuracy: 0.9267578125\n",
      "Batch: 74, Loss: 0.25932636857032776, Accuracy: 0.916015625\n",
      "Batch: 75, Loss: 0.22668464481830597, Accuracy: 0.9169921875\n",
      "Batch: 76, Loss: 0.1768898367881775, Accuracy: 0.9365234375\n",
      "Batch: 77, Loss: 0.22681793570518494, Accuracy: 0.935546875\n",
      "Batch: 78, Loss: 0.27049553394317627, Accuracy: 0.9091796875\n",
      "Batch: 79, Loss: 0.2748030424118042, Accuracy: 0.900390625\n",
      "Batch: 80, Loss: 0.23358701169490814, Accuracy: 0.9130859375\n",
      "Batch: 81, Loss: 0.27556416392326355, Accuracy: 0.904296875\n",
      "Batch: 82, Loss: 0.2615857720375061, Accuracy: 0.9140625\n",
      "Batch: 83, Loss: 0.23518595099449158, Accuracy: 0.919921875\n",
      "Batch: 84, Loss: 0.23043730854988098, Accuracy: 0.9228515625\n",
      "Batch: 85, Loss: 0.22705014050006866, Accuracy: 0.9208984375\n",
      "Batch: 86, Loss: 0.24796020984649658, Accuracy: 0.9140625\n",
      "Batch: 87, Loss: 0.26661449670791626, Accuracy: 0.916015625\n",
      "Batch: 88, Loss: 0.2515259385108948, Accuracy: 0.9130859375\n",
      "Batch: 89, Loss: 0.2471114695072174, Accuracy: 0.908203125\n",
      "Batch: 90, Loss: 0.2991005778312683, Accuracy: 0.88671875\n",
      "Batch: 91, Loss: 0.28133267164230347, Accuracy: 0.90625\n",
      "Batch: 92, Loss: 0.2787662744522095, Accuracy: 0.904296875\n",
      "Batch: 93, Loss: 0.27744579315185547, Accuracy: 0.8974609375\n",
      "Batch: 94, Loss: 0.2914813160896301, Accuracy: 0.8974609375\n",
      "Batch: 95, Loss: 0.2576618790626526, Accuracy: 0.9150390625\n",
      "Batch: 96, Loss: 0.2530370354652405, Accuracy: 0.9267578125\n",
      "Batch: 97, Loss: 0.24868611991405487, Accuracy: 0.9130859375\n",
      "Batch: 98, Loss: 0.2520422339439392, Accuracy: 0.91796875\n",
      "Batch: 99, Loss: 0.2023422122001648, Accuracy: 0.9267578125\n",
      "Batch: 100, Loss: 0.230059415102005, Accuracy: 0.923828125\n",
      "Batch: 101, Loss: 0.2328052818775177, Accuracy: 0.916015625\n",
      "Batch: 102, Loss: 0.2616756856441498, Accuracy: 0.908203125\n",
      "Batch: 103, Loss: 0.2523665428161621, Accuracy: 0.923828125\n",
      "Batch: 104, Loss: 0.2670087218284607, Accuracy: 0.9140625\n",
      "Batch: 105, Loss: 0.2047211229801178, Accuracy: 0.931640625\n",
      "Batch: 106, Loss: 0.2665013372898102, Accuracy: 0.9033203125\n",
      "Batch: 107, Loss: 0.2196335345506668, Accuracy: 0.9248046875\n",
      "Batch: 108, Loss: 0.24522238969802856, Accuracy: 0.9130859375\n",
      "Batch: 109, Loss: 0.20027711987495422, Accuracy: 0.9248046875\n",
      "Batch: 110, Loss: 0.22620856761932373, Accuracy: 0.9296875\n",
      "Batch: 111, Loss: 0.24680529534816742, Accuracy: 0.9169921875\n",
      "Batch: 112, Loss: 0.2680332064628601, Accuracy: 0.9140625\n",
      "Epoch 73/90\n",
      "Batch: 1, Loss: 0.3166000247001648, Accuracy: 0.9052734375\n",
      "Batch: 2, Loss: 0.23918351531028748, Accuracy: 0.919921875\n",
      "Batch: 3, Loss: 0.24338281154632568, Accuracy: 0.9150390625\n",
      "Batch: 4, Loss: 0.239486426115036, Accuracy: 0.9150390625\n",
      "Batch: 5, Loss: 0.21427853405475616, Accuracy: 0.9296875\n",
      "Batch: 6, Loss: 0.2511972188949585, Accuracy: 0.9248046875\n",
      "Batch: 7, Loss: 0.20977486670017242, Accuracy: 0.93359375\n",
      "Batch: 8, Loss: 0.23491600155830383, Accuracy: 0.9169921875\n",
      "Batch: 9, Loss: 0.25749799609184265, Accuracy: 0.91796875\n",
      "Batch: 10, Loss: 0.27103596925735474, Accuracy: 0.9072265625\n",
      "Batch: 11, Loss: 0.26009565591812134, Accuracy: 0.916015625\n",
      "Batch: 12, Loss: 0.21809245645999908, Accuracy: 0.9248046875\n",
      "Batch: 13, Loss: 0.19471125304698944, Accuracy: 0.9365234375\n",
      "Batch: 14, Loss: 0.2507174611091614, Accuracy: 0.91796875\n",
      "Batch: 15, Loss: 0.2438904345035553, Accuracy: 0.9208984375\n",
      "Batch: 16, Loss: 0.2409316599369049, Accuracy: 0.931640625\n",
      "Batch: 17, Loss: 0.24868452548980713, Accuracy: 0.9228515625\n",
      "Batch: 18, Loss: 0.1852130889892578, Accuracy: 0.939453125\n",
      "Batch: 19, Loss: 0.22027602791786194, Accuracy: 0.92578125\n",
      "Batch: 20, Loss: 0.22543014585971832, Accuracy: 0.9150390625\n",
      "Batch: 21, Loss: 0.23693564534187317, Accuracy: 0.9228515625\n",
      "Batch: 22, Loss: 0.23532837629318237, Accuracy: 0.9248046875\n",
      "Batch: 23, Loss: 0.28675830364227295, Accuracy: 0.9130859375\n",
      "Batch: 24, Loss: 0.2932877540588379, Accuracy: 0.9033203125\n",
      "Batch: 25, Loss: 0.2586592435836792, Accuracy: 0.916015625\n",
      "Batch: 26, Loss: 0.27207615971565247, Accuracy: 0.9130859375\n",
      "Batch: 27, Loss: 0.27596378326416016, Accuracy: 0.9052734375\n",
      "Batch: 28, Loss: 0.2404642254114151, Accuracy: 0.927734375\n",
      "Batch: 29, Loss: 0.28629493713378906, Accuracy: 0.896484375\n",
      "Batch: 30, Loss: 0.24836832284927368, Accuracy: 0.919921875\n",
      "Batch: 31, Loss: 0.26902222633361816, Accuracy: 0.9033203125\n",
      "Batch: 32, Loss: 0.22970178723335266, Accuracy: 0.9208984375\n",
      "Batch: 33, Loss: 0.25146007537841797, Accuracy: 0.91015625\n",
      "Batch: 34, Loss: 0.20522724092006683, Accuracy: 0.9345703125\n",
      "Batch: 35, Loss: 0.2592555284500122, Accuracy: 0.9072265625\n",
      "Batch: 36, Loss: 0.27897578477859497, Accuracy: 0.9033203125\n",
      "Batch: 37, Loss: 0.20829246938228607, Accuracy: 0.9296875\n",
      "Batch: 38, Loss: 0.2831743359565735, Accuracy: 0.908203125\n",
      "Batch: 39, Loss: 0.22587572038173676, Accuracy: 0.916015625\n",
      "Batch: 40, Loss: 0.22129982709884644, Accuracy: 0.9189453125\n",
      "Batch: 41, Loss: 0.257549524307251, Accuracy: 0.9189453125\n",
      "Batch: 42, Loss: 0.23299959301948547, Accuracy: 0.916015625\n",
      "Batch: 43, Loss: 0.24144870042800903, Accuracy: 0.9189453125\n",
      "Batch: 44, Loss: 0.24981290102005005, Accuracy: 0.9130859375\n",
      "Batch: 45, Loss: 0.2497216761112213, Accuracy: 0.9169921875\n",
      "Batch: 46, Loss: 0.25948619842529297, Accuracy: 0.912109375\n",
      "Batch: 47, Loss: 0.2311180830001831, Accuracy: 0.921875\n",
      "Batch: 48, Loss: 0.25365906953811646, Accuracy: 0.916015625\n",
      "Batch: 49, Loss: 0.23334459960460663, Accuracy: 0.923828125\n",
      "Batch: 50, Loss: 0.2240164577960968, Accuracy: 0.9345703125\n",
      "Batch: 51, Loss: 0.24115675687789917, Accuracy: 0.9150390625\n",
      "Batch: 52, Loss: 0.22716420888900757, Accuracy: 0.9208984375\n",
      "Batch: 53, Loss: 0.26902830600738525, Accuracy: 0.904296875\n",
      "Batch: 54, Loss: 0.25592055916786194, Accuracy: 0.9111328125\n",
      "Batch: 55, Loss: 0.266245573759079, Accuracy: 0.9052734375\n",
      "Batch: 56, Loss: 0.225465327501297, Accuracy: 0.919921875\n",
      "Batch: 57, Loss: 0.2776339054107666, Accuracy: 0.90625\n",
      "Batch: 58, Loss: 0.26115918159484863, Accuracy: 0.916015625\n",
      "Batch: 59, Loss: 0.2763940691947937, Accuracy: 0.9130859375\n",
      "Batch: 60, Loss: 0.24050851166248322, Accuracy: 0.9248046875\n",
      "Batch: 61, Loss: 0.241557776927948, Accuracy: 0.9208984375\n",
      "Batch: 62, Loss: 0.24128469824790955, Accuracy: 0.927734375\n",
      "Batch: 63, Loss: 0.21394139528274536, Accuracy: 0.916015625\n",
      "Batch: 64, Loss: 0.2571573853492737, Accuracy: 0.916015625\n",
      "Batch: 65, Loss: 0.21919649839401245, Accuracy: 0.9208984375\n",
      "Batch: 66, Loss: 0.22184477746486664, Accuracy: 0.927734375\n",
      "Batch: 67, Loss: 0.23955339193344116, Accuracy: 0.916015625\n",
      "Batch: 68, Loss: 0.2527660131454468, Accuracy: 0.9130859375\n",
      "Batch: 69, Loss: 0.22331342101097107, Accuracy: 0.9228515625\n",
      "Batch: 70, Loss: 0.24303483963012695, Accuracy: 0.923828125\n",
      "Batch: 71, Loss: 0.26423725485801697, Accuracy: 0.900390625\n",
      "Batch: 72, Loss: 0.2721410095691681, Accuracy: 0.908203125\n",
      "Batch: 73, Loss: 0.23722124099731445, Accuracy: 0.9189453125\n",
      "Batch: 74, Loss: 0.24921274185180664, Accuracy: 0.9169921875\n",
      "Batch: 75, Loss: 0.21431905031204224, Accuracy: 0.927734375\n",
      "Batch: 76, Loss: 0.19852247834205627, Accuracy: 0.9306640625\n",
      "Batch: 77, Loss: 0.22267211973667145, Accuracy: 0.9296875\n",
      "Batch: 78, Loss: 0.25042179226875305, Accuracy: 0.91015625\n",
      "Batch: 79, Loss: 0.24645179510116577, Accuracy: 0.921875\n",
      "Batch: 80, Loss: 0.2230730950832367, Accuracy: 0.916015625\n",
      "Batch: 81, Loss: 0.2626914978027344, Accuracy: 0.9091796875\n",
      "Batch: 82, Loss: 0.2020701915025711, Accuracy: 0.93359375\n",
      "Batch: 83, Loss: 0.1972748339176178, Accuracy: 0.9375\n",
      "Batch: 84, Loss: 0.23876890540122986, Accuracy: 0.912109375\n",
      "Batch: 85, Loss: 0.2521737217903137, Accuracy: 0.9169921875\n",
      "Batch: 86, Loss: 0.25448817014694214, Accuracy: 0.9130859375\n",
      "Batch: 87, Loss: 0.2168617695569992, Accuracy: 0.92578125\n",
      "Batch: 88, Loss: 0.2444596290588379, Accuracy: 0.912109375\n",
      "Batch: 89, Loss: 0.22208544611930847, Accuracy: 0.9287109375\n",
      "Batch: 90, Loss: 0.2710513472557068, Accuracy: 0.9013671875\n",
      "Batch: 91, Loss: 0.30351459980010986, Accuracy: 0.8916015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 92, Loss: 0.259516179561615, Accuracy: 0.9013671875\n",
      "Batch: 93, Loss: 0.28225016593933105, Accuracy: 0.8994140625\n",
      "Batch: 94, Loss: 0.2724356949329376, Accuracy: 0.904296875\n",
      "Batch: 95, Loss: 0.26835423707962036, Accuracy: 0.9013671875\n",
      "Batch: 96, Loss: 0.24082452058792114, Accuracy: 0.9208984375\n",
      "Batch: 97, Loss: 0.2323991358280182, Accuracy: 0.92578125\n",
      "Batch: 98, Loss: 0.2422395497560501, Accuracy: 0.9130859375\n",
      "Batch: 99, Loss: 0.18881279230117798, Accuracy: 0.9326171875\n",
      "Batch: 100, Loss: 0.20939931273460388, Accuracy: 0.9267578125\n",
      "Batch: 101, Loss: 0.24184852838516235, Accuracy: 0.9130859375\n",
      "Batch: 102, Loss: 0.2496723234653473, Accuracy: 0.9169921875\n",
      "Batch: 103, Loss: 0.2522033751010895, Accuracy: 0.91796875\n",
      "Batch: 104, Loss: 0.23597973585128784, Accuracy: 0.92578125\n",
      "Batch: 105, Loss: 0.2095385491847992, Accuracy: 0.9267578125\n",
      "Batch: 106, Loss: 0.242497980594635, Accuracy: 0.9189453125\n",
      "Batch: 107, Loss: 0.23260246217250824, Accuracy: 0.9248046875\n",
      "Batch: 108, Loss: 0.21651506423950195, Accuracy: 0.931640625\n",
      "Batch: 109, Loss: 0.17629694938659668, Accuracy: 0.9404296875\n",
      "Batch: 110, Loss: 0.21613341569900513, Accuracy: 0.931640625\n",
      "Batch: 111, Loss: 0.2349146604537964, Accuracy: 0.9306640625\n",
      "Batch: 112, Loss: 0.24713507294654846, Accuracy: 0.9130859375\n",
      "Epoch 74/90\n",
      "Batch: 1, Loss: 0.3095262050628662, Accuracy: 0.90234375\n",
      "Batch: 2, Loss: 0.2700561285018921, Accuracy: 0.9130859375\n",
      "Batch: 3, Loss: 0.24618181586265564, Accuracy: 0.9208984375\n",
      "Batch: 4, Loss: 0.1983722448348999, Accuracy: 0.9228515625\n",
      "Batch: 5, Loss: 0.19502082467079163, Accuracy: 0.9375\n",
      "Batch: 6, Loss: 0.22059130668640137, Accuracy: 0.9375\n",
      "Batch: 7, Loss: 0.22159746289253235, Accuracy: 0.9296875\n",
      "Batch: 8, Loss: 0.22501249611377716, Accuracy: 0.9208984375\n",
      "Batch: 9, Loss: 0.2478598952293396, Accuracy: 0.9189453125\n",
      "Batch: 10, Loss: 0.25562798976898193, Accuracy: 0.9091796875\n",
      "Batch: 11, Loss: 0.2715928852558136, Accuracy: 0.9052734375\n",
      "Batch: 12, Loss: 0.2230912148952484, Accuracy: 0.9267578125\n",
      "Batch: 13, Loss: 0.21943514049053192, Accuracy: 0.9228515625\n",
      "Batch: 14, Loss: 0.26251205801963806, Accuracy: 0.908203125\n",
      "Batch: 15, Loss: 0.2239612340927124, Accuracy: 0.9306640625\n",
      "Batch: 16, Loss: 0.2518395185470581, Accuracy: 0.9208984375\n",
      "Batch: 17, Loss: 0.24298131465911865, Accuracy: 0.919921875\n",
      "Batch: 18, Loss: 0.24790261685848236, Accuracy: 0.9208984375\n",
      "Batch: 19, Loss: 0.21390938758850098, Accuracy: 0.923828125\n",
      "Batch: 20, Loss: 0.23967187106609344, Accuracy: 0.9150390625\n",
      "Batch: 21, Loss: 0.24539723992347717, Accuracy: 0.9150390625\n",
      "Batch: 22, Loss: 0.23701700568199158, Accuracy: 0.919921875\n",
      "Batch: 23, Loss: 0.27775052189826965, Accuracy: 0.9130859375\n",
      "Batch: 24, Loss: 0.31081026792526245, Accuracy: 0.900390625\n",
      "Batch: 25, Loss: 0.2551197409629822, Accuracy: 0.90625\n",
      "Batch: 26, Loss: 0.27143627405166626, Accuracy: 0.9072265625\n",
      "Batch: 27, Loss: 0.29084497690200806, Accuracy: 0.90625\n",
      "Batch: 28, Loss: 0.26065585017204285, Accuracy: 0.912109375\n",
      "Batch: 29, Loss: 0.3162888288497925, Accuracy: 0.8916015625\n",
      "Batch: 30, Loss: 0.22652992606163025, Accuracy: 0.9287109375\n",
      "Batch: 31, Loss: 0.2568517327308655, Accuracy: 0.9111328125\n",
      "Batch: 32, Loss: 0.22413286566734314, Accuracy: 0.9208984375\n",
      "Batch: 33, Loss: 0.21965326368808746, Accuracy: 0.927734375\n",
      "Batch: 34, Loss: 0.24695387482643127, Accuracy: 0.908203125\n",
      "Batch: 35, Loss: 0.232072114944458, Accuracy: 0.9111328125\n",
      "Batch: 36, Loss: 0.2942008972167969, Accuracy: 0.9072265625\n",
      "Batch: 37, Loss: 0.2321252077817917, Accuracy: 0.912109375\n",
      "Batch: 38, Loss: 0.2342069149017334, Accuracy: 0.921875\n",
      "Batch: 39, Loss: 0.23412171006202698, Accuracy: 0.9130859375\n",
      "Batch: 40, Loss: 0.24337850511074066, Accuracy: 0.908203125\n",
      "Batch: 41, Loss: 0.24134793877601624, Accuracy: 0.9130859375\n",
      "Batch: 42, Loss: 0.22403346002101898, Accuracy: 0.9169921875\n",
      "Batch: 43, Loss: 0.2238970696926117, Accuracy: 0.9208984375\n",
      "Batch: 44, Loss: 0.2286950647830963, Accuracy: 0.923828125\n",
      "Batch: 45, Loss: 0.22797071933746338, Accuracy: 0.9248046875\n",
      "Batch: 46, Loss: 0.2390243411064148, Accuracy: 0.9140625\n",
      "Batch: 47, Loss: 0.24034520983695984, Accuracy: 0.9169921875\n",
      "Batch: 48, Loss: 0.23185144364833832, Accuracy: 0.921875\n",
      "Batch: 49, Loss: 0.24453948438167572, Accuracy: 0.921875\n",
      "Batch: 50, Loss: 0.22135122120380402, Accuracy: 0.9208984375\n",
      "Batch: 51, Loss: 0.2658345401287079, Accuracy: 0.9140625\n",
      "Batch: 52, Loss: 0.2279813587665558, Accuracy: 0.9228515625\n",
      "Batch: 53, Loss: 0.26647162437438965, Accuracy: 0.90234375\n",
      "Batch: 54, Loss: 0.2806505262851715, Accuracy: 0.9091796875\n",
      "Batch: 55, Loss: 0.2629234194755554, Accuracy: 0.9130859375\n",
      "Batch: 56, Loss: 0.18629863858222961, Accuracy: 0.943359375\n",
      "Batch: 57, Loss: 0.2688688337802887, Accuracy: 0.916015625\n",
      "Batch: 58, Loss: 0.2901436686515808, Accuracy: 0.91015625\n",
      "Batch: 59, Loss: 0.29900771379470825, Accuracy: 0.91015625\n",
      "Batch: 60, Loss: 0.2582094073295593, Accuracy: 0.9130859375\n",
      "Batch: 61, Loss: 0.21247632801532745, Accuracy: 0.921875\n",
      "Batch: 62, Loss: 0.24870391190052032, Accuracy: 0.916015625\n",
      "Batch: 63, Loss: 0.200099378824234, Accuracy: 0.9306640625\n",
      "Batch: 64, Loss: 0.24860551953315735, Accuracy: 0.916015625\n",
      "Batch: 65, Loss: 0.22822971642017365, Accuracy: 0.9208984375\n",
      "Batch: 66, Loss: 0.20874370634555817, Accuracy: 0.9228515625\n",
      "Batch: 67, Loss: 0.23970413208007812, Accuracy: 0.9150390625\n",
      "Batch: 68, Loss: 0.25541767477989197, Accuracy: 0.9111328125\n",
      "Batch: 69, Loss: 0.20732654631137848, Accuracy: 0.9287109375\n",
      "Batch: 70, Loss: 0.25404155254364014, Accuracy: 0.9169921875\n",
      "Batch: 71, Loss: 0.26145315170288086, Accuracy: 0.908203125\n",
      "Batch: 72, Loss: 0.24338698387145996, Accuracy: 0.923828125\n",
      "Batch: 73, Loss: 0.23030027747154236, Accuracy: 0.9130859375\n",
      "Batch: 74, Loss: 0.23761571943759918, Accuracy: 0.92578125\n",
      "Batch: 75, Loss: 0.2335430085659027, Accuracy: 0.9111328125\n",
      "Batch: 76, Loss: 0.17763857543468475, Accuracy: 0.94140625\n",
      "Batch: 77, Loss: 0.23180468380451202, Accuracy: 0.9326171875\n",
      "Batch: 78, Loss: 0.21612021327018738, Accuracy: 0.9228515625\n",
      "Batch: 79, Loss: 0.2536707818508148, Accuracy: 0.9111328125\n",
      "Batch: 80, Loss: 0.23580113053321838, Accuracy: 0.9228515625\n",
      "Batch: 81, Loss: 0.26653623580932617, Accuracy: 0.9111328125\n",
      "Batch: 82, Loss: 0.23070621490478516, Accuracy: 0.9228515625\n",
      "Batch: 83, Loss: 0.2145429253578186, Accuracy: 0.9208984375\n",
      "Batch: 84, Loss: 0.24397072196006775, Accuracy: 0.912109375\n",
      "Batch: 85, Loss: 0.25002217292785645, Accuracy: 0.9189453125\n",
      "Batch: 86, Loss: 0.2837502062320709, Accuracy: 0.8955078125\n",
      "Batch: 87, Loss: 0.23585167527198792, Accuracy: 0.91796875\n",
      "Batch: 88, Loss: 0.2695358395576477, Accuracy: 0.9072265625\n",
      "Batch: 89, Loss: 0.24648894369602203, Accuracy: 0.9140625\n",
      "Batch: 90, Loss: 0.3011525273323059, Accuracy: 0.884765625\n",
      "Batch: 91, Loss: 0.28314414620399475, Accuracy: 0.9052734375\n",
      "Batch: 92, Loss: 0.28038090467453003, Accuracy: 0.904296875\n",
      "Batch: 93, Loss: 0.27206623554229736, Accuracy: 0.912109375\n",
      "Batch: 94, Loss: 0.26217663288116455, Accuracy: 0.908203125\n",
      "Batch: 95, Loss: 0.25180357694625854, Accuracy: 0.90625\n",
      "Batch: 96, Loss: 0.2552236318588257, Accuracy: 0.9208984375\n",
      "Batch: 97, Loss: 0.22805750370025635, Accuracy: 0.9287109375\n",
      "Batch: 98, Loss: 0.26469045877456665, Accuracy: 0.912109375\n",
      "Batch: 99, Loss: 0.21178331971168518, Accuracy: 0.9248046875\n",
      "Batch: 100, Loss: 0.23412010073661804, Accuracy: 0.9091796875\n",
      "Batch: 101, Loss: 0.24362948536872864, Accuracy: 0.9169921875\n",
      "Batch: 102, Loss: 0.24255108833312988, Accuracy: 0.91015625\n",
      "Batch: 103, Loss: 0.28511279821395874, Accuracy: 0.896484375\n",
      "Batch: 104, Loss: 0.26205605268478394, Accuracy: 0.908203125\n",
      "Batch: 105, Loss: 0.19825510680675507, Accuracy: 0.9306640625\n",
      "Batch: 106, Loss: 0.24124866724014282, Accuracy: 0.916015625\n",
      "Batch: 107, Loss: 0.21466265618801117, Accuracy: 0.919921875\n",
      "Batch: 108, Loss: 0.22988927364349365, Accuracy: 0.927734375\n",
      "Batch: 109, Loss: 0.18453088402748108, Accuracy: 0.93359375\n",
      "Batch: 110, Loss: 0.21695274114608765, Accuracy: 0.921875\n",
      "Batch: 111, Loss: 0.2629031836986542, Accuracy: 0.916015625\n",
      "Batch: 112, Loss: 0.24017596244812012, Accuracy: 0.9189453125\n",
      "Epoch 75/90\n",
      "Batch: 1, Loss: 0.2915853261947632, Accuracy: 0.9189453125\n",
      "Batch: 2, Loss: 0.24991528689861298, Accuracy: 0.9169921875\n",
      "Batch: 3, Loss: 0.2506859302520752, Accuracy: 0.916015625\n",
      "Batch: 4, Loss: 0.2073518931865692, Accuracy: 0.93359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 5, Loss: 0.20705558359622955, Accuracy: 0.923828125\n",
      "Batch: 6, Loss: 0.23952248692512512, Accuracy: 0.919921875\n",
      "Batch: 7, Loss: 0.23703478276729584, Accuracy: 0.9140625\n",
      "Batch: 8, Loss: 0.20560605823993683, Accuracy: 0.9345703125\n",
      "Batch: 9, Loss: 0.2418895959854126, Accuracy: 0.921875\n",
      "Batch: 10, Loss: 0.2449122965335846, Accuracy: 0.9140625\n",
      "Batch: 11, Loss: 0.25429826974868774, Accuracy: 0.9228515625\n",
      "Batch: 12, Loss: 0.2427942305803299, Accuracy: 0.9228515625\n",
      "Batch: 13, Loss: 0.2084701806306839, Accuracy: 0.9296875\n",
      "Batch: 14, Loss: 0.224380761384964, Accuracy: 0.9248046875\n",
      "Batch: 15, Loss: 0.25201094150543213, Accuracy: 0.916015625\n",
      "Batch: 16, Loss: 0.2488667070865631, Accuracy: 0.9248046875\n",
      "Batch: 17, Loss: 0.23709747195243835, Accuracy: 0.9130859375\n",
      "Batch: 18, Loss: 0.21062560379505157, Accuracy: 0.923828125\n",
      "Batch: 19, Loss: 0.23019170761108398, Accuracy: 0.9228515625\n",
      "Batch: 20, Loss: 0.22190627455711365, Accuracy: 0.916015625\n",
      "Batch: 21, Loss: 0.26552894711494446, Accuracy: 0.9169921875\n",
      "Batch: 22, Loss: 0.23159898817539215, Accuracy: 0.921875\n",
      "Batch: 23, Loss: 0.26782143115997314, Accuracy: 0.912109375\n",
      "Batch: 24, Loss: 0.27437925338745117, Accuracy: 0.9091796875\n",
      "Batch: 25, Loss: 0.2766459882259369, Accuracy: 0.896484375\n",
      "Batch: 26, Loss: 0.2552573084831238, Accuracy: 0.908203125\n",
      "Batch: 27, Loss: 0.2650550305843353, Accuracy: 0.9150390625\n",
      "Batch: 28, Loss: 0.25910788774490356, Accuracy: 0.9169921875\n",
      "Batch: 29, Loss: 0.26855605840682983, Accuracy: 0.90625\n",
      "Batch: 30, Loss: 0.246595099568367, Accuracy: 0.9248046875\n",
      "Batch: 31, Loss: 0.2560162842273712, Accuracy: 0.9091796875\n",
      "Batch: 32, Loss: 0.1992708146572113, Accuracy: 0.9375\n",
      "Batch: 33, Loss: 0.23060308396816254, Accuracy: 0.9189453125\n",
      "Batch: 34, Loss: 0.2381664514541626, Accuracy: 0.9189453125\n",
      "Batch: 35, Loss: 0.25137633085250854, Accuracy: 0.9140625\n",
      "Batch: 36, Loss: 0.25656184554100037, Accuracy: 0.919921875\n",
      "Batch: 37, Loss: 0.22089508175849915, Accuracy: 0.916015625\n",
      "Batch: 38, Loss: 0.2946392297744751, Accuracy: 0.904296875\n",
      "Batch: 39, Loss: 0.25827357172966003, Accuracy: 0.9189453125\n",
      "Batch: 40, Loss: 0.23581768572330475, Accuracy: 0.91796875\n",
      "Batch: 41, Loss: 0.2622114419937134, Accuracy: 0.90625\n",
      "Batch: 42, Loss: 0.2470867931842804, Accuracy: 0.9208984375\n",
      "Batch: 43, Loss: 0.21586325764656067, Accuracy: 0.91796875\n",
      "Batch: 44, Loss: 0.23085881769657135, Accuracy: 0.9130859375\n",
      "Batch: 45, Loss: 0.24966149032115936, Accuracy: 0.9140625\n",
      "Batch: 46, Loss: 0.2697691321372986, Accuracy: 0.9052734375\n",
      "Batch: 47, Loss: 0.21990898251533508, Accuracy: 0.931640625\n",
      "Batch: 48, Loss: 0.23954910039901733, Accuracy: 0.923828125\n",
      "Batch: 49, Loss: 0.24332094192504883, Accuracy: 0.927734375\n",
      "Batch: 50, Loss: 0.21037933230400085, Accuracy: 0.923828125\n",
      "Batch: 51, Loss: 0.2432180792093277, Accuracy: 0.916015625\n",
      "Batch: 52, Loss: 0.22548052668571472, Accuracy: 0.9248046875\n",
      "Batch: 53, Loss: 0.2652115821838379, Accuracy: 0.9052734375\n",
      "Batch: 54, Loss: 0.25133514404296875, Accuracy: 0.9140625\n",
      "Batch: 55, Loss: 0.26455891132354736, Accuracy: 0.9169921875\n",
      "Batch: 56, Loss: 0.19293725490570068, Accuracy: 0.935546875\n",
      "Batch: 57, Loss: 0.2393452227115631, Accuracy: 0.919921875\n",
      "Batch: 58, Loss: 0.28464534878730774, Accuracy: 0.90625\n",
      "Batch: 59, Loss: 0.26681429147720337, Accuracy: 0.9150390625\n",
      "Batch: 60, Loss: 0.264369398355484, Accuracy: 0.9111328125\n",
      "Batch: 61, Loss: 0.2349892258644104, Accuracy: 0.9189453125\n",
      "Batch: 62, Loss: 0.22755509614944458, Accuracy: 0.919921875\n",
      "Batch: 63, Loss: 0.20839115977287292, Accuracy: 0.9326171875\n",
      "Batch: 64, Loss: 0.2208797037601471, Accuracy: 0.9267578125\n",
      "Batch: 65, Loss: 0.21272701025009155, Accuracy: 0.923828125\n",
      "Batch: 66, Loss: 0.20672088861465454, Accuracy: 0.9365234375\n",
      "Batch: 67, Loss: 0.26110178232192993, Accuracy: 0.9111328125\n",
      "Batch: 68, Loss: 0.23309403657913208, Accuracy: 0.92578125\n",
      "Batch: 69, Loss: 0.20166015625, Accuracy: 0.931640625\n",
      "Batch: 70, Loss: 0.23986056447029114, Accuracy: 0.92578125\n",
      "Batch: 71, Loss: 0.2561233341693878, Accuracy: 0.91015625\n",
      "Batch: 72, Loss: 0.2535591721534729, Accuracy: 0.923828125\n",
      "Batch: 73, Loss: 0.2424655258655548, Accuracy: 0.9208984375\n",
      "Batch: 74, Loss: 0.2180776298046112, Accuracy: 0.9345703125\n",
      "Batch: 75, Loss: 0.21410953998565674, Accuracy: 0.921875\n",
      "Batch: 76, Loss: 0.20191507041454315, Accuracy: 0.9384765625\n",
      "Batch: 77, Loss: 0.21037442982196808, Accuracy: 0.9326171875\n",
      "Batch: 78, Loss: 0.21009504795074463, Accuracy: 0.9345703125\n",
      "Batch: 79, Loss: 0.2520484924316406, Accuracy: 0.9140625\n",
      "Batch: 80, Loss: 0.21985775232315063, Accuracy: 0.921875\n",
      "Batch: 81, Loss: 0.2605191469192505, Accuracy: 0.9111328125\n",
      "Batch: 82, Loss: 0.24598291516304016, Accuracy: 0.9072265625\n",
      "Batch: 83, Loss: 0.2038843035697937, Accuracy: 0.92578125\n",
      "Batch: 84, Loss: 0.23557378351688385, Accuracy: 0.921875\n",
      "Batch: 85, Loss: 0.23606832325458527, Accuracy: 0.9208984375\n",
      "Batch: 86, Loss: 0.2534497380256653, Accuracy: 0.9091796875\n",
      "Batch: 87, Loss: 0.23436088860034943, Accuracy: 0.9228515625\n",
      "Batch: 88, Loss: 0.27055639028549194, Accuracy: 0.8994140625\n",
      "Batch: 89, Loss: 0.23032690584659576, Accuracy: 0.9169921875\n",
      "Batch: 90, Loss: 0.28396785259246826, Accuracy: 0.8984375\n",
      "Batch: 91, Loss: 0.2509155571460724, Accuracy: 0.9150390625\n",
      "Batch: 92, Loss: 0.250186026096344, Accuracy: 0.912109375\n",
      "Batch: 93, Loss: 0.25239551067352295, Accuracy: 0.9130859375\n",
      "Batch: 94, Loss: 0.2424471080303192, Accuracy: 0.916015625\n",
      "Batch: 95, Loss: 0.24663376808166504, Accuracy: 0.916015625\n",
      "Batch: 96, Loss: 0.2503648102283478, Accuracy: 0.927734375\n",
      "Batch: 97, Loss: 0.23069384694099426, Accuracy: 0.92578125\n",
      "Batch: 98, Loss: 0.23640842735767365, Accuracy: 0.9169921875\n",
      "Batch: 99, Loss: 0.19512277841567993, Accuracy: 0.9365234375\n",
      "Batch: 100, Loss: 0.248550146818161, Accuracy: 0.9189453125\n",
      "Batch: 101, Loss: 0.23400157690048218, Accuracy: 0.921875\n",
      "Batch: 102, Loss: 0.22865965962409973, Accuracy: 0.927734375\n",
      "Batch: 103, Loss: 0.23704813420772552, Accuracy: 0.9228515625\n",
      "Batch: 104, Loss: 0.25739753246307373, Accuracy: 0.91015625\n",
      "Batch: 105, Loss: 0.19571137428283691, Accuracy: 0.9326171875\n",
      "Batch: 106, Loss: 0.258004754781723, Accuracy: 0.9033203125\n",
      "Batch: 107, Loss: 0.20145362615585327, Accuracy: 0.921875\n",
      "Batch: 108, Loss: 0.2337862253189087, Accuracy: 0.9228515625\n",
      "Batch: 109, Loss: 0.17595966160297394, Accuracy: 0.9462890625\n",
      "Batch: 110, Loss: 0.2167849838733673, Accuracy: 0.9287109375\n",
      "Batch: 111, Loss: 0.24394431710243225, Accuracy: 0.9140625\n",
      "Batch: 112, Loss: 0.2543513774871826, Accuracy: 0.916015625\n",
      "Epoch 76/90\n",
      "Batch: 1, Loss: 0.31244009733200073, Accuracy: 0.90625\n",
      "Batch: 2, Loss: 0.23437859117984772, Accuracy: 0.9248046875\n",
      "Batch: 3, Loss: 0.2501145601272583, Accuracy: 0.90625\n",
      "Batch: 4, Loss: 0.21057897806167603, Accuracy: 0.931640625\n",
      "Batch: 5, Loss: 0.201257586479187, Accuracy: 0.93359375\n",
      "Batch: 6, Loss: 0.21266993880271912, Accuracy: 0.9306640625\n",
      "Batch: 7, Loss: 0.2443964183330536, Accuracy: 0.916015625\n",
      "Batch: 8, Loss: 0.22137868404388428, Accuracy: 0.9296875\n",
      "Batch: 9, Loss: 0.2493961602449417, Accuracy: 0.908203125\n",
      "Batch: 10, Loss: 0.28275400400161743, Accuracy: 0.8994140625\n",
      "Batch: 11, Loss: 0.2461628019809723, Accuracy: 0.9228515625\n",
      "Batch: 12, Loss: 0.20058074593544006, Accuracy: 0.9267578125\n",
      "Batch: 13, Loss: 0.20663237571716309, Accuracy: 0.9208984375\n",
      "Batch: 14, Loss: 0.22678518295288086, Accuracy: 0.9248046875\n",
      "Batch: 15, Loss: 0.20509915053844452, Accuracy: 0.93359375\n",
      "Batch: 16, Loss: 0.22696083784103394, Accuracy: 0.9306640625\n",
      "Batch: 17, Loss: 0.24308037757873535, Accuracy: 0.91796875\n",
      "Batch: 18, Loss: 0.21578346192836761, Accuracy: 0.927734375\n",
      "Batch: 19, Loss: 0.22729195654392242, Accuracy: 0.91796875\n",
      "Batch: 20, Loss: 0.24230094254016876, Accuracy: 0.91015625\n",
      "Batch: 21, Loss: 0.22730061411857605, Accuracy: 0.921875\n",
      "Batch: 22, Loss: 0.21216844022274017, Accuracy: 0.9306640625\n",
      "Batch: 23, Loss: 0.26232796907424927, Accuracy: 0.9130859375\n",
      "Batch: 24, Loss: 0.2829616963863373, Accuracy: 0.908203125\n",
      "Batch: 25, Loss: 0.2786104083061218, Accuracy: 0.919921875\n",
      "Batch: 26, Loss: 0.28408151865005493, Accuracy: 0.8994140625\n",
      "Batch: 27, Loss: 0.24063114821910858, Accuracy: 0.9208984375\n",
      "Batch: 28, Loss: 0.27673056721687317, Accuracy: 0.908203125\n",
      "Batch: 29, Loss: 0.2681901454925537, Accuracy: 0.916015625\n",
      "Batch: 30, Loss: 0.2184804379940033, Accuracy: 0.9287109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 31, Loss: 0.23864908516407013, Accuracy: 0.9169921875\n",
      "Batch: 32, Loss: 0.20414316654205322, Accuracy: 0.9267578125\n",
      "Batch: 33, Loss: 0.2211018204689026, Accuracy: 0.9326171875\n",
      "Batch: 34, Loss: 0.21077044308185577, Accuracy: 0.927734375\n",
      "Batch: 35, Loss: 0.2114403247833252, Accuracy: 0.9248046875\n",
      "Batch: 36, Loss: 0.2790125608444214, Accuracy: 0.9111328125\n",
      "Batch: 37, Loss: 0.2085156887769699, Accuracy: 0.9267578125\n",
      "Batch: 38, Loss: 0.24300473928451538, Accuracy: 0.9189453125\n",
      "Batch: 39, Loss: 0.27715927362442017, Accuracy: 0.904296875\n",
      "Batch: 40, Loss: 0.22617678344249725, Accuracy: 0.9228515625\n",
      "Batch: 41, Loss: 0.234900563955307, Accuracy: 0.923828125\n",
      "Batch: 42, Loss: 0.21653015911579132, Accuracy: 0.9306640625\n",
      "Batch: 43, Loss: 0.2151617407798767, Accuracy: 0.9267578125\n",
      "Batch: 44, Loss: 0.23587611317634583, Accuracy: 0.92578125\n",
      "Batch: 45, Loss: 0.22273996472358704, Accuracy: 0.9345703125\n",
      "Batch: 46, Loss: 0.21799077093601227, Accuracy: 0.9248046875\n",
      "Batch: 47, Loss: 0.19793912768363953, Accuracy: 0.93359375\n",
      "Batch: 48, Loss: 0.2463614046573639, Accuracy: 0.9169921875\n",
      "Batch: 49, Loss: 0.24503105878829956, Accuracy: 0.9140625\n",
      "Batch: 50, Loss: 0.22106310725212097, Accuracy: 0.9287109375\n",
      "Batch: 51, Loss: 0.24662047624588013, Accuracy: 0.9111328125\n",
      "Batch: 52, Loss: 0.22447676956653595, Accuracy: 0.9189453125\n",
      "Batch: 53, Loss: 0.30247247219085693, Accuracy: 0.9091796875\n",
      "Batch: 54, Loss: 0.2346174716949463, Accuracy: 0.9267578125\n",
      "Batch: 55, Loss: 0.25752508640289307, Accuracy: 0.9169921875\n",
      "Batch: 56, Loss: 0.21841298043727875, Accuracy: 0.9296875\n",
      "Batch: 57, Loss: 0.25257694721221924, Accuracy: 0.91796875\n",
      "Batch: 58, Loss: 0.28950953483581543, Accuracy: 0.896484375\n",
      "Batch: 59, Loss: 0.2404422014951706, Accuracy: 0.923828125\n",
      "Batch: 60, Loss: 0.241136372089386, Accuracy: 0.9248046875\n",
      "Batch: 61, Loss: 0.2204546332359314, Accuracy: 0.9228515625\n",
      "Batch: 62, Loss: 0.21870198845863342, Accuracy: 0.927734375\n",
      "Batch: 63, Loss: 0.19471421837806702, Accuracy: 0.9345703125\n",
      "Batch: 64, Loss: 0.2370704859495163, Accuracy: 0.9111328125\n",
      "Batch: 65, Loss: 0.22227275371551514, Accuracy: 0.9208984375\n",
      "Batch: 66, Loss: 0.21909619867801666, Accuracy: 0.9296875\n",
      "Batch: 67, Loss: 0.23276494443416595, Accuracy: 0.921875\n",
      "Batch: 68, Loss: 0.2348298281431198, Accuracy: 0.9248046875\n",
      "Batch: 69, Loss: 0.20135734975337982, Accuracy: 0.9365234375\n",
      "Batch: 70, Loss: 0.19646728038787842, Accuracy: 0.9296875\n",
      "Batch: 71, Loss: 0.2190425992012024, Accuracy: 0.9248046875\n",
      "Batch: 72, Loss: 0.25311893224716187, Accuracy: 0.9169921875\n",
      "Batch: 73, Loss: 0.2035309225320816, Accuracy: 0.93359375\n",
      "Batch: 74, Loss: 0.21713796257972717, Accuracy: 0.923828125\n",
      "Batch: 75, Loss: 0.21622955799102783, Accuracy: 0.9208984375\n",
      "Batch: 76, Loss: 0.195444256067276, Accuracy: 0.931640625\n",
      "Batch: 77, Loss: 0.24380473792552948, Accuracy: 0.916015625\n",
      "Batch: 78, Loss: 0.23323261737823486, Accuracy: 0.9228515625\n",
      "Batch: 79, Loss: 0.24208617210388184, Accuracy: 0.927734375\n",
      "Batch: 80, Loss: 0.2219969928264618, Accuracy: 0.9267578125\n",
      "Batch: 81, Loss: 0.24144725501537323, Accuracy: 0.912109375\n",
      "Batch: 82, Loss: 0.25614285469055176, Accuracy: 0.9033203125\n",
      "Batch: 83, Loss: 0.20118841528892517, Accuracy: 0.93359375\n",
      "Batch: 84, Loss: 0.24523600935935974, Accuracy: 0.91796875\n",
      "Batch: 85, Loss: 0.2632193863391876, Accuracy: 0.9140625\n",
      "Batch: 86, Loss: 0.24522478878498077, Accuracy: 0.90625\n",
      "Batch: 87, Loss: 0.22833770513534546, Accuracy: 0.919921875\n",
      "Batch: 88, Loss: 0.2408362179994583, Accuracy: 0.9111328125\n",
      "Batch: 89, Loss: 0.24959176778793335, Accuracy: 0.9130859375\n",
      "Batch: 90, Loss: 0.26952382922172546, Accuracy: 0.908203125\n",
      "Batch: 91, Loss: 0.2729890048503876, Accuracy: 0.9052734375\n",
      "Batch: 92, Loss: 0.24941939115524292, Accuracy: 0.908203125\n",
      "Batch: 93, Loss: 0.26668477058410645, Accuracy: 0.904296875\n",
      "Batch: 94, Loss: 0.24166491627693176, Accuracy: 0.921875\n",
      "Batch: 95, Loss: 0.266770601272583, Accuracy: 0.9072265625\n",
      "Batch: 96, Loss: 0.23332826793193817, Accuracy: 0.9228515625\n",
      "Batch: 97, Loss: 0.20713689923286438, Accuracy: 0.931640625\n",
      "Batch: 98, Loss: 0.24251332879066467, Accuracy: 0.9228515625\n",
      "Batch: 99, Loss: 0.21125711500644684, Accuracy: 0.921875\n",
      "Batch: 100, Loss: 0.24549195170402527, Accuracy: 0.91796875\n",
      "Batch: 101, Loss: 0.2263004332780838, Accuracy: 0.9189453125\n",
      "Batch: 102, Loss: 0.21447138488292694, Accuracy: 0.919921875\n",
      "Batch: 103, Loss: 0.24372699856758118, Accuracy: 0.9189453125\n",
      "Batch: 104, Loss: 0.24415065348148346, Accuracy: 0.916015625\n",
      "Batch: 105, Loss: 0.17610010504722595, Accuracy: 0.9326171875\n",
      "Batch: 106, Loss: 0.2271733283996582, Accuracy: 0.9228515625\n",
      "Batch: 107, Loss: 0.20042191445827484, Accuracy: 0.9296875\n",
      "Batch: 108, Loss: 0.2141832411289215, Accuracy: 0.9287109375\n",
      "Batch: 109, Loss: 0.17377951741218567, Accuracy: 0.9423828125\n",
      "Batch: 110, Loss: 0.20084956288337708, Accuracy: 0.9306640625\n",
      "Batch: 111, Loss: 0.2603394091129303, Accuracy: 0.9189453125\n",
      "Batch: 112, Loss: 0.23838995397090912, Accuracy: 0.9140625\n",
      "Epoch 77/90\n",
      "Batch: 1, Loss: 0.2850111126899719, Accuracy: 0.9150390625\n",
      "Batch: 2, Loss: 0.21159061789512634, Accuracy: 0.9326171875\n",
      "Batch: 3, Loss: 0.263378381729126, Accuracy: 0.9072265625\n",
      "Batch: 4, Loss: 0.22707578539848328, Accuracy: 0.9248046875\n",
      "Batch: 5, Loss: 0.2060796618461609, Accuracy: 0.931640625\n",
      "Batch: 6, Loss: 0.20005781948566437, Accuracy: 0.9384765625\n",
      "Batch: 7, Loss: 0.22688011825084686, Accuracy: 0.9189453125\n",
      "Batch: 8, Loss: 0.22279030084609985, Accuracy: 0.93359375\n",
      "Batch: 9, Loss: 0.2360524982213974, Accuracy: 0.91796875\n",
      "Batch: 10, Loss: 0.27530989050865173, Accuracy: 0.908203125\n",
      "Batch: 11, Loss: 0.25391462445259094, Accuracy: 0.9140625\n",
      "Batch: 12, Loss: 0.20962576568126678, Accuracy: 0.927734375\n",
      "Batch: 13, Loss: 0.20003867149353027, Accuracy: 0.9365234375\n",
      "Batch: 14, Loss: 0.2326301485300064, Accuracy: 0.9189453125\n",
      "Batch: 15, Loss: 0.2144605964422226, Accuracy: 0.9267578125\n",
      "Batch: 16, Loss: 0.2295042872428894, Accuracy: 0.9306640625\n",
      "Batch: 17, Loss: 0.24695760011672974, Accuracy: 0.908203125\n",
      "Batch: 18, Loss: 0.19705121219158173, Accuracy: 0.9365234375\n",
      "Batch: 19, Loss: 0.225826695561409, Accuracy: 0.9208984375\n",
      "Batch: 20, Loss: 0.23735305666923523, Accuracy: 0.916015625\n",
      "Batch: 21, Loss: 0.26234912872314453, Accuracy: 0.9091796875\n",
      "Batch: 22, Loss: 0.236587256193161, Accuracy: 0.923828125\n",
      "Batch: 23, Loss: 0.29461604356765747, Accuracy: 0.8955078125\n",
      "Batch: 24, Loss: 0.2709382176399231, Accuracy: 0.9130859375\n",
      "Batch: 25, Loss: 0.2597149610519409, Accuracy: 0.9130859375\n",
      "Batch: 26, Loss: 0.23667843639850616, Accuracy: 0.9287109375\n",
      "Batch: 27, Loss: 0.27202868461608887, Accuracy: 0.916015625\n",
      "Batch: 28, Loss: 0.25979533791542053, Accuracy: 0.9169921875\n",
      "Batch: 29, Loss: 0.2817143201828003, Accuracy: 0.9091796875\n",
      "Batch: 30, Loss: 0.22211411595344543, Accuracy: 0.9248046875\n",
      "Batch: 31, Loss: 0.22940553724765778, Accuracy: 0.916015625\n",
      "Batch: 32, Loss: 0.2125091552734375, Accuracy: 0.921875\n",
      "Batch: 33, Loss: 0.21615110337734222, Accuracy: 0.921875\n",
      "Batch: 34, Loss: 0.2368047833442688, Accuracy: 0.91015625\n",
      "Batch: 35, Loss: 0.22772298753261566, Accuracy: 0.9130859375\n",
      "Batch: 36, Loss: 0.2587330937385559, Accuracy: 0.9130859375\n",
      "Batch: 37, Loss: 0.19703784584999084, Accuracy: 0.9267578125\n",
      "Batch: 38, Loss: 0.22981694340705872, Accuracy: 0.9296875\n",
      "Batch: 39, Loss: 0.2229294776916504, Accuracy: 0.9169921875\n",
      "Batch: 40, Loss: 0.23973645269870758, Accuracy: 0.91796875\n",
      "Batch: 41, Loss: 0.25312715768814087, Accuracy: 0.91015625\n",
      "Batch: 42, Loss: 0.2818225622177124, Accuracy: 0.912109375\n",
      "Batch: 43, Loss: 0.2375122308731079, Accuracy: 0.9091796875\n",
      "Batch: 44, Loss: 0.2259475290775299, Accuracy: 0.9248046875\n",
      "Batch: 45, Loss: 0.2672504782676697, Accuracy: 0.9091796875\n",
      "Batch: 46, Loss: 0.22921881079673767, Accuracy: 0.9189453125\n",
      "Batch: 47, Loss: 0.2504386901855469, Accuracy: 0.912109375\n",
      "Batch: 48, Loss: 0.23827630281448364, Accuracy: 0.919921875\n",
      "Batch: 49, Loss: 0.2691345512866974, Accuracy: 0.9130859375\n",
      "Batch: 50, Loss: 0.20103871822357178, Accuracy: 0.9326171875\n",
      "Batch: 51, Loss: 0.22644807398319244, Accuracy: 0.9248046875\n",
      "Batch: 52, Loss: 0.2110273838043213, Accuracy: 0.927734375\n",
      "Batch: 53, Loss: 0.27256208658218384, Accuracy: 0.9052734375\n",
      "Batch: 54, Loss: 0.2422773838043213, Accuracy: 0.9140625\n",
      "Batch: 55, Loss: 0.27528101205825806, Accuracy: 0.9091796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 56, Loss: 0.2058214247226715, Accuracy: 0.9296875\n",
      "Batch: 57, Loss: 0.24948927760124207, Accuracy: 0.91796875\n",
      "Batch: 58, Loss: 0.271435022354126, Accuracy: 0.908203125\n",
      "Batch: 59, Loss: 0.2486436665058136, Accuracy: 0.9189453125\n",
      "Batch: 60, Loss: 0.26166173815727234, Accuracy: 0.916015625\n",
      "Batch: 61, Loss: 0.20888595283031464, Accuracy: 0.9326171875\n",
      "Batch: 62, Loss: 0.23155149817466736, Accuracy: 0.919921875\n",
      "Batch: 63, Loss: 0.2056158483028412, Accuracy: 0.931640625\n",
      "Batch: 64, Loss: 0.23253189027309418, Accuracy: 0.9267578125\n",
      "Batch: 65, Loss: 0.2163490653038025, Accuracy: 0.9267578125\n",
      "Batch: 66, Loss: 0.20540279150009155, Accuracy: 0.9501953125\n",
      "Batch: 67, Loss: 0.23597274720668793, Accuracy: 0.91796875\n",
      "Batch: 68, Loss: 0.213751882314682, Accuracy: 0.927734375\n",
      "Batch: 69, Loss: 0.21321871876716614, Accuracy: 0.9296875\n",
      "Batch: 70, Loss: 0.22794413566589355, Accuracy: 0.921875\n",
      "Batch: 71, Loss: 0.21306054294109344, Accuracy: 0.927734375\n",
      "Batch: 72, Loss: 0.24632321298122406, Accuracy: 0.9208984375\n",
      "Batch: 73, Loss: 0.2191302478313446, Accuracy: 0.9208984375\n",
      "Batch: 74, Loss: 0.22316423058509827, Accuracy: 0.9248046875\n",
      "Batch: 75, Loss: 0.233014315366745, Accuracy: 0.9169921875\n",
      "Batch: 76, Loss: 0.18356020748615265, Accuracy: 0.935546875\n",
      "Batch: 77, Loss: 0.2358151525259018, Accuracy: 0.9189453125\n",
      "Batch: 78, Loss: 0.24053925275802612, Accuracy: 0.91796875\n",
      "Batch: 79, Loss: 0.2325563281774521, Accuracy: 0.9296875\n",
      "Batch: 80, Loss: 0.22230540215969086, Accuracy: 0.9208984375\n",
      "Batch: 81, Loss: 0.2201579362154007, Accuracy: 0.9287109375\n",
      "Batch: 82, Loss: 0.2334844172000885, Accuracy: 0.919921875\n",
      "Batch: 83, Loss: 0.20901939272880554, Accuracy: 0.9296875\n",
      "Batch: 84, Loss: 0.18580898642539978, Accuracy: 0.93359375\n",
      "Batch: 85, Loss: 0.2729387879371643, Accuracy: 0.91796875\n",
      "Batch: 86, Loss: 0.23397450149059296, Accuracy: 0.908203125\n",
      "Batch: 87, Loss: 0.22353026270866394, Accuracy: 0.9287109375\n",
      "Batch: 88, Loss: 0.237173393368721, Accuracy: 0.916015625\n",
      "Batch: 89, Loss: 0.22644127905368805, Accuracy: 0.9248046875\n",
      "Batch: 90, Loss: 0.24968816339969635, Accuracy: 0.9140625\n",
      "Batch: 91, Loss: 0.28281068801879883, Accuracy: 0.912109375\n",
      "Batch: 92, Loss: 0.22878164052963257, Accuracy: 0.9248046875\n",
      "Batch: 93, Loss: 0.25337427854537964, Accuracy: 0.9189453125\n",
      "Batch: 94, Loss: 0.2397705316543579, Accuracy: 0.9130859375\n",
      "Batch: 95, Loss: 0.26192620396614075, Accuracy: 0.9140625\n",
      "Batch: 96, Loss: 0.20593270659446716, Accuracy: 0.939453125\n",
      "Batch: 97, Loss: 0.22622713446617126, Accuracy: 0.9208984375\n",
      "Batch: 98, Loss: 0.24518880248069763, Accuracy: 0.9140625\n",
      "Batch: 99, Loss: 0.19511154294013977, Accuracy: 0.9365234375\n",
      "Batch: 100, Loss: 0.21140213310718536, Accuracy: 0.923828125\n",
      "Batch: 101, Loss: 0.27320465445518494, Accuracy: 0.90234375\n",
      "Batch: 102, Loss: 0.2143760621547699, Accuracy: 0.9208984375\n",
      "Batch: 103, Loss: 0.24281641840934753, Accuracy: 0.9248046875\n",
      "Batch: 104, Loss: 0.24818752706050873, Accuracy: 0.9150390625\n",
      "Batch: 105, Loss: 0.19147905707359314, Accuracy: 0.9365234375\n",
      "Batch: 106, Loss: 0.24113765358924866, Accuracy: 0.9033203125\n",
      "Batch: 107, Loss: 0.20906470715999603, Accuracy: 0.9208984375\n",
      "Batch: 108, Loss: 0.20244553685188293, Accuracy: 0.931640625\n",
      "Batch: 109, Loss: 0.17976772785186768, Accuracy: 0.9365234375\n",
      "Batch: 110, Loss: 0.2137751281261444, Accuracy: 0.9228515625\n",
      "Batch: 111, Loss: 0.2345539927482605, Accuracy: 0.91796875\n",
      "Batch: 112, Loss: 0.236129492521286, Accuracy: 0.9169921875\n",
      "Epoch 78/90\n",
      "Batch: 1, Loss: 0.2652353048324585, Accuracy: 0.9208984375\n",
      "Batch: 2, Loss: 0.2520121932029724, Accuracy: 0.9150390625\n",
      "Batch: 3, Loss: 0.2317691147327423, Accuracy: 0.91796875\n",
      "Batch: 4, Loss: 0.19230470061302185, Accuracy: 0.9384765625\n",
      "Batch: 5, Loss: 0.18346849083900452, Accuracy: 0.9345703125\n",
      "Batch: 6, Loss: 0.23752336204051971, Accuracy: 0.9189453125\n",
      "Batch: 7, Loss: 0.19019880890846252, Accuracy: 0.9384765625\n",
      "Batch: 8, Loss: 0.17736808955669403, Accuracy: 0.9384765625\n",
      "Batch: 9, Loss: 0.2247176468372345, Accuracy: 0.921875\n",
      "Batch: 10, Loss: 0.26495108008384705, Accuracy: 0.9091796875\n",
      "Batch: 11, Loss: 0.26865237951278687, Accuracy: 0.91796875\n",
      "Batch: 12, Loss: 0.21836119890213013, Accuracy: 0.9326171875\n",
      "Batch: 13, Loss: 0.19865202903747559, Accuracy: 0.93359375\n",
      "Batch: 14, Loss: 0.22419334948062897, Accuracy: 0.921875\n",
      "Batch: 15, Loss: 0.21371065080165863, Accuracy: 0.927734375\n",
      "Batch: 16, Loss: 0.2166120558977127, Accuracy: 0.9375\n",
      "Batch: 17, Loss: 0.19413962960243225, Accuracy: 0.93359375\n",
      "Batch: 18, Loss: 0.2082207202911377, Accuracy: 0.9326171875\n",
      "Batch: 19, Loss: 0.22594183683395386, Accuracy: 0.916015625\n",
      "Batch: 20, Loss: 0.20663733780384064, Accuracy: 0.93359375\n",
      "Batch: 21, Loss: 0.2044992744922638, Accuracy: 0.9423828125\n",
      "Batch: 22, Loss: 0.21570953726768494, Accuracy: 0.927734375\n",
      "Batch: 23, Loss: 0.251666784286499, Accuracy: 0.919921875\n",
      "Batch: 24, Loss: 0.27862367033958435, Accuracy: 0.8974609375\n",
      "Batch: 25, Loss: 0.2546992301940918, Accuracy: 0.9091796875\n",
      "Batch: 26, Loss: 0.24085968732833862, Accuracy: 0.9091796875\n",
      "Batch: 27, Loss: 0.2797619104385376, Accuracy: 0.912109375\n",
      "Batch: 28, Loss: 0.2578777074813843, Accuracy: 0.9150390625\n",
      "Batch: 29, Loss: 0.24322862923145294, Accuracy: 0.9189453125\n",
      "Batch: 30, Loss: 0.23915886878967285, Accuracy: 0.91796875\n",
      "Batch: 31, Loss: 0.23225045204162598, Accuracy: 0.91796875\n",
      "Batch: 32, Loss: 0.24914687871932983, Accuracy: 0.912109375\n",
      "Batch: 33, Loss: 0.21772146224975586, Accuracy: 0.919921875\n",
      "Batch: 34, Loss: 0.2095891684293747, Accuracy: 0.9287109375\n",
      "Batch: 35, Loss: 0.23102521896362305, Accuracy: 0.9150390625\n",
      "Batch: 36, Loss: 0.22928664088249207, Accuracy: 0.923828125\n",
      "Batch: 37, Loss: 0.21665935218334198, Accuracy: 0.9189453125\n",
      "Batch: 38, Loss: 0.24613550305366516, Accuracy: 0.9111328125\n",
      "Batch: 39, Loss: 0.2199622541666031, Accuracy: 0.923828125\n",
      "Batch: 40, Loss: 0.1939266175031662, Accuracy: 0.9375\n",
      "Batch: 41, Loss: 0.2272166758775711, Accuracy: 0.9267578125\n",
      "Batch: 42, Loss: 0.2347966730594635, Accuracy: 0.9248046875\n",
      "Batch: 43, Loss: 0.21020492911338806, Accuracy: 0.927734375\n",
      "Batch: 44, Loss: 0.23579733073711395, Accuracy: 0.921875\n",
      "Batch: 45, Loss: 0.21304884552955627, Accuracy: 0.9267578125\n",
      "Batch: 46, Loss: 0.23167690634727478, Accuracy: 0.9228515625\n",
      "Batch: 47, Loss: 0.21240022778511047, Accuracy: 0.923828125\n",
      "Batch: 48, Loss: 0.20754291117191315, Accuracy: 0.9228515625\n",
      "Batch: 49, Loss: 0.2586153745651245, Accuracy: 0.912109375\n",
      "Batch: 50, Loss: 0.19123591482639313, Accuracy: 0.9345703125\n",
      "Batch: 51, Loss: 0.22472280263900757, Accuracy: 0.921875\n",
      "Batch: 52, Loss: 0.2176806926727295, Accuracy: 0.927734375\n",
      "Batch: 53, Loss: 0.27076947689056396, Accuracy: 0.9150390625\n",
      "Batch: 54, Loss: 0.27747154235839844, Accuracy: 0.9033203125\n",
      "Batch: 55, Loss: 0.24255076050758362, Accuracy: 0.9111328125\n",
      "Batch: 56, Loss: 0.19060301780700684, Accuracy: 0.935546875\n",
      "Batch: 57, Loss: 0.2575797140598297, Accuracy: 0.9091796875\n",
      "Batch: 58, Loss: 0.2774202823638916, Accuracy: 0.9052734375\n",
      "Batch: 59, Loss: 0.2564123868942261, Accuracy: 0.912109375\n",
      "Batch: 60, Loss: 0.24614450335502625, Accuracy: 0.921875\n",
      "Batch: 61, Loss: 0.23464561998844147, Accuracy: 0.9228515625\n",
      "Batch: 62, Loss: 0.1982336938381195, Accuracy: 0.935546875\n",
      "Batch: 63, Loss: 0.20446954667568207, Accuracy: 0.93359375\n",
      "Batch: 64, Loss: 0.21558284759521484, Accuracy: 0.93359375\n",
      "Batch: 65, Loss: 0.2258610725402832, Accuracy: 0.9208984375\n",
      "Batch: 66, Loss: 0.2106652706861496, Accuracy: 0.9296875\n",
      "Batch: 67, Loss: 0.21326802670955658, Accuracy: 0.931640625\n",
      "Batch: 68, Loss: 0.2209930717945099, Accuracy: 0.9306640625\n",
      "Batch: 69, Loss: 0.22994089126586914, Accuracy: 0.9248046875\n",
      "Batch: 70, Loss: 0.2041548192501068, Accuracy: 0.9326171875\n",
      "Batch: 71, Loss: 0.24114568531513214, Accuracy: 0.919921875\n",
      "Batch: 72, Loss: 0.240628182888031, Accuracy: 0.921875\n",
      "Batch: 73, Loss: 0.24601644277572632, Accuracy: 0.9228515625\n",
      "Batch: 74, Loss: 0.24231299757957458, Accuracy: 0.9130859375\n",
      "Batch: 75, Loss: 0.19688200950622559, Accuracy: 0.931640625\n",
      "Batch: 76, Loss: 0.17733316123485565, Accuracy: 0.9482421875\n",
      "Batch: 77, Loss: 0.2229289412498474, Accuracy: 0.9228515625\n",
      "Batch: 78, Loss: 0.24599626660346985, Accuracy: 0.912109375\n",
      "Batch: 79, Loss: 0.254122257232666, Accuracy: 0.9208984375\n",
      "Batch: 80, Loss: 0.2268381118774414, Accuracy: 0.9296875\n",
      "Batch: 81, Loss: 0.2652892470359802, Accuracy: 0.912109375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 82, Loss: 0.2529769539833069, Accuracy: 0.9169921875\n",
      "Batch: 83, Loss: 0.2089851200580597, Accuracy: 0.923828125\n",
      "Batch: 84, Loss: 0.21313050389289856, Accuracy: 0.931640625\n",
      "Batch: 85, Loss: 0.24432799220085144, Accuracy: 0.9169921875\n",
      "Batch: 86, Loss: 0.2502555251121521, Accuracy: 0.9013671875\n",
      "Batch: 87, Loss: 0.23506905138492584, Accuracy: 0.9189453125\n",
      "Batch: 88, Loss: 0.250200092792511, Accuracy: 0.9189453125\n",
      "Batch: 89, Loss: 0.2399149239063263, Accuracy: 0.9140625\n",
      "Batch: 90, Loss: 0.24152332544326782, Accuracy: 0.9228515625\n",
      "Batch: 91, Loss: 0.25575390458106995, Accuracy: 0.916015625\n",
      "Batch: 92, Loss: 0.2503456473350525, Accuracy: 0.9111328125\n",
      "Batch: 93, Loss: 0.2482067346572876, Accuracy: 0.9140625\n",
      "Batch: 94, Loss: 0.25079435110092163, Accuracy: 0.9228515625\n",
      "Batch: 95, Loss: 0.23274856805801392, Accuracy: 0.9169921875\n",
      "Batch: 96, Loss: 0.24310684204101562, Accuracy: 0.9208984375\n",
      "Batch: 97, Loss: 0.22017735242843628, Accuracy: 0.91796875\n",
      "Batch: 98, Loss: 0.2237536609172821, Accuracy: 0.9189453125\n",
      "Batch: 99, Loss: 0.20059429109096527, Accuracy: 0.9296875\n",
      "Batch: 100, Loss: 0.22811585664749146, Accuracy: 0.9169921875\n",
      "Batch: 101, Loss: 0.23879343271255493, Accuracy: 0.9189453125\n",
      "Batch: 102, Loss: 0.2143537700176239, Accuracy: 0.927734375\n",
      "Batch: 103, Loss: 0.2347608208656311, Accuracy: 0.9189453125\n",
      "Batch: 104, Loss: 0.27104616165161133, Accuracy: 0.89453125\n",
      "Batch: 105, Loss: 0.19331000745296478, Accuracy: 0.9296875\n",
      "Batch: 106, Loss: 0.2503099739551544, Accuracy: 0.908203125\n",
      "Batch: 107, Loss: 0.216609925031662, Accuracy: 0.9267578125\n",
      "Batch: 108, Loss: 0.22541789710521698, Accuracy: 0.923828125\n",
      "Batch: 109, Loss: 0.17446626722812653, Accuracy: 0.94140625\n",
      "Batch: 110, Loss: 0.20530927181243896, Accuracy: 0.9326171875\n",
      "Batch: 111, Loss: 0.22932225465774536, Accuracy: 0.916015625\n",
      "Batch: 112, Loss: 0.23518487811088562, Accuracy: 0.919921875\n",
      "Epoch 79/90\n",
      "Batch: 1, Loss: 0.27318382263183594, Accuracy: 0.916015625\n",
      "Batch: 2, Loss: 0.259093701839447, Accuracy: 0.919921875\n",
      "Batch: 3, Loss: 0.24120965600013733, Accuracy: 0.9208984375\n",
      "Batch: 4, Loss: 0.22641968727111816, Accuracy: 0.9248046875\n",
      "Batch: 5, Loss: 0.19852803647518158, Accuracy: 0.9306640625\n",
      "Batch: 6, Loss: 0.23044142127037048, Accuracy: 0.9208984375\n",
      "Batch: 7, Loss: 0.21187007427215576, Accuracy: 0.9248046875\n",
      "Batch: 8, Loss: 0.22272594273090363, Accuracy: 0.9267578125\n",
      "Batch: 9, Loss: 0.22394956648349762, Accuracy: 0.9296875\n",
      "Batch: 10, Loss: 0.25064945220947266, Accuracy: 0.9130859375\n",
      "Batch: 11, Loss: 0.2524512708187103, Accuracy: 0.916015625\n",
      "Batch: 12, Loss: 0.1912240982055664, Accuracy: 0.939453125\n",
      "Batch: 13, Loss: 0.18974262475967407, Accuracy: 0.93359375\n",
      "Batch: 14, Loss: 0.2266862690448761, Accuracy: 0.921875\n",
      "Batch: 15, Loss: 0.21249741315841675, Accuracy: 0.92578125\n",
      "Batch: 16, Loss: 0.20279008150100708, Accuracy: 0.9326171875\n",
      "Batch: 17, Loss: 0.25589489936828613, Accuracy: 0.9111328125\n",
      "Batch: 18, Loss: 0.2180250734090805, Accuracy: 0.9287109375\n",
      "Batch: 19, Loss: 0.20775049924850464, Accuracy: 0.9287109375\n",
      "Batch: 20, Loss: 0.25468775629997253, Accuracy: 0.9130859375\n",
      "Batch: 21, Loss: 0.24381333589553833, Accuracy: 0.91796875\n",
      "Batch: 22, Loss: 0.21961230039596558, Accuracy: 0.921875\n",
      "Batch: 23, Loss: 0.25209224224090576, Accuracy: 0.9150390625\n",
      "Batch: 24, Loss: 0.2947610318660736, Accuracy: 0.904296875\n",
      "Batch: 25, Loss: 0.2162686586380005, Accuracy: 0.9267578125\n",
      "Batch: 26, Loss: 0.23479366302490234, Accuracy: 0.919921875\n",
      "Batch: 27, Loss: 0.23798923194408417, Accuracy: 0.916015625\n",
      "Batch: 28, Loss: 0.22762146592140198, Accuracy: 0.9296875\n",
      "Batch: 29, Loss: 0.2587483525276184, Accuracy: 0.92578125\n",
      "Batch: 30, Loss: 0.22064052522182465, Accuracy: 0.9228515625\n",
      "Batch: 31, Loss: 0.24546048045158386, Accuracy: 0.9208984375\n",
      "Batch: 32, Loss: 0.2139487862586975, Accuracy: 0.91796875\n",
      "Batch: 33, Loss: 0.21928417682647705, Accuracy: 0.921875\n",
      "Batch: 34, Loss: 0.2212478667497635, Accuracy: 0.916015625\n",
      "Batch: 35, Loss: 0.23182950913906097, Accuracy: 0.921875\n",
      "Batch: 36, Loss: 0.25235146284103394, Accuracy: 0.9130859375\n",
      "Batch: 37, Loss: 0.21764875948429108, Accuracy: 0.9169921875\n",
      "Batch: 38, Loss: 0.24483433365821838, Accuracy: 0.9228515625\n",
      "Batch: 39, Loss: 0.22465723752975464, Accuracy: 0.927734375\n",
      "Batch: 40, Loss: 0.22985771298408508, Accuracy: 0.921875\n",
      "Batch: 41, Loss: 0.24539345502853394, Accuracy: 0.9111328125\n",
      "Batch: 42, Loss: 0.2294832170009613, Accuracy: 0.921875\n",
      "Batch: 43, Loss: 0.22768008708953857, Accuracy: 0.9130859375\n",
      "Batch: 44, Loss: 0.21681717038154602, Accuracy: 0.921875\n",
      "Batch: 45, Loss: 0.2156229466199875, Accuracy: 0.9296875\n",
      "Batch: 46, Loss: 0.2227593958377838, Accuracy: 0.9267578125\n",
      "Batch: 47, Loss: 0.21579262614250183, Accuracy: 0.93359375\n",
      "Batch: 48, Loss: 0.25190460681915283, Accuracy: 0.912109375\n",
      "Batch: 49, Loss: 0.26609909534454346, Accuracy: 0.91796875\n",
      "Batch: 50, Loss: 0.193223774433136, Accuracy: 0.9326171875\n",
      "Batch: 51, Loss: 0.21664297580718994, Accuracy: 0.93359375\n",
      "Batch: 52, Loss: 0.22343842685222626, Accuracy: 0.9326171875\n",
      "Batch: 53, Loss: 0.28158020973205566, Accuracy: 0.90625\n",
      "Batch: 54, Loss: 0.25545233488082886, Accuracy: 0.9248046875\n",
      "Batch: 55, Loss: 0.26311981678009033, Accuracy: 0.912109375\n",
      "Batch: 56, Loss: 0.18961822986602783, Accuracy: 0.9306640625\n",
      "Batch: 57, Loss: 0.27336376905441284, Accuracy: 0.912109375\n",
      "Batch: 58, Loss: 0.290098637342453, Accuracy: 0.900390625\n",
      "Batch: 59, Loss: 0.2574450969696045, Accuracy: 0.9130859375\n",
      "Batch: 60, Loss: 0.2599029541015625, Accuracy: 0.9130859375\n",
      "Batch: 61, Loss: 0.22698138654232025, Accuracy: 0.9248046875\n",
      "Batch: 62, Loss: 0.1999824047088623, Accuracy: 0.9326171875\n",
      "Batch: 63, Loss: 0.18862773478031158, Accuracy: 0.939453125\n",
      "Batch: 64, Loss: 0.2398878037929535, Accuracy: 0.9169921875\n",
      "Batch: 65, Loss: 0.23006953299045563, Accuracy: 0.9208984375\n",
      "Batch: 66, Loss: 0.23975993692874908, Accuracy: 0.916015625\n",
      "Batch: 67, Loss: 0.21850596368312836, Accuracy: 0.9228515625\n",
      "Batch: 68, Loss: 0.22877313196659088, Accuracy: 0.93359375\n",
      "Batch: 69, Loss: 0.19665338099002838, Accuracy: 0.9326171875\n",
      "Batch: 70, Loss: 0.1992751955986023, Accuracy: 0.9296875\n",
      "Batch: 71, Loss: 0.2092132866382599, Accuracy: 0.9306640625\n",
      "Batch: 72, Loss: 0.23760227859020233, Accuracy: 0.9248046875\n",
      "Batch: 73, Loss: 0.23129236698150635, Accuracy: 0.9208984375\n",
      "Batch: 74, Loss: 0.21636907756328583, Accuracy: 0.921875\n",
      "Batch: 75, Loss: 0.22034284472465515, Accuracy: 0.9228515625\n",
      "Batch: 76, Loss: 0.18451277911663055, Accuracy: 0.94921875\n",
      "Batch: 77, Loss: 0.22475315630435944, Accuracy: 0.9267578125\n",
      "Batch: 78, Loss: 0.23707282543182373, Accuracy: 0.9189453125\n",
      "Batch: 79, Loss: 0.21086978912353516, Accuracy: 0.939453125\n",
      "Batch: 80, Loss: 0.19584791362285614, Accuracy: 0.935546875\n",
      "Batch: 81, Loss: 0.2295686900615692, Accuracy: 0.923828125\n",
      "Batch: 82, Loss: 0.22396567463874817, Accuracy: 0.923828125\n",
      "Batch: 83, Loss: 0.208722785115242, Accuracy: 0.93359375\n",
      "Batch: 84, Loss: 0.18125352263450623, Accuracy: 0.943359375\n",
      "Batch: 85, Loss: 0.2658238708972931, Accuracy: 0.9150390625\n",
      "Batch: 86, Loss: 0.22191482782363892, Accuracy: 0.91796875\n",
      "Batch: 87, Loss: 0.21000446379184723, Accuracy: 0.9287109375\n",
      "Batch: 88, Loss: 0.2481352835893631, Accuracy: 0.9150390625\n",
      "Batch: 89, Loss: 0.21356165409088135, Accuracy: 0.927734375\n",
      "Batch: 90, Loss: 0.2650792896747589, Accuracy: 0.9140625\n",
      "Batch: 91, Loss: 0.253113716840744, Accuracy: 0.9072265625\n",
      "Batch: 92, Loss: 0.24180379509925842, Accuracy: 0.9208984375\n",
      "Batch: 93, Loss: 0.24325856566429138, Accuracy: 0.9150390625\n",
      "Batch: 94, Loss: 0.26025390625, Accuracy: 0.9130859375\n",
      "Batch: 95, Loss: 0.217568039894104, Accuracy: 0.919921875\n",
      "Batch: 96, Loss: 0.22938871383666992, Accuracy: 0.927734375\n",
      "Batch: 97, Loss: 0.21097734570503235, Accuracy: 0.923828125\n",
      "Batch: 98, Loss: 0.22199195623397827, Accuracy: 0.921875\n",
      "Batch: 99, Loss: 0.2083856463432312, Accuracy: 0.9306640625\n",
      "Batch: 100, Loss: 0.21088963747024536, Accuracy: 0.921875\n",
      "Batch: 101, Loss: 0.21965189278125763, Accuracy: 0.9228515625\n",
      "Batch: 102, Loss: 0.2248825877904892, Accuracy: 0.9228515625\n",
      "Batch: 103, Loss: 0.226762056350708, Accuracy: 0.9306640625\n",
      "Batch: 104, Loss: 0.24316325783729553, Accuracy: 0.923828125\n",
      "Batch: 105, Loss: 0.17696934938430786, Accuracy: 0.939453125\n",
      "Batch: 106, Loss: 0.2337457537651062, Accuracy: 0.9189453125\n",
      "Batch: 107, Loss: 0.21875163912773132, Accuracy: 0.919921875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 108, Loss: 0.1922016590833664, Accuracy: 0.9345703125\n",
      "Batch: 109, Loss: 0.19521461427211761, Accuracy: 0.93359375\n",
      "Batch: 110, Loss: 0.19514200091362, Accuracy: 0.923828125\n",
      "Batch: 111, Loss: 0.22582454979419708, Accuracy: 0.921875\n",
      "Batch: 112, Loss: 0.24605880677700043, Accuracy: 0.9267578125\n",
      "Epoch 80/90\n",
      "Batch: 1, Loss: 0.2568178176879883, Accuracy: 0.919921875\n",
      "Batch: 2, Loss: 0.23814477026462555, Accuracy: 0.923828125\n",
      "Batch: 3, Loss: 0.210476815700531, Accuracy: 0.9384765625\n",
      "Batch: 4, Loss: 0.19036290049552917, Accuracy: 0.935546875\n",
      "Batch: 5, Loss: 0.16905826330184937, Accuracy: 0.9404296875\n",
      "Batch: 6, Loss: 0.21233659982681274, Accuracy: 0.9404296875\n",
      "Batch: 7, Loss: 0.19186705350875854, Accuracy: 0.9326171875\n",
      "Batch: 8, Loss: 0.17782330513000488, Accuracy: 0.94140625\n",
      "Batch: 9, Loss: 0.2233925312757492, Accuracy: 0.9208984375\n",
      "Batch: 10, Loss: 0.2428576648235321, Accuracy: 0.912109375\n",
      "Batch: 11, Loss: 0.2489689290523529, Accuracy: 0.9111328125\n",
      "Batch: 12, Loss: 0.1966269612312317, Accuracy: 0.9306640625\n",
      "Batch: 13, Loss: 0.18784019351005554, Accuracy: 0.931640625\n",
      "Batch: 14, Loss: 0.21703475713729858, Accuracy: 0.923828125\n",
      "Batch: 15, Loss: 0.20137271285057068, Accuracy: 0.9326171875\n",
      "Batch: 16, Loss: 0.23359136283397675, Accuracy: 0.9267578125\n",
      "Batch: 17, Loss: 0.20665165781974792, Accuracy: 0.9287109375\n",
      "Batch: 18, Loss: 0.22177158296108246, Accuracy: 0.91796875\n",
      "Batch: 19, Loss: 0.20070070028305054, Accuracy: 0.93359375\n",
      "Batch: 20, Loss: 0.2253696173429489, Accuracy: 0.9150390625\n",
      "Batch: 21, Loss: 0.22832532227039337, Accuracy: 0.9287109375\n",
      "Batch: 22, Loss: 0.21301859617233276, Accuracy: 0.93359375\n",
      "Batch: 23, Loss: 0.24086669087409973, Accuracy: 0.9208984375\n",
      "Batch: 24, Loss: 0.3060522675514221, Accuracy: 0.90234375\n",
      "Batch: 25, Loss: 0.2545337677001953, Accuracy: 0.9150390625\n",
      "Batch: 26, Loss: 0.22709766030311584, Accuracy: 0.9228515625\n",
      "Batch: 27, Loss: 0.2878521680831909, Accuracy: 0.90625\n",
      "Batch: 28, Loss: 0.21500131487846375, Accuracy: 0.9326171875\n",
      "Batch: 29, Loss: 0.22322975099086761, Accuracy: 0.92578125\n",
      "Batch: 30, Loss: 0.20678484439849854, Accuracy: 0.9267578125\n",
      "Batch: 31, Loss: 0.2733013927936554, Accuracy: 0.916015625\n",
      "Batch: 32, Loss: 0.2251262664794922, Accuracy: 0.9111328125\n",
      "Batch: 33, Loss: 0.21452957391738892, Accuracy: 0.9365234375\n",
      "Batch: 34, Loss: 0.22625376284122467, Accuracy: 0.9169921875\n",
      "Batch: 35, Loss: 0.2138374149799347, Accuracy: 0.9228515625\n",
      "Batch: 36, Loss: 0.266728937625885, Accuracy: 0.904296875\n",
      "Batch: 37, Loss: 0.19912436604499817, Accuracy: 0.9326171875\n",
      "Batch: 38, Loss: 0.2518478035926819, Accuracy: 0.9130859375\n",
      "Batch: 39, Loss: 0.21033290028572083, Accuracy: 0.9267578125\n",
      "Batch: 40, Loss: 0.21560177206993103, Accuracy: 0.92578125\n",
      "Batch: 41, Loss: 0.25508275628089905, Accuracy: 0.91015625\n",
      "Batch: 42, Loss: 0.2458067536354065, Accuracy: 0.921875\n",
      "Batch: 43, Loss: 0.2391393482685089, Accuracy: 0.91796875\n",
      "Batch: 44, Loss: 0.225885808467865, Accuracy: 0.921875\n",
      "Batch: 45, Loss: 0.20282573997974396, Accuracy: 0.93359375\n",
      "Batch: 46, Loss: 0.21097266674041748, Accuracy: 0.9306640625\n",
      "Batch: 47, Loss: 0.22315336763858795, Accuracy: 0.9208984375\n",
      "Batch: 48, Loss: 0.20419928431510925, Accuracy: 0.927734375\n",
      "Batch: 49, Loss: 0.2629995048046112, Accuracy: 0.923828125\n",
      "Batch: 50, Loss: 0.20211976766586304, Accuracy: 0.9345703125\n",
      "Batch: 51, Loss: 0.2122270166873932, Accuracy: 0.91796875\n",
      "Batch: 52, Loss: 0.20528173446655273, Accuracy: 0.9384765625\n",
      "Batch: 53, Loss: 0.28222131729125977, Accuracy: 0.8994140625\n",
      "Batch: 54, Loss: 0.25215792655944824, Accuracy: 0.91015625\n",
      "Batch: 55, Loss: 0.24104392528533936, Accuracy: 0.91015625\n",
      "Batch: 56, Loss: 0.1890564262866974, Accuracy: 0.9423828125\n",
      "Batch: 57, Loss: 0.2549305558204651, Accuracy: 0.9072265625\n",
      "Batch: 58, Loss: 0.2530854046344757, Accuracy: 0.9248046875\n",
      "Batch: 59, Loss: 0.26160144805908203, Accuracy: 0.91015625\n",
      "Batch: 60, Loss: 0.21087700128555298, Accuracy: 0.9267578125\n",
      "Batch: 61, Loss: 0.20462451875209808, Accuracy: 0.9306640625\n",
      "Batch: 62, Loss: 0.2065034806728363, Accuracy: 0.927734375\n",
      "Batch: 63, Loss: 0.2285955846309662, Accuracy: 0.9150390625\n",
      "Batch: 64, Loss: 0.22208070755004883, Accuracy: 0.9287109375\n",
      "Batch: 65, Loss: 0.21923255920410156, Accuracy: 0.9326171875\n",
      "Batch: 66, Loss: 0.2034502923488617, Accuracy: 0.931640625\n",
      "Batch: 67, Loss: 0.2009972631931305, Accuracy: 0.9267578125\n",
      "Batch: 68, Loss: 0.2083895206451416, Accuracy: 0.931640625\n",
      "Batch: 69, Loss: 0.19429051876068115, Accuracy: 0.9326171875\n",
      "Batch: 70, Loss: 0.20854902267456055, Accuracy: 0.93359375\n",
      "Batch: 71, Loss: 0.2152291089296341, Accuracy: 0.9189453125\n",
      "Batch: 72, Loss: 0.20600104331970215, Accuracy: 0.9296875\n",
      "Batch: 73, Loss: 0.22384290397167206, Accuracy: 0.923828125\n",
      "Batch: 74, Loss: 0.2597668468952179, Accuracy: 0.9189453125\n",
      "Batch: 75, Loss: 0.1663837730884552, Accuracy: 0.943359375\n",
      "Batch: 76, Loss: 0.20604629814624786, Accuracy: 0.9306640625\n",
      "Batch: 77, Loss: 0.22252926230430603, Accuracy: 0.9208984375\n",
      "Batch: 78, Loss: 0.22554370760917664, Accuracy: 0.9296875\n",
      "Batch: 79, Loss: 0.24983331561088562, Accuracy: 0.90625\n",
      "Batch: 80, Loss: 0.21366232633590698, Accuracy: 0.9228515625\n",
      "Batch: 81, Loss: 0.2489573061466217, Accuracy: 0.9130859375\n",
      "Batch: 82, Loss: 0.21418337523937225, Accuracy: 0.9169921875\n",
      "Batch: 83, Loss: 0.19436469674110413, Accuracy: 0.9326171875\n",
      "Batch: 84, Loss: 0.20303022861480713, Accuracy: 0.9345703125\n",
      "Batch: 85, Loss: 0.21535208821296692, Accuracy: 0.927734375\n",
      "Batch: 86, Loss: 0.23387594521045685, Accuracy: 0.9189453125\n",
      "Batch: 87, Loss: 0.21506904065608978, Accuracy: 0.92578125\n",
      "Batch: 88, Loss: 0.2187342345714569, Accuracy: 0.921875\n",
      "Batch: 89, Loss: 0.22951781749725342, Accuracy: 0.923828125\n",
      "Batch: 90, Loss: 0.2591436505317688, Accuracy: 0.91796875\n",
      "Batch: 91, Loss: 0.26012787222862244, Accuracy: 0.91015625\n",
      "Batch: 92, Loss: 0.25446343421936035, Accuracy: 0.912109375\n",
      "Batch: 93, Loss: 0.23615673184394836, Accuracy: 0.91015625\n",
      "Batch: 94, Loss: 0.24924805760383606, Accuracy: 0.9111328125\n",
      "Batch: 95, Loss: 0.22786259651184082, Accuracy: 0.9111328125\n",
      "Batch: 96, Loss: 0.21561366319656372, Accuracy: 0.931640625\n",
      "Batch: 97, Loss: 0.20381906628608704, Accuracy: 0.9306640625\n",
      "Batch: 98, Loss: 0.22351187467575073, Accuracy: 0.919921875\n",
      "Batch: 99, Loss: 0.19684681296348572, Accuracy: 0.931640625\n",
      "Batch: 100, Loss: 0.20953369140625, Accuracy: 0.9248046875\n",
      "Batch: 101, Loss: 0.21052099764347076, Accuracy: 0.9267578125\n",
      "Batch: 102, Loss: 0.2055589109659195, Accuracy: 0.9267578125\n",
      "Batch: 103, Loss: 0.23079469799995422, Accuracy: 0.9267578125\n",
      "Batch: 104, Loss: 0.2629537880420685, Accuracy: 0.9111328125\n",
      "Batch: 105, Loss: 0.18199995160102844, Accuracy: 0.9345703125\n",
      "Batch: 106, Loss: 0.2300734966993332, Accuracy: 0.9189453125\n",
      "Batch: 107, Loss: 0.21405839920043945, Accuracy: 0.921875\n",
      "Batch: 108, Loss: 0.19361865520477295, Accuracy: 0.9326171875\n",
      "Batch: 109, Loss: 0.1649927794933319, Accuracy: 0.94140625\n",
      "Batch: 110, Loss: 0.18987730145454407, Accuracy: 0.9345703125\n",
      "Batch: 111, Loss: 0.24938011169433594, Accuracy: 0.9169921875\n",
      "Batch: 112, Loss: 0.20662644505500793, Accuracy: 0.919921875\n",
      "Saved Weights at epoch 80 to file Weights_80.h5\n",
      "Epoch 81/90\n",
      "Batch: 1, Loss: 0.23956435918807983, Accuracy: 0.9267578125\n",
      "Batch: 2, Loss: 0.22702224552631378, Accuracy: 0.9228515625\n",
      "Batch: 3, Loss: 0.2363026887178421, Accuracy: 0.9228515625\n",
      "Batch: 4, Loss: 0.20166276395320892, Accuracy: 0.9267578125\n",
      "Batch: 5, Loss: 0.18972502648830414, Accuracy: 0.9365234375\n",
      "Batch: 6, Loss: 0.2267385721206665, Accuracy: 0.9208984375\n",
      "Batch: 7, Loss: 0.19888097047805786, Accuracy: 0.9345703125\n",
      "Batch: 8, Loss: 0.20937976241111755, Accuracy: 0.927734375\n",
      "Batch: 9, Loss: 0.2173508107662201, Accuracy: 0.9248046875\n",
      "Batch: 10, Loss: 0.22239921987056732, Accuracy: 0.9208984375\n",
      "Batch: 11, Loss: 0.24756313860416412, Accuracy: 0.912109375\n",
      "Batch: 12, Loss: 0.21424491703510284, Accuracy: 0.9287109375\n",
      "Batch: 13, Loss: 0.18086960911750793, Accuracy: 0.935546875\n",
      "Batch: 14, Loss: 0.2113201916217804, Accuracy: 0.9287109375\n",
      "Batch: 15, Loss: 0.22430409491062164, Accuracy: 0.9248046875\n",
      "Batch: 16, Loss: 0.2513376474380493, Accuracy: 0.9248046875\n",
      "Batch: 17, Loss: 0.20720016956329346, Accuracy: 0.93359375\n",
      "Batch: 18, Loss: 0.1993831992149353, Accuracy: 0.9267578125\n",
      "Batch: 19, Loss: 0.21805046498775482, Accuracy: 0.9267578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 20, Loss: 0.21197547018527985, Accuracy: 0.9267578125\n",
      "Batch: 21, Loss: 0.256368488073349, Accuracy: 0.912109375\n",
      "Batch: 22, Loss: 0.2355690896511078, Accuracy: 0.919921875\n",
      "Batch: 23, Loss: 0.22872421145439148, Accuracy: 0.9228515625\n",
      "Batch: 24, Loss: 0.25451424717903137, Accuracy: 0.9091796875\n",
      "Batch: 25, Loss: 0.23358310759067535, Accuracy: 0.921875\n",
      "Batch: 26, Loss: 0.24089890718460083, Accuracy: 0.9140625\n",
      "Batch: 27, Loss: 0.24666255712509155, Accuracy: 0.921875\n",
      "Batch: 28, Loss: 0.2455788254737854, Accuracy: 0.9189453125\n",
      "Batch: 29, Loss: 0.23499399423599243, Accuracy: 0.921875\n",
      "Batch: 30, Loss: 0.18424402177333832, Accuracy: 0.9443359375\n",
      "Batch: 31, Loss: 0.2622416019439697, Accuracy: 0.9130859375\n",
      "Batch: 32, Loss: 0.1824873685836792, Accuracy: 0.9365234375\n",
      "Batch: 33, Loss: 0.21512770652770996, Accuracy: 0.931640625\n",
      "Batch: 34, Loss: 0.18522042036056519, Accuracy: 0.9423828125\n",
      "Batch: 35, Loss: 0.20396354794502258, Accuracy: 0.9326171875\n",
      "Batch: 36, Loss: 0.2559473514556885, Accuracy: 0.9140625\n",
      "Batch: 37, Loss: 0.24514219164848328, Accuracy: 0.9150390625\n",
      "Batch: 38, Loss: 0.2595744729042053, Accuracy: 0.912109375\n",
      "Batch: 39, Loss: 0.21425606310367584, Accuracy: 0.9208984375\n",
      "Batch: 40, Loss: 0.19171744585037231, Accuracy: 0.9384765625\n",
      "Batch: 41, Loss: 0.21540449559688568, Accuracy: 0.9296875\n",
      "Batch: 42, Loss: 0.21366721391677856, Accuracy: 0.9287109375\n",
      "Batch: 43, Loss: 0.2139960527420044, Accuracy: 0.9208984375\n",
      "Batch: 44, Loss: 0.2189876139163971, Accuracy: 0.921875\n",
      "Batch: 45, Loss: 0.2068730741739273, Accuracy: 0.9296875\n",
      "Batch: 46, Loss: 0.22283969819545746, Accuracy: 0.9228515625\n",
      "Batch: 47, Loss: 0.20684999227523804, Accuracy: 0.9228515625\n",
      "Batch: 48, Loss: 0.22368799149990082, Accuracy: 0.923828125\n",
      "Batch: 49, Loss: 0.22991491854190826, Accuracy: 0.91796875\n",
      "Batch: 50, Loss: 0.21304917335510254, Accuracy: 0.92578125\n",
      "Batch: 51, Loss: 0.20815366506576538, Accuracy: 0.931640625\n",
      "Batch: 52, Loss: 0.2218511998653412, Accuracy: 0.9189453125\n",
      "Batch: 53, Loss: 0.2362823188304901, Accuracy: 0.9228515625\n",
      "Batch: 54, Loss: 0.206324964761734, Accuracy: 0.93359375\n",
      "Batch: 55, Loss: 0.2190876603126526, Accuracy: 0.923828125\n",
      "Batch: 56, Loss: 0.2029561847448349, Accuracy: 0.927734375\n",
      "Batch: 57, Loss: 0.2644108831882477, Accuracy: 0.9130859375\n",
      "Batch: 58, Loss: 0.26435303688049316, Accuracy: 0.9091796875\n",
      "Batch: 59, Loss: 0.25035130977630615, Accuracy: 0.9189453125\n",
      "Batch: 60, Loss: 0.22859510779380798, Accuracy: 0.92578125\n",
      "Batch: 61, Loss: 0.22485321760177612, Accuracy: 0.9248046875\n",
      "Batch: 62, Loss: 0.21075287461280823, Accuracy: 0.9326171875\n",
      "Batch: 63, Loss: 0.17869333922863007, Accuracy: 0.92578125\n",
      "Batch: 64, Loss: 0.24812911450862885, Accuracy: 0.9140625\n",
      "Batch: 65, Loss: 0.20527872443199158, Accuracy: 0.9248046875\n",
      "Batch: 66, Loss: 0.20499476790428162, Accuracy: 0.931640625\n",
      "Batch: 67, Loss: 0.20991981029510498, Accuracy: 0.9267578125\n",
      "Batch: 68, Loss: 0.23509091138839722, Accuracy: 0.9140625\n",
      "Batch: 69, Loss: 0.17995649576187134, Accuracy: 0.9404296875\n",
      "Batch: 70, Loss: 0.20930495858192444, Accuracy: 0.9296875\n",
      "Batch: 71, Loss: 0.22044654190540314, Accuracy: 0.9267578125\n",
      "Batch: 72, Loss: 0.24448004364967346, Accuracy: 0.9208984375\n",
      "Batch: 73, Loss: 0.20842304825782776, Accuracy: 0.9287109375\n",
      "Batch: 74, Loss: 0.25371813774108887, Accuracy: 0.912109375\n",
      "Batch: 75, Loss: 0.18436278402805328, Accuracy: 0.931640625\n",
      "Batch: 76, Loss: 0.2176510989665985, Accuracy: 0.9345703125\n",
      "Batch: 77, Loss: 0.22928035259246826, Accuracy: 0.92578125\n",
      "Batch: 78, Loss: 0.2103365659713745, Accuracy: 0.9326171875\n",
      "Batch: 79, Loss: 0.2342045158147812, Accuracy: 0.9208984375\n",
      "Batch: 80, Loss: 0.2015494853258133, Accuracy: 0.9306640625\n",
      "Batch: 81, Loss: 0.25393277406692505, Accuracy: 0.919921875\n",
      "Batch: 82, Loss: 0.23013167083263397, Accuracy: 0.9267578125\n",
      "Batch: 83, Loss: 0.1930200755596161, Accuracy: 0.9375\n",
      "Batch: 84, Loss: 0.18980035185813904, Accuracy: 0.9365234375\n",
      "Batch: 85, Loss: 0.2214343249797821, Accuracy: 0.931640625\n",
      "Batch: 86, Loss: 0.2505946755409241, Accuracy: 0.9169921875\n",
      "Batch: 87, Loss: 0.2014632225036621, Accuracy: 0.9296875\n",
      "Batch: 88, Loss: 0.24287740886211395, Accuracy: 0.916015625\n",
      "Batch: 89, Loss: 0.23298333585262299, Accuracy: 0.9169921875\n",
      "Batch: 90, Loss: 0.2539423108100891, Accuracy: 0.9111328125\n",
      "Batch: 91, Loss: 0.2621379792690277, Accuracy: 0.9130859375\n",
      "Batch: 92, Loss: 0.23560619354248047, Accuracy: 0.9248046875\n",
      "Batch: 93, Loss: 0.23316900432109833, Accuracy: 0.927734375\n",
      "Batch: 94, Loss: 0.2612763047218323, Accuracy: 0.9111328125\n",
      "Batch: 95, Loss: 0.213328555226326, Accuracy: 0.9267578125\n",
      "Batch: 96, Loss: 0.22320744395256042, Accuracy: 0.93359375\n",
      "Batch: 97, Loss: 0.19652871787548065, Accuracy: 0.9326171875\n",
      "Batch: 98, Loss: 0.21529540419578552, Accuracy: 0.92578125\n",
      "Batch: 99, Loss: 0.19638624787330627, Accuracy: 0.9267578125\n",
      "Batch: 100, Loss: 0.2252018004655838, Accuracy: 0.9208984375\n",
      "Batch: 101, Loss: 0.2370249181985855, Accuracy: 0.916015625\n",
      "Batch: 102, Loss: 0.22488069534301758, Accuracy: 0.9287109375\n",
      "Batch: 103, Loss: 0.2083955854177475, Accuracy: 0.9375\n",
      "Batch: 104, Loss: 0.23637640476226807, Accuracy: 0.919921875\n",
      "Batch: 105, Loss: 0.2328675389289856, Accuracy: 0.923828125\n",
      "Batch: 106, Loss: 0.1892019361257553, Accuracy: 0.9345703125\n",
      "Batch: 107, Loss: 0.22168634831905365, Accuracy: 0.9287109375\n",
      "Batch: 108, Loss: 0.1883026659488678, Accuracy: 0.9287109375\n",
      "Batch: 109, Loss: 0.1742931604385376, Accuracy: 0.939453125\n",
      "Batch: 110, Loss: 0.18977311253547668, Accuracy: 0.935546875\n",
      "Batch: 111, Loss: 0.19623813033103943, Accuracy: 0.9404296875\n",
      "Batch: 112, Loss: 0.2622830271720886, Accuracy: 0.916015625\n",
      "Epoch 82/90\n",
      "Batch: 1, Loss: 0.28192663192749023, Accuracy: 0.9091796875\n",
      "Batch: 2, Loss: 0.2263767421245575, Accuracy: 0.9208984375\n",
      "Batch: 3, Loss: 0.20857152342796326, Accuracy: 0.921875\n",
      "Batch: 4, Loss: 0.21305200457572937, Accuracy: 0.9287109375\n",
      "Batch: 5, Loss: 0.1926310956478119, Accuracy: 0.935546875\n",
      "Batch: 6, Loss: 0.22785072028636932, Accuracy: 0.923828125\n",
      "Batch: 7, Loss: 0.1984195113182068, Accuracy: 0.927734375\n",
      "Batch: 8, Loss: 0.23776917159557343, Accuracy: 0.9208984375\n",
      "Batch: 9, Loss: 0.2171408236026764, Accuracy: 0.9287109375\n",
      "Batch: 10, Loss: 0.2454463541507721, Accuracy: 0.90625\n",
      "Batch: 11, Loss: 0.21794091165065765, Accuracy: 0.9228515625\n",
      "Batch: 12, Loss: 0.19659671187400818, Accuracy: 0.9326171875\n",
      "Batch: 13, Loss: 0.20272418856620789, Accuracy: 0.9296875\n",
      "Batch: 14, Loss: 0.22801871597766876, Accuracy: 0.9189453125\n",
      "Batch: 15, Loss: 0.2084086835384369, Accuracy: 0.927734375\n",
      "Batch: 16, Loss: 0.21664917469024658, Accuracy: 0.93359375\n",
      "Batch: 17, Loss: 0.2557310461997986, Accuracy: 0.912109375\n",
      "Batch: 18, Loss: 0.23229600489139557, Accuracy: 0.9169921875\n",
      "Batch: 19, Loss: 0.22304672002792358, Accuracy: 0.9228515625\n",
      "Batch: 20, Loss: 0.23295637965202332, Accuracy: 0.916015625\n",
      "Batch: 21, Loss: 0.2294100970029831, Accuracy: 0.9208984375\n",
      "Batch: 22, Loss: 0.22657373547554016, Accuracy: 0.92578125\n",
      "Batch: 23, Loss: 0.25538668036460876, Accuracy: 0.921875\n",
      "Batch: 24, Loss: 0.2556568384170532, Accuracy: 0.9150390625\n",
      "Batch: 25, Loss: 0.22320114076137543, Accuracy: 0.9296875\n",
      "Batch: 26, Loss: 0.24322202801704407, Accuracy: 0.9169921875\n",
      "Batch: 27, Loss: 0.25230270624160767, Accuracy: 0.916015625\n",
      "Batch: 28, Loss: 0.23896707594394684, Accuracy: 0.9287109375\n",
      "Batch: 29, Loss: 0.25411713123321533, Accuracy: 0.9189453125\n",
      "Batch: 30, Loss: 0.21808180212974548, Accuracy: 0.9228515625\n",
      "Batch: 31, Loss: 0.25227785110473633, Accuracy: 0.9072265625\n",
      "Batch: 32, Loss: 0.2017722874879837, Accuracy: 0.9267578125\n",
      "Batch: 33, Loss: 0.20663224160671234, Accuracy: 0.927734375\n",
      "Batch: 34, Loss: 0.21606220304965973, Accuracy: 0.923828125\n",
      "Batch: 35, Loss: 0.2051585614681244, Accuracy: 0.931640625\n",
      "Batch: 36, Loss: 0.2621508836746216, Accuracy: 0.9130859375\n",
      "Batch: 37, Loss: 0.17764848470687866, Accuracy: 0.94140625\n",
      "Batch: 38, Loss: 0.2151811271905899, Accuracy: 0.9228515625\n",
      "Batch: 39, Loss: 0.23357468843460083, Accuracy: 0.916015625\n",
      "Batch: 40, Loss: 0.21452759206295013, Accuracy: 0.9306640625\n",
      "Batch: 41, Loss: 0.2465025782585144, Accuracy: 0.919921875\n",
      "Batch: 42, Loss: 0.2000734508037567, Accuracy: 0.9326171875\n",
      "Batch: 43, Loss: 0.21048110723495483, Accuracy: 0.921875\n",
      "Batch: 44, Loss: 0.21888259053230286, Accuracy: 0.93359375\n",
      "Batch: 45, Loss: 0.21163234114646912, Accuracy: 0.931640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 46, Loss: 0.22346967458724976, Accuracy: 0.9189453125\n",
      "Batch: 47, Loss: 0.21145159006118774, Accuracy: 0.92578125\n",
      "Batch: 48, Loss: 0.21999147534370422, Accuracy: 0.91796875\n",
      "Batch: 49, Loss: 0.2068929374217987, Accuracy: 0.9169921875\n",
      "Batch: 50, Loss: 0.17539456486701965, Accuracy: 0.939453125\n",
      "Batch: 51, Loss: 0.22055262327194214, Accuracy: 0.923828125\n",
      "Batch: 52, Loss: 0.21596072614192963, Accuracy: 0.9228515625\n",
      "Batch: 53, Loss: 0.27710291743278503, Accuracy: 0.904296875\n",
      "Batch: 54, Loss: 0.25124406814575195, Accuracy: 0.919921875\n",
      "Batch: 55, Loss: 0.24613164365291595, Accuracy: 0.9150390625\n",
      "Batch: 56, Loss: 0.21889737248420715, Accuracy: 0.93359375\n",
      "Batch: 57, Loss: 0.251478910446167, Accuracy: 0.9150390625\n",
      "Batch: 58, Loss: 0.2631998360157013, Accuracy: 0.9169921875\n",
      "Batch: 59, Loss: 0.2500672936439514, Accuracy: 0.90625\n",
      "Batch: 60, Loss: 0.23338919878005981, Accuracy: 0.9189453125\n",
      "Batch: 61, Loss: 0.2464316040277481, Accuracy: 0.9189453125\n",
      "Batch: 62, Loss: 0.23139600455760956, Accuracy: 0.919921875\n",
      "Batch: 63, Loss: 0.19684015214443207, Accuracy: 0.931640625\n",
      "Batch: 64, Loss: 0.2639196813106537, Accuracy: 0.9189453125\n",
      "Batch: 65, Loss: 0.20797738432884216, Accuracy: 0.9189453125\n",
      "Batch: 66, Loss: 0.21331274509429932, Accuracy: 0.9287109375\n",
      "Batch: 67, Loss: 0.23445650935173035, Accuracy: 0.916015625\n",
      "Batch: 68, Loss: 0.22850054502487183, Accuracy: 0.92578125\n",
      "Batch: 69, Loss: 0.2122112214565277, Accuracy: 0.93359375\n",
      "Batch: 70, Loss: 0.20416998863220215, Accuracy: 0.9326171875\n",
      "Batch: 71, Loss: 0.2192133218050003, Accuracy: 0.919921875\n",
      "Batch: 72, Loss: 0.21788181364536285, Accuracy: 0.9306640625\n",
      "Batch: 73, Loss: 0.20243825018405914, Accuracy: 0.9287109375\n",
      "Batch: 74, Loss: 0.25095319747924805, Accuracy: 0.916015625\n",
      "Batch: 75, Loss: 0.18218231201171875, Accuracy: 0.94140625\n",
      "Batch: 76, Loss: 0.18189923465251923, Accuracy: 0.9375\n",
      "Batch: 77, Loss: 0.19687649607658386, Accuracy: 0.9326171875\n",
      "Batch: 78, Loss: 0.239929661154747, Accuracy: 0.9072265625\n",
      "Batch: 79, Loss: 0.23279640078544617, Accuracy: 0.9267578125\n",
      "Batch: 80, Loss: 0.2361576110124588, Accuracy: 0.92578125\n",
      "Batch: 81, Loss: 0.2316109836101532, Accuracy: 0.923828125\n",
      "Batch: 82, Loss: 0.22332458198070526, Accuracy: 0.92578125\n",
      "Batch: 83, Loss: 0.19706788659095764, Accuracy: 0.93359375\n",
      "Batch: 84, Loss: 0.18536102771759033, Accuracy: 0.9375\n",
      "Batch: 85, Loss: 0.220549076795578, Accuracy: 0.9306640625\n",
      "Batch: 86, Loss: 0.23935481905937195, Accuracy: 0.91796875\n",
      "Batch: 87, Loss: 0.19937604665756226, Accuracy: 0.9287109375\n",
      "Batch: 88, Loss: 0.22555702924728394, Accuracy: 0.9228515625\n",
      "Batch: 89, Loss: 0.22935935854911804, Accuracy: 0.916015625\n",
      "Batch: 90, Loss: 0.243728905916214, Accuracy: 0.9140625\n",
      "Batch: 91, Loss: 0.2230432778596878, Accuracy: 0.9267578125\n",
      "Batch: 92, Loss: 0.2314833253622055, Accuracy: 0.921875\n",
      "Batch: 93, Loss: 0.23421330749988556, Accuracy: 0.9267578125\n",
      "Batch: 94, Loss: 0.24184319376945496, Accuracy: 0.921875\n",
      "Batch: 95, Loss: 0.22592410445213318, Accuracy: 0.921875\n",
      "Batch: 96, Loss: 0.2173190712928772, Accuracy: 0.9296875\n",
      "Batch: 97, Loss: 0.19082629680633545, Accuracy: 0.9326171875\n",
      "Batch: 98, Loss: 0.211534321308136, Accuracy: 0.9287109375\n",
      "Batch: 99, Loss: 0.1667056679725647, Accuracy: 0.94140625\n",
      "Batch: 100, Loss: 0.19022002816200256, Accuracy: 0.935546875\n",
      "Batch: 101, Loss: 0.2299874722957611, Accuracy: 0.927734375\n",
      "Batch: 102, Loss: 0.2173689305782318, Accuracy: 0.9326171875\n",
      "Batch: 103, Loss: 0.19696730375289917, Accuracy: 0.92578125\n",
      "Batch: 104, Loss: 0.2432662546634674, Accuracy: 0.9140625\n",
      "Batch: 105, Loss: 0.1755008101463318, Accuracy: 0.935546875\n",
      "Batch: 106, Loss: 0.22613349556922913, Accuracy: 0.9228515625\n",
      "Batch: 107, Loss: 0.18726173043251038, Accuracy: 0.9384765625\n",
      "Batch: 108, Loss: 0.19142964482307434, Accuracy: 0.9462890625\n",
      "Batch: 109, Loss: 0.16692489385604858, Accuracy: 0.94140625\n",
      "Batch: 110, Loss: 0.19101449847221375, Accuracy: 0.943359375\n",
      "Batch: 111, Loss: 0.25206229090690613, Accuracy: 0.923828125\n",
      "Batch: 112, Loss: 0.24303525686264038, Accuracy: 0.927734375\n",
      "Epoch 83/90\n",
      "Batch: 1, Loss: 0.26951169967651367, Accuracy: 0.923828125\n",
      "Batch: 2, Loss: 0.22000610828399658, Accuracy: 0.927734375\n",
      "Batch: 3, Loss: 0.20021633803844452, Accuracy: 0.9296875\n",
      "Batch: 4, Loss: 0.20732678472995758, Accuracy: 0.921875\n",
      "Batch: 5, Loss: 0.1757630705833435, Accuracy: 0.9453125\n",
      "Batch: 6, Loss: 0.22620639204978943, Accuracy: 0.9287109375\n",
      "Batch: 7, Loss: 0.19420698285102844, Accuracy: 0.9345703125\n",
      "Batch: 8, Loss: 0.18833327293395996, Accuracy: 0.94140625\n",
      "Batch: 9, Loss: 0.2220008224248886, Accuracy: 0.923828125\n",
      "Batch: 10, Loss: 0.22204771637916565, Accuracy: 0.923828125\n",
      "Batch: 11, Loss: 0.22100991010665894, Accuracy: 0.91796875\n",
      "Batch: 12, Loss: 0.1803511679172516, Accuracy: 0.9345703125\n",
      "Batch: 13, Loss: 0.18032017350196838, Accuracy: 0.94140625\n",
      "Batch: 14, Loss: 0.20451155304908752, Accuracy: 0.9228515625\n",
      "Batch: 15, Loss: 0.18635287880897522, Accuracy: 0.9345703125\n",
      "Batch: 16, Loss: 0.2181333601474762, Accuracy: 0.9248046875\n",
      "Batch: 17, Loss: 0.22089534997940063, Accuracy: 0.923828125\n",
      "Batch: 18, Loss: 0.1951254904270172, Accuracy: 0.9345703125\n",
      "Batch: 19, Loss: 0.1837586760520935, Accuracy: 0.9345703125\n",
      "Batch: 20, Loss: 0.21889615058898926, Accuracy: 0.92578125\n",
      "Batch: 21, Loss: 0.22525013983249664, Accuracy: 0.9208984375\n",
      "Batch: 22, Loss: 0.1782681792974472, Accuracy: 0.9404296875\n",
      "Batch: 23, Loss: 0.23696520924568176, Accuracy: 0.91796875\n",
      "Batch: 24, Loss: 0.23401577770709991, Accuracy: 0.9150390625\n",
      "Batch: 25, Loss: 0.248668372631073, Accuracy: 0.919921875\n",
      "Batch: 26, Loss: 0.25690463185310364, Accuracy: 0.9140625\n",
      "Batch: 27, Loss: 0.2634934186935425, Accuracy: 0.9111328125\n",
      "Batch: 28, Loss: 0.23102682828903198, Accuracy: 0.9169921875\n",
      "Batch: 29, Loss: 0.24366453289985657, Accuracy: 0.921875\n",
      "Batch: 30, Loss: 0.20337581634521484, Accuracy: 0.92578125\n",
      "Batch: 31, Loss: 0.25095465779304504, Accuracy: 0.9130859375\n",
      "Batch: 32, Loss: 0.20318377017974854, Accuracy: 0.931640625\n",
      "Batch: 33, Loss: 0.18283723294734955, Accuracy: 0.9423828125\n",
      "Batch: 34, Loss: 0.20039957761764526, Accuracy: 0.9306640625\n",
      "Batch: 35, Loss: 0.20781368017196655, Accuracy: 0.9287109375\n",
      "Batch: 36, Loss: 0.22845295071601868, Accuracy: 0.9248046875\n",
      "Batch: 37, Loss: 0.18159562349319458, Accuracy: 0.9462890625\n",
      "Batch: 38, Loss: 0.22531628608703613, Accuracy: 0.9228515625\n",
      "Batch: 39, Loss: 0.22256560623645782, Accuracy: 0.9248046875\n",
      "Batch: 40, Loss: 0.2097051590681076, Accuracy: 0.9267578125\n",
      "Batch: 41, Loss: 0.2378944754600525, Accuracy: 0.9189453125\n",
      "Batch: 42, Loss: 0.2204391062259674, Accuracy: 0.923828125\n",
      "Batch: 43, Loss: 0.20519176125526428, Accuracy: 0.9267578125\n",
      "Batch: 44, Loss: 0.19827964901924133, Accuracy: 0.9365234375\n",
      "Batch: 45, Loss: 0.2144327163696289, Accuracy: 0.9345703125\n",
      "Batch: 46, Loss: 0.21776705980300903, Accuracy: 0.92578125\n",
      "Batch: 47, Loss: 0.1870945692062378, Accuracy: 0.931640625\n",
      "Batch: 48, Loss: 0.21020638942718506, Accuracy: 0.9326171875\n",
      "Batch: 49, Loss: 0.2236211597919464, Accuracy: 0.92578125\n",
      "Batch: 50, Loss: 0.1869983971118927, Accuracy: 0.9375\n",
      "Batch: 51, Loss: 0.2123516947031021, Accuracy: 0.9169921875\n",
      "Batch: 52, Loss: 0.21833589673042297, Accuracy: 0.9208984375\n",
      "Batch: 53, Loss: 0.2808200418949127, Accuracy: 0.90234375\n",
      "Batch: 54, Loss: 0.2431984543800354, Accuracy: 0.919921875\n",
      "Batch: 55, Loss: 0.23831181228160858, Accuracy: 0.9228515625\n",
      "Batch: 56, Loss: 0.19638264179229736, Accuracy: 0.9326171875\n",
      "Batch: 57, Loss: 0.24941232800483704, Accuracy: 0.91796875\n",
      "Batch: 58, Loss: 0.23482239246368408, Accuracy: 0.921875\n",
      "Batch: 59, Loss: 0.22299516201019287, Accuracy: 0.923828125\n",
      "Batch: 60, Loss: 0.20713132619857788, Accuracy: 0.9189453125\n",
      "Batch: 61, Loss: 0.20196744799613953, Accuracy: 0.9287109375\n",
      "Batch: 62, Loss: 0.19869917631149292, Accuracy: 0.935546875\n",
      "Batch: 63, Loss: 0.17864812910556793, Accuracy: 0.9375\n",
      "Batch: 64, Loss: 0.232151061296463, Accuracy: 0.9208984375\n",
      "Batch: 65, Loss: 0.20599365234375, Accuracy: 0.921875\n",
      "Batch: 66, Loss: 0.20150227844715118, Accuracy: 0.9287109375\n",
      "Batch: 67, Loss: 0.20590761303901672, Accuracy: 0.9228515625\n",
      "Batch: 68, Loss: 0.2210254669189453, Accuracy: 0.92578125\n",
      "Batch: 69, Loss: 0.1947907656431198, Accuracy: 0.9443359375\n",
      "Batch: 70, Loss: 0.208271324634552, Accuracy: 0.9296875\n",
      "Batch: 71, Loss: 0.1986701488494873, Accuracy: 0.9326171875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 72, Loss: 0.2481871098279953, Accuracy: 0.9140625\n",
      "Batch: 73, Loss: 0.20767900347709656, Accuracy: 0.91796875\n",
      "Batch: 74, Loss: 0.22981105744838715, Accuracy: 0.9189453125\n",
      "Batch: 75, Loss: 0.21108397841453552, Accuracy: 0.92578125\n",
      "Batch: 76, Loss: 0.1906331479549408, Accuracy: 0.9365234375\n",
      "Batch: 77, Loss: 0.2015702724456787, Accuracy: 0.9345703125\n",
      "Batch: 78, Loss: 0.2255839705467224, Accuracy: 0.923828125\n",
      "Batch: 79, Loss: 0.19714060425758362, Accuracy: 0.9423828125\n",
      "Batch: 80, Loss: 0.22735565900802612, Accuracy: 0.931640625\n",
      "Batch: 81, Loss: 0.23682090640068054, Accuracy: 0.9208984375\n",
      "Batch: 82, Loss: 0.25361958146095276, Accuracy: 0.923828125\n",
      "Batch: 83, Loss: 0.18829913437366486, Accuracy: 0.9365234375\n",
      "Batch: 84, Loss: 0.22505158185958862, Accuracy: 0.9267578125\n",
      "Batch: 85, Loss: 0.21083512902259827, Accuracy: 0.9296875\n",
      "Batch: 86, Loss: 0.23986637592315674, Accuracy: 0.9208984375\n",
      "Batch: 87, Loss: 0.18032298982143402, Accuracy: 0.9443359375\n",
      "Batch: 88, Loss: 0.23503421247005463, Accuracy: 0.9169921875\n",
      "Batch: 89, Loss: 0.18704278767108917, Accuracy: 0.9326171875\n",
      "Batch: 90, Loss: 0.24349281191825867, Accuracy: 0.9208984375\n",
      "Batch: 91, Loss: 0.2445770502090454, Accuracy: 0.9169921875\n",
      "Batch: 92, Loss: 0.22574952244758606, Accuracy: 0.921875\n",
      "Batch: 93, Loss: 0.22552800178527832, Accuracy: 0.9208984375\n",
      "Batch: 94, Loss: 0.23083919286727905, Accuracy: 0.9169921875\n",
      "Batch: 95, Loss: 0.22154301404953003, Accuracy: 0.927734375\n",
      "Batch: 96, Loss: 0.20235633850097656, Accuracy: 0.9375\n",
      "Batch: 97, Loss: 0.2266685664653778, Accuracy: 0.927734375\n",
      "Batch: 98, Loss: 0.22881656885147095, Accuracy: 0.91796875\n",
      "Batch: 99, Loss: 0.19698470830917358, Accuracy: 0.927734375\n",
      "Batch: 100, Loss: 0.2058735191822052, Accuracy: 0.9267578125\n",
      "Batch: 101, Loss: 0.20815274119377136, Accuracy: 0.919921875\n",
      "Batch: 102, Loss: 0.21590283513069153, Accuracy: 0.9296875\n",
      "Batch: 103, Loss: 0.2179723083972931, Accuracy: 0.92578125\n",
      "Batch: 104, Loss: 0.22655752301216125, Accuracy: 0.91796875\n",
      "Batch: 105, Loss: 0.16997283697128296, Accuracy: 0.9365234375\n",
      "Batch: 106, Loss: 0.2241721898317337, Accuracy: 0.9296875\n",
      "Batch: 107, Loss: 0.19282883405685425, Accuracy: 0.9384765625\n",
      "Batch: 108, Loss: 0.17983631789684296, Accuracy: 0.947265625\n",
      "Batch: 109, Loss: 0.14057046175003052, Accuracy: 0.9521484375\n",
      "Batch: 110, Loss: 0.18853464722633362, Accuracy: 0.9384765625\n",
      "Batch: 111, Loss: 0.21704509854316711, Accuracy: 0.9306640625\n",
      "Batch: 112, Loss: 0.26592519879341125, Accuracy: 0.908203125\n",
      "Epoch 84/90\n",
      "Batch: 1, Loss: 0.28444331884384155, Accuracy: 0.90625\n",
      "Batch: 2, Loss: 0.22153884172439575, Accuracy: 0.927734375\n",
      "Batch: 3, Loss: 0.23021866381168365, Accuracy: 0.919921875\n",
      "Batch: 4, Loss: 0.18960987031459808, Accuracy: 0.9365234375\n",
      "Batch: 5, Loss: 0.17125248908996582, Accuracy: 0.939453125\n",
      "Batch: 6, Loss: 0.2292037010192871, Accuracy: 0.9345703125\n",
      "Batch: 7, Loss: 0.1836695820093155, Accuracy: 0.931640625\n",
      "Batch: 8, Loss: 0.18221688270568848, Accuracy: 0.9365234375\n",
      "Batch: 9, Loss: 0.1975756734609604, Accuracy: 0.927734375\n",
      "Batch: 10, Loss: 0.23779863119125366, Accuracy: 0.9150390625\n",
      "Batch: 11, Loss: 0.22732825577259064, Accuracy: 0.939453125\n",
      "Batch: 12, Loss: 0.2054043859243393, Accuracy: 0.931640625\n",
      "Batch: 13, Loss: 0.1746608316898346, Accuracy: 0.9443359375\n",
      "Batch: 14, Loss: 0.2103460133075714, Accuracy: 0.9296875\n",
      "Batch: 15, Loss: 0.19502994418144226, Accuracy: 0.931640625\n",
      "Batch: 16, Loss: 0.2047678530216217, Accuracy: 0.9404296875\n",
      "Batch: 17, Loss: 0.2024243026971817, Accuracy: 0.923828125\n",
      "Batch: 18, Loss: 0.19544737040996552, Accuracy: 0.9345703125\n",
      "Batch: 19, Loss: 0.19717101752758026, Accuracy: 0.93359375\n",
      "Batch: 20, Loss: 0.21465447545051575, Accuracy: 0.919921875\n",
      "Batch: 21, Loss: 0.21770134568214417, Accuracy: 0.92578125\n",
      "Batch: 22, Loss: 0.2006978988647461, Accuracy: 0.9296875\n",
      "Batch: 23, Loss: 0.21553489565849304, Accuracy: 0.9228515625\n",
      "Batch: 24, Loss: 0.24463960528373718, Accuracy: 0.912109375\n",
      "Batch: 25, Loss: 0.20924070477485657, Accuracy: 0.9296875\n",
      "Batch: 26, Loss: 0.2272592931985855, Accuracy: 0.9296875\n",
      "Batch: 27, Loss: 0.23555156588554382, Accuracy: 0.935546875\n",
      "Batch: 28, Loss: 0.2524576187133789, Accuracy: 0.921875\n",
      "Batch: 29, Loss: 0.22230154275894165, Accuracy: 0.9345703125\n",
      "Batch: 30, Loss: 0.18067733943462372, Accuracy: 0.9306640625\n",
      "Batch: 31, Loss: 0.20549434423446655, Accuracy: 0.9326171875\n",
      "Batch: 32, Loss: 0.1902136653661728, Accuracy: 0.93359375\n",
      "Batch: 33, Loss: 0.19000981748104095, Accuracy: 0.9404296875\n",
      "Batch: 34, Loss: 0.17077486217021942, Accuracy: 0.9453125\n",
      "Batch: 35, Loss: 0.22347140312194824, Accuracy: 0.9267578125\n",
      "Batch: 36, Loss: 0.2329293042421341, Accuracy: 0.9228515625\n",
      "Batch: 37, Loss: 0.19063004851341248, Accuracy: 0.9306640625\n",
      "Batch: 38, Loss: 0.21922609210014343, Accuracy: 0.919921875\n",
      "Batch: 39, Loss: 0.1901220977306366, Accuracy: 0.9345703125\n",
      "Batch: 40, Loss: 0.1737377941608429, Accuracy: 0.939453125\n",
      "Batch: 41, Loss: 0.22987765073776245, Accuracy: 0.927734375\n",
      "Batch: 42, Loss: 0.21329158544540405, Accuracy: 0.9296875\n",
      "Batch: 43, Loss: 0.19933882355690002, Accuracy: 0.9296875\n",
      "Batch: 44, Loss: 0.21580500900745392, Accuracy: 0.9267578125\n",
      "Batch: 45, Loss: 0.21607539057731628, Accuracy: 0.9267578125\n",
      "Batch: 46, Loss: 0.2225162237882614, Accuracy: 0.927734375\n",
      "Batch: 47, Loss: 0.18071550130844116, Accuracy: 0.943359375\n",
      "Batch: 48, Loss: 0.1997327208518982, Accuracy: 0.9326171875\n",
      "Batch: 49, Loss: 0.2151319980621338, Accuracy: 0.931640625\n",
      "Batch: 50, Loss: 0.16657647490501404, Accuracy: 0.9443359375\n",
      "Batch: 51, Loss: 0.24205617606639862, Accuracy: 0.919921875\n",
      "Batch: 52, Loss: 0.23191164433956146, Accuracy: 0.9208984375\n",
      "Batch: 53, Loss: 0.25651025772094727, Accuracy: 0.9150390625\n",
      "Batch: 54, Loss: 0.2218009978532791, Accuracy: 0.9306640625\n",
      "Batch: 55, Loss: 0.2372296303510666, Accuracy: 0.908203125\n",
      "Batch: 56, Loss: 0.15625444054603577, Accuracy: 0.947265625\n",
      "Batch: 57, Loss: 0.2263340950012207, Accuracy: 0.91796875\n",
      "Batch: 58, Loss: 0.2280396819114685, Accuracy: 0.9189453125\n",
      "Batch: 59, Loss: 0.2448146939277649, Accuracy: 0.916015625\n",
      "Batch: 60, Loss: 0.22238436341285706, Accuracy: 0.9208984375\n",
      "Batch: 61, Loss: 0.20204752683639526, Accuracy: 0.927734375\n",
      "Batch: 62, Loss: 0.19834744930267334, Accuracy: 0.9345703125\n",
      "Batch: 63, Loss: 0.18075719475746155, Accuracy: 0.9365234375\n",
      "Batch: 64, Loss: 0.20364010334014893, Accuracy: 0.9287109375\n",
      "Batch: 65, Loss: 0.20597751438617706, Accuracy: 0.93359375\n",
      "Batch: 66, Loss: 0.18465286493301392, Accuracy: 0.9345703125\n",
      "Batch: 67, Loss: 0.2265813797712326, Accuracy: 0.912109375\n",
      "Batch: 68, Loss: 0.22245940566062927, Accuracy: 0.9267578125\n",
      "Batch: 69, Loss: 0.19842107594013214, Accuracy: 0.9345703125\n",
      "Batch: 70, Loss: 0.1924595981836319, Accuracy: 0.931640625\n",
      "Batch: 71, Loss: 0.2165011465549469, Accuracy: 0.9306640625\n",
      "Batch: 72, Loss: 0.22235338389873505, Accuracy: 0.9326171875\n",
      "Batch: 73, Loss: 0.20638342201709747, Accuracy: 0.93359375\n",
      "Batch: 74, Loss: 0.18992316722869873, Accuracy: 0.943359375\n",
      "Batch: 75, Loss: 0.18841353058815002, Accuracy: 0.9326171875\n",
      "Batch: 76, Loss: 0.13889455795288086, Accuracy: 0.9462890625\n",
      "Batch: 77, Loss: 0.19859139621257782, Accuracy: 0.931640625\n",
      "Batch: 78, Loss: 0.21680065989494324, Accuracy: 0.9345703125\n",
      "Batch: 79, Loss: 0.2274663746356964, Accuracy: 0.9287109375\n",
      "Batch: 80, Loss: 0.22347509860992432, Accuracy: 0.9287109375\n",
      "Batch: 81, Loss: 0.20916025340557098, Accuracy: 0.92578125\n",
      "Batch: 82, Loss: 0.2349587082862854, Accuracy: 0.919921875\n",
      "Batch: 83, Loss: 0.18458789587020874, Accuracy: 0.9365234375\n",
      "Batch: 84, Loss: 0.22930188477039337, Accuracy: 0.919921875\n",
      "Batch: 85, Loss: 0.22255408763885498, Accuracy: 0.927734375\n",
      "Batch: 86, Loss: 0.23646336793899536, Accuracy: 0.916015625\n",
      "Batch: 87, Loss: 0.18597115576267242, Accuracy: 0.94140625\n",
      "Batch: 88, Loss: 0.25092846155166626, Accuracy: 0.9091796875\n",
      "Batch: 89, Loss: 0.18700450658798218, Accuracy: 0.93359375\n",
      "Batch: 90, Loss: 0.24458259344100952, Accuracy: 0.912109375\n",
      "Batch: 91, Loss: 0.2382678985595703, Accuracy: 0.9248046875\n",
      "Batch: 92, Loss: 0.23239193856716156, Accuracy: 0.9208984375\n",
      "Batch: 93, Loss: 0.23931927978992462, Accuracy: 0.916015625\n",
      "Batch: 94, Loss: 0.24409325420856476, Accuracy: 0.916015625\n",
      "Batch: 95, Loss: 0.21883508563041687, Accuracy: 0.927734375\n",
      "Batch: 96, Loss: 0.2237434834241867, Accuracy: 0.92578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 97, Loss: 0.18514084815979004, Accuracy: 0.935546875\n",
      "Batch: 98, Loss: 0.19555768370628357, Accuracy: 0.9296875\n",
      "Batch: 99, Loss: 0.17495644092559814, Accuracy: 0.9404296875\n",
      "Batch: 100, Loss: 0.21045376360416412, Accuracy: 0.9306640625\n",
      "Batch: 101, Loss: 0.21753667294979095, Accuracy: 0.9228515625\n",
      "Batch: 102, Loss: 0.19616353511810303, Accuracy: 0.9423828125\n",
      "Batch: 103, Loss: 0.2185308188199997, Accuracy: 0.9189453125\n",
      "Batch: 104, Loss: 0.2255321890115738, Accuracy: 0.9208984375\n",
      "Batch: 105, Loss: 0.16594524681568146, Accuracy: 0.9384765625\n",
      "Batch: 106, Loss: 0.202675923705101, Accuracy: 0.927734375\n",
      "Batch: 107, Loss: 0.16861703991889954, Accuracy: 0.9423828125\n",
      "Batch: 108, Loss: 0.1811477541923523, Accuracy: 0.9365234375\n",
      "Batch: 109, Loss: 0.17476603388786316, Accuracy: 0.939453125\n",
      "Batch: 110, Loss: 0.19206230342388153, Accuracy: 0.9306640625\n",
      "Batch: 111, Loss: 0.2290378212928772, Accuracy: 0.92578125\n",
      "Batch: 112, Loss: 0.24847190082073212, Accuracy: 0.9208984375\n",
      "Epoch 85/90\n",
      "Batch: 1, Loss: 0.24272313714027405, Accuracy: 0.9248046875\n",
      "Batch: 2, Loss: 0.20838627219200134, Accuracy: 0.9287109375\n",
      "Batch: 3, Loss: 0.20490291714668274, Accuracy: 0.935546875\n",
      "Batch: 4, Loss: 0.19851304590702057, Accuracy: 0.9306640625\n",
      "Batch: 5, Loss: 0.19363617897033691, Accuracy: 0.9326171875\n",
      "Batch: 6, Loss: 0.20755693316459656, Accuracy: 0.923828125\n",
      "Batch: 7, Loss: 0.18778815865516663, Accuracy: 0.9462890625\n",
      "Batch: 8, Loss: 0.1814764142036438, Accuracy: 0.935546875\n",
      "Batch: 9, Loss: 0.21891555190086365, Accuracy: 0.9345703125\n",
      "Batch: 10, Loss: 0.2168390452861786, Accuracy: 0.927734375\n",
      "Batch: 11, Loss: 0.234664648771286, Accuracy: 0.923828125\n",
      "Batch: 12, Loss: 0.17745095491409302, Accuracy: 0.931640625\n",
      "Batch: 13, Loss: 0.1712317317724228, Accuracy: 0.9384765625\n",
      "Batch: 14, Loss: 0.22232219576835632, Accuracy: 0.921875\n",
      "Batch: 15, Loss: 0.2139720469713211, Accuracy: 0.923828125\n",
      "Batch: 16, Loss: 0.20605316758155823, Accuracy: 0.9345703125\n",
      "Batch: 17, Loss: 0.2165890336036682, Accuracy: 0.927734375\n",
      "Batch: 18, Loss: 0.19547292590141296, Accuracy: 0.9404296875\n",
      "Batch: 19, Loss: 0.21764077246189117, Accuracy: 0.927734375\n",
      "Batch: 20, Loss: 0.22509567439556122, Accuracy: 0.923828125\n",
      "Batch: 21, Loss: 0.2202165722846985, Accuracy: 0.9228515625\n",
      "Batch: 22, Loss: 0.21706540882587433, Accuracy: 0.9345703125\n",
      "Batch: 23, Loss: 0.23736542463302612, Accuracy: 0.9150390625\n",
      "Batch: 24, Loss: 0.23815080523490906, Accuracy: 0.9169921875\n",
      "Batch: 25, Loss: 0.2335018366575241, Accuracy: 0.923828125\n",
      "Batch: 26, Loss: 0.2174769937992096, Accuracy: 0.9228515625\n",
      "Batch: 27, Loss: 0.23090919852256775, Accuracy: 0.931640625\n",
      "Batch: 28, Loss: 0.200667142868042, Accuracy: 0.9326171875\n",
      "Batch: 29, Loss: 0.22980502247810364, Accuracy: 0.919921875\n",
      "Batch: 30, Loss: 0.18565568327903748, Accuracy: 0.9404296875\n",
      "Batch: 31, Loss: 0.2300516664981842, Accuracy: 0.92578125\n",
      "Batch: 32, Loss: 0.18050013482570648, Accuracy: 0.9267578125\n",
      "Batch: 33, Loss: 0.18217623233795166, Accuracy: 0.9443359375\n",
      "Batch: 34, Loss: 0.19486141204833984, Accuracy: 0.9345703125\n",
      "Batch: 35, Loss: 0.15742804110050201, Accuracy: 0.9501953125\n",
      "Batch: 36, Loss: 0.20855668187141418, Accuracy: 0.9287109375\n",
      "Batch: 37, Loss: 0.1928035020828247, Accuracy: 0.9306640625\n",
      "Batch: 38, Loss: 0.23772674798965454, Accuracy: 0.921875\n",
      "Batch: 39, Loss: 0.19759085774421692, Accuracy: 0.9365234375\n",
      "Batch: 40, Loss: 0.20212295651435852, Accuracy: 0.927734375\n",
      "Batch: 41, Loss: 0.2384609878063202, Accuracy: 0.921875\n",
      "Batch: 42, Loss: 0.20294521749019623, Accuracy: 0.9326171875\n",
      "Batch: 43, Loss: 0.1990298330783844, Accuracy: 0.92578125\n",
      "Batch: 44, Loss: 0.19535376131534576, Accuracy: 0.93359375\n",
      "Batch: 45, Loss: 0.2206185907125473, Accuracy: 0.9287109375\n",
      "Batch: 46, Loss: 0.22044086456298828, Accuracy: 0.9248046875\n",
      "Batch: 47, Loss: 0.1898057758808136, Accuracy: 0.9375\n",
      "Batch: 48, Loss: 0.2264229953289032, Accuracy: 0.921875\n",
      "Batch: 49, Loss: 0.21141844987869263, Accuracy: 0.9375\n",
      "Batch: 50, Loss: 0.16445481777191162, Accuracy: 0.9443359375\n",
      "Batch: 51, Loss: 0.19916130602359772, Accuracy: 0.939453125\n",
      "Batch: 52, Loss: 0.19833719730377197, Accuracy: 0.9267578125\n",
      "Batch: 53, Loss: 0.24580614268779755, Accuracy: 0.9111328125\n",
      "Batch: 54, Loss: 0.21086034178733826, Accuracy: 0.9208984375\n",
      "Batch: 55, Loss: 0.2439832240343094, Accuracy: 0.9169921875\n",
      "Batch: 56, Loss: 0.1956292688846588, Accuracy: 0.939453125\n",
      "Batch: 57, Loss: 0.22812511026859283, Accuracy: 0.91796875\n",
      "Batch: 58, Loss: 0.24697473645210266, Accuracy: 0.9228515625\n",
      "Batch: 59, Loss: 0.22653982043266296, Accuracy: 0.9150390625\n",
      "Batch: 60, Loss: 0.21575145423412323, Accuracy: 0.91796875\n",
      "Batch: 61, Loss: 0.20054976642131805, Accuracy: 0.931640625\n",
      "Batch: 62, Loss: 0.19887840747833252, Accuracy: 0.9267578125\n",
      "Batch: 63, Loss: 0.18098947405815125, Accuracy: 0.93359375\n",
      "Batch: 64, Loss: 0.21050983667373657, Accuracy: 0.935546875\n",
      "Batch: 65, Loss: 0.20078730583190918, Accuracy: 0.931640625\n",
      "Batch: 66, Loss: 0.19042670726776123, Accuracy: 0.947265625\n",
      "Batch: 67, Loss: 0.21464315056800842, Accuracy: 0.927734375\n",
      "Batch: 68, Loss: 0.21878886222839355, Accuracy: 0.9208984375\n",
      "Batch: 69, Loss: 0.1998252272605896, Accuracy: 0.92578125\n",
      "Batch: 70, Loss: 0.21321696043014526, Accuracy: 0.9267578125\n",
      "Batch: 71, Loss: 0.21550333499908447, Accuracy: 0.931640625\n",
      "Batch: 72, Loss: 0.2384791225194931, Accuracy: 0.923828125\n",
      "Batch: 73, Loss: 0.19543428719043732, Accuracy: 0.9365234375\n",
      "Batch: 74, Loss: 0.20792695879936218, Accuracy: 0.9365234375\n",
      "Batch: 75, Loss: 0.18333829939365387, Accuracy: 0.9384765625\n",
      "Batch: 76, Loss: 0.16177639365196228, Accuracy: 0.947265625\n",
      "Batch: 77, Loss: 0.19965708255767822, Accuracy: 0.9365234375\n",
      "Batch: 78, Loss: 0.22587163746356964, Accuracy: 0.92578125\n",
      "Batch: 79, Loss: 0.22827956080436707, Accuracy: 0.9306640625\n",
      "Batch: 80, Loss: 0.19679784774780273, Accuracy: 0.935546875\n",
      "Batch: 81, Loss: 0.20142051577568054, Accuracy: 0.9345703125\n",
      "Batch: 82, Loss: 0.20178920030593872, Accuracy: 0.935546875\n",
      "Batch: 83, Loss: 0.19809316098690033, Accuracy: 0.93359375\n",
      "Batch: 84, Loss: 0.19067487120628357, Accuracy: 0.931640625\n",
      "Batch: 85, Loss: 0.20174577832221985, Accuracy: 0.935546875\n",
      "Batch: 86, Loss: 0.20823602378368378, Accuracy: 0.9306640625\n",
      "Batch: 87, Loss: 0.19888189435005188, Accuracy: 0.9267578125\n",
      "Batch: 88, Loss: 0.22087348997592926, Accuracy: 0.93359375\n",
      "Batch: 89, Loss: 0.20329268276691437, Accuracy: 0.927734375\n",
      "Batch: 90, Loss: 0.24253493547439575, Accuracy: 0.919921875\n",
      "Batch: 91, Loss: 0.23890559375286102, Accuracy: 0.9140625\n",
      "Batch: 92, Loss: 0.22552457451820374, Accuracy: 0.927734375\n",
      "Batch: 93, Loss: 0.25365105271339417, Accuracy: 0.9150390625\n",
      "Batch: 94, Loss: 0.2253710925579071, Accuracy: 0.9248046875\n",
      "Batch: 95, Loss: 0.21910469233989716, Accuracy: 0.93359375\n",
      "Batch: 96, Loss: 0.2013460248708725, Accuracy: 0.9384765625\n",
      "Batch: 97, Loss: 0.20557290315628052, Accuracy: 0.9384765625\n",
      "Batch: 98, Loss: 0.20961478352546692, Accuracy: 0.9228515625\n",
      "Batch: 99, Loss: 0.1958857923746109, Accuracy: 0.9423828125\n",
      "Batch: 100, Loss: 0.1976124793291092, Accuracy: 0.9296875\n",
      "Batch: 101, Loss: 0.20532865822315216, Accuracy: 0.935546875\n",
      "Batch: 102, Loss: 0.18105284869670868, Accuracy: 0.9443359375\n",
      "Batch: 103, Loss: 0.21309414505958557, Accuracy: 0.9296875\n",
      "Batch: 104, Loss: 0.22490079700946808, Accuracy: 0.919921875\n",
      "Batch: 105, Loss: 0.1598142683506012, Accuracy: 0.951171875\n",
      "Batch: 106, Loss: 0.19361968338489532, Accuracy: 0.94140625\n",
      "Batch: 107, Loss: 0.17907020449638367, Accuracy: 0.9384765625\n",
      "Batch: 108, Loss: 0.17291738092899323, Accuracy: 0.9453125\n",
      "Batch: 109, Loss: 0.16821306943893433, Accuracy: 0.943359375\n",
      "Batch: 110, Loss: 0.17817465960979462, Accuracy: 0.9384765625\n",
      "Batch: 111, Loss: 0.22633346915245056, Accuracy: 0.9267578125\n",
      "Batch: 112, Loss: 0.2100122570991516, Accuracy: 0.9296875\n",
      "Epoch 86/90\n",
      "Batch: 1, Loss: 0.25516289472579956, Accuracy: 0.92578125\n",
      "Batch: 2, Loss: 0.22836533188819885, Accuracy: 0.923828125\n",
      "Batch: 3, Loss: 0.20785948634147644, Accuracy: 0.9375\n",
      "Batch: 4, Loss: 0.22671152651309967, Accuracy: 0.9228515625\n",
      "Batch: 5, Loss: 0.18174584209918976, Accuracy: 0.94140625\n",
      "Batch: 6, Loss: 0.2062264233827591, Accuracy: 0.9287109375\n",
      "Batch: 7, Loss: 0.18899580836296082, Accuracy: 0.931640625\n",
      "Batch: 8, Loss: 0.1881394386291504, Accuracy: 0.9345703125\n",
      "Batch: 9, Loss: 0.19999411702156067, Accuracy: 0.9296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 10, Loss: 0.242435485124588, Accuracy: 0.908203125\n",
      "Batch: 11, Loss: 0.21155117452144623, Accuracy: 0.927734375\n",
      "Batch: 12, Loss: 0.19548249244689941, Accuracy: 0.9287109375\n",
      "Batch: 13, Loss: 0.18344922363758087, Accuracy: 0.9345703125\n",
      "Batch: 14, Loss: 0.20540715754032135, Accuracy: 0.9306640625\n",
      "Batch: 15, Loss: 0.19707223773002625, Accuracy: 0.9306640625\n",
      "Batch: 16, Loss: 0.21805718541145325, Accuracy: 0.93359375\n",
      "Batch: 17, Loss: 0.21207080781459808, Accuracy: 0.9326171875\n",
      "Batch: 18, Loss: 0.19063729047775269, Accuracy: 0.935546875\n",
      "Batch: 19, Loss: 0.19038617610931396, Accuracy: 0.9267578125\n",
      "Batch: 20, Loss: 0.2185623049736023, Accuracy: 0.9228515625\n",
      "Batch: 21, Loss: 0.21124695241451263, Accuracy: 0.92578125\n",
      "Batch: 22, Loss: 0.1878751814365387, Accuracy: 0.9404296875\n",
      "Batch: 23, Loss: 0.20415060222148895, Accuracy: 0.923828125\n",
      "Batch: 24, Loss: 0.25665026903152466, Accuracy: 0.916015625\n",
      "Batch: 25, Loss: 0.2265990972518921, Accuracy: 0.9248046875\n",
      "Batch: 26, Loss: 0.2098989188671112, Accuracy: 0.9345703125\n",
      "Batch: 27, Loss: 0.2378142774105072, Accuracy: 0.912109375\n",
      "Batch: 28, Loss: 0.24366143345832825, Accuracy: 0.9208984375\n",
      "Batch: 29, Loss: 0.21807065606117249, Accuracy: 0.9287109375\n",
      "Batch: 30, Loss: 0.18465840816497803, Accuracy: 0.9306640625\n",
      "Batch: 31, Loss: 0.24320665001869202, Accuracy: 0.92578125\n",
      "Batch: 32, Loss: 0.20380406081676483, Accuracy: 0.9345703125\n",
      "Batch: 33, Loss: 0.1989549845457077, Accuracy: 0.927734375\n",
      "Batch: 34, Loss: 0.17365136742591858, Accuracy: 0.9443359375\n",
      "Batch: 35, Loss: 0.18313193321228027, Accuracy: 0.943359375\n",
      "Batch: 36, Loss: 0.21589338779449463, Accuracy: 0.9296875\n",
      "Batch: 37, Loss: 0.18872475624084473, Accuracy: 0.9326171875\n",
      "Batch: 38, Loss: 0.2080538272857666, Accuracy: 0.9248046875\n",
      "Batch: 39, Loss: 0.21196062862873077, Accuracy: 0.9248046875\n",
      "Batch: 40, Loss: 0.2111544907093048, Accuracy: 0.9267578125\n",
      "Batch: 41, Loss: 0.2326599359512329, Accuracy: 0.9189453125\n",
      "Batch: 42, Loss: 0.19959330558776855, Accuracy: 0.939453125\n",
      "Batch: 43, Loss: 0.16446226835250854, Accuracy: 0.9453125\n",
      "Batch: 44, Loss: 0.20396307110786438, Accuracy: 0.927734375\n",
      "Batch: 45, Loss: 0.2087608277797699, Accuracy: 0.9287109375\n",
      "Batch: 46, Loss: 0.1953308880329132, Accuracy: 0.931640625\n",
      "Batch: 47, Loss: 0.17729680240154266, Accuracy: 0.9404296875\n",
      "Batch: 48, Loss: 0.22638657689094543, Accuracy: 0.9296875\n",
      "Batch: 49, Loss: 0.21180880069732666, Accuracy: 0.9267578125\n",
      "Batch: 50, Loss: 0.16733327507972717, Accuracy: 0.9453125\n",
      "Batch: 51, Loss: 0.20351362228393555, Accuracy: 0.93359375\n",
      "Batch: 52, Loss: 0.20768755674362183, Accuracy: 0.9345703125\n",
      "Batch: 53, Loss: 0.24415011703968048, Accuracy: 0.9150390625\n",
      "Batch: 54, Loss: 0.22172322869300842, Accuracy: 0.9287109375\n",
      "Batch: 55, Loss: 0.22656293213367462, Accuracy: 0.9130859375\n",
      "Batch: 56, Loss: 0.15619292855262756, Accuracy: 0.951171875\n",
      "Batch: 57, Loss: 0.215487539768219, Accuracy: 0.93359375\n",
      "Batch: 58, Loss: 0.22736486792564392, Accuracy: 0.9267578125\n",
      "Batch: 59, Loss: 0.2244323194026947, Accuracy: 0.921875\n",
      "Batch: 60, Loss: 0.21111343801021576, Accuracy: 0.931640625\n",
      "Batch: 61, Loss: 0.19553902745246887, Accuracy: 0.9345703125\n",
      "Batch: 62, Loss: 0.1926058828830719, Accuracy: 0.9345703125\n",
      "Batch: 63, Loss: 0.19372083246707916, Accuracy: 0.939453125\n",
      "Batch: 64, Loss: 0.24495983123779297, Accuracy: 0.923828125\n",
      "Batch: 65, Loss: 0.16335433721542358, Accuracy: 0.951171875\n",
      "Batch: 66, Loss: 0.17625315487384796, Accuracy: 0.9482421875\n",
      "Batch: 67, Loss: 0.19232186675071716, Accuracy: 0.9248046875\n",
      "Batch: 68, Loss: 0.20227473974227905, Accuracy: 0.92578125\n",
      "Batch: 69, Loss: 0.15662550926208496, Accuracy: 0.9462890625\n",
      "Batch: 70, Loss: 0.18949583172798157, Accuracy: 0.9345703125\n",
      "Batch: 71, Loss: 0.2236332893371582, Accuracy: 0.9189453125\n",
      "Batch: 72, Loss: 0.1790919303894043, Accuracy: 0.94140625\n",
      "Batch: 73, Loss: 0.2121756374835968, Accuracy: 0.9267578125\n",
      "Batch: 74, Loss: 0.19619128108024597, Accuracy: 0.935546875\n",
      "Batch: 75, Loss: 0.1949697732925415, Accuracy: 0.9306640625\n",
      "Batch: 76, Loss: 0.16979968547821045, Accuracy: 0.94140625\n",
      "Batch: 77, Loss: 0.20003464818000793, Accuracy: 0.939453125\n",
      "Batch: 78, Loss: 0.1864945888519287, Accuracy: 0.93359375\n",
      "Batch: 79, Loss: 0.18912890553474426, Accuracy: 0.93359375\n",
      "Batch: 80, Loss: 0.23052138090133667, Accuracy: 0.9248046875\n",
      "Batch: 81, Loss: 0.21491789817810059, Accuracy: 0.921875\n",
      "Batch: 82, Loss: 0.22834934294223785, Accuracy: 0.921875\n",
      "Batch: 83, Loss: 0.17203909158706665, Accuracy: 0.9443359375\n",
      "Batch: 84, Loss: 0.18264341354370117, Accuracy: 0.93359375\n",
      "Batch: 85, Loss: 0.22257155179977417, Accuracy: 0.931640625\n",
      "Batch: 86, Loss: 0.21673598885536194, Accuracy: 0.9189453125\n",
      "Batch: 87, Loss: 0.1919381469488144, Accuracy: 0.935546875\n",
      "Batch: 88, Loss: 0.2058100402355194, Accuracy: 0.9306640625\n",
      "Batch: 89, Loss: 0.1870475858449936, Accuracy: 0.9404296875\n",
      "Batch: 90, Loss: 0.2460584044456482, Accuracy: 0.91015625\n",
      "Batch: 91, Loss: 0.2311307191848755, Accuracy: 0.912109375\n",
      "Batch: 92, Loss: 0.24977938830852509, Accuracy: 0.91796875\n",
      "Batch: 93, Loss: 0.22121647000312805, Accuracy: 0.9287109375\n",
      "Batch: 94, Loss: 0.22025632858276367, Accuracy: 0.9248046875\n",
      "Batch: 95, Loss: 0.21515733003616333, Accuracy: 0.9189453125\n",
      "Batch: 96, Loss: 0.19866396486759186, Accuracy: 0.9443359375\n",
      "Batch: 97, Loss: 0.2165069282054901, Accuracy: 0.9306640625\n",
      "Batch: 98, Loss: 0.21380920708179474, Accuracy: 0.91796875\n",
      "Batch: 99, Loss: 0.17843633890151978, Accuracy: 0.9365234375\n",
      "Batch: 100, Loss: 0.19029511511325836, Accuracy: 0.9326171875\n",
      "Batch: 101, Loss: 0.19336441159248352, Accuracy: 0.939453125\n",
      "Batch: 102, Loss: 0.20604567229747772, Accuracy: 0.9384765625\n",
      "Batch: 103, Loss: 0.20880930125713348, Accuracy: 0.92578125\n",
      "Batch: 104, Loss: 0.19352707266807556, Accuracy: 0.9345703125\n",
      "Batch: 105, Loss: 0.18548592925071716, Accuracy: 0.939453125\n",
      "Batch: 106, Loss: 0.20603042840957642, Accuracy: 0.9296875\n",
      "Batch: 107, Loss: 0.16940627992153168, Accuracy: 0.9453125\n",
      "Batch: 108, Loss: 0.18312512338161469, Accuracy: 0.9423828125\n",
      "Batch: 109, Loss: 0.14202234148979187, Accuracy: 0.9560546875\n",
      "Batch: 110, Loss: 0.22067561745643616, Accuracy: 0.9248046875\n",
      "Batch: 111, Loss: 0.219826802611351, Accuracy: 0.9287109375\n",
      "Batch: 112, Loss: 0.22268477082252502, Accuracy: 0.9150390625\n",
      "Epoch 87/90\n",
      "Batch: 1, Loss: 0.2819868326187134, Accuracy: 0.921875\n",
      "Batch: 2, Loss: 0.2161947339773178, Accuracy: 0.927734375\n",
      "Batch: 3, Loss: 0.2085801064968109, Accuracy: 0.9345703125\n",
      "Batch: 4, Loss: 0.21538934111595154, Accuracy: 0.9326171875\n",
      "Batch: 5, Loss: 0.16929152607917786, Accuracy: 0.9404296875\n",
      "Batch: 6, Loss: 0.2173425555229187, Accuracy: 0.9326171875\n",
      "Batch: 7, Loss: 0.21243834495544434, Accuracy: 0.9375\n",
      "Batch: 8, Loss: 0.16877785325050354, Accuracy: 0.935546875\n",
      "Batch: 9, Loss: 0.20597311854362488, Accuracy: 0.9267578125\n",
      "Batch: 10, Loss: 0.22347640991210938, Accuracy: 0.9189453125\n",
      "Batch: 11, Loss: 0.22769096493721008, Accuracy: 0.923828125\n",
      "Batch: 12, Loss: 0.21118788421154022, Accuracy: 0.919921875\n",
      "Batch: 13, Loss: 0.16753259301185608, Accuracy: 0.94140625\n",
      "Batch: 14, Loss: 0.21533948183059692, Accuracy: 0.931640625\n",
      "Batch: 15, Loss: 0.19276878237724304, Accuracy: 0.9326171875\n",
      "Batch: 16, Loss: 0.22425341606140137, Accuracy: 0.9326171875\n",
      "Batch: 17, Loss: 0.19195696711540222, Accuracy: 0.9345703125\n",
      "Batch: 18, Loss: 0.18539685010910034, Accuracy: 0.93359375\n",
      "Batch: 19, Loss: 0.20736360549926758, Accuracy: 0.927734375\n",
      "Batch: 20, Loss: 0.1938597559928894, Accuracy: 0.921875\n",
      "Batch: 21, Loss: 0.23496794700622559, Accuracy: 0.92578125\n",
      "Batch: 22, Loss: 0.1895570158958435, Accuracy: 0.931640625\n",
      "Batch: 23, Loss: 0.25365787744522095, Accuracy: 0.90625\n",
      "Batch: 24, Loss: 0.26056206226348877, Accuracy: 0.916015625\n",
      "Batch: 25, Loss: 0.23980942368507385, Accuracy: 0.91796875\n",
      "Batch: 26, Loss: 0.21952864527702332, Accuracy: 0.9228515625\n",
      "Batch: 27, Loss: 0.2576751112937927, Accuracy: 0.9208984375\n",
      "Batch: 28, Loss: 0.20962019264698029, Accuracy: 0.935546875\n",
      "Batch: 29, Loss: 0.24866525828838348, Accuracy: 0.9140625\n",
      "Batch: 30, Loss: 0.19289685785770416, Accuracy: 0.939453125\n",
      "Batch: 31, Loss: 0.2176392376422882, Accuracy: 0.9248046875\n",
      "Batch: 32, Loss: 0.19705665111541748, Accuracy: 0.9306640625\n",
      "Batch: 33, Loss: 0.2083444893360138, Accuracy: 0.9326171875\n",
      "Batch: 34, Loss: 0.18277154862880707, Accuracy: 0.9384765625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 35, Loss: 0.20861482620239258, Accuracy: 0.93359375\n",
      "Batch: 36, Loss: 0.21484413743019104, Accuracy: 0.9287109375\n",
      "Batch: 37, Loss: 0.20130498707294464, Accuracy: 0.927734375\n",
      "Batch: 38, Loss: 0.18422700464725494, Accuracy: 0.93359375\n",
      "Batch: 39, Loss: 0.182630717754364, Accuracy: 0.9384765625\n",
      "Batch: 40, Loss: 0.22678537666797638, Accuracy: 0.919921875\n",
      "Batch: 41, Loss: 0.21051549911499023, Accuracy: 0.9267578125\n",
      "Batch: 42, Loss: 0.1907273232936859, Accuracy: 0.935546875\n",
      "Batch: 43, Loss: 0.19982926547527313, Accuracy: 0.9267578125\n",
      "Batch: 44, Loss: 0.19764015078544617, Accuracy: 0.9296875\n",
      "Batch: 45, Loss: 0.21628962457180023, Accuracy: 0.9248046875\n",
      "Batch: 46, Loss: 0.21916688978672028, Accuracy: 0.9306640625\n",
      "Batch: 47, Loss: 0.19497571885585785, Accuracy: 0.9326171875\n",
      "Batch: 48, Loss: 0.22689944505691528, Accuracy: 0.9287109375\n",
      "Batch: 49, Loss: 0.2207934558391571, Accuracy: 0.92578125\n",
      "Batch: 50, Loss: 0.169953852891922, Accuracy: 0.9453125\n",
      "Batch: 51, Loss: 0.2086137980222702, Accuracy: 0.9345703125\n",
      "Batch: 52, Loss: 0.19149306416511536, Accuracy: 0.9326171875\n",
      "Batch: 53, Loss: 0.25287145376205444, Accuracy: 0.9306640625\n",
      "Batch: 54, Loss: 0.21439620852470398, Accuracy: 0.93359375\n",
      "Batch: 55, Loss: 0.21456152200698853, Accuracy: 0.9208984375\n",
      "Batch: 56, Loss: 0.20218126475811005, Accuracy: 0.9228515625\n",
      "Batch: 57, Loss: 0.24892260134220123, Accuracy: 0.9228515625\n",
      "Batch: 58, Loss: 0.2520545423030853, Accuracy: 0.91015625\n",
      "Batch: 59, Loss: 0.243544802069664, Accuracy: 0.91796875\n",
      "Batch: 60, Loss: 0.19473594427108765, Accuracy: 0.9365234375\n",
      "Batch: 61, Loss: 0.21375709772109985, Accuracy: 0.9287109375\n",
      "Batch: 62, Loss: 0.2258424460887909, Accuracy: 0.9140625\n",
      "Batch: 63, Loss: 0.1975862979888916, Accuracy: 0.9267578125\n",
      "Batch: 64, Loss: 0.231695294380188, Accuracy: 0.92578125\n",
      "Batch: 65, Loss: 0.18331345915794373, Accuracy: 0.9384765625\n",
      "Batch: 66, Loss: 0.19087184965610504, Accuracy: 0.9375\n",
      "Batch: 67, Loss: 0.21001291275024414, Accuracy: 0.9326171875\n",
      "Batch: 68, Loss: 0.19832155108451843, Accuracy: 0.931640625\n",
      "Batch: 69, Loss: 0.1603710651397705, Accuracy: 0.94140625\n",
      "Batch: 70, Loss: 0.18136486411094666, Accuracy: 0.9384765625\n",
      "Batch: 71, Loss: 0.22340548038482666, Accuracy: 0.923828125\n",
      "Batch: 72, Loss: 0.22957436740398407, Accuracy: 0.9287109375\n",
      "Batch: 73, Loss: 0.2364535927772522, Accuracy: 0.9169921875\n",
      "Batch: 74, Loss: 0.2015361785888672, Accuracy: 0.923828125\n",
      "Batch: 75, Loss: 0.1803658902645111, Accuracy: 0.93359375\n",
      "Batch: 76, Loss: 0.16237828135490417, Accuracy: 0.9404296875\n",
      "Batch: 77, Loss: 0.24408993124961853, Accuracy: 0.923828125\n",
      "Batch: 78, Loss: 0.1992107331752777, Accuracy: 0.9306640625\n",
      "Batch: 79, Loss: 0.18594256043434143, Accuracy: 0.94921875\n",
      "Batch: 80, Loss: 0.17874279618263245, Accuracy: 0.939453125\n",
      "Batch: 81, Loss: 0.20309509336948395, Accuracy: 0.923828125\n",
      "Batch: 82, Loss: 0.20141446590423584, Accuracy: 0.927734375\n",
      "Batch: 83, Loss: 0.19084811210632324, Accuracy: 0.931640625\n",
      "Batch: 84, Loss: 0.20568090677261353, Accuracy: 0.9287109375\n",
      "Batch: 85, Loss: 0.21911707520484924, Accuracy: 0.9287109375\n",
      "Batch: 86, Loss: 0.21181516349315643, Accuracy: 0.9208984375\n",
      "Batch: 87, Loss: 0.19759488105773926, Accuracy: 0.9375\n",
      "Batch: 88, Loss: 0.24083492159843445, Accuracy: 0.9169921875\n",
      "Batch: 89, Loss: 0.23931899666786194, Accuracy: 0.9140625\n",
      "Batch: 90, Loss: 0.2501111626625061, Accuracy: 0.9130859375\n",
      "Batch: 91, Loss: 0.23992955684661865, Accuracy: 0.9189453125\n",
      "Batch: 92, Loss: 0.22297826409339905, Accuracy: 0.9140625\n",
      "Batch: 93, Loss: 0.22083473205566406, Accuracy: 0.923828125\n",
      "Batch: 94, Loss: 0.20686769485473633, Accuracy: 0.92578125\n",
      "Batch: 95, Loss: 0.2302446961402893, Accuracy: 0.9248046875\n",
      "Batch: 96, Loss: 0.19070854783058167, Accuracy: 0.931640625\n",
      "Batch: 97, Loss: 0.1897353231906891, Accuracy: 0.9287109375\n",
      "Batch: 98, Loss: 0.18431833386421204, Accuracy: 0.9375\n",
      "Batch: 99, Loss: 0.20034867525100708, Accuracy: 0.9248046875\n",
      "Batch: 100, Loss: 0.18993788957595825, Accuracy: 0.9375\n",
      "Batch: 101, Loss: 0.19345027208328247, Accuracy: 0.9306640625\n",
      "Batch: 102, Loss: 0.19586914777755737, Accuracy: 0.9365234375\n",
      "Batch: 103, Loss: 0.24341528117656708, Accuracy: 0.9208984375\n",
      "Batch: 104, Loss: 0.242226243019104, Accuracy: 0.9228515625\n",
      "Batch: 105, Loss: 0.17100101709365845, Accuracy: 0.935546875\n",
      "Batch: 106, Loss: 0.22792606055736542, Accuracy: 0.91796875\n",
      "Batch: 107, Loss: 0.18323495984077454, Accuracy: 0.9296875\n",
      "Batch: 108, Loss: 0.1925734579563141, Accuracy: 0.9326171875\n",
      "Batch: 109, Loss: 0.1493881642818451, Accuracy: 0.9462890625\n",
      "Batch: 110, Loss: 0.19334818422794342, Accuracy: 0.9365234375\n",
      "Batch: 111, Loss: 0.2448524832725525, Accuracy: 0.9189453125\n",
      "Batch: 112, Loss: 0.21927519142627716, Accuracy: 0.9248046875\n",
      "Epoch 88/90\n",
      "Batch: 1, Loss: 0.2508651316165924, Accuracy: 0.9140625\n",
      "Batch: 2, Loss: 0.2298351377248764, Accuracy: 0.921875\n",
      "Batch: 3, Loss: 0.21144811809062958, Accuracy: 0.9228515625\n",
      "Batch: 4, Loss: 0.1825300008058548, Accuracy: 0.939453125\n",
      "Batch: 5, Loss: 0.15287159383296967, Accuracy: 0.9482421875\n",
      "Batch: 6, Loss: 0.19247916340827942, Accuracy: 0.939453125\n",
      "Batch: 7, Loss: 0.19264726340770721, Accuracy: 0.9384765625\n",
      "Batch: 8, Loss: 0.18546929955482483, Accuracy: 0.93359375\n",
      "Batch: 9, Loss: 0.18038582801818848, Accuracy: 0.9326171875\n",
      "Batch: 10, Loss: 0.2375383973121643, Accuracy: 0.9228515625\n",
      "Batch: 11, Loss: 0.23102110624313354, Accuracy: 0.9169921875\n",
      "Batch: 12, Loss: 0.22791314125061035, Accuracy: 0.916015625\n",
      "Batch: 13, Loss: 0.1706049144268036, Accuracy: 0.94921875\n",
      "Batch: 14, Loss: 0.19394952058792114, Accuracy: 0.9365234375\n",
      "Batch: 15, Loss: 0.1973092257976532, Accuracy: 0.9326171875\n",
      "Batch: 16, Loss: 0.20048516988754272, Accuracy: 0.93359375\n",
      "Batch: 17, Loss: 0.22003507614135742, Accuracy: 0.9189453125\n",
      "Batch: 18, Loss: 0.20011462271213531, Accuracy: 0.9326171875\n",
      "Batch: 19, Loss: 0.19006240367889404, Accuracy: 0.9326171875\n",
      "Batch: 20, Loss: 0.19951388239860535, Accuracy: 0.927734375\n",
      "Batch: 21, Loss: 0.2095317840576172, Accuracy: 0.9296875\n",
      "Batch: 22, Loss: 0.22589467465877533, Accuracy: 0.9208984375\n",
      "Batch: 23, Loss: 0.2088845819234848, Accuracy: 0.9208984375\n",
      "Batch: 24, Loss: 0.2673896551132202, Accuracy: 0.9130859375\n",
      "Batch: 25, Loss: 0.21960248053073883, Accuracy: 0.9228515625\n",
      "Batch: 26, Loss: 0.21515771746635437, Accuracy: 0.9267578125\n",
      "Batch: 27, Loss: 0.23446713387966156, Accuracy: 0.91796875\n",
      "Batch: 28, Loss: 0.2123255729675293, Accuracy: 0.92578125\n",
      "Batch: 29, Loss: 0.21438413858413696, Accuracy: 0.9228515625\n",
      "Batch: 30, Loss: 0.19750916957855225, Accuracy: 0.9228515625\n",
      "Batch: 31, Loss: 0.22403398156166077, Accuracy: 0.927734375\n",
      "Batch: 32, Loss: 0.19849810004234314, Accuracy: 0.9208984375\n",
      "Batch: 33, Loss: 0.18359611928462982, Accuracy: 0.935546875\n",
      "Batch: 34, Loss: 0.189023956656456, Accuracy: 0.9423828125\n",
      "Batch: 35, Loss: 0.19653886556625366, Accuracy: 0.931640625\n",
      "Batch: 36, Loss: 0.23272807896137238, Accuracy: 0.9228515625\n",
      "Batch: 37, Loss: 0.1809036135673523, Accuracy: 0.93359375\n",
      "Batch: 38, Loss: 0.20528565347194672, Accuracy: 0.9267578125\n",
      "Batch: 39, Loss: 0.1776454895734787, Accuracy: 0.9345703125\n",
      "Batch: 40, Loss: 0.22139567136764526, Accuracy: 0.9306640625\n",
      "Batch: 41, Loss: 0.21422085165977478, Accuracy: 0.9228515625\n",
      "Batch: 42, Loss: 0.22594521939754486, Accuracy: 0.9208984375\n",
      "Batch: 43, Loss: 0.1612282395362854, Accuracy: 0.9462890625\n",
      "Batch: 44, Loss: 0.18675604462623596, Accuracy: 0.935546875\n",
      "Batch: 45, Loss: 0.21239790320396423, Accuracy: 0.9326171875\n",
      "Batch: 46, Loss: 0.20100393891334534, Accuracy: 0.92578125\n",
      "Batch: 47, Loss: 0.1720978170633316, Accuracy: 0.9375\n",
      "Batch: 48, Loss: 0.22326162457466125, Accuracy: 0.9228515625\n",
      "Batch: 49, Loss: 0.19378817081451416, Accuracy: 0.943359375\n",
      "Batch: 50, Loss: 0.1940692812204361, Accuracy: 0.9423828125\n",
      "Batch: 51, Loss: 0.18576672673225403, Accuracy: 0.9453125\n",
      "Batch: 52, Loss: 0.20676884055137634, Accuracy: 0.9326171875\n",
      "Batch: 53, Loss: 0.24667976796627045, Accuracy: 0.9150390625\n",
      "Batch: 54, Loss: 0.2600395381450653, Accuracy: 0.9111328125\n",
      "Batch: 55, Loss: 0.21867619454860687, Accuracy: 0.923828125\n",
      "Batch: 56, Loss: 0.17881768941879272, Accuracy: 0.9375\n",
      "Batch: 57, Loss: 0.2278479039669037, Accuracy: 0.9189453125\n",
      "Batch: 58, Loss: 0.21026477217674255, Accuracy: 0.9306640625\n",
      "Batch: 59, Loss: 0.21661579608917236, Accuracy: 0.9267578125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 60, Loss: 0.17704902589321136, Accuracy: 0.9423828125\n",
      "Batch: 61, Loss: 0.22054672241210938, Accuracy: 0.931640625\n",
      "Batch: 62, Loss: 0.20428934693336487, Accuracy: 0.9326171875\n",
      "Batch: 63, Loss: 0.1932634711265564, Accuracy: 0.935546875\n",
      "Batch: 64, Loss: 0.2385597825050354, Accuracy: 0.912109375\n",
      "Batch: 65, Loss: 0.19380253553390503, Accuracy: 0.9365234375\n",
      "Batch: 66, Loss: 0.18457120656967163, Accuracy: 0.9404296875\n",
      "Batch: 67, Loss: 0.18652929365634918, Accuracy: 0.94140625\n",
      "Batch: 68, Loss: 0.21081598103046417, Accuracy: 0.9296875\n",
      "Batch: 69, Loss: 0.1714889407157898, Accuracy: 0.9404296875\n",
      "Batch: 70, Loss: 0.1872512400150299, Accuracy: 0.9345703125\n",
      "Batch: 71, Loss: 0.17850996553897858, Accuracy: 0.9453125\n",
      "Batch: 72, Loss: 0.21589791774749756, Accuracy: 0.9267578125\n",
      "Batch: 73, Loss: 0.17458167672157288, Accuracy: 0.9423828125\n",
      "Batch: 74, Loss: 0.18084321916103363, Accuracy: 0.9365234375\n",
      "Batch: 75, Loss: 0.18169158697128296, Accuracy: 0.9365234375\n",
      "Batch: 76, Loss: 0.175572007894516, Accuracy: 0.9384765625\n",
      "Batch: 77, Loss: 0.2172478288412094, Accuracy: 0.935546875\n",
      "Batch: 78, Loss: 0.20751363039016724, Accuracy: 0.9345703125\n",
      "Batch: 79, Loss: 0.1851768046617508, Accuracy: 0.939453125\n",
      "Batch: 80, Loss: 0.19588378071784973, Accuracy: 0.93359375\n",
      "Batch: 81, Loss: 0.21458345651626587, Accuracy: 0.9306640625\n",
      "Batch: 82, Loss: 0.1928219348192215, Accuracy: 0.923828125\n",
      "Batch: 83, Loss: 0.17865535616874695, Accuracy: 0.93359375\n",
      "Batch: 84, Loss: 0.1917811781167984, Accuracy: 0.9345703125\n",
      "Batch: 85, Loss: 0.18401464819908142, Accuracy: 0.9345703125\n",
      "Batch: 86, Loss: 0.215615913271904, Accuracy: 0.9267578125\n",
      "Batch: 87, Loss: 0.1989865005016327, Accuracy: 0.927734375\n",
      "Batch: 88, Loss: 0.2143312692642212, Accuracy: 0.9248046875\n",
      "Batch: 89, Loss: 0.17718040943145752, Accuracy: 0.9375\n",
      "Batch: 90, Loss: 0.25609296560287476, Accuracy: 0.9111328125\n",
      "Batch: 91, Loss: 0.2432570904493332, Accuracy: 0.9140625\n",
      "Batch: 92, Loss: 0.2118256688117981, Accuracy: 0.927734375\n",
      "Batch: 93, Loss: 0.22695398330688477, Accuracy: 0.9287109375\n",
      "Batch: 94, Loss: 0.22461074590682983, Accuracy: 0.9228515625\n",
      "Batch: 95, Loss: 0.19700998067855835, Accuracy: 0.9375\n",
      "Batch: 96, Loss: 0.24218975007534027, Accuracy: 0.92578125\n",
      "Batch: 97, Loss: 0.19150716066360474, Accuracy: 0.939453125\n",
      "Batch: 98, Loss: 0.18894511461257935, Accuracy: 0.92578125\n",
      "Batch: 99, Loss: 0.19108988344669342, Accuracy: 0.9345703125\n",
      "Batch: 100, Loss: 0.17567522823810577, Accuracy: 0.94140625\n",
      "Batch: 101, Loss: 0.16807956993579865, Accuracy: 0.9462890625\n",
      "Batch: 102, Loss: 0.17265507578849792, Accuracy: 0.939453125\n",
      "Batch: 103, Loss: 0.21719364821910858, Accuracy: 0.92578125\n",
      "Batch: 104, Loss: 0.23063239455223083, Accuracy: 0.919921875\n",
      "Batch: 105, Loss: 0.17212066054344177, Accuracy: 0.9404296875\n",
      "Batch: 106, Loss: 0.20063874125480652, Accuracy: 0.939453125\n",
      "Batch: 107, Loss: 0.17887115478515625, Accuracy: 0.94140625\n",
      "Batch: 108, Loss: 0.180221289396286, Accuracy: 0.9345703125\n",
      "Batch: 109, Loss: 0.17171484231948853, Accuracy: 0.9443359375\n",
      "Batch: 110, Loss: 0.16279390454292297, Accuracy: 0.943359375\n",
      "Batch: 111, Loss: 0.19985496997833252, Accuracy: 0.9345703125\n",
      "Batch: 112, Loss: 0.2282562106847763, Accuracy: 0.921875\n",
      "Epoch 89/90\n",
      "Batch: 1, Loss: 0.23052769899368286, Accuracy: 0.9365234375\n",
      "Batch: 2, Loss: 0.20310762524604797, Accuracy: 0.927734375\n",
      "Batch: 3, Loss: 0.19822914898395538, Accuracy: 0.93359375\n",
      "Batch: 4, Loss: 0.17640963196754456, Accuracy: 0.94140625\n",
      "Batch: 5, Loss: 0.1553700566291809, Accuracy: 0.9482421875\n",
      "Batch: 6, Loss: 0.19983820617198944, Accuracy: 0.9267578125\n",
      "Batch: 7, Loss: 0.18600815534591675, Accuracy: 0.935546875\n",
      "Batch: 8, Loss: 0.16803061962127686, Accuracy: 0.939453125\n",
      "Batch: 9, Loss: 0.20104295015335083, Accuracy: 0.9287109375\n",
      "Batch: 10, Loss: 0.23001544177532196, Accuracy: 0.9189453125\n",
      "Batch: 11, Loss: 0.20184902846813202, Accuracy: 0.9375\n",
      "Batch: 12, Loss: 0.17432746291160583, Accuracy: 0.9384765625\n",
      "Batch: 13, Loss: 0.18390192091464996, Accuracy: 0.9423828125\n",
      "Batch: 14, Loss: 0.21755100786685944, Accuracy: 0.923828125\n",
      "Batch: 15, Loss: 0.21658693253993988, Accuracy: 0.923828125\n",
      "Batch: 16, Loss: 0.17346113920211792, Accuracy: 0.9462890625\n",
      "Batch: 17, Loss: 0.17670786380767822, Accuracy: 0.9501953125\n",
      "Batch: 18, Loss: 0.2032882124185562, Accuracy: 0.9228515625\n",
      "Batch: 19, Loss: 0.19314678013324738, Accuracy: 0.9365234375\n",
      "Batch: 20, Loss: 0.19508953392505646, Accuracy: 0.923828125\n",
      "Batch: 21, Loss: 0.2157110720872879, Accuracy: 0.931640625\n",
      "Batch: 22, Loss: 0.22335276007652283, Accuracy: 0.9267578125\n",
      "Batch: 23, Loss: 0.20182377099990845, Accuracy: 0.93359375\n",
      "Batch: 24, Loss: 0.26047030091285706, Accuracy: 0.904296875\n",
      "Batch: 25, Loss: 0.2119545340538025, Accuracy: 0.9296875\n",
      "Batch: 26, Loss: 0.2181171476840973, Accuracy: 0.923828125\n",
      "Batch: 27, Loss: 0.23657281696796417, Accuracy: 0.9228515625\n",
      "Batch: 28, Loss: 0.20561492443084717, Accuracy: 0.9228515625\n",
      "Batch: 29, Loss: 0.277114599943161, Accuracy: 0.9140625\n",
      "Batch: 30, Loss: 0.1885877549648285, Accuracy: 0.9345703125\n",
      "Batch: 31, Loss: 0.2444671094417572, Accuracy: 0.9189453125\n",
      "Batch: 32, Loss: 0.1979244500398636, Accuracy: 0.9345703125\n",
      "Batch: 33, Loss: 0.22159583866596222, Accuracy: 0.9287109375\n",
      "Batch: 34, Loss: 0.19641998410224915, Accuracy: 0.9326171875\n",
      "Batch: 35, Loss: 0.18935555219650269, Accuracy: 0.9365234375\n",
      "Batch: 36, Loss: 0.23386012017726898, Accuracy: 0.9248046875\n",
      "Batch: 37, Loss: 0.18845027685165405, Accuracy: 0.9296875\n",
      "Batch: 38, Loss: 0.2161046862602234, Accuracy: 0.92578125\n",
      "Batch: 39, Loss: 0.20110413432121277, Accuracy: 0.93359375\n",
      "Batch: 40, Loss: 0.19395659863948822, Accuracy: 0.9326171875\n",
      "Batch: 41, Loss: 0.20455363392829895, Accuracy: 0.92578125\n",
      "Batch: 42, Loss: 0.21103815734386444, Accuracy: 0.9140625\n",
      "Batch: 43, Loss: 0.20095913112163544, Accuracy: 0.9267578125\n",
      "Batch: 44, Loss: 0.188140407204628, Accuracy: 0.927734375\n",
      "Batch: 45, Loss: 0.17719057202339172, Accuracy: 0.939453125\n",
      "Batch: 46, Loss: 0.20087414979934692, Accuracy: 0.921875\n",
      "Batch: 47, Loss: 0.16016021370887756, Accuracy: 0.943359375\n",
      "Batch: 48, Loss: 0.20955660939216614, Accuracy: 0.9375\n",
      "Batch: 49, Loss: 0.22041422128677368, Accuracy: 0.9296875\n",
      "Batch: 50, Loss: 0.2066594660282135, Accuracy: 0.9287109375\n",
      "Batch: 51, Loss: 0.19169151782989502, Accuracy: 0.9267578125\n",
      "Batch: 52, Loss: 0.2101234495639801, Accuracy: 0.927734375\n",
      "Batch: 53, Loss: 0.23437228798866272, Accuracy: 0.9189453125\n",
      "Batch: 54, Loss: 0.19502362608909607, Accuracy: 0.9384765625\n",
      "Batch: 55, Loss: 0.21660761535167694, Accuracy: 0.9287109375\n",
      "Batch: 56, Loss: 0.21777595579624176, Accuracy: 0.9306640625\n",
      "Batch: 57, Loss: 0.23040840029716492, Accuracy: 0.9150390625\n",
      "Batch: 58, Loss: 0.2199135273694992, Accuracy: 0.92578125\n",
      "Batch: 59, Loss: 0.2136060893535614, Accuracy: 0.919921875\n",
      "Batch: 60, Loss: 0.2018442153930664, Accuracy: 0.93359375\n",
      "Batch: 61, Loss: 0.18632154166698456, Accuracy: 0.9375\n",
      "Batch: 62, Loss: 0.20283015072345734, Accuracy: 0.939453125\n",
      "Batch: 63, Loss: 0.19128701090812683, Accuracy: 0.9365234375\n",
      "Batch: 64, Loss: 0.19671347737312317, Accuracy: 0.921875\n",
      "Batch: 65, Loss: 0.17953628301620483, Accuracy: 0.94140625\n",
      "Batch: 66, Loss: 0.1591935008764267, Accuracy: 0.9482421875\n",
      "Batch: 67, Loss: 0.19944004714488983, Accuracy: 0.9326171875\n",
      "Batch: 68, Loss: 0.20970813930034637, Accuracy: 0.93359375\n",
      "Batch: 69, Loss: 0.1771439164876938, Accuracy: 0.9462890625\n",
      "Batch: 70, Loss: 0.21596312522888184, Accuracy: 0.931640625\n",
      "Batch: 71, Loss: 0.20578932762145996, Accuracy: 0.9365234375\n",
      "Batch: 72, Loss: 0.22013859450817108, Accuracy: 0.921875\n",
      "Batch: 73, Loss: 0.16187304258346558, Accuracy: 0.9521484375\n",
      "Batch: 74, Loss: 0.1952938437461853, Accuracy: 0.9375\n",
      "Batch: 75, Loss: 0.17472968995571136, Accuracy: 0.94140625\n",
      "Batch: 76, Loss: 0.1753823161125183, Accuracy: 0.9462890625\n",
      "Batch: 77, Loss: 0.18436157703399658, Accuracy: 0.9462890625\n",
      "Batch: 78, Loss: 0.21753962337970734, Accuracy: 0.9296875\n",
      "Batch: 79, Loss: 0.19625355303287506, Accuracy: 0.9384765625\n",
      "Batch: 80, Loss: 0.17115788161754608, Accuracy: 0.939453125\n",
      "Batch: 81, Loss: 0.21505066752433777, Accuracy: 0.9267578125\n",
      "Batch: 82, Loss: 0.21465925872325897, Accuracy: 0.9228515625\n",
      "Batch: 83, Loss: 0.19343042373657227, Accuracy: 0.935546875\n",
      "Batch: 84, Loss: 0.17056339979171753, Accuracy: 0.9423828125\n",
      "Batch: 85, Loss: 0.20209437608718872, Accuracy: 0.9443359375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 86, Loss: 0.21048617362976074, Accuracy: 0.92578125\n",
      "Batch: 87, Loss: 0.19240888953208923, Accuracy: 0.931640625\n",
      "Batch: 88, Loss: 0.1732483208179474, Accuracy: 0.93359375\n",
      "Batch: 89, Loss: 0.21475151181221008, Accuracy: 0.931640625\n",
      "Batch: 90, Loss: 0.25639665126800537, Accuracy: 0.9150390625\n",
      "Batch: 91, Loss: 0.23314499855041504, Accuracy: 0.9169921875\n",
      "Batch: 92, Loss: 0.2127162665128708, Accuracy: 0.9248046875\n",
      "Batch: 93, Loss: 0.23148460686206818, Accuracy: 0.91796875\n",
      "Batch: 94, Loss: 0.20599037408828735, Accuracy: 0.931640625\n",
      "Batch: 95, Loss: 0.22016136348247528, Accuracy: 0.9189453125\n",
      "Batch: 96, Loss: 0.21404044330120087, Accuracy: 0.9306640625\n",
      "Batch: 97, Loss: 0.1755153238773346, Accuracy: 0.943359375\n",
      "Batch: 98, Loss: 0.191127210855484, Accuracy: 0.9287109375\n",
      "Batch: 99, Loss: 0.17581862211227417, Accuracy: 0.931640625\n",
      "Batch: 100, Loss: 0.17239823937416077, Accuracy: 0.9404296875\n",
      "Batch: 101, Loss: 0.18505150079727173, Accuracy: 0.931640625\n",
      "Batch: 102, Loss: 0.16786208748817444, Accuracy: 0.947265625\n",
      "Batch: 103, Loss: 0.2008233517408371, Accuracy: 0.9375\n",
      "Batch: 104, Loss: 0.22613778710365295, Accuracy: 0.9140625\n",
      "Batch: 105, Loss: 0.15115110576152802, Accuracy: 0.94921875\n",
      "Batch: 106, Loss: 0.20734037458896637, Accuracy: 0.927734375\n",
      "Batch: 107, Loss: 0.1898880898952484, Accuracy: 0.943359375\n",
      "Batch: 108, Loss: 0.16053909063339233, Accuracy: 0.955078125\n",
      "Batch: 109, Loss: 0.16637089848518372, Accuracy: 0.9423828125\n",
      "Batch: 110, Loss: 0.17791855335235596, Accuracy: 0.939453125\n",
      "Batch: 111, Loss: 0.21926183998584747, Accuracy: 0.9248046875\n",
      "Batch: 112, Loss: 0.22401130199432373, Accuracy: 0.9189453125\n",
      "Epoch 90/90\n",
      "Batch: 1, Loss: 0.25358492136001587, Accuracy: 0.923828125\n",
      "Batch: 2, Loss: 0.20452558994293213, Accuracy: 0.93359375\n",
      "Batch: 3, Loss: 0.20527859032154083, Accuracy: 0.931640625\n",
      "Batch: 4, Loss: 0.20015840232372284, Accuracy: 0.9296875\n",
      "Batch: 5, Loss: 0.14818179607391357, Accuracy: 0.94921875\n",
      "Batch: 6, Loss: 0.17948541045188904, Accuracy: 0.9404296875\n",
      "Batch: 7, Loss: 0.1885955035686493, Accuracy: 0.9423828125\n",
      "Batch: 8, Loss: 0.17420035600662231, Accuracy: 0.9384765625\n",
      "Batch: 9, Loss: 0.19250038266181946, Accuracy: 0.9306640625\n",
      "Batch: 10, Loss: 0.20762449502944946, Accuracy: 0.9150390625\n",
      "Batch: 11, Loss: 0.22300168871879578, Accuracy: 0.9248046875\n",
      "Batch: 12, Loss: 0.18741963803768158, Accuracy: 0.9326171875\n",
      "Batch: 13, Loss: 0.17101505398750305, Accuracy: 0.94140625\n",
      "Batch: 14, Loss: 0.20644667744636536, Accuracy: 0.9375\n",
      "Batch: 15, Loss: 0.1783626675605774, Accuracy: 0.9384765625\n",
      "Batch: 16, Loss: 0.23087553679943085, Accuracy: 0.92578125\n",
      "Batch: 17, Loss: 0.21218478679656982, Accuracy: 0.9267578125\n",
      "Batch: 18, Loss: 0.19763529300689697, Accuracy: 0.9423828125\n",
      "Batch: 19, Loss: 0.2002587914466858, Accuracy: 0.931640625\n",
      "Batch: 20, Loss: 0.2184012234210968, Accuracy: 0.9267578125\n",
      "Batch: 21, Loss: 0.2051563858985901, Accuracy: 0.935546875\n",
      "Batch: 22, Loss: 0.18029943108558655, Accuracy: 0.9404296875\n",
      "Batch: 23, Loss: 0.20454011857509613, Accuracy: 0.9296875\n",
      "Batch: 24, Loss: 0.24234217405319214, Accuracy: 0.9267578125\n",
      "Batch: 25, Loss: 0.23375076055526733, Accuracy: 0.91796875\n",
      "Batch: 26, Loss: 0.24455717206001282, Accuracy: 0.919921875\n",
      "Batch: 27, Loss: 0.22189931571483612, Accuracy: 0.923828125\n",
      "Batch: 28, Loss: 0.22191214561462402, Accuracy: 0.9228515625\n",
      "Batch: 29, Loss: 0.2349381148815155, Accuracy: 0.9306640625\n",
      "Batch: 30, Loss: 0.19224286079406738, Accuracy: 0.9326171875\n",
      "Batch: 31, Loss: 0.21437135338783264, Accuracy: 0.935546875\n",
      "Batch: 32, Loss: 0.20472405850887299, Accuracy: 0.92578125\n",
      "Batch: 33, Loss: 0.18489328026771545, Accuracy: 0.94140625\n",
      "Batch: 34, Loss: 0.1956135332584381, Accuracy: 0.9326171875\n",
      "Batch: 35, Loss: 0.18048399686813354, Accuracy: 0.947265625\n",
      "Batch: 36, Loss: 0.2046458125114441, Accuracy: 0.9296875\n",
      "Batch: 37, Loss: 0.17712706327438354, Accuracy: 0.93359375\n",
      "Batch: 38, Loss: 0.21766072511672974, Accuracy: 0.931640625\n",
      "Batch: 39, Loss: 0.22236326336860657, Accuracy: 0.9248046875\n",
      "Batch: 40, Loss: 0.1814643293619156, Accuracy: 0.9443359375\n",
      "Batch: 41, Loss: 0.23642081022262573, Accuracy: 0.9189453125\n",
      "Batch: 42, Loss: 0.21936103701591492, Accuracy: 0.931640625\n",
      "Batch: 43, Loss: 0.19203969836235046, Accuracy: 0.94140625\n",
      "Batch: 44, Loss: 0.18499378859996796, Accuracy: 0.9423828125\n",
      "Batch: 45, Loss: 0.22578899562358856, Accuracy: 0.91796875\n",
      "Batch: 46, Loss: 0.1949796974658966, Accuracy: 0.9375\n",
      "Batch: 47, Loss: 0.17864304780960083, Accuracy: 0.9404296875\n",
      "Batch: 48, Loss: 0.19007942080497742, Accuracy: 0.93359375\n",
      "Batch: 49, Loss: 0.232916459441185, Accuracy: 0.9189453125\n",
      "Batch: 50, Loss: 0.1739431917667389, Accuracy: 0.9375\n",
      "Batch: 51, Loss: 0.19210030138492584, Accuracy: 0.9365234375\n",
      "Batch: 52, Loss: 0.18874520063400269, Accuracy: 0.9375\n",
      "Batch: 53, Loss: 0.22710201144218445, Accuracy: 0.9189453125\n",
      "Batch: 54, Loss: 0.2076530009508133, Accuracy: 0.935546875\n",
      "Batch: 55, Loss: 0.2033691704273224, Accuracy: 0.9345703125\n",
      "Batch: 56, Loss: 0.1953166276216507, Accuracy: 0.935546875\n",
      "Batch: 57, Loss: 0.2199692577123642, Accuracy: 0.9228515625\n",
      "Batch: 58, Loss: 0.2086038738489151, Accuracy: 0.9375\n",
      "Batch: 59, Loss: 0.24342063069343567, Accuracy: 0.9169921875\n",
      "Batch: 60, Loss: 0.2033625990152359, Accuracy: 0.931640625\n",
      "Batch: 61, Loss: 0.2240292876958847, Accuracy: 0.92578125\n",
      "Batch: 62, Loss: 0.21275240182876587, Accuracy: 0.9287109375\n",
      "Batch: 63, Loss: 0.1484626829624176, Accuracy: 0.9501953125\n",
      "Batch: 64, Loss: 0.19390666484832764, Accuracy: 0.9384765625\n",
      "Batch: 65, Loss: 0.1903206706047058, Accuracy: 0.9345703125\n",
      "Batch: 66, Loss: 0.16241468489170074, Accuracy: 0.9521484375\n",
      "Batch: 67, Loss: 0.18973031640052795, Accuracy: 0.9326171875\n",
      "Batch: 68, Loss: 0.20599132776260376, Accuracy: 0.9345703125\n",
      "Batch: 69, Loss: 0.15985116362571716, Accuracy: 0.9423828125\n",
      "Batch: 70, Loss: 0.20344151556491852, Accuracy: 0.9287109375\n",
      "Batch: 71, Loss: 0.2100851982831955, Accuracy: 0.935546875\n",
      "Batch: 72, Loss: 0.24702224135398865, Accuracy: 0.91796875\n",
      "Batch: 73, Loss: 0.20253556966781616, Accuracy: 0.9306640625\n",
      "Batch: 74, Loss: 0.19164685904979706, Accuracy: 0.935546875\n",
      "Batch: 75, Loss: 0.16478851437568665, Accuracy: 0.947265625\n",
      "Batch: 76, Loss: 0.18303103744983673, Accuracy: 0.9423828125\n",
      "Batch: 77, Loss: 0.20040512084960938, Accuracy: 0.93359375\n",
      "Batch: 78, Loss: 0.2006424516439438, Accuracy: 0.9345703125\n",
      "Batch: 79, Loss: 0.20043033361434937, Accuracy: 0.9521484375\n",
      "Batch: 80, Loss: 0.18882982432842255, Accuracy: 0.94140625\n",
      "Batch: 81, Loss: 0.2091962993144989, Accuracy: 0.931640625\n",
      "Batch: 82, Loss: 0.20045652985572815, Accuracy: 0.927734375\n",
      "Batch: 83, Loss: 0.150121808052063, Accuracy: 0.9501953125\n",
      "Batch: 84, Loss: 0.18381065130233765, Accuracy: 0.9482421875\n",
      "Batch: 85, Loss: 0.18756046891212463, Accuracy: 0.9423828125\n",
      "Batch: 86, Loss: 0.21676456928253174, Accuracy: 0.9296875\n",
      "Batch: 87, Loss: 0.2065976858139038, Accuracy: 0.931640625\n",
      "Batch: 88, Loss: 0.22406555712223053, Accuracy: 0.919921875\n",
      "Batch: 89, Loss: 0.20806710422039032, Accuracy: 0.921875\n",
      "Batch: 90, Loss: 0.2327919453382492, Accuracy: 0.9208984375\n",
      "Batch: 91, Loss: 0.290144145488739, Accuracy: 0.9033203125\n",
      "Batch: 92, Loss: 0.219644695520401, Accuracy: 0.9248046875\n",
      "Batch: 93, Loss: 0.20392873883247375, Accuracy: 0.9375\n",
      "Batch: 94, Loss: 0.240973562002182, Accuracy: 0.908203125\n",
      "Batch: 95, Loss: 0.22496241331100464, Accuracy: 0.916015625\n",
      "Batch: 96, Loss: 0.2200230062007904, Accuracy: 0.9267578125\n",
      "Batch: 97, Loss: 0.2080395221710205, Accuracy: 0.919921875\n",
      "Batch: 98, Loss: 0.21455100178718567, Accuracy: 0.923828125\n",
      "Batch: 99, Loss: 0.19547559320926666, Accuracy: 0.93359375\n",
      "Batch: 100, Loss: 0.17093852162361145, Accuracy: 0.9453125\n",
      "Batch: 101, Loss: 0.21433673799037933, Accuracy: 0.923828125\n",
      "Batch: 102, Loss: 0.19515696167945862, Accuracy: 0.9384765625\n",
      "Batch: 103, Loss: 0.23487284779548645, Accuracy: 0.9150390625\n",
      "Batch: 104, Loss: 0.19069835543632507, Accuracy: 0.9267578125\n",
      "Batch: 105, Loss: 0.16194163262844086, Accuracy: 0.9384765625\n",
      "Batch: 106, Loss: 0.1874108910560608, Accuracy: 0.9453125\n",
      "Batch: 107, Loss: 0.16761958599090576, Accuracy: 0.939453125\n",
      "Batch: 108, Loss: 0.2129395604133606, Accuracy: 0.927734375\n",
      "Batch: 109, Loss: 0.16606900095939636, Accuracy: 0.9443359375\n",
      "Batch: 110, Loss: 0.17063748836517334, Accuracy: 0.9423828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 111, Loss: 0.21455270051956177, Accuracy: 0.9208984375\n",
      "Batch: 112, Loss: 0.20647786557674408, Accuracy: 0.93359375\n",
      "Saved Weights at epoch 90 to file Weights_90.h5\n"
     ]
    }
   ],
   "source": [
    "training_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(unique_chars):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(input_dim = unique_chars, output_dim = 512, batch_input_shape = (1, 1))) \n",
    "  \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(256, return_sequences = True, stateful = True))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(LSTM(256, stateful = True)) \n",
    "    #remember, that here we haven't given return_sequences = True because here we will give only one character to generate the\n",
    "    #sequence. In the end, we just have to get one output which is equivalent to getting output at the last time-stamp. So, here\n",
    "    #in last layer there is no need of giving return sequences = True.\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add((Dense(unique_chars)))\n",
    "    model.add(Activation(\"softmax\"))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(epoch_num, initial_index, seq_length):\n",
    "    with open(os.path.join(data_directory, charIndex_json)) as f:\n",
    "        char_to_index = json.load(f)\n",
    "    index_to_char = {i:ch for ch, i in char_to_index.items()}\n",
    "    unique_chars = len(index_to_char)\n",
    "    \n",
    "    model = make_model(unique_chars)\n",
    "    model.load_weights(model_weights_directory + \"Weights_{}.h5\".format(epoch_num))\n",
    "     \n",
    "    sequence_index = [initial_index]\n",
    "    \n",
    "    for _ in range(seq_length):\n",
    "        batch = np.zeros((1, 1))\n",
    "        batch[0, 0] = sequence_index[-1]\n",
    "        \n",
    "        predicted_probs = model.predict_on_batch(batch).ravel()\n",
    "        sample = np.random.choice(range(unique_chars), size = 1, p = predicted_probs)\n",
    "        \n",
    "        sequence_index.append(sample[0])\n",
    "    \n",
    "    seq = ''.join(index_to_char[c] for c in sequence_index)\n",
    "    \n",
    "    cnt = 0\n",
    "    for i in seq:\n",
    "        cnt += 1\n",
    "        if i == \"\\n\":\n",
    "            break\n",
    "    seq1 = seq[cnt:]\n",
    "    #above code is for ignoring the starting string of a generated sequence. This is because we are passing any arbitrary \n",
    "    #character to the model for generating music. Now, the model start generating sequence from that character itself which we \n",
    "    #have passed, so first few characters before \"\\n\" contains meaningless word. Model start generating the music rhythm from\n",
    "    #next line onwards. The correct sequence it start generating from next line onwards which we are considering.\n",
    "    \n",
    "    cnt = 0\n",
    "    for i in seq1:\n",
    "        cnt += 1\n",
    "        if i == \"\\n\" and seq1[cnt] == \"\\n\":\n",
    "            break\n",
    "    seq2 = seq1[:cnt]\n",
    "    #Now our data contains three newline characters after every tune. So, the model has leart that too. So, above code is used for\n",
    "    #ignoring all the characters that model has generated after three new line characters. So, here we are considering only one\n",
    "    #tune of music at a time and finally we are returning it..\n",
    "    \n",
    "    return seq2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Which epoch number weight you want to load into the model(10, 20, 30, ..., 90). Small number will generate more errors in music: 80\n",
      "\n",
      "2. Enter any number between 0 to 86 which will be given as initial charcter to model for generating sequence: 78\n",
      "\n",
      "3. Enter the length of music sequence you want to generate. Typical number is between 300-600. Too small number will generate hardly generate any sequence: 700\n",
      "\n",
      "MUSIC SEQUENCE GENERATED: \n",
      "\n",
      " X:1\n",
      "T:Cuetrine Gersc\n",
      "Z: by Tiamo/Skjald\n",
      "L: 1/4\n",
      "Q: 1/4=100\n",
      "K: c\n",
      "[^a7/8^f7/8^G,7/8] c/8 [c/8z/8] [f/4z/8] [f/8z/8] [^d/4z/8] [^d7/8z3/8] [^D15/8z/2] [^G15/8z3/8] [f15/8^G15/8z/2] [^c7/8z3/8] [f11/8^G15/8z/2] [^c7/8z3/8] [F15/8z/2] [^A7/8z/2] [f7/8^G7/8z3/8] [^A7/8z/2] [=F7/4z3/8] [ez/2] [^c7/4=F7/4z/2] [^A7/8z3/8] [=F,7/4z/2] [^G11/8z3/8] [^c/2F15/8]\n",
      "=c3/8 z/8 [^A11/8^F,15/8z/2] c/2 [^f7/4^D7/4z3/8] ^d/2 [=c3/4^G,7/4z3/8] [^d7/8z/2] [^C15/8z/2] [f7/8z/2] [^g7/4^c7/8z3/8] [fz/2] [^A,zz/2] [=c7/8z/2] [^f7/4^G7/4z3/8] [cz/2] [^D7/4z3/8] [c7/8z/2]\n",
      "[=f11/8^G,7/4z3/8]\n",
      "[^c15/8z/2] [^G,7/4z3/8] ^d/2\n",
      "[^g7/4^G,7/8z3/8] [=c7/8z/2] [^C15/8z/2] [^c7/8z3/8] [f11/8^G7/4z/2]\n",
      "[^c7/4z3/8] [^G,7/4z/2] [^d/2z3/\n"
     ]
    }
   ],
   "source": [
    "ep = int(input(\"1. Which epoch number weight you want to load into the model(10, 20, 30, ..., 90). Small number will generate more errors in music: \"))\n",
    "ar = int(input(\"\\n2. Enter any number between 0 to 86 which will be given as initial charcter to model for generating sequence: \"))\n",
    "ln = int(input(\"\\n3. Enter the length of music sequence you want to generate. Typical number is between 300-600. Too small number will generate hardly generate any sequence: \"))\n",
    "\n",
    "music = generate_sequence(ep, ar, ln)\n",
    "\n",
    "print(\"\\nMUSIC SEQUENCE GENERATED: \\n\")\n",
    "\n",
    "print(music)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
